<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Pranath Fernando">
<meta name="dcterms.date" content="2023-08-19">
<meta name="description" content="In this article we show how to use labeled preference scoring to help compare two versions of a system and choose the preferred outputs">

<title>LivingDataLab - Comparing Question and Answer LLM System Outputs</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../images/favicon.ico" rel="icon">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

<script type="text/javascript">

(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
ga('create', 'UA-91568149-1', 'auto');

ga('send', {
  hitType: 'pageview',
  'anonymizeIp': true,
});
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>
<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>


<link rel="stylesheet" href="../css/styles.css">
<meta property="og:title" content="LivingDataLab - Comparing Question and Answer LLM System Outputs">
<meta property="og:description" content="In this article we show how to use labeled preference scoring to help compare two versions of a system and choose the preferred outputs">
<meta property="og:image" content="https://github.com/pranath/blog/raw/master/images/ai-eval4.png">
<meta property="og:site-name" content="LivingDataLab">
<meta name="twitter:title" content="LivingDataLab - Comparing Question and Answer LLM System Outputs">
<meta name="twitter:description" content="In this article we show how to use labeled preference scoring to help compare two versions of a system and choose the preferred outputs">
<meta name="twitter:image" content="https://github.com/pranath/blog/raw/master/images/ai-eval4.png">
<meta name="twitter:card" content="summary_large_image">
</head>

<body class="nav-sidebar docked nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a href="../index.html" class="navbar-brand navbar-brand-logo">
    <img src="../images/logo.png" alt="" class="navbar-logo">
    </a>
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">LivingDataLab</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../index.html" rel="" target="">
 <span class="menu-text">Blog</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link active" href="../projects.html" rel="" target="" aria-current="page">
 <span class="menu-text">Projects</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../about.html" rel="" target="">
 <span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/in/pranath-fernando/" rel="" target=""><i class="bi bi-linkedin" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/LivingDataLab" rel="" target=""><i class="bi bi-twitter" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/pranath" rel="" target=""><i class="bi bi-github" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="../index.xml" rel="" target=""><i class="bi bi-rss" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
            <div class="quarto-navbar-tools">
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item">Comparing Question and Answer LLM System Outputs</li></ol></nav>
      <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
    </div>
  </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Comparing Question and Answer LLM System Outputs</h1>
                  <div>
        <div class="description">
          In this article we show how to use labeled preference scoring to help compare two versions of a system and choose the preferred outputs
        </div>
      </div>
                          <div class="quarto-categories">
                <div class="quarto-category">natural-language-processing</div>
                <div class="quarto-category">deep-learning</div>
                <div class="quarto-category">langchain</div>
                <div class="quarto-category">openai</div>
                <div class="quarto-category">llm-evaluation</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Pranath Fernando </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">August 19, 2023</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation docked overflow-auto">
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../projects.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Projects Overview</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
 <span class="menu-text">Projects</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../projects/doc-chat.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Document Chat</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../projects/doc-summarisation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Document Summarisation</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../projects/web-page-chat.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Web Page Chat</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../projects/web-page-summarisation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Web Page Summarisation</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../projects/youtube-chat.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">YouTube Chat</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../projects/youtube-summarisation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">YouTube Summarisation</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar"><div class="quarto-margin-header"><div class="margin-header-item">
<!-- Begin Mailchimp Signup Form -->
<link href="//cdn-images.mailchimp.com/embedcode/classic-071822.css" rel="stylesheet" type="text/css">
<style type="text/css">
    #mc_embed_signup{background:#fff; clear:left; font:14px Helvetica,Arial,sans-serif; }
    /* Add your own Mailchimp form style overrides in your site stylesheet or in this style block.
       We recommend moving this block and the preceding CSS link to the HEAD of your HTML file. */
</style>
<div id="mc_embed_signup">
    <form action="https://livingdatalab.us8.list-manage.com/subscribe/post?u=e2d57b0d6e43b4f6bff927a55&amp;id=a30bdff125&amp;f_id=009d05e0f0" method="post" id="mc-embedded-subscribe-form" name="mc-embedded-subscribe-form" class="validate" target="_blank" novalidate="">
        <div id="mc_embed_signup_scroll">
        <h2>Subscribe</h2>
<div class="mc-field-group">
    <label for="mce-EMAIL">Email Address
</label>
    <input type="email" value="" name="EMAIL" class="required email" id="mce-EMAIL" required="">
    <span id="mce-EMAIL-HELPERTEXT" class="helper_text"></span>
</div>
    <div id="mce-responses" class="clear foot">
        <div class="response" id="mce-error-response" style="display:none"></div>
        <div class="response" id="mce-success-response" style="display:none"></div>
    </div>    <!-- real people should not fill this in and expect good things - do not remove this or risk form bot signups-->
    <div style="position: absolute; left: -5000px;" aria-hidden="true"><input type="text" name="b_e2d57b0d6e43b4f6bff927a55_a30bdff125" tabindex="-1" value=""></div>
        <div class="optionalParent">
            <div class="clear foot">
                <input type="submit" value="Subscribe" name="subscribe" id="mc-embedded-subscribe" class="button">
            </div>
        </div>
    </div>
</form>
</div>
<script type="text/javascript" src="//s3.amazonaws.com/downloads.mailchimp.com/js/mc-validate.js"></script><script type="text/javascript">(function($) {window.fnames = new Array(); window.ftypes = new Array();fnames[0]='EMAIL';ftypes[0]='email';fnames[1]='FNAME';ftypes[1]='text';fnames[2]='LNAME';ftypes[2]='text';fnames[3]='ADDRESS';ftypes[3]='address';fnames[4]='PHONE';ftypes[4]='phone';fnames[5]='BIRTHDAY';ftypes[5]='birthday';}(jQuery));var $mcj = jQuery.noConflict(true);</script>
<!--End mc_embed_signup-->

</div></div>
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#prerequisites" id="toc-prerequisites" class="nav-link active" data-scroll-target="#prerequisites"><span class="header-section-number">1</span> Prerequisites</a></li>
  <li><a href="#setup" id="toc-setup" class="nav-link" data-scroll-target="#setup"><span class="header-section-number">2</span> Setup</a>
  <ul class="collapse">
  <li><a href="#create-a-dataset" id="toc-create-a-dataset" class="nav-link" data-scroll-target="#create-a-dataset"><span class="header-section-number">2.1</span> Create a dataset</a></li>
  <li><a href="#define-rag-qa-system" id="toc-define-rag-qa-system" class="nav-link" data-scroll-target="#define-rag-qa-system"><span class="header-section-number">2.2</span> Define RAG Q&amp;A system</a></li>
  <li><a href="#evaluate-the-chains" id="toc-evaluate-the-chains" class="nav-link" data-scroll-target="#evaluate-the-chains"><span class="header-section-number">2.3</span> Evaluate the chains</a></li>
  </ul></li>
  <li><a href="#pairwise-evaluation" id="toc-pairwise-evaluation" class="nav-link" data-scroll-target="#pairwise-evaluation"><span class="header-section-number">3</span> Pairwise Evaluation</a></li>
  <li><a href="#conclusion" id="toc-conclusion" class="nav-link" data-scroll-target="#conclusion"><span class="header-section-number">4</span> Conclusion</a></li>
  <li><a href="#acknowledgements" id="toc-acknowledgements" class="nav-link" data-scroll-target="#acknowledgements"><span class="header-section-number">5</span> Acknowledgements</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">




<p>The most frequent method for comparing two models is to run them both on the same dataset and compare the aggregate metrics. This method is valuable, but it may miss out on important information regarding the quality of the two system alternatives. In this instance, it may be useful to run direct pairwise comparisons on the responses and examine the resulting preference scores.</p>
<p>In this post, we’ll show you how to do it in code. As a motivating example, we will employ a retrieval Q&amp;A system over LangSmith’s docs.</p>
<p>The main steps are:</p>
<ol type="1">
<li>Setup
<ul>
<li>Create a dataset of questions and answers.</li>
<li>Define different versions of your chains to evaluate.</li>
<li>Evaluate chains directly on a dataset using regular metrics (e.g.&nbsp;correctness).</li>
</ul></li>
<li>Evaluate the pairwise preferences over that dataset</li>
</ol>
<p>In this case, we will test the impact of chunk sizes on our result quality.</p>
<section id="prerequisites" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="prerequisites"><span class="header-section-number">1</span> Prerequisites</h2>
<p>This tutorial uses OpenAI for the model, ChromaDB to store documents, and LangChain to compose the chain. To make sure the tracing and evals are set up for <a href="https://smith.langchain.com">LangSmith</a>, please configure your API Key appropriately.</p>
<p>We will also use pandas to render the results in the notebook.</p>
<div class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># %env LANGCHAIN_API_KEY=&lt;YOUR_API_KEY&gt;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Install the required packages. <code>lxml</code> and <code>html2text</code> are used by the document loader.</p>
<div class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co"># %pip install -U "langchain[openai]" --quiet</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="co"># %pip install chromadb --quiet</span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="co"># %pip install lxml --quiet</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="co"># %pip install html2text --quiet</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="co"># %pip install pandas --quiet</span></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a><span class="co"># %pip install nest_asyncio --quiet</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># %env OPENAI_API_KEY=&lt;YOUR-API-KEY&gt;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Used for running in jupyter</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> nest_asyncio</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>nest_asyncio.<span class="bu">apply</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="setup" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="setup"><span class="header-section-number">2</span> Setup</h2>
<section id="create-a-dataset" class="level3" data-number="2.1">
<h3 data-number="2.1" class="anchored" data-anchor-id="create-a-dataset"><span class="header-section-number">2.1</span> Create a dataset</h3>
<p>A development dataset is required for any evaluation procedure. To demonstrate the procedure, we’ve hard-coded a few samples below. In general, statistically significant results require a large number of pairs (&gt;100). Drawing on actual user inquiries can help to provide a more accurate portrayal of the domain.</p>
<div class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>examples <span class="op">=</span> [</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>    (<span class="st">"What is LangChain?"</span>, <span class="st">"LangChain is an open-source framework for building applications using large language models. It is also the name of the company building LangSmith."</span>),</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>    (<span class="st">"How might I query for all runs in a project?"</span>, <span class="st">"client.list_runs(project_name='my-project-name'), or in TypeScript, client.ListRuns({projectName: 'my-project-anme'})"</span>),</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>    (<span class="st">"What's a langsmith dataset?"</span>, <span class="st">"A LangSmith dataset is a collection of examples. Each example contains inputs and optional expected outputs or references for that data point."</span>),</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>    (<span class="st">"How do I use a traceable decorator?"</span>, <span class="st">"""The traceable decorator is available in the langsmith python SDK. To use, configure your environment with your API key,</span><span class="ch">\</span></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a><span class="st">import the required function, decorate your function, and then call the function. Below is an example:</span></span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a><span class="st">```python</span></span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a><span class="st">from langsmith.run_helpers import traceable</span></span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a><span class="st">@traceable(run_type="chain") # or "llm", etc.</span></span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a><span class="st">def my_function(input_param):</span></span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a><span class="st">    # Function logic goes here</span></span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a><span class="st">    return output</span></span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a><span class="st">result = my_function(input_param)</span></span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a><span class="st">```"""</span>),</span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a>    (<span class="st">"Can I trace my Llama V2 llm?"</span>, <span class="st">"So long as you are using one of LangChain's LLM implementations, all your calls can be traced"</span>),</span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a>    (<span class="st">"Why do I have to set environment variables?"</span>, <span class="st">"Environment variables can tell your LangChain application to perform tracing and contain the information necessary to authenticate to LangSmith."</span></span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a>     <span class="st">" While there are other ways to connect, environment variables tend to be the simplest way to configure your application."</span>),</span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a>    (<span class="st">"How do I move my project between organizations?"</span>, <span class="st">"LangSmith doesn't directly support moving projects between organizations."</span>)</span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> langsmith <span class="im">import</span> Client</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>client <span class="op">=</span> Client()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>dataset_name <span class="op">=</span> <span class="st">"Retrieval QA Questions"</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>dataset <span class="op">=</span> client.create_dataset(dataset_name<span class="op">=</span>dataset_name)</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> q, a <span class="kw">in</span> examples:</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>    client.create_example(inputs<span class="op">=</span>{<span class="st">"question"</span>: q}, outputs<span class="op">=</span>{<span class="st">"answer"</span>: a}, dataset_id<span class="op">=</span>dataset.<span class="bu">id</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="define-rag-qa-system" class="level3" data-number="2.2">
<h3 data-number="2.2" class="anchored" data-anchor-id="define-rag-qa-system"><span class="header-section-number">2.2</span> Define RAG Q&amp;A system</h3>
<p>Our Q&amp;A system employs a straightforward retriever and an LLM response generator. To further simplify, the chain will consist of:</p>
<ol type="1">
<li>A <a href="https://api.python.langchain.com/en/latest/vectorstores/langchain.vectorstores.base.VectorStoreRetriever.html#langchain.vectorstores.base.VectorStoreRetriever">VectorStoreRetriever</a> to retrieve documents. This uses:
<ul>
<li>An embedding model to vectorize documents and user queries for retrieval. In this case, the <a href="https://api.python.langchain.com/en/latest/embeddings/langchain.embeddings.openai.OpenAIEmbeddings.html">OpenAIEmbeddings</a> model.</li>
<li>A vectorstore, in this case we will use <a href="https://api.python.langchain.com/en/latest/vectorstores/langchain.vectorstores.chroma.Chroma.html#langchain.vectorstores.chroma.Chroma">Chroma</a>.</li>
</ul></li>
<li>A response generator. This uses:
<ul>
<li>A <a href="https://api.python.langchain.com/en/latest/prompts/langchain.prompts.chat.ChatPromptTemplate.html#langchain.prompts.chat.ChatPromptTemplate">ChatPromptTemplate</a> to combine the query and documents.</li>
<li>An LLM, in this case, the 16k token context window version of <code>gpt-3.5-turbo</code> via <a href="https://api.python.langchain.com/en/latest/chat_models/langchain.chat_models.openai.ChatOpenAI.html#langchain.chat_models.openai.ChatOpenAI">ChatOpenAI</a>.</li>
</ul></li>
</ol>
<p>We will combine them using LangChain’s <a href="https://python.langchain.com/docs/guides/expression_language/cookbook">expression syntax</a>.</p>
<p>First, load the documents to populate the vectorstore:</p>
<div class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> langchain.document_loaders <span class="im">import</span> RecursiveUrlLoader</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> langchain.document_transformers <span class="im">import</span> Html2TextTransformer</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> langchain.text_splitter <span class="im">import</span> TokenTextSplitter</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> langchain.embeddings <span class="im">import</span> OpenAIEmbeddings</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> langchain.vectorstores <span class="im">import</span> Chroma</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>api_loader <span class="op">=</span> RecursiveUrlLoader(<span class="st">"https://docs.smith.langchain.com"</span>)</span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>doc_transformer <span class="op">=</span> Html2TextTransformer()</span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>raw_documents <span class="op">=</span> api_loader.load()</span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a>transformed <span class="op">=</span> doc_transformer.transform_documents(raw_documents)</span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> create_retriever(transformed_documents, text_splitter):</span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a>    documents <span class="op">=</span> text_splitter.split_documents(transformed_documents)</span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a>    embeddings <span class="op">=</span> OpenAIEmbeddings()</span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a>    vectorstore <span class="op">=</span> Chroma.from_documents(documents, embeddings)</span>
<span id="cb8-16"><a href="#cb8-16" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> vectorstore.as_retriever(search_kwargs<span class="op">=</span>{<span class="st">"k"</span>: <span class="dv">4</span>})</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/bs4/builder/__init__.py:545: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features="xml"` into the BeautifulSoup constructor.
  warnings.warn(</code></pre>
</div>
</div>
<p>Next up, we’ll define the chain. Since we are going to vary the retriever parameters, our constructor will take the retriever as an argument.</p>
<div class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> datetime <span class="im">import</span> datetime</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> operator <span class="im">import</span> itemgetter</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> langchain.prompts <span class="im">import</span> ChatPromptTemplate</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> langchain.chat_models <span class="im">import</span> ChatOpenAI</span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> langchain.schema.output_parser <span class="im">import</span> StrOutputParser</span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> create_chain(retriever):</span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a>    prompt <span class="op">=</span> ChatPromptTemplate.from_messages(</span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a>            [</span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a>                (<span class="st">"system"</span>, <span class="st">"You are a helpful documentation Q&amp;A assistant, trained to answer"</span></span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a>                <span class="st">" questions from LangSmith's documentation."</span></span>
<span id="cb10-14"><a href="#cb10-14" aria-hidden="true" tabindex="-1"></a>                <span class="st">" LangChain is a framework for building applications using large language models."</span></span>
<span id="cb10-15"><a href="#cb10-15" aria-hidden="true" tabindex="-1"></a>                <span class="st">"</span><span class="ch">\n</span><span class="st">The current time is </span><span class="sc">{time}</span><span class="st">.</span><span class="ch">\n\n</span><span class="st">Relevant documents will be retrieved in the following messages."</span>),</span>
<span id="cb10-16"><a href="#cb10-16" aria-hidden="true" tabindex="-1"></a>                (<span class="st">"system"</span>, <span class="st">"</span><span class="sc">{context}</span><span class="st">"</span>),</span>
<span id="cb10-17"><a href="#cb10-17" aria-hidden="true" tabindex="-1"></a>                (<span class="st">"human"</span>,<span class="st">"</span><span class="sc">{question}</span><span class="st">"</span>)</span>
<span id="cb10-18"><a href="#cb10-18" aria-hidden="true" tabindex="-1"></a>            ]</span>
<span id="cb10-19"><a href="#cb10-19" aria-hidden="true" tabindex="-1"></a>        ).partial(time<span class="op">=</span><span class="bu">str</span>(datetime.now()))</span>
<span id="cb10-20"><a href="#cb10-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-21"><a href="#cb10-21" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> ChatOpenAI(model<span class="op">=</span><span class="st">"gpt-3.5-turbo-16k"</span>, temperature<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb10-22"><a href="#cb10-22" aria-hidden="true" tabindex="-1"></a>    response_generator <span class="op">=</span> (</span>
<span id="cb10-23"><a href="#cb10-23" aria-hidden="true" tabindex="-1"></a>        prompt </span>
<span id="cb10-24"><a href="#cb10-24" aria-hidden="true" tabindex="-1"></a>        <span class="op">|</span> model </span>
<span id="cb10-25"><a href="#cb10-25" aria-hidden="true" tabindex="-1"></a>        <span class="op">|</span> StrOutputParser()</span>
<span id="cb10-26"><a href="#cb10-26" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb10-27"><a href="#cb10-27" aria-hidden="true" tabindex="-1"></a>    chain <span class="op">=</span> (</span>
<span id="cb10-28"><a href="#cb10-28" aria-hidden="true" tabindex="-1"></a>        <span class="co"># The runnable map here routes the original inputs to a context and a question dictionary to pass to the response generator</span></span>
<span id="cb10-29"><a href="#cb10-29" aria-hidden="true" tabindex="-1"></a>        {</span>
<span id="cb10-30"><a href="#cb10-30" aria-hidden="true" tabindex="-1"></a>            <span class="st">"context"</span>: itemgetter(<span class="st">"question"</span>) <span class="op">|</span> retriever <span class="op">|</span> (<span class="kw">lambda</span> docs: <span class="st">"</span><span class="ch">\n</span><span class="st">"</span>.join([doc.page_content <span class="cf">for</span> doc <span class="kw">in</span> docs])),</span>
<span id="cb10-31"><a href="#cb10-31" aria-hidden="true" tabindex="-1"></a>            <span class="st">"question"</span>: itemgetter(<span class="st">"question"</span>)</span>
<span id="cb10-32"><a href="#cb10-32" aria-hidden="true" tabindex="-1"></a>        }</span>
<span id="cb10-33"><a href="#cb10-33" aria-hidden="true" tabindex="-1"></a>        <span class="op">|</span> response_generator</span>
<span id="cb10-34"><a href="#cb10-34" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb10-35"><a href="#cb10-35" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> chain</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>With the documents prepared, and the chain constructor ready, it’s time to create and evaluate our chains. We will vary the split size and overlap to evaluate its impact on the response quality.</p>
<div class="cell" data-tags="[]" data-execution_count="10">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>text_splitter <span class="op">=</span> TokenTextSplitter(</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>    model_name<span class="op">=</span><span class="st">"gpt-3.5-turbo"</span>,</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>    chunk_size<span class="op">=</span><span class="dv">2000</span>,</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>    chunk_overlap<span class="op">=</span><span class="dv">200</span>,</span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>retriever <span class="op">=</span> create_retriever(transformed, text_splitter)</span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a>chain_1 <span class="op">=</span> create_chain(retriever)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-tags="[]" data-execution_count="11">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="co"># We will shrink both the chunk size and overlap</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>text_splitter_2 <span class="op">=</span> TokenTextSplitter(</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>    model_name<span class="op">=</span><span class="st">"gpt-3.5-turbo"</span>,</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>    chunk_size<span class="op">=</span><span class="dv">500</span>,</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>    chunk_overlap<span class="op">=</span><span class="dv">50</span>,</span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>retriever_2 <span class="op">=</span> create_retriever(transformed, text_splitter_2)</span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a>chain_2 <span class="op">=</span> create_chain(retriever_2)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="evaluate-the-chains" class="level3" data-number="2.3">
<h3 data-number="2.3" class="anchored" data-anchor-id="evaluate-the-chains"><span class="header-section-number">2.3</span> Evaluate the chains</h3>
<p>At the moment, we’re still going through the standard development -&gt; evaluation cycle. We have two candidates and will evaluate them using a LangChain correctness evaluator. We will produce projected responses to each question in the dataset and log feedback from the evaluator for that data point by running ‘run_on_dataset’.</p>
<div class="cell" data-tags="[]" data-execution_count="12">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> langchain.smith <span class="im">import</span> RunEvalConfig</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>eval_config <span class="op">=</span> RunEvalConfig(</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>    <span class="co"># We will use the chain-of-thought Q&amp;A correctness evaluator</span></span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>    evaluators<span class="op">=</span>[<span class="st">"cot_qa"</span>],</span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-tags="[]" data-execution_count="13">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>results <span class="op">=</span> client.run_on_dataset(</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>    dataset_name<span class="op">=</span>dataset_name,</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>    llm_or_chain_factory<span class="op">=</span>chain_1,</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>    evaluation<span class="op">=</span>eval_config</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>project_name <span class="op">=</span> results[<span class="st">"project_name"</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>View the evaluation results for project '883bc88d0e994280aee27945d7c65496-RunnableSequence' at:
https://smith.langchain.com/projects/p/ab79529c-e05a-4fe3-b290-1b62523b4572?eval=true</code></pre>
</div>
</div>
<div class="cell" data-tags="[]" data-execution_count="14">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>results_2 <span class="op">=</span> client.run_on_dataset(</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>    dataset_name<span class="op">=</span>dataset_name,</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>    llm_or_chain_factory<span class="op">=</span>chain_2,</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>    evaluation<span class="op">=</span>eval_config</span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a>project_name_2 <span class="op">=</span> results_2[<span class="st">"project_name"</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>View the evaluation results for project '476151a4fdcd468b8f84b3312f61345a-RunnableSequence' at:
https://smith.langchain.com/projects/p/abddba69-614f-4d2c-8dd3-96dbd8942b67?eval=true</code></pre>
</div>
</div>
<p>Now you should have two test run projects over the same dataset. If you click on one, it should look something like the following:</p>
<p><img src="https://github.com/pranath/blog/raw/master/images/langsmith19.png" width="800"></p>
<p>You can look at the aggregate results here and for the other project to compare them, but let’s move on to the pairwise comparison.</p>
</section>
</section>
<section id="pairwise-evaluation" class="level2" data-number="3">
<h2 data-number="3" class="anchored" data-anchor-id="pairwise-evaluation"><span class="header-section-number">3</span> Pairwise Evaluation</h2>
<p>Assume that when both approaches are assessed separately, they yield similar results.</p>
<p>We can use a pairwise evaluator to see how well we can anticipate favoured outcomes. To begin, we will construct a couple of helper functions that will be used to run the evaluator on each prediction pair. Let’s dissect this function:</p>
<ul>
<li>The function accepts a dataset example and loads the predictions of each model on that data point.</li>
<li>It then invokes the evaluator and randomises the order of the predictions. This is done to account for any ordering bias in the evaluator LLM.</li>
<li>When the evaluation result is returned, we validate it and then log feedback for both models.</li>
</ul>
<p>Once this is complete, the values are all returned so we can display them in a table in the notebook below.</p>
<div class="cell" data-tags="[]" data-execution_count="19">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> random</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> logging</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> _get_run_and_prediction(example_id, project_name):</span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>    run <span class="op">=</span> <span class="bu">next</span>(client.list_runs(reference_example_id<span class="op">=</span>example_id, project_name<span class="op">=</span>project_name))</span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>    prediction <span class="op">=</span> <span class="bu">next</span>(<span class="bu">iter</span>(run.outputs.values()))</span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> run, prediction</span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> _log_feedback(run_ids):</span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> score, run_id <span class="kw">in</span> <span class="bu">enumerate</span>(run_ids):</span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a>        client.create_feedback(run_id, key<span class="op">=</span><span class="st">"preference"</span>, score<span class="op">=</span>score)</span>
<span id="cb18-12"><a href="#cb18-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-13"><a href="#cb18-13" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> predict_preference(example, project_a, project_b, eval_chain):</span>
<span id="cb18-14"><a href="#cb18-14" aria-hidden="true" tabindex="-1"></a>    example_id <span class="op">=</span> example.<span class="bu">id</span></span>
<span id="cb18-15"><a href="#cb18-15" aria-hidden="true" tabindex="-1"></a>    run_a, pred_a <span class="op">=</span> _get_run_and_prediction(example_id, project_a)</span>
<span id="cb18-16"><a href="#cb18-16" aria-hidden="true" tabindex="-1"></a>    run_b, pred_b <span class="op">=</span> _get_run_and_prediction(example_id, project_b)</span>
<span id="cb18-17"><a href="#cb18-17" aria-hidden="true" tabindex="-1"></a>    input_, answer <span class="op">=</span> example.inputs[<span class="st">'question'</span>], example.outputs[<span class="st">'answer'</span>]</span>
<span id="cb18-18"><a href="#cb18-18" aria-hidden="true" tabindex="-1"></a>    result <span class="op">=</span> {<span class="st">"input"</span>: input_, <span class="st">"answer"</span>: answer, <span class="st">"A"</span>: pred_a, <span class="st">"B"</span>: pred_b}</span>
<span id="cb18-19"><a href="#cb18-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-20"><a href="#cb18-20" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Flip a coin to average out persistent positional bias</span></span>
<span id="cb18-21"><a href="#cb18-21" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> random.random() <span class="op">&lt;</span> <span class="fl">0.5</span>:</span>
<span id="cb18-22"><a href="#cb18-22" aria-hidden="true" tabindex="-1"></a>        result[<span class="st">'A'</span>], result[<span class="st">'B'</span>] <span class="op">=</span> result[<span class="st">'B'</span>], result[<span class="st">'A'</span>]</span>
<span id="cb18-23"><a href="#cb18-23" aria-hidden="true" tabindex="-1"></a>        run_a, run_b <span class="op">=</span> run_b, run_a</span>
<span id="cb18-24"><a href="#cb18-24" aria-hidden="true" tabindex="-1"></a>    <span class="cf">try</span>:</span>
<span id="cb18-25"><a href="#cb18-25" aria-hidden="true" tabindex="-1"></a>        eval_res <span class="op">=</span> eval_chain.evaluate_string_pairs(</span>
<span id="cb18-26"><a href="#cb18-26" aria-hidden="true" tabindex="-1"></a>            prediction<span class="op">=</span>result[<span class="st">'A'</span>],</span>
<span id="cb18-27"><a href="#cb18-27" aria-hidden="true" tabindex="-1"></a>            prediction_b<span class="op">=</span>result[<span class="st">'B'</span>],</span>
<span id="cb18-28"><a href="#cb18-28" aria-hidden="true" tabindex="-1"></a>            <span class="bu">input</span><span class="op">=</span>input_, </span>
<span id="cb18-29"><a href="#cb18-29" aria-hidden="true" tabindex="-1"></a>            reference<span class="op">=</span>answer</span>
<span id="cb18-30"><a href="#cb18-30" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb18-31"><a href="#cb18-31" aria-hidden="true" tabindex="-1"></a>    <span class="cf">except</span> <span class="pp">Exception</span> <span class="im">as</span> e:</span>
<span id="cb18-32"><a href="#cb18-32" aria-hidden="true" tabindex="-1"></a>        logging.warning(e)</span>
<span id="cb18-33"><a href="#cb18-33" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> result</span>
<span id="cb18-34"><a href="#cb18-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-35"><a href="#cb18-35" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> eval_res[<span class="st">"value"</span>] <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb18-36"><a href="#cb18-36" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> result</span>
<span id="cb18-37"><a href="#cb18-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-38"><a href="#cb18-38" aria-hidden="true" tabindex="-1"></a>    preferred_run <span class="op">=</span> (run_a.<span class="bu">id</span>, <span class="st">"A"</span>) <span class="cf">if</span> eval_res[<span class="st">"value"</span>] <span class="op">==</span> <span class="st">"A"</span> <span class="cf">else</span> (run_b.<span class="bu">id</span>, <span class="st">"B"</span>)</span>
<span id="cb18-39"><a href="#cb18-39" aria-hidden="true" tabindex="-1"></a>    runner_up_run <span class="op">=</span> (run_b.<span class="bu">id</span>, <span class="st">"B"</span>) <span class="cf">if</span> eval_res[<span class="st">"value"</span>] <span class="op">==</span> <span class="st">"A"</span> <span class="cf">else</span> (run_a.<span class="bu">id</span>, <span class="st">"A"</span>)</span>
<span id="cb18-40"><a href="#cb18-40" aria-hidden="true" tabindex="-1"></a>    _log_feedback((runner_up_run[<span class="dv">0</span>], preferred_run[<span class="dv">0</span>]))</span>
<span id="cb18-41"><a href="#cb18-41" aria-hidden="true" tabindex="-1"></a>    result[<span class="st">"Preferred"</span>] <span class="op">=</span> preferred_run[<span class="dv">1</span>]</span>
<span id="cb18-42"><a href="#cb18-42" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> result</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>For this example, we will use the <code>labeled_pairwise_string</code> evaluator from LangChain off-the-shelf. By default, instructs the evaluation llm to choose the preference based on helpfulness, relevance, correctness, and depth of thought. In your case, you will likely want to customize the criteria used!</p>
<p>For more information on how to configure it, check out the <a href="https://python.langchain.com/docs/guides/evaluation/comparison/labeled_pairwise_string">Labeled Pairwise String Evaluator</a> documentation and inspect the resulting traces when running this notebook.</p>
<div class="cell" data-execution_count="20">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> langchain.evaluation <span class="im">import</span> load_evaluator</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>pairwise_evaluator <span class="op">=</span> load_evaluator(<span class="st">"labeled_pairwise_string"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-tags="[]" data-execution_count="21">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> functools</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> langchain.schema.runnable <span class="im">import</span> RunnableLambda</span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a>eval_func <span class="op">=</span> functools.partial(</span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a>    predict_preference,</span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a>    project_a<span class="op">=</span>project_name,</span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a>    project_b<span class="op">=</span>project_name_2,</span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a>    eval_chain<span class="op">=</span>pairwise_evaluator,</span>
<span id="cb20-10"><a href="#cb20-10" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb20-11"><a href="#cb20-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-12"><a href="#cb20-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-13"><a href="#cb20-13" aria-hidden="true" tabindex="-1"></a><span class="co"># We will wrap in a lambda to take advantage of its default `batch` convenience method</span></span>
<span id="cb20-14"><a href="#cb20-14" aria-hidden="true" tabindex="-1"></a>runnable <span class="op">=</span> RunnableLambda(eval_func)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-tags="[]" data-execution_count="22">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a>examples <span class="op">=</span> <span class="bu">list</span>(client.list_examples(dataset_name<span class="op">=</span><span class="st">"Retrieval QA Questions"</span>))</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>values <span class="op">=</span> runnable.batch(examples)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>WARNING:root:Invalid verdict: Final decision: [[A. Verdict must be one of 'A', 'B', or 'C'.</code></pre>
</div>
</div>
<p>The “preference” feedback was automatically logged to the test projects you created in step 3 by calling the method above. The image below shows the same test run as before, but with the preference scores added. This model appears to be less popular than the other!</p>
<p><img src="https://github.com/pranath/blog/raw/master/images/langsmith20.png" width="800"></p>
<p>Because the ‘predict_preference’ function we built above is configured to not log input in the event of a tie, some of the cases do not have a corresponding preference score. You are free to modify this behaviour as you see fit.</p>
<p>In the app, you may also check the feedback findings for the other test run to determine how well the evaluator’s results match your expectations.</p>
<div class="cell" data-tags="[]" data-execution_count="23">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.DataFrame(values)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-tags="[]" data-execution_count="24">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> IPython.core.display <span class="im">import</span> HTML</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> word_wrap_on_hover(df):</span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a><span class="co">    Takes a Pandas DataFrame and returns an HTML table with word wrap on hover.</span></span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a>    styles <span class="op">=</span> <span class="st">"""</span></span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a><span class="st">    &lt;style&gt;</span></span>
<span id="cb24-9"><a href="#cb24-9" aria-hidden="true" tabindex="-1"></a><span class="st">        .hover_table td {</span></span>
<span id="cb24-10"><a href="#cb24-10" aria-hidden="true" tabindex="-1"></a><span class="st">            max-width: 200px; /* You can adjust this value */</span></span>
<span id="cb24-11"><a href="#cb24-11" aria-hidden="true" tabindex="-1"></a><span class="st">            overflow: hidden;</span></span>
<span id="cb24-12"><a href="#cb24-12" aria-hidden="true" tabindex="-1"></a><span class="st">            text-overflow: ellipsis;</span></span>
<span id="cb24-13"><a href="#cb24-13" aria-hidden="true" tabindex="-1"></a><span class="st">            white-space: nowrap;</span></span>
<span id="cb24-14"><a href="#cb24-14" aria-hidden="true" tabindex="-1"></a><span class="st">        }</span></span>
<span id="cb24-15"><a href="#cb24-15" aria-hidden="true" tabindex="-1"></a><span class="st">        .hover_table td:hover {</span></span>
<span id="cb24-16"><a href="#cb24-16" aria-hidden="true" tabindex="-1"></a><span class="st">            white-space: normal;</span></span>
<span id="cb24-17"><a href="#cb24-17" aria-hidden="true" tabindex="-1"></a><span class="st">            word-wrap: break-word;</span></span>
<span id="cb24-18"><a href="#cb24-18" aria-hidden="true" tabindex="-1"></a><span class="st">        }</span></span>
<span id="cb24-19"><a href="#cb24-19" aria-hidden="true" tabindex="-1"></a><span class="st">    &lt;/style&gt;</span></span>
<span id="cb24-20"><a href="#cb24-20" aria-hidden="true" tabindex="-1"></a><span class="st">    """</span></span>
<span id="cb24-21"><a href="#cb24-21" aria-hidden="true" tabindex="-1"></a>    html_table <span class="op">=</span> df.to_html(classes<span class="op">=</span><span class="st">'hover_table'</span>)</span>
<span id="cb24-22"><a href="#cb24-22" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> HTML(styles <span class="op">+</span> html_table)</span>
<span id="cb24-23"><a href="#cb24-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-24"><a href="#cb24-24" aria-hidden="true" tabindex="-1"></a>word_wrap_on_hover(df)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="24">


    
    
<table class="dataframe hover_table table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">input</th>
<th data-quarto-table-cell-role="th">answer</th>
<th data-quarto-table-cell-role="th">A</th>
<th data-quarto-table-cell-role="th">B</th>
<th data-quarto-table-cell-role="th">Preferred</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>How do I move my project between organizations?</td>
<td>LangSmith doesn't directly support moving projects between organizations.</td>
<td>Currently, LangSmith does not support project migration between organizations. If you want to move your project to a different organization, the recommended approach is to create a new project within the desired organization and manually transfer the necessary data, such as runs and datasets, to the new project.\n\nYou can achieve this by using the LangSmith SDK or REST API to export the data from the original project and import it into the new project. Here are the general steps you can follow:\n\n1. Export the runs and datasets from the original project using the LangSmith API or SDK. You can filter the runs and datasets based on your requirements.\n\n2. Save the exported data to a local file or storage location.\n\n3. Create a new project in the desired organization using the LangSmith web app or API.\n\n4. Import the exported runs and datasets into the new project using the LangSmith API or SDK. Make sure to map the data correctly to the new project's structure.\n\nBy following these steps, you can effectively move your project from one organization to another.</td>
<td>Currently, LangSmith does not support project migration between organizations. However, you can manually export and import runs and datasets using the SDK to imitate project migration. Here's how you can do it:\n\n1. Export Runs: Use the LangSmith SDK to export the runs from your current organization. You can find examples of exporting runs in the LangSmith SDK documentation.\n\n2. Export Datasets: Similarly, use the LangSmith SDK to export the datasets associated with your project.\n\n3. Create a New Project: In the new organization, create a new project where you want to move your project to.\n\n4. Import Runs: Use the LangSmith SDK to import the exported runs into the new project. Again, you can find examples of importing runs in the LangSmith SDK documentation.\n\n5. Import Datasets: Finally, use the LangSmith SDK to import the exported datasets into the new project.\n\nBy following these steps, you can effectively move your project from one organization to another.</td>
<td>A</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>Why do I have to set environment variables?</td>
<td>Environment variables can tell your LangChain application to perform tracing and contain the information necessary to authenticate to LangSmith. While there are other ways to connect, environment variables tend to be the simplest way to configure your application.</td>
<td>Setting environment variables is a common practice in software development for configuring and customizing the behavior of applications. In the context of LangSmith and LangChain, environment variables are used to enable and configure tracing, which allows you to log and monitor the execution of your language models.\n\nBy setting the `LANGCHAIN_TRACING_V2` environment variable, you enable tracing for your LangChain applications. This allows you to log the input, output, and other relevant information about each run of your language model. Tracing can be useful for debugging, understanding model behavior, and monitoring the performance of your applications.\n\nSetting environment variables provides a flexible and configurable way to enable tracing without modifying your code. It allows you to control tracing behavior across different environments and deployments without the need for code changes.</td>
<td>Setting environment variables is a common practice in software development to configure the behavior of applications or libraries. In the case of LangSmith, setting environment variables is necessary to enable tracing and logging of run traces to LangSmith.\n\nBy setting the `LANGCHAIN_TRACING_V2` environment variable, LangChain components such as LLMs, chains, agents, tools, and retrievers will automatically log their calls and responses to LangSmith. This allows you to easily debug and monitor the behavior of your application, track inputs and outputs, analyze latency and token usage, and more.\n\nUsing environment variables provides a flexible and consistent way to configure tracing across different programming languages and environments. It allows you to enable or disable tracing without modifying your code, making it easier to switch between development, testing, and production environments.\n\nWhile setting environment variables may require some initial setup, it provides a powerful and convenient way to leverage the capabilities of LangSmith for debugging and monitoring your LangChain applications.</td>
<td>B</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>Can I trace my Llama V2 llm?</td>
<td>So long as you are using one of LangChain's LLM implementations, all your calls can be traced</td>
<td>Yes, you can trace your Llama V2 LLM using LangSmith's tracing feature. Tracing allows you to log the runs of your LLM application and inspect the inputs and outputs of each component in the chain. To enable tracing for your Llama V2 LLM, you need to set the `LANGCHAIN_TRACING_V2` environment variable to `true` before running your application. Here's an example of how to enable tracing in Python:\n\n```python\nimport os\nfrom langchain.chat_models import LlamaV2\n\nos.environ["LANGCHAIN_TRACING_V2"] = "true"\n\nllm = LlamaV2()\nllm.invoke("Hello, world!")\n```\n\nMake sure you have also set the `LANGCHAIN_ENDPOINT` and `LANGCHAIN_API_KEY` environment variables to the appropriate values for your LangSmith account.</td>
<td>Yes, you can trace your Llama V2 LLM using LangSmith. Tracing allows you to log the inputs, outputs, and other important information of your LLM runs to LangSmith for visualization and debugging purposes.\n\nTo enable tracing for your Llama V2 LLM, you need to set the `LANGCHAIN_TRACING_V2` environment variable to `true` before running your LLM code. Here's an example of how to enable tracing in Python:\n\n```python\nimport os\nfrom langchain.chat_models import LlamaV2\n\nos.environ["LANGCHAIN_TRACING_V2"] = "true"\n\nllm = LlamaV2()\nllm.invoke("Hello, world!")\n```\n\nMake sure you have the LangSmith SDK installed and your API key and project name configured correctly. The traces from your Llama V2 LLM runs will be logged to LangSmith and can be visualized in the LangSmith web app.\n\nNote that tracing is asynchronous, so you may need to wait for the traces to be submitted before exiting your application. You can use the `wait_for_all_tracers()` function from the `langsmith.callbacks.tracers.langchain` module to ensure all traces are logged before exiting.</td>
<td>B</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>How do I use a traceable decorator?</td>
<td>The traceable decorator is available in the langsmith python SDK. To use, configure your environment with your API key,import the required function, decorate your function, and then call the function. Below is an example:\n```python\nfrom langsmith.run_helpers import traceable\n@traceable(run_type="chain") # or "llm", etc.\ndef my_function(input_param):\n # Function logic goes here\n return output\nresult = my_function(input_param)\n```</td>
<td>To use the `traceable` decorator, you need to import it from the `langsmith.run_helpers` module. The `traceable` decorator allows you to easily log the execution of a function as a run in LangSmith.\n\nHere's an example of how to use the `traceable` decorator:\n\n```python\nfrom langsmith.run_helpers import traceable\n\n@traceable(run_type="llm", name="openai.ChatCompletion.create")\ndef my_llm(*args, **kwargs):\n # Your function logic here\n pass\n```\n\nIn the example above, the `traceable` decorator is applied to the `my_llm` function. The `run_type` parameter specifies the type of the run (e.g., "llm", "tool", "chain"), and the `name` parameter specifies the name of the run. You can customize these parameters based on your specific use case.\n\nOnce the `traceable` decorator is applied, every time the `my_llm` function is called, a run will be logged to LangSmith with the specified run type and name.\n\nNote that the `traceable` decorator works for both synchronous and asynchronous functions. If you're using an asynchronous function, make sure to use the `await` keyword when calling the function.\n\nYou can find more information about the `traceable` decorator in the LangSmith documentation under the "Tracing" section.</td>
<td>To use the `traceable` decorator in LangSmith, you can follow these steps:\n\n1. Import the necessary modules:\n```python\nfrom langsmith.run_helpers import traceable\n```\n\n2. Define your function and decorate it with the `traceable` decorator:\n```python\n@traceable(run_type="llm")\ndef my_function(arg1, arg2):\n # Function logic here\n return result\n```\nThe `run_type` argument specifies the type of the run, such as "llm", "chain", or "tool". You can choose the appropriate run type based on your use case.\n\n3. Call your function as usual:\n```python\nresult = my_function(arg1, arg2)\n```\n\nWhen you call the decorated function, it will automatically log a trace of the function execution to LangSmith. The trace will include the inputs, outputs, and other relevant information.\n\nNote that the `traceable` decorator works for both synchronous and asynchronous functions. If you're using an asynchronous function, make sure to use the `await` keyword when calling it.\n\nYou can find more examples and details in the [traceable notebook](https://github.com/langchain-ai/langsmith-cookbook/blob/main/tracing-examples/traceable/traceable.ipynb) in the LangSmith Cookbook.</td>
<td>B</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>What's a langsmith dataset?</td>
<td>A LangSmith dataset is a collection of examples. Each example contains inputs and optional expected outputs or references for that data point.</td>
<td>A LangSmith dataset is a collection of input-output examples that are used for testing, evaluation, and training purposes in the LangSmith framework. It consists of pairs of input prompts and their corresponding model outputs. These examples can be created and curated during the development and debugging process of building applications using large language models (LLMs).\n\nLangSmith datasets are valuable for several reasons:\n\n1. **Testing and Evaluation:** Datasets can be used to test the performance of prompts, chains, agents, and other components of LLM applications. By running the examples in the dataset through the application, developers can observe the outputs and evaluate the effectiveness of their models.\n\n2. **Debugging and Troubleshooting:** When encountering unexpected or incorrect outputs, developers can add these examples to a dataset for further analysis and debugging. By examining the inputs and outputs in the dataset, they can identify issues and improve the application.\n\n3. **Benchmarking and Comparison:** Datasets provide a benchmark for comparing different versions of prompts, chains, or models. Developers can use the dataset to measure the performance of different configurations and make informed decisions about which version to use.\n\n4. **Training and Fine-tuning:** LangSmith datasets can also be exported for use in training or fine-tuning language models. These datasets can be used to improve the performance of the models by incorporating real-world examples and specific use cases.\n\nLangSmith provides features to easily create, edit, and manage datasets within the LangSmith framework. Developers can add examples to datasets during the debugging process, and these datasets can be exported for use in other contexts, such as OpenAI Evals or fine-tuning with external tools like FireworksAI.</td>
<td>A LangSmith dataset is a collection of examples that can be used to evaluate or improve a chain, agent, or model. It consists of rows, where each row represents an example and contains the inputs and (optionally) the expected outputs for a given interaction. Datasets in LangSmith can be created from existing runs, uploaded as CSV files, or manually created using the LangSmith client. Datasets are useful for testing and evaluating models, monitoring performance, and exporting data for use in other contexts.</td>
<td>NaN</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">5</td>
<td>How might I query for all runs in a project?</td>
<td>client.list_runs(project_name='my-project-name'), or in TypeScript, client.ListRuns({projectName: 'my-project-anme'})</td>
<td>To query for all runs in a project, you can use the LangSmith SDK or the web app. Here's how you can do it using the SDK in Python:\n\n```python\nfrom langsmith import Client\n\nclient = Client()\nruns = list(client.list_runs(project_name="&lt;your_project&gt;"))\n```\n\nIn this example, replace `&lt;your_project&gt;` with the name of your project. The `list_runs` method retrieves all runs in the specified project.\n\nIf you prefer to use the web app, you can navigate to the project and view all the runs in the runs table. You can also use the search bar in the runs table to filter and search for specific runs based on various criteria.\n\nRemember to authenticate with your LangSmith credentials when using the SDK to access your projects and runs.</td>
<td>To query for all runs in a project, you can use the LangSmith SDK or the LangSmith REST API. Here's an example of how to do it using the LangSmith SDK in Python:\n\n```python\nfrom langsmith import Client\n\nclient = Client()\nruns = list(client.list_runs(project_name="Your Project Name"))\n```\n\nIn this example, replace "Your Project Name" with the name of your project. The `list_runs` method returns a generator that you can iterate over to get all the runs in the project.\n\nIf you prefer to use the LangSmith REST API directly, you can make a GET request to the `/runs` endpoint with the appropriate project name parameter.\n\nKeep in mind that you may need to paginate through the results if there are a large number of runs in the project. The LangSmith SDK provides convenient methods for pagination, such as `client.list_runs_paginated()`, which returns a paginated generator that you can iterate over.\n\nRemember to authenticate your requests with your API key.</td>
<td>B</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">6</td>
<td>What is LangChain?</td>
<td>LangChain is an open-source framework for building applications using large language models. It is also the name of the company building LangSmith.</td>
<td>LangChain is a framework for building applications using large language models (LLMs). It aims to simplify the process of building reliable LLM applications by providing tools and features to enhance development, testing, evaluation, and monitoring.\n\nLangChain helps bridge the gap between the initial setup of LLMs and their performance in production. It offers a tracing feature that logs all calls to LLMs, chains, agents, tools, and retrievers, providing visibility into the behavior of the application. This tracing feature can be used for debugging purposes, such as identifying unexpected end results, understanding why an agent is looping, or investigating the latency of a chain.\n\nThe framework also includes a playground feature that allows developers to modify prompts and observe the resulting changes to the output. This helps in experimenting with different inputs and understanding the impact on the application's behavior.\n\nLangChain provides a visualization of the sequence of events in complicated chains and agents, making it easier to understand the flow and interactions between different components. It also tracks the token usage of each step in the chain, helping developers identify potentially costly parts.\n\nAdditionally, LangChain supports collaborative debugging by allowing users to share faulty chains and LLM runs with colleagues for troubleshooting. It also enables the collection of examples to create datasets for testing and evaluation. Developers can add input/output examples to datasets at different steps of the chain, facilitating benchmarking and testing against known issues.\n\nFor evaluation purposes, LangChain allows the uploading of datasets and running chains over the data points. The results can be visualized and evaluated using built-in evaluators or custom evaluators. Feedback can be assigned to runs and marked as correct or incorrect, providing aggregate statistics for each test project.\n\nFinally, LangChain can be used for monitoring applications in production. It provides the ability to log traces, visualize latency and token usage statistics, and troubleshoot specific issues as they arise.\n\nOverall, LangChain aims to simplify the development, testing, evaluation, and monitoring of LLM applications, making it easier to build reliable and performant language-based applications.</td>
<td>LangChain is a framework for building applications using large language models (LLMs). It aims to simplify the process of developing reliable LLM applications by providing tools and features to enhance debugging, testing, evaluation, and monitoring.\n\nLangChain helps bridge the gap between the initial setup of LLMs and their performance in production. It offers a tracing feature that logs all calls to LLMs, chains, agents, tools, and retrievers, providing visibility into the inputs and outputs of each call. This tracing feature is enabled by default in LangChain.\n\nDebugging LLMs, chains, and agents can be challenging, but LangChain provides tools to address common pain points. It offers a visualization of the exact inputs and outputs of LLM calls, allowing developers to understand the formatting logic, transformations to user input, and missing input. LangChain also provides a playground where developers can modify prompts and observe the resulting changes to the output.\n\nIn complex chains and agents, it can be difficult to understand the sequence of events and the interactions between different calls. LangChain's tracing feature includes a visualization of the sequence of calls, helping developers gain insights into the inner workings of their applications.\n\nLangChain also helps identify performance issues by tracking the latency of each step in a chain. Developers can identify and optimize the slowest components of their applications. Additionally, LangChain tracks the token usage of each step, making it easy to identify potentially costly parts of the chain.\n\nCollecting examples of failures and unexpected outcomes is crucial for testing and improving LLM applications. LangChain allows developers to add input/output examples to datasets, which can be used for testing changes to prompts or chains. These datasets can be evaluated using LangChain's evaluators, providing guidance on examples that require further investigation.\n\nLangChain can also be used for monitoring LLM applications in production. It allows developers to log traces, visualize latency and token usage statistics, and troubleshoot specific issues as they arise. Feedback can be associated with runs, enabling performance tracking over time.\n\nOverall, LangChain aims to simplify the development, testing, evaluation, and monitoring of LLM applications, providing tools and features to enhance reliability and performance.</td>
<td>NaN</td>
</tr>
</tbody>
</table>
</div>
</div>
</section>
<section id="conclusion" class="level2" data-number="4">
<h2 data-number="4" class="anchored" data-anchor-id="conclusion"><span class="header-section-number">4</span> Conclusion</h2>
<p>We compared two variations of a RAG Q&amp;A chain in this post by predicting preference scores for each pair of predictions. This methodology is one method for automatically comparing two versions of a chain, which can provide context beyond ordinary benchmarking.</p>
<p>There are numerous methods for evaluating preferences. We compared the two models using binary choices and only evaluated once, but you might get better results if you attempt one of the following approaches:</p>
<ul>
<li>Evaluate each position multiple times and return a victory rate</li>
<li>Evaluators of ensembles</li>
<li>Tell the model to produce continuous scores.</li>
<li>Tell the model to utilise a different prompt method than the chain of thinking.</li>
</ul>
<p>For more information on measuring the reliability of this and other approaches, you can check out the <a href="https://python.langchain.com/docs/guides/evaluation/examples">evaluations examples</a> in the LangChain repo.</p>
</section>
<section id="acknowledgements" class="level2" data-number="5">
<h2 data-number="5" class="anchored" data-anchor-id="acknowledgements"><span class="header-section-number">5</span> Acknowledgements</h2>
<p>I’d like to express my thanks to the wonderful <a href="https://github.com/langchain-ai/langsmith-cookbook/">Langsmith Cookbook Repo</a> and acknowledge the use of some images and other materials from this project in writing this article.</p>


</section>

<link href="//cdn-images.mailchimp.com/embedcode/classic-071822.css" rel="stylesheet" type="text/css"><div id="mc_embed_signup">
    <form action="https://livingdatalab.us8.list-manage.com/subscribe/post?u=e2d57b0d6e43b4f6bff927a55&amp;id=a30bdff125&amp;f_id=009d05e0f0" method="post" id="mc-embedded-subscribe-form" name="mc-embedded-subscribe-form" class="validate" target="_blank" novalidate="">
        <div id="mc_embed_signup_scroll">
        <h2 class="anchored">Subscribe</h2>
<div class="mc-field-group">
    <label for="mce-EMAIL">Email Address
</label>
    <input type="email" value="" name="EMAIL" class="required email" id="mce-EMAIL" required="">
    <span id="mce-EMAIL-HELPERTEXT" class="helper_text"></span>
</div>
    <div id="mce-responses" class="clear foot">
        <div class="response" id="mce-error-response" style="display:none"></div>
        <div class="response" id="mce-success-response" style="display:none"></div>
    </div>    <!-- real people should not fill this in and expect good things - do not remove this or risk form bot signups-->
    <div style="position: absolute; left: -5000px;" aria-hidden="true"><input type="text" name="b_e2d57b0d6e43b4f6bff927a55_a30bdff125" tabindex="-1" value=""></div>
        <div class="optionalParent">
            <div class="clear foot">
                <input type="submit" value="Subscribe" name="subscribe" id="mc-embedded-subscribe" class="button">
            </div>
        </div>
    </div>
</form>
</div><script type="text/javascript">(function($) {window.fnames = new Array(); window.ftypes = new Array();fnames[0]='EMAIL';ftypes[0]='email';fnames[1]='FNAME';ftypes[1]='text';fnames[2]='LNAME';ftypes[2]='text';fnames[3]='ADDRESS';ftypes[3]='address';fnames[4]='PHONE';ftypes[4]='phone';fnames[5]='BIRTHDAY';ftypes[5]='birthday';}(jQuery));var $mcj = jQuery.noConflict(true);</script></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var filterRegex = new RegExp("http:\/\/livingdatalab\.com");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
          // target, if specified
          link.setAttribute("target", "_blank");
      }
    }
});
</script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      &nbsp;
    </div>   
    <div class="nav-footer-center">LivingDataLab AI Technical Blog</div>
    <div class="nav-footer-right">
      &nbsp;
    </div>
  </div>
</footer>



</body></html>