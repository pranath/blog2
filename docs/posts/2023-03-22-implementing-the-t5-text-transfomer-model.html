<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.335">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Pranath Fernando">
<meta name="dcterms.date" content="2023-03-22">
<meta name="description" content="We implement the Text to Text Transfer from Transformers model (better known as T5) which can perform a wide variety of NLP tasks and is a versatile model.">

<title>LivingDataLab - Implementing the T5 text transformer model</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../favicon.ico" rel="icon">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>

<script type="text/javascript">

(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
ga('create', 'UA-91568149-1', 'auto');

ga('send', {
  hitType: 'pageview',
  'anonymizeIp': true,
});
</script>


<link rel="stylesheet" href="../styles.css">
<meta property="og:title" content="LivingDataLab - Implementing the T5 text transformer model">
<meta property="og:description" content="We implement the Text to Text Transfer from Transformers model (better known as T5) which can perform a wide variety of NLP tasks and is a versatile model.">
<meta property="og:image" content="https://github.com/pranath/blog/raw/master/images/t5.png">
<meta property="og:site-name" content="LivingDataLab">
<meta name="twitter:title" content="LivingDataLab - Implementing the T5 text transformer model">
<meta name="twitter:description" content="We implement the Text to Text Transfer from Transformers model (better known as T5) which can perform a wide variety of NLP tasks and is a versatile model.">
<meta name="twitter:image" content="https://github.com/pranath/blog/raw/master/images/t5.png">
<meta name="twitter:card" content="summary_large_image">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a href="../index.html" class="navbar-brand navbar-brand-logo">
    <img src="../logo.png" alt="" class="navbar-logo">
    </a>
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">LivingDataLab</span>
    </a>
  </div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../about.html">
 <span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/pranath"><i class="bi bi-github" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/LivingDataLab"><i class="bi bi-twitter" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
              <div id="quarto-search" class="" title="Search"></div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Implementing the T5 text transformer model</h1>
                  <div>
        <div class="description">
          We implement the Text to Text Transfer from Transformers model (better known as T5) which can perform a wide variety of NLP tasks and is a versatile model.
        </div>
      </div>
                          <div class="quarto-categories">
                <div class="quarto-category">natural-language-processing</div>
                <div class="quarto-category">deep-learning</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Pranath Fernando </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">March 22, 2023</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar"><div class="quarto-margin-header"><div class="margin-header-item">
<!-- Begin Mailchimp Signup Form -->
<link href="//cdn-images.mailchimp.com/embedcode/classic-071822.css" rel="stylesheet" type="text/css">
<style type="text/css">
    #mc_embed_signup{background:#fff; clear:left; font:14px Helvetica,Arial,sans-serif; }
    /* Add your own Mailchimp form style overrides in your site stylesheet or in this style block.
       We recommend moving this block and the preceding CSS link to the HEAD of your HTML file. */
</style>
<div id="mc_embed_signup">
    <form action="https://livingdatalab.us8.list-manage.com/subscribe/post?u=e2d57b0d6e43b4f6bff927a55&amp;id=a30bdff125&amp;f_id=009d05e0f0" method="post" id="mc-embedded-subscribe-form" name="mc-embedded-subscribe-form" class="validate" target="_blank" novalidate="">
        <div id="mc_embed_signup_scroll">
        <h2>Subscribe</h2>
<div class="mc-field-group">
    <label for="mce-EMAIL">Email Address
</label>
    <input type="email" value="" name="EMAIL" class="required email" id="mce-EMAIL" required="">
    <span id="mce-EMAIL-HELPERTEXT" class="helper_text"></span>
</div>
    <div id="mce-responses" class="clear foot">
        <div class="response" id="mce-error-response" style="display:none"></div>
        <div class="response" id="mce-success-response" style="display:none"></div>
    </div>    <!-- real people should not fill this in and expect good things - do not remove this or risk form bot signups-->
    <div style="position: absolute; left: -5000px;" aria-hidden="true"><input type="text" name="b_e2d57b0d6e43b4f6bff927a55_a30bdff125" tabindex="-1" value=""></div>
        <div class="optionalParent">
            <div class="clear foot">
                <input type="submit" value="Subscribe" name="subscribe" id="mc-embedded-subscribe" class="button">
            </div>
        </div>
    </div>
</form>
</div>
<script type="text/javascript" src="//s3.amazonaws.com/downloads.mailchimp.com/js/mc-validate.js"></script><script type="text/javascript">(function($) {window.fnames = new Array(); window.ftypes = new Array();fnames[0]='EMAIL';ftypes[0]='email';fnames[1]='FNAME';ftypes[1]='text';fnames[2]='LNAME';ftypes[2]='text';fnames[3]='ADDRESS';ftypes[3]='address';fnames[4]='PHONE';ftypes[4]='phone';fnames[5]='BIRTHDAY';ftypes[5]='birthday';}(jQuery));var $mcj = jQuery.noConflict(true);</script>
<!--End mc_embed_signup-->

</div></div>
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction"><span class="toc-section-number">1</span>  Introduction</a></li>
  <li><a href="#importing-the-packages" id="toc-importing-the-packages" class="nav-link" data-scroll-target="#importing-the-packages"><span class="toc-section-number">2</span>  Importing the Packages</a></li>
  <li><a href="#c4-dataset" id="toc-c4-dataset" class="nav-link" data-scroll-target="#c4-dataset"><span class="toc-section-number">3</span>  C4 Dataset</a>
  <ul class="collapse">
  <li><a href="#pre-training-objective" id="toc-pre-training-objective" class="nav-link" data-scroll-target="#pre-training-objective"><span class="toc-section-number">3.1</span>  Pre-Training Objective</a></li>
  <li><a href="#process-c4" id="toc-process-c4" class="nav-link" data-scroll-target="#process-c4"><span class="toc-section-number">3.2</span>  Process C4</a></li>
  <li><a href="#tokenizing-and-masking" id="toc-tokenizing-and-masking" class="nav-link" data-scroll-target="#tokenizing-and-masking"><span class="toc-section-number">3.3</span>  Tokenizing and Masking</a></li>
  <li><a href="#creating-the-pairs" id="toc-creating-the-pairs" class="nav-link" data-scroll-target="#creating-the-pairs"><span class="toc-section-number">3.4</span>  Creating the Pairs</a></li>
  </ul></li>
  <li><a href="#transformer" id="toc-transformer" class="nav-link" data-scroll-target="#transformer"><span class="toc-section-number">4</span>  Transformer</a></li>
  <li><a href="#transformer-encoder" id="toc-transformer-encoder" class="nav-link" data-scroll-target="#transformer-encoder"><span class="toc-section-number">5</span>  Transformer Encoder</a>
  <ul class="collapse">
  <li><a href="#the-feedforward-block" id="toc-the-feedforward-block" class="nav-link" data-scroll-target="#the-feedforward-block"><span class="toc-section-number">5.1</span>  The Feedforward Block</a></li>
  <li><a href="#the-encoder-block" id="toc-the-encoder-block" class="nav-link" data-scroll-target="#the-encoder-block"><span class="toc-section-number">5.2</span>  The Encoder Block</a></li>
  <li><a href="#the-transformer-encoder" id="toc-the-transformer-encoder" class="nav-link" data-scroll-target="#the-transformer-encoder"><span class="toc-section-number">5.3</span>  The Transformer Encoder</a></li>
  </ul></li>
  <li><a href="#acknowledgements" id="toc-acknowledgements" class="nav-link" data-scroll-target="#acknowledgements"><span class="toc-section-number">6</span>  Acknowledgements</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">




<section id="introduction" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="introduction"><span class="header-section-number">1</span> Introduction</h2>
<p>In this article we will explore question answering. We will implement the “Text to Text Transfer from Transformers” model (better known as T5) which can perform a wide variety of NLP tasks.</p>
<p><img src="https://github.com/pranath/blog/raw/master/images/t5.png"></p>
<p>We will create the necessary building blocks for the transformer encoder model required and will use a pretrained version of the same model.</p>
<p>After completing these tasks we will:</p>
<ul>
<li>Understand how the C4 dataset is structured.</li>
<li>Use a pretrained model for inference.</li>
<li>Understand how the “Text to Text Transfer from Transformers” or T5 model works.</li>
</ul>
</section>
<section id="importing-the-packages" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="importing-the-packages"><span class="header-section-number">2</span> Importing the Packages</h2>
<div class="cell" data-outputid="64947d91-eef3-425b-9b4b-7ca7cefcc823" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> ast</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pprint</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> string</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> textwrap</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> itertools</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> w3_tests</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> trax </span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> trax <span class="im">import</span> layers <span class="im">as</span> tl</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> trax.supervised <span class="im">import</span> decoding</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Will come handy later.</span></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>wrapper <span class="op">=</span> textwrap.TextWrapper(width<span class="op">=</span><span class="dv">70</span>)</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Set random seed</span></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">42</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="c4-dataset" class="level2" data-number="3">
<h2 data-number="3" class="anchored" data-anchor-id="c4-dataset"><span class="header-section-number">3</span> C4 Dataset</h2>
<p>The <a href="https://www.tensorflow.org/datasets/catalog/c4">C4</a> is a huge data set. For the purpose of this project we will use a few examples out of it which are present in <code>data.txt</code>. C4 is based on the <a href="https://commoncrawl.org/">common crawl</a> project. Feel free to read more on their website.</p>
<div class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co"># load example jsons</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>example_jsons <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(ast.literal_eval, <span class="bu">open</span>(<span class="st">'data/data.txt'</span>)))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-outputid="338e9751-8fc1-4f64-817a-3406b67f5dd5" data-execution_count="3">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Printing the examples to see how the data looks like</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">5</span>):</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f'example number </span><span class="sc">{</span>i<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">: </span><span class="ch">\n\n</span><span class="sc">{</span>example_jsons[i]<span class="sc">}</span><span class="ss"> </span><span class="ch">\n</span><span class="ss">'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>example number 1: 

{'content-length': b'1970', 'content-type': b'text/plain', 'text': b'Beginners BBQ Class Taking Place in Missoula!\nDo you want to get better at making delicious BBQ? You will have the opportunity, put this on your calendar now. Thursday, September 22nd join World Class BBQ Champion, Tony Balay from Lonestar Smoke Rangers. He will be teaching a beginner level class for everyone who wants to get better with their culinary skills.\nHe will teach you everything you need to know to compete in a KCBS BBQ competition, including techniques, recipes, timelines, meat selection and trimming, plus smoker and fire information.\nThe cost to be in the class is $35 per person, and for spectators it is free. Included in the cost will be either a t-shirt or apron and you will be tasting samples of each meat that is prepared.', 'timestamp': b'2019-04-25T12:57:54Z', 'url': b'https://klyq.com/beginners-bbq-class-taking-place-in-missoula/'} 

example number 2: 

{'content-length': b'12064', 'content-type': b'text/plain', 'text': b'Discussion in \'Mac OS X Lion (10.7)\' started by axboi87, Jan 20, 2012.\nI\'ve got a 500gb internal drive and a 240gb SSD.\nWhen trying to restore using disk utility i\'m given the error "Not enough space on disk ____ to restore"\nBut I shouldn\'t have to do that!!!\nAny ideas or workarounds before resorting to the above?\nUse Carbon Copy Cloner to copy one drive to the other. I\'ve done this several times going from larger HDD to smaller SSD and I wound up with a bootable SSD drive. One step you have to remember not to skip is to use Disk Utility to partition the SSD as GUID partition scheme HFS+ before doing the clone. If it came Apple Partition Scheme, even if you let CCC do the clone, the resulting drive won\'t be bootable. CCC usually works in "file mode" and it can easily copy a larger drive (that\'s mostly empty) onto a smaller drive. If you tell CCC to clone a drive you did NOT boot from, it can work in block copy mode where the destination drive must be the same size or larger than the drive you are cloning from (if I recall).\nI\'ve actually done this somehow on Disk Utility several times (booting from a different drive (or even the dvd) so not running disk utility from the drive your cloning) and had it work just fine from larger to smaller bootable clone. Definitely format the drive cloning to first, as bootable Apple etc..\nThanks for pointing this out. My only experience using DU to go larger to smaller was when I was trying to make a Lion install stick and I was unable to restore InstallESD.dmg to a 4 GB USB stick but of course the reason that wouldn\'t fit is there was slightly more than 4 GB of data.', 'timestamp': b'2019-04-21T10:07:13Z', 'url': b'https://forums.macrumors.com/threads/restore-from-larger-disk-to-smaller-disk.1311329/'} 

example number 3: 

{'content-length': b'5235', 'content-type': b'text/plain', 'text': b'Foil plaid lycra and spandex shortall with metallic slinky insets. Attached metallic elastic belt with O-ring. Headband included. Great hip hop or jazz dance costume. Made in the USA.', 'timestamp': b'2019-04-25T10:40:23Z', 'url': b'https://awishcometrue.com/Catalogs/Clearance/Tweens/V1960-Find-A-Way'} 

example number 4: 

{'content-length': b'4967', 'content-type': b'text/plain', 'text': b"How many backlinks per day for new site?\nDiscussion in 'Black Hat SEO' started by Omoplata, Dec 3, 2010.\n1) for a newly created site, what's the max # backlinks per day I should do to be safe?\n2) how long do I have to let my site age before I can start making more blinks?\nI did about 6000 forum profiles every 24 hours for 10 days for one of my sites which had a brand new domain.\nThere is three backlinks for every of these forum profile so thats 18 000 backlinks every 24 hours and nothing happened in terms of being penalized or sandboxed. This is now maybe 3 months ago and the site is ranking on first page for a lot of my targeted keywords.\nbuild more you can in starting but do manual submission and not spammy type means manual + relevant to the post.. then after 1 month you can make a big blast..\nWow, dude, you built 18k backlinks a day on a brand new site? How quickly did you rank up? What kind of competition/searches did those keywords have?", 'timestamp': b'2019-04-21T12:46:19Z', 'url': b'https://www.blackhatworld.com/seo/how-many-backlinks-per-day-for-new-site.258615/'} 

example number 5: 

{'content-length': b'4499', 'content-type': b'text/plain', 'text': b'The Denver Board of Education opened the 2017-18 school year with an update on projects that include new construction, upgrades, heat mitigation and quality learning environments.\nWe are excited that Denver students will be the beneficiaries of a four year, $572 million General Obligation Bond. Since the passage of the bond, our construction team has worked to schedule the projects over the four-year term of the bond.\nDenver voters on Tuesday approved bond and mill funding measures for students in Denver Public Schools, agreeing to invest $572 million in bond funding to build and improve schools and $56.6 million in operating dollars to support proven initiatives, such as early literacy.\nDenver voters say yes to bond and mill levy funding support for DPS students and schools. Click to learn more about the details of the voter-approved bond measure.\nDenver voters on Nov. 8 approved bond and mill funding measures for DPS students and schools. Learn more about what\xe2\x80\x99s included in the mill levy measure.', 'timestamp': b'2019-04-20T14:33:21Z', 'url': b'http://bond.dpsk12.org/category/news/'} 
</code></pre>
</div>
</div>
<p>Notice the <code>b</code> before each string? This means that this data comes as bytes rather than strings. Strings are actually lists of bytes the name <code>strings</code> will be used to describe the data.</p>
<div class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="bu">type</span>(example_jsons[<span class="dv">0</span>].get(<span class="st">'text'</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="4">
<pre><code>bytes</code></pre>
</div>
</div>
<section id="pre-training-objective" class="level3" data-number="3.1">
<h3 data-number="3.1" class="anchored" data-anchor-id="pre-training-objective"><span class="header-section-number">3.1</span> Pre-Training Objective</h3>
<p><strong>Note:</strong> The word “mask” will be used throughout this project in context of hiding/removing word(s)</p>
<p>We will be implementing the BERT loss as shown in the following image.</p>
<p><img src="https://github.com/pranath/blog/raw/master/images/loss.png" width="600" height="400"></p>
<p>Say we have the following text: <span style="color:blue"> <strong>Thank you <span style="color:red">for inviting </span> me to your party <span style="color:red">last</span> week</strong> </span></p>
<p>Now as input we will mask the words in red in the text:</p>
<p><span style="color:blue"> <strong>Input:</strong></span> Thank you <strong>X</strong> me to your party <strong>Y</strong> week.</p>
<p><span style="color:blue"><strong>Output:</strong></span> The model should predict the words(s) for <strong>X</strong> and <strong>Y</strong>.</p>
<p><strong>Z</strong> is used to represent the end.</p>
</section>
<section id="process-c4" class="level3" data-number="3.2">
<h3 data-number="3.2" class="anchored" data-anchor-id="process-c4"><span class="header-section-number">3.2</span> Process C4</h3>
<p>C4 only has the plain string <code>text</code> field, so we will tokenize and have <code>inputs</code> and <code>targets</code> out of it for supervised learning. Given our inputs, the goal is to predict the targets during training.</p>
<p>We will now take the <code>text</code> and convert it to <code>inputs</code> and <code>targets</code>.</p>
<div class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Grab text field from dictionary</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>natural_language_texts <span class="op">=</span> [example_json[<span class="st">'text'</span>] <span class="cf">for</span> example_json <span class="kw">in</span> example_jsons]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-outputid="4f689b44-8ecb-45d6-d73f-22a0b2bf6d48" data-execution_count="6">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co"># First text example</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>natural_language_texts[<span class="dv">4</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="6">
<pre><code>b'The Denver Board of Education opened the 2017-18 school year with an update on projects that include new construction, upgrades, heat mitigation and quality learning environments.\nWe are excited that Denver students will be the beneficiaries of a four year, $572 million General Obligation Bond. Since the passage of the bond, our construction team has worked to schedule the projects over the four-year term of the bond.\nDenver voters on Tuesday approved bond and mill funding measures for students in Denver Public Schools, agreeing to invest $572 million in bond funding to build and improve schools and $56.6 million in operating dollars to support proven initiatives, such as early literacy.\nDenver voters say yes to bond and mill levy funding support for DPS students and schools. Click to learn more about the details of the voter-approved bond measure.\nDenver voters on Nov. 8 approved bond and mill funding measures for DPS students and schools. Learn more about what\xe2\x80\x99s included in the mill levy measure.'</code></pre>
</div>
</div>
<section id="decode-to-natural-language" class="level4">
<h4 class="anchored" data-anchor-id="decode-to-natural-language">Decode to Natural Language</h4>
<p>The following functions will help us <code>detokenize</code> and<code>tokenize</code> the text data.</p>
<p>The <code>sentencepiece</code> vocabulary was used to convert from text to ids. This vocabulary file is loaded and used in these helper functions.</p>
<p><code>natural_language_texts</code> has the text from the examples.</p>
<div class="cell" data-outputid="023a227c-d895-4fd9-ae83-9394fe48cebd" data-execution_count="7">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Special tokens</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>PAD, EOS, UNK <span class="op">=</span> <span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">2</span></span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> detokenize(np_array):</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> trax.data.detokenize(</span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>        np_array,</span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>        vocab_type<span class="op">=</span><span class="st">'sentencepiece'</span>,</span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>        vocab_file<span class="op">=</span><span class="st">'sentencepiece.model'</span>,</span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a>        vocab_dir<span class="op">=</span><span class="st">'./models'</span>)</span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> tokenize(s):</span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a>  <span class="co"># The trax.data.tokenize function operates on streams,</span></span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a>  <span class="co"># that's why we have to create 1-element stream with iter</span></span>
<span id="cb10-14"><a href="#cb10-14" aria-hidden="true" tabindex="-1"></a>  <span class="co"># and later retrieve the result with next.</span></span>
<span id="cb10-15"><a href="#cb10-15" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="bu">next</span>(trax.data.tokenize(</span>
<span id="cb10-16"><a href="#cb10-16" aria-hidden="true" tabindex="-1"></a>        <span class="bu">iter</span>([s]),</span>
<span id="cb10-17"><a href="#cb10-17" aria-hidden="true" tabindex="-1"></a>        vocab_type<span class="op">=</span><span class="st">'sentencepiece'</span>,</span>
<span id="cb10-18"><a href="#cb10-18" aria-hidden="true" tabindex="-1"></a>        vocab_file<span class="op">=</span><span class="st">'sentencepiece.model'</span>,</span>
<span id="cb10-19"><a href="#cb10-19" aria-hidden="true" tabindex="-1"></a>        vocab_dir<span class="op">=</span><span class="st">'./models'</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-outputid="023a227c-d895-4fd9-ae83-9394fe48cebd" data-execution_count="8">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="co"># printing the encoding of each word to see how subwords are tokenized</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>tokenized_text <span class="op">=</span> [(tokenize(word).tolist(), word) <span class="cf">for</span> word <span class="kw">in</span> natural_language_texts[<span class="dv">0</span>].split()]</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(tokenized_text, <span class="st">'</span><span class="ch">\n</span><span class="st">'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[([12847, 277], b'Beginners'), ([15068], b'BBQ'), ([4501], b'Class'), ([3, 12297], b'Taking'), ([3399], b'Place'), ([16], b'in'), ([5964, 7115, 9, 55], b'Missoula!'), ([531], b'Do'), ([25], b'you'), ([241], b'want'), ([12], b'to'), ([129], b'get'), ([394], b'better'), ([44], b'at'), ([492], b'making'), ([3326], b'delicious'), ([15068, 58], b'BBQ?'), ([148], b'You'), ([56], b'will'), ([43], b'have'), ([8], b'the'), ([1004, 6], b'opportunity,'), ([474], b'put'), ([48], b'this'), ([30], b'on'), ([39], b'your'), ([4793], b'calendar'), ([230, 5], b'now.'), ([2721, 6], b'Thursday,'), ([1600], b'September'), ([1630, 727], b'22nd'), ([1715], b'join'), ([1150], b'World'), ([4501], b'Class'), ([15068], b'BBQ'), ([16127, 6], b'Champion,'), ([9137], b'Tony'), ([2659, 5595], b'Balay'), ([45], b'from'), ([301, 782, 3624], b'Lonestar'), ([14627, 15], b'Smoke'), ([12612, 277, 5], b'Rangers.'), ([216], b'He'), ([56], b'will'), ([36], b'be'), ([2119], b'teaching'), ([3, 9], b'a'), ([19529], b'beginner'), ([593], b'level'), ([853], b'class'), ([21], b'for'), ([921], b'everyone'), ([113], b'who'), ([2746], b'wants'), ([12], b'to'), ([129], b'get'), ([394], b'better'), ([28], b'with'), ([70], b'their'), ([17712], b'culinary'), ([1098, 5], b'skills.'), ([216], b'He'), ([56], b'will'), ([3884], b'teach'), ([25], b'you'), ([762], b'everything'), ([25], b'you'), ([174], b'need'), ([12], b'to'), ([214], b'know'), ([12], b'to'), ([5978], b'compete'), ([16], b'in'), ([3, 9], b'a'), ([3, 23405, 4547], b'KCBS'), ([15068], b'BBQ'), ([2259, 6], b'competition,'), ([379], b'including'), ([2097, 6], b'techniques,'), ([5459, 6], b'recipes,'), ([13618, 7, 6], b'timelines,'), ([3604], b'meat'), ([1801], b'selection'), ([11], b'and'), ([27856, 6], b'trimming,'), ([303], b'plus'), ([24190], b'smoker'), ([11], b'and'), ([1472], b'fire'), ([251, 5], b'information.'), ([37], b'The'), ([583], b'cost'), ([12], b'to'), ([36], b'be'), ([16], b'in'), ([8], b'the'), ([853], b'class'), ([19], b'is'), ([25264], b'$35'), ([399], b'per'), ([568, 6], b'person,'), ([11], b'and'), ([21], b'for'), ([21380, 7], b'spectators'), ([34], b'it'), ([19], b'is'), ([339, 5], b'free.'), ([15746, 26], b'Included'), ([16], b'in'), ([8], b'the'), ([583], b'cost'), ([56], b'will'), ([36], b'be'), ([893], b'either'), ([3, 9], b'a'), ([3, 17, 18, 9486], b't-shirt'), ([42], b'or'), ([3, 9, 1409, 29], b'apron'), ([11], b'and'), ([25], b'you'), ([56], b'will'), ([36], b'be'), ([12246], b'tasting'), ([5977], b'samples'), ([13], b'of'), ([284], b'each'), ([3604], b'meat'), ([24], b'that'), ([19], b'is'), ([2657, 5], b'prepared.')] 
</code></pre>
</div>
</div>
<div class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="co"># We can see that detokenize successfully undoes the tokenization</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"tokenized: </span><span class="sc">{</span>tokenize(<span class="st">'Beginners'</span>)<span class="sc">}</span><span class="ch">\n</span><span class="ss">detokenized: </span><span class="sc">{</span>detokenize(tokenize(<span class="st">'Beginners'</span>))<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>tokenized: [12847   277]
detokenized: Beginners</code></pre>
</div>
</div>
<p>As we can see above, we were able to take a piece of string and tokenize it.</p>
<p>Now we will create <code>input</code> and <code>target</code> pairs that will allow us to train our model. T5 uses the ids at the end of the vocab file as sentinels. For example, it will replace: - <code>vocab_size - 1</code> by <code>&lt;Z&gt;</code> - <code>vocab_size - 2</code> by <code>&lt;Y&gt;</code> - and so forth.</p>
<p>It assigns every word a <code>chr</code>.</p>
<p>The <code>pretty_decode</code> function below, which we will use in a bit, helps in handling the type when decoding.</p>
<p>Notice that:</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>string.ascii_letters <span class="op">=</span> <span class="st">'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ'</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>NOTE:</strong> Targets may have more than the 52 sentinels we replace, but this is just to give us an idea of things.</p>
<div class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>vocab_size <span class="op">=</span> trax.data.vocab_size(</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>    vocab_type<span class="op">=</span><span class="st">'sentencepiece'</span>,</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>    vocab_file<span class="op">=</span><span class="st">'sentencepiece.model'</span>,</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>    vocab_dir<span class="op">=</span><span class="st">'./models'</span>)</span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_sentinels(vocab_size<span class="op">=</span><span class="dv">32000</span>, display<span class="op">=</span><span class="va">False</span>):</span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a>    sentinels <span class="op">=</span> {}</span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i, char <span class="kw">in</span> <span class="bu">enumerate</span>(<span class="bu">reversed</span>(string.ascii_letters), <span class="dv">1</span>):</span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a>        decoded_text <span class="op">=</span> detokenize([vocab_size <span class="op">-</span> i]) </span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Sentinels, ex: &lt;Z&gt; - &lt;a&gt;</span></span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a>        sentinels[decoded_text] <span class="op">=</span> <span class="ss">f'&lt;</span><span class="sc">{</span>char<span class="sc">}</span><span class="ss">&gt;'</span>    </span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> display:</span>
<span id="cb16-15"><a href="#cb16-15" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f'The sentinel is &lt;</span><span class="sc">{</span>char<span class="sc">}</span><span class="ss">&gt; and the decoded token is:'</span>, decoded_text)</span>
<span id="cb16-16"><a href="#cb16-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-17"><a href="#cb16-17" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> sentinels</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>sentinels <span class="op">=</span> get_sentinels(vocab_size, display<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>The sentinel is &lt;Z&gt; and the decoded token is: Internațional
The sentinel is &lt;Y&gt; and the decoded token is: erwachsene
The sentinel is &lt;X&gt; and the decoded token is: Cushion
The sentinel is &lt;W&gt; and the decoded token is: imunitar
The sentinel is &lt;V&gt; and the decoded token is: Intellectual
The sentinel is &lt;U&gt; and the decoded token is: traditi
The sentinel is &lt;T&gt; and the decoded token is: disguise
The sentinel is &lt;S&gt; and the decoded token is: exerce
The sentinel is &lt;R&gt; and the decoded token is: nourishe
The sentinel is &lt;Q&gt; and the decoded token is: predominant
The sentinel is &lt;P&gt; and the decoded token is: amitié
The sentinel is &lt;O&gt; and the decoded token is: erkennt
The sentinel is &lt;N&gt; and the decoded token is: dimension
The sentinel is &lt;M&gt; and the decoded token is: inférieur
The sentinel is &lt;L&gt; and the decoded token is: refugi
The sentinel is &lt;K&gt; and the decoded token is: cheddar
The sentinel is &lt;J&gt; and the decoded token is: unterlieg
The sentinel is &lt;I&gt; and the decoded token is: garanteaz
The sentinel is &lt;H&gt; and the decoded token is: făcute
The sentinel is &lt;G&gt; and the decoded token is: réglage
The sentinel is &lt;F&gt; and the decoded token is: pedepse
The sentinel is &lt;E&gt; and the decoded token is: Germain
The sentinel is &lt;D&gt; and the decoded token is: distinctly
The sentinel is &lt;C&gt; and the decoded token is: Schraub
The sentinel is &lt;B&gt; and the decoded token is: emanat
The sentinel is &lt;A&gt; and the decoded token is: trimestre
The sentinel is &lt;z&gt; and the decoded token is: disrespect
The sentinel is &lt;y&gt; and the decoded token is: Erasmus
The sentinel is &lt;x&gt; and the decoded token is: Australia
The sentinel is &lt;w&gt; and the decoded token is: permeabil
The sentinel is &lt;v&gt; and the decoded token is: deseori
The sentinel is &lt;u&gt; and the decoded token is: manipulated
The sentinel is &lt;t&gt; and the decoded token is: suggér
The sentinel is &lt;s&gt; and the decoded token is: corespund
The sentinel is &lt;r&gt; and the decoded token is: nitro
The sentinel is &lt;q&gt; and the decoded token is: oyons
The sentinel is &lt;p&gt; and the decoded token is: Account
The sentinel is &lt;o&gt; and the decoded token is: échéan
The sentinel is &lt;n&gt; and the decoded token is: laundering
The sentinel is &lt;m&gt; and the decoded token is: genealogy
The sentinel is &lt;l&gt; and the decoded token is: QuickBooks
The sentinel is &lt;k&gt; and the decoded token is: constituted
The sentinel is &lt;j&gt; and the decoded token is: Fertigung
The sentinel is &lt;i&gt; and the decoded token is: goutte
The sentinel is &lt;h&gt; and the decoded token is: regulă
The sentinel is &lt;g&gt; and the decoded token is: overwhelmingly
The sentinel is &lt;f&gt; and the decoded token is: émerg
The sentinel is &lt;e&gt; and the decoded token is: broyeur
The sentinel is &lt;d&gt; and the decoded token is: povești
The sentinel is &lt;c&gt; and the decoded token is: emulator
The sentinel is &lt;b&gt; and the decoded token is: halloween
The sentinel is &lt;a&gt; and the decoded token is: combustibil</code></pre>
</div>
</div>
<div class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> pretty_decode(encoded_str_list, sentinels):</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>    <span class="co"># If already a string, just do the replacements.</span></span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="bu">isinstance</span>(encoded_str_list, (<span class="bu">str</span>, <span class="bu">bytes</span>)):</span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> token, char <span class="kw">in</span> sentinels.items():</span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>            encoded_str_list <span class="op">=</span> encoded_str_list.replace(token, char)</span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> encoded_str_list</span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a>    <span class="co"># We need to decode and then prettyfy it.</span></span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> pretty_decode(detokenize(encoded_str_list), sentinels)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>pretty_decode(<span class="st">"I want to dress up as an Intellectual this halloween."</span>, sentinels)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="13">
<pre><code>'I want to dress up as an &lt;V&gt; this &lt;b&gt;.'</code></pre>
</div>
</div>
<p>The functions above make our <code>inputs</code> and <code>targets</code> more readable. For example, we might see something like this once we implement the masking function below.</p>
<ul>
<li><span style="color:red"> Input sentence: </span> Younes and Lukasz were working together in the lab yesterday after lunch.</li>
<li><span style="color:red">Input: </span> Younes and Lukasz <strong>Z</strong> together in the <strong>Y</strong> yesterday after lunch.</li>
<li><span style="color:red">Target: </span> <strong>Z</strong> were working <strong>Y</strong> lab.</li>
</ul>
</section>
</section>
<section id="tokenizing-and-masking" class="level3" data-number="3.3">
<h3 data-number="3.3" class="anchored" data-anchor-id="tokenizing-and-masking"><span class="header-section-number">3.3</span> Tokenizing and Masking</h3>
<p>We will now implement the <code>tokenize_and_mask</code> function. This function will allow us to tokenize and mask input words with a noise probability. We usually mask 15% of the words.</p>
<div class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> tokenize_and_mask(text, vocab_size<span class="op">=</span><span class="dv">32000</span>, noise<span class="op">=</span><span class="fl">0.15</span>, </span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>                      randomizer<span class="op">=</span>np.random.uniform, tokenize<span class="op">=</span>tokenize):</span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Tokenizes and masks a given input.</span></span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a><span class="co">    Args:</span></span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a><span class="co">        text (str or bytes): Text input.</span></span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a><span class="co">        vocab_size (int, optional): Size of the vocabulary. Defaults to vocab_size.</span></span>
<span id="cb22-8"><a href="#cb22-8" aria-hidden="true" tabindex="-1"></a><span class="co">        noise (float, optional): Probability of masking a token. Defaults to 0.15.</span></span>
<span id="cb22-9"><a href="#cb22-9" aria-hidden="true" tabindex="-1"></a><span class="co">        randomizer (function, optional): Function that generates random values. Defaults to np.random.uniform.</span></span>
<span id="cb22-10"><a href="#cb22-10" aria-hidden="true" tabindex="-1"></a><span class="co">        tokenize (function, optional): Tokenizer function. Defaults to tokenize.</span></span>
<span id="cb22-11"><a href="#cb22-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-12"><a href="#cb22-12" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb22-13"><a href="#cb22-13" aria-hidden="true" tabindex="-1"></a><span class="co">        tuple: Tuple of lists of integers associated to inputs and targets.</span></span>
<span id="cb22-14"><a href="#cb22-14" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb22-15"><a href="#cb22-15" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb22-16"><a href="#cb22-16" aria-hidden="true" tabindex="-1"></a>    <span class="co"># current sentinel number (starts at 0)</span></span>
<span id="cb22-17"><a href="#cb22-17" aria-hidden="true" tabindex="-1"></a>    cur_sentinel_num <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb22-18"><a href="#cb22-18" aria-hidden="true" tabindex="-1"></a>    <span class="co"># inputs</span></span>
<span id="cb22-19"><a href="#cb22-19" aria-hidden="true" tabindex="-1"></a>    inps <span class="op">=</span> []</span>
<span id="cb22-20"><a href="#cb22-20" aria-hidden="true" tabindex="-1"></a>    <span class="co"># targets</span></span>
<span id="cb22-21"><a href="#cb22-21" aria-hidden="true" tabindex="-1"></a>    targs <span class="op">=</span> []</span>
<span id="cb22-22"><a href="#cb22-22" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb22-23"><a href="#cb22-23" aria-hidden="true" tabindex="-1"></a>    <span class="co"># prev_no_mask is True if the previous token was NOT masked, False otherwise</span></span>
<span id="cb22-24"><a href="#cb22-24" aria-hidden="true" tabindex="-1"></a>    <span class="co"># set prev_no_mask to True</span></span>
<span id="cb22-25"><a href="#cb22-25" aria-hidden="true" tabindex="-1"></a>    prev_no_mask <span class="op">=</span> <span class="va">True</span></span>
<span id="cb22-26"><a href="#cb22-26" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb22-27"><a href="#cb22-27" aria-hidden="true" tabindex="-1"></a>    <span class="co"># loop through tokenized `text`</span></span>
<span id="cb22-28"><a href="#cb22-28" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> token <span class="kw">in</span> tokenize(text):</span>
<span id="cb22-29"><a href="#cb22-29" aria-hidden="true" tabindex="-1"></a>        <span class="co"># check if the `noise` is greater than a random value (weighted coin flip)</span></span>
<span id="cb22-30"><a href="#cb22-30" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> randomizer() <span class="op">&lt;</span> noise:</span>
<span id="cb22-31"><a href="#cb22-31" aria-hidden="true" tabindex="-1"></a>            <span class="co"># check to see if the previous token was not masked</span></span>
<span id="cb22-32"><a href="#cb22-32" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> prev_no_mask<span class="op">==</span><span class="va">True</span>: <span class="co"># add new masked token at end_id</span></span>
<span id="cb22-33"><a href="#cb22-33" aria-hidden="true" tabindex="-1"></a>                <span class="co"># number of masked tokens increases by 1</span></span>
<span id="cb22-34"><a href="#cb22-34" aria-hidden="true" tabindex="-1"></a>                cur_sentinel_num <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb22-35"><a href="#cb22-35" aria-hidden="true" tabindex="-1"></a>                <span class="co"># compute `end_id` by subtracting current sentinel value out of the total vocabulary size</span></span>
<span id="cb22-36"><a href="#cb22-36" aria-hidden="true" tabindex="-1"></a>                end_id <span class="op">=</span> vocab_size <span class="op">-</span> cur_sentinel_num</span>
<span id="cb22-37"><a href="#cb22-37" aria-hidden="true" tabindex="-1"></a>                <span class="co"># append `end_id` at the end of the targets</span></span>
<span id="cb22-38"><a href="#cb22-38" aria-hidden="true" tabindex="-1"></a>                targs.append(end_id)</span>
<span id="cb22-39"><a href="#cb22-39" aria-hidden="true" tabindex="-1"></a>                <span class="co"># append `end_id` at the end of the inputs</span></span>
<span id="cb22-40"><a href="#cb22-40" aria-hidden="true" tabindex="-1"></a>                inps.append(end_id)</span>
<span id="cb22-41"><a href="#cb22-41" aria-hidden="true" tabindex="-1"></a>            <span class="co"># append `token` at the end of the targets</span></span>
<span id="cb22-42"><a href="#cb22-42" aria-hidden="true" tabindex="-1"></a>            targs.append(token)</span>
<span id="cb22-43"><a href="#cb22-43" aria-hidden="true" tabindex="-1"></a>            <span class="co"># set prev_no_mask accordingly</span></span>
<span id="cb22-44"><a href="#cb22-44" aria-hidden="true" tabindex="-1"></a>            prev_no_mask <span class="op">=</span> <span class="va">False</span></span>
<span id="cb22-45"><a href="#cb22-45" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb22-46"><a href="#cb22-46" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>: <span class="co"># don't have two masked tokens in a row</span></span>
<span id="cb22-47"><a href="#cb22-47" aria-hidden="true" tabindex="-1"></a>            <span class="co"># append `token ` at the end of the inputs</span></span>
<span id="cb22-48"><a href="#cb22-48" aria-hidden="true" tabindex="-1"></a>            inps.append(token)</span>
<span id="cb22-49"><a href="#cb22-49" aria-hidden="true" tabindex="-1"></a>            <span class="co"># set prev_no_mask accordingly</span></span>
<span id="cb22-50"><a href="#cb22-50" aria-hidden="true" tabindex="-1"></a>            prev_no_mask <span class="op">=</span> <span class="va">True</span></span>
<span id="cb22-51"><a href="#cb22-51" aria-hidden="true" tabindex="-1"></a>                </span>
<span id="cb22-52"><a href="#cb22-52" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> inps, targs</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-outputid="2b0dc5e4-8d58-4eb0-a146-0c9f158264ac" data-execution_count="15">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Some logic to mock a np.random value generator</span></span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Needs to be in the same cell for it to always generate same output</span></span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> testing_rnd():</span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> dummy_generator():</span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a>        vals <span class="op">=</span> np.linspace(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">10</span>)</span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a>        cyclic_vals <span class="op">=</span> itertools.cycle(vals)</span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">100</span>):</span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a>            <span class="cf">yield</span> <span class="bu">next</span>(cyclic_vals)</span>
<span id="cb23-9"><a href="#cb23-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-10"><a href="#cb23-10" aria-hidden="true" tabindex="-1"></a>    dumr <span class="op">=</span> itertools.cycle(dummy_generator())</span>
<span id="cb23-11"><a href="#cb23-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-12"><a href="#cb23-12" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> dummy_randomizer():</span>
<span id="cb23-13"><a href="#cb23-13" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="bu">next</span>(dumr)</span>
<span id="cb23-14"><a href="#cb23-14" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-15"><a href="#cb23-15" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> dummy_randomizer</span>
<span id="cb23-16"><a href="#cb23-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-17"><a href="#cb23-17" aria-hidden="true" tabindex="-1"></a>input_str <span class="op">=</span> natural_language_texts[<span class="dv">0</span>]</span>
<span id="cb23-18"><a href="#cb23-18" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"input string:</span><span class="ch">\n\n</span><span class="sc">{</span>input_str<span class="sc">}</span><span class="ch">\n</span><span class="ss">"</span>)</span>
<span id="cb23-19"><a href="#cb23-19" aria-hidden="true" tabindex="-1"></a>inps, targs <span class="op">=</span> tokenize_and_mask(input_str, randomizer<span class="op">=</span>testing_rnd())</span>
<span id="cb23-20"><a href="#cb23-20" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"tokenized inputs:</span><span class="ch">\n\n</span><span class="sc">{</span>inps<span class="sc">}</span><span class="ch">\n</span><span class="ss">"</span>)</span>
<span id="cb23-21"><a href="#cb23-21" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"targets:</span><span class="ch">\n\n</span><span class="sc">{</span>targs<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>input string:

b'Beginners BBQ Class Taking Place in Missoula!\nDo you want to get better at making delicious BBQ? You will have the opportunity, put this on your calendar now. Thursday, September 22nd join World Class BBQ Champion, Tony Balay from Lonestar Smoke Rangers. He will be teaching a beginner level class for everyone who wants to get better with their culinary skills.\nHe will teach you everything you need to know to compete in a KCBS BBQ competition, including techniques, recipes, timelines, meat selection and trimming, plus smoker and fire information.\nThe cost to be in the class is $35 per person, and for spectators it is free. Included in the cost will be either a t-shirt or apron and you will be tasting samples of each meat that is prepared.'

tokenized inputs:

[31999, 15068, 4501, 3, 12297, 3399, 16, 5964, 7115, 31998, 531, 25, 241, 12, 129, 394, 44, 492, 31997, 58, 148, 56, 43, 8, 1004, 6, 474, 31996, 39, 4793, 230, 5, 2721, 6, 1600, 1630, 31995, 1150, 4501, 15068, 16127, 6, 9137, 2659, 5595, 31994, 782, 3624, 14627, 15, 12612, 277, 5, 216, 31993, 2119, 3, 9, 19529, 593, 853, 21, 921, 31992, 12, 129, 394, 28, 70, 17712, 1098, 5, 31991, 3884, 25, 762, 25, 174, 12, 214, 12, 31990, 3, 9, 3, 23405, 4547, 15068, 2259, 6, 31989, 6, 5459, 6, 13618, 7, 6, 3604, 1801, 31988, 6, 303, 24190, 11, 1472, 251, 5, 37, 31987, 36, 16, 8, 853, 19, 25264, 399, 568, 31986, 21, 21380, 7, 34, 19, 339, 5, 15746, 31985, 8, 583, 56, 36, 893, 3, 9, 3, 31984, 9486, 42, 3, 9, 1409, 29, 11, 25, 31983, 12246, 5977, 13, 284, 3604, 24, 19, 2657, 31982]

targets:

[31999, 12847, 277, 31998, 9, 55, 31997, 3326, 15068, 31996, 48, 30, 31995, 727, 1715, 31994, 45, 301, 31993, 56, 36, 31992, 113, 2746, 31991, 216, 56, 31990, 5978, 16, 31989, 379, 2097, 31988, 11, 27856, 31987, 583, 12, 31986, 6, 11, 31985, 26, 16, 31984, 17, 18, 31983, 56, 36, 31982, 5]</code></pre>
</div>
</div>
<div class="cell" data-outputid="4330ae1e-1805-40c9-daf3-c6bbe92d957b" data-execution_count="16">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Inputs: </span><span class="ch">\n\n</span><span class="st">'</span>, pretty_decode(inps, sentinels))</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'</span><span class="ch">\n</span><span class="st">Targets: </span><span class="ch">\n\n</span><span class="st">'</span>, pretty_decode(targs, sentinels))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Inputs: 

 &lt;Z&gt; BBQ Class Taking Place in Missoul &lt;Y&gt; Do you want to get better at making &lt;X&gt;? You will have the opportunity, put &lt;W&gt; your calendar now. Thursday, September 22 &lt;V&gt; World Class BBQ Champion, Tony Balay &lt;U&gt;onestar Smoke Rangers. He &lt;T&gt; teaching a beginner level class for everyone&lt;S&gt; to get better with their culinary skills.&lt;R&gt; teach you everything you need to know to &lt;Q&gt; a KCBS BBQ competition,&lt;P&gt;, recipes, timelines, meat selection &lt;O&gt;, plus smoker and fire information. The&lt;N&gt; be in the class is $35 per person &lt;M&gt; for spectators it is free. Include &lt;L&gt; the cost will be either a  &lt;K&gt;shirt or apron and you &lt;J&gt; tasting samples of each meat that is prepared &lt;I&gt;

Targets: 

 &lt;Z&gt; Beginners &lt;Y&gt;a! &lt;X&gt; delicious BBQ &lt;W&gt; this on &lt;V&gt;nd join &lt;U&gt; from L &lt;T&gt; will be&lt;S&gt; who wants&lt;R&gt; He will &lt;Q&gt; compete in&lt;P&gt; including techniques &lt;O&gt; and trimming&lt;N&gt; cost to &lt;M&gt;, and &lt;L&gt;d in &lt;K&gt;t- &lt;J&gt; will be &lt;I&gt;.</code></pre>
</div>
</div>
<p>We will now use the inputs and the targets from the <code>tokenize_and_mask</code> function we implemented above.</p>
</section>
<section id="creating-the-pairs" class="level3" data-number="3.4">
<h3 data-number="3.4" class="anchored" data-anchor-id="creating-the-pairs"><span class="header-section-number">3.4</span> Creating the Pairs</h3>
<p>We will now create pairs using our dataset. We will iterate over our data and create (inp, targ) pairs using the functions already defined.</p>
<div class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply tokenize_and_mask</span></span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>inputs_targets_pairs <span class="op">=</span> [tokenize_and_mask(text) <span class="cf">for</span> text <span class="kw">in</span> natural_language_texts]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-outputid="fc194524-41de-4d3b-87d9-ae35c29c9f79" data-execution_count="19">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> display_input_target_pairs(inputs_targets_pairs, sentinels, wrapper<span class="op">=</span>textwrap.TextWrapper(width<span class="op">=</span><span class="dv">70</span>)):</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i, inp_tgt_pair <span class="kw">in</span> <span class="bu">enumerate</span>(inputs_targets_pairs, <span class="dv">1</span>):</span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a>        inps, tgts <span class="op">=</span> inp_tgt_pair</span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a>        inps, tgts <span class="op">=</span> pretty_decode(inps, sentinels), pretty_decode(tgts, sentinels)</span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f'[</span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">]</span><span class="ch">\n\n</span><span class="ss">'</span></span>
<span id="cb28-6"><a href="#cb28-6" aria-hidden="true" tabindex="-1"></a>              <span class="ss">f'inputs:</span><span class="ch">\n</span><span class="sc">{</span>wrapper<span class="sc">.</span>fill(text<span class="op">=</span>inps)<span class="sc">}</span><span class="ch">\n\n</span><span class="ss">'</span></span>
<span id="cb28-7"><a href="#cb28-7" aria-hidden="true" tabindex="-1"></a>              <span class="ss">f'targets:</span><span class="ch">\n</span><span class="sc">{</span>wrapper<span class="sc">.</span>fill(text<span class="op">=</span>tgts)<span class="sc">}</span><span class="ch">\n\n\n\n</span><span class="ss">'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="20">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a>display_input_target_pairs(inputs_targets_pairs, sentinels, wrapper)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1]

inputs:
Beginners BBQ Class Taking Place in Missoula! Do you &lt;Z&gt; to get better
at making delicious BBQ? You will have the opportunity, put this on
your calendar now. Thursday, September 22nd join World Class &lt;Y&gt;
Champion, Tony Ba &lt;X&gt; from Lone &lt;W&gt;e Rangers. He will be teaching  &lt;V&gt;
beginner level class for everyone who wants &lt;U&gt; get better with their
culinary &lt;T&gt;. He&lt;S&gt; teach you everything you&lt;R&gt; to know to compete in
a KCBS BBQ competition, including techniques, &lt;Q&gt;, timelines,&lt;P&gt;
selection and &lt;O&gt;, plus smoker and fire information. The cost to be in
the class is $35 per&lt;N&gt; and for &lt;M&gt;s it &lt;L&gt; free. &lt;K&gt;d in &lt;J&gt; will be
either a t-shirt or  &lt;I&gt;pron and you will be tasting samples of each
meat that is prepared.

targets:
&lt;Z&gt; want &lt;Y&gt; BBQ &lt;X&gt;lay &lt;W&gt;star Smok &lt;V&gt;a &lt;U&gt; to &lt;T&gt; skills&lt;S&gt; will&lt;R&gt;
need &lt;Q&gt; recipes&lt;P&gt; meat &lt;O&gt; trimming&lt;N&gt; person, &lt;M&gt; spectator &lt;L&gt; is
&lt;K&gt; Include &lt;J&gt; the cost &lt;I&gt;a




[2]

inputs:
Discussion in ' &lt;Z&gt; OS X Lion (10.7) &lt;Y&gt; axboi87, Jan 20, 2012. I've
&lt;X&gt; a 500gb internal drive and &lt;W&gt;a 240gb SSD. When trying to restore
using &lt;V&gt; utility i'm given &lt;U&gt; error "Not enough space &lt;T&gt; disk
&lt;S&gt;___ to restore"&lt;R&gt; I shouldn't have to do that!!! Any ideas or
workarounds before resort &lt;Q&gt; the above&lt;P&gt; Use Carbon &lt;O&gt; Cloner to
copy one drive to the other. I've done this several times&lt;N&gt; from
larger HD &lt;M&gt; to &lt;L&gt; I &lt;K&gt; up with a bootable SSD drive &lt;J&gt; One &lt;I&gt;
you have&lt;H&gt; remember not to skip is to use Disk Utility to partition
the SSD as GUID partition scheme HFS+ before&lt;G&gt; the clone. If it came
Apple &lt;F&gt;ition Scheme,&lt;E&gt;if you let CCC do the clone, the resulting
drive won't be bootable.&lt;D&gt;CC&lt;C&gt; works in "file mode" &lt;B&gt; can &lt;A&gt; copy
a larger drive (that &lt;z&gt; mostly empty) onto a smaller drive. If &lt;y&gt;
tell C&lt;x&gt; to&lt;w&gt;clone a drive you did NOT&lt;v&gt; from, it can work in block
copy mode&lt;u&gt; the destination drive must be the same size or larger
than the drive you &lt;t&gt; cloning from (if I recall). I've actually done
this somehow on Disk Utility several times (booting from a different
drive ( &lt;s&gt; even the dvd) so&lt;r&gt; disk utility from&lt;q&gt; your cloning)
and&lt;p&gt; work just fine from larger &lt;o&gt; smaller bootable clone &lt;n&gt;
Definitely &lt;m&gt; the drive clo &lt;l&gt;ing to&lt;k&gt;, &lt;j&gt; boot&lt;i&gt; Apple etc..
Thanks for pointing this&lt;h&gt; My only&lt;g&gt; using DU to go larger to &lt;f&gt;
was when I was trying&lt;e&gt; make a Lion install &lt;d&gt; and &lt;c&gt; was unable to
restore InstallESD.dmg to a 4 GB USB stick but of &lt;b&gt; the reason that
wouldn't fit is there was &lt;a&gt; more than Théâtre GB of data.

targets:
&lt;Z&gt;Mac &lt;Y&gt;' started by &lt;X&gt; got &lt;W&gt;  &lt;V&gt; disk &lt;U&gt; the &lt;T&gt; on&lt;S&gt;_&lt;R&gt; But
&lt;Q&gt;ing to&lt;P&gt;? &lt;O&gt; Copy&lt;N&gt; going &lt;M&gt;D &lt;L&gt; smaller SSD and &lt;K&gt; wound
&lt;J&gt;. &lt;I&gt; step&lt;H&gt; to&lt;G&gt; doing &lt;F&gt; Part&lt;E&gt; even &lt;D&gt; C&lt;C&gt; usually &lt;B&gt; and
it &lt;A&gt; easily &lt;z&gt;'s &lt;y&gt; you&lt;x&gt;CC&lt;w&gt; &lt;v&gt; boot&lt;u&gt; where &lt;t&gt; are &lt;s&gt;or&lt;r&gt;
not running&lt;q&gt; the drive&lt;p&gt; had it &lt;o&gt; to &lt;n&gt;. &lt;m&gt; format &lt;l&gt;n&lt;k&gt;
first &lt;j&gt; as&lt;i&gt;able&lt;h&gt; out.&lt;g&gt; experience &lt;f&gt; smaller&lt;e&gt; to &lt;d&gt; stick
&lt;c&gt; I &lt;b&gt; course &lt;a&gt; slightly Théâtre 4




[3]

inputs:
&lt;Z&gt;il plaid lycra and span &lt;Y&gt;ex shortall with metallic slink &lt;X&gt;
inset &lt;W&gt;. Attached metallic elastic belt with O &lt;V&gt;ring. Headband
included. &lt;U&gt; hip &lt;T&gt; jazz dance costume.&lt;S&gt; in the USA.

targets:
&lt;Z&gt; Fo &lt;Y&gt;d &lt;X&gt;y &lt;W&gt;s &lt;V&gt;- &lt;U&gt; Great &lt;T&gt; hop or&lt;S&gt; Made




[4]

inputs:
&lt;Z&gt; many backlinks per day for new site &lt;Y&gt; Discussion in &lt;X&gt;'Black
Hat SEO' started by Omopla &lt;W&gt;a, Dec 3, 2010. 1) for &lt;V&gt;a newly
created site, what's the max # backlinks per &lt;U&gt; I should do to be
safe? 2) how &lt;T&gt; do I have to let my site age before I can start
making&lt;S&gt;s? I did about 6000 forum profiles every 24 hours for 10 days
for one of my sites&lt;R&gt; had a brand new &lt;Q&gt; There is three back&lt;P&gt;s for
every of these forum profile so thats 18 000 &lt;O&gt;links every&lt;N&gt; hours
and nothing happened in terms &lt;M&gt; being &lt;L&gt;ized or  &lt;K&gt;andbox &lt;J&gt;d &lt;I&gt;
This is now&lt;H&gt; 3 months ago and the&lt;G&gt; is ranking on first page &lt;F&gt; a
lot of my targeted keywords. build more you can in starting but do
manual submission and not spammy type means manual +&lt;E&gt; to the
post.&lt;D&gt; then after 1 month&lt;C&gt; can make  &lt;B&gt; big blast.. Wow, dude,
you &lt;A&gt; 18k backlinks a day on  &lt;z&gt; brand new site? How quickly did
you rank up? What kind of competition/search &lt;y&gt;s did those keywords
have?

targets:
&lt;Z&gt; How &lt;Y&gt;? &lt;X&gt;  &lt;W&gt;t &lt;V&gt;  &lt;U&gt; day &lt;T&gt; long&lt;S&gt; more blink&lt;R&gt; which
&lt;Q&gt; domain.&lt;P&gt;link &lt;O&gt; back&lt;N&gt; 24 &lt;M&gt; of &lt;L&gt; penal &lt;K&gt;s &lt;J&gt;e &lt;I&gt;.&lt;H&gt;
maybe&lt;G&gt; site &lt;F&gt; for&lt;E&gt; relevant&lt;D&gt;.&lt;C&gt; you &lt;B&gt;a &lt;A&gt; built &lt;z&gt;a &lt;y&gt;e




[5]

inputs:
The Denver Board of Education opened the &lt;Z&gt;-18 school year with an
&lt;Y&gt; on projects &lt;X&gt; include new &lt;W&gt;, upgrades, &lt;V&gt; mitigation and
quality learning environments. We &lt;U&gt; that &lt;T&gt; students will be the
beneficiaries&lt;S&gt; a four year, $572 million General Obligation Bond.
Since the passage of the&lt;R&gt;, our construction team has worked to &lt;Q&gt;
the projects over the four-year term of the&lt;P&gt;. Denver voters on
Tuesday approved bond and mill &lt;O&gt; measures for students in Denver
Public Schools, agreeing to invest $5&lt;N&gt; million in &lt;M&gt; funding to
build and improve schools and $56.6 million in operating dollars to
&lt;L&gt; proven initiatives, such as early literacy. Denver voters say &lt;K&gt;
to bond and mill levy &lt;J&gt; support for D &lt;I&gt; students and schools.
Click to learn more about&lt;H&gt; details of the voter-approved bond
measure. Denver voters on&lt;G&gt;. 8 approved bond and mill funding
measures for DPS students and schools. Learn more about &lt;F&gt;’s included
in the mill &lt;E&gt;.

targets:
&lt;Z&gt; 2017 &lt;Y&gt; update &lt;X&gt; that &lt;W&gt; construction &lt;V&gt; heat &lt;U&gt; are excited
&lt;T&gt; Denver&lt;S&gt; of&lt;R&gt; bond &lt;Q&gt; schedule&lt;P&gt; bond &lt;O&gt; funding&lt;N&gt;72 &lt;M&gt;
bond &lt;L&gt; support &lt;K&gt; yes &lt;J&gt; funding &lt;I&gt;PS&lt;H&gt; the&lt;G&gt; Nov &lt;F&gt;
what&lt;E&gt;levy measure



</code></pre>
</div>
</div>
</section>
</section>
<section id="transformer" class="level2" data-number="4">
<h2 data-number="4" class="anchored" data-anchor-id="transformer"><span class="header-section-number">4</span> Transformer</h2>
<p>We now load a Transformer model checkpoint that has been pre-trained using the above C4 dataset and decode from it. This will save us a lot of time rather than have to train our model from scratch. Later we will see how to fine-tune our model.</p>
<p><img src="https://github.com/pranath/blog/raw/master/images/fulltransformer.png" width="300" height="600"></p>
<p>We will start by loading in the model. We copy the checkpoint to local dir for speed, otherwise initialization takes a very long time. Now you will implement the encoder part of the transformer architecture for this. Concretely we will implement the following.</p>
<p><img src="https://github.com/pranath/blog/raw/master/images/encoder.png" width="300" height="600"></p>
</section>
<section id="transformer-encoder" class="level2" data-number="5">
<h2 data-number="5" class="anchored" data-anchor-id="transformer-encoder"><span class="header-section-number">5</span> Transformer Encoder</h2>
<p>We will now implement the transformer encoder. Concretely we will implement two functions. The first function is <code>FeedForwardBlock</code>.</p>
<section id="the-feedforward-block" class="level3" data-number="5.1">
<h3 data-number="5.1" class="anchored" data-anchor-id="the-feedforward-block"><span class="header-section-number">5.1</span> The Feedforward Block</h3>
<p>The <code>FeedForwardBlock</code> function is an important one so we will start by implementing it. To do so, we need to return a list of the following:</p>
<ul>
<li><a href="https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.normalization.LayerNorm"><code>tl.LayerNorm()</code></a> = layer normalization.</li>
<li><a href="https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.core.Dense"><code>tl.Dense(d_ff)</code></a> = fully connected layer.</li>
<li><a href="https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.activation_fns.Relu"><code>activation</code></a> = activation relu, tanh, sigmoid etc.</li>
<li><code>dropout_middle</code> = we gave you this function (don’t worry about its implementation).</li>
<li><a href="https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.core.Dense"><code>tl.Dense(d_model)</code></a> = fully connected layer with same dimension as the model.</li>
<li><code>dropout_final</code> = we gave you this function (don’t worry about its implementation).</li>
</ul>
<p>We can always take a look at <a href="https://trax-ml.readthedocs.io/en/latest/">trax documentation</a> if needed.</p>
<div class="cell" data-execution_count="21">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> FeedForwardBlock(d_model, d_ff, dropout, dropout_shared_axes, mode, activation):</span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Returns a list of layers implementing a feed-forward block.</span></span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Args:</span></span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a><span class="co">        d_model: int:  depth of embedding</span></span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a><span class="co">        d_ff: int: depth of feed-forward layer</span></span>
<span id="cb31-6"><a href="#cb31-6" aria-hidden="true" tabindex="-1"></a><span class="co">        dropout: float: dropout rate (how much to drop out)</span></span>
<span id="cb31-7"><a href="#cb31-7" aria-hidden="true" tabindex="-1"></a><span class="co">        dropout_shared_axes: list of integers, axes to share dropout mask</span></span>
<span id="cb31-8"><a href="#cb31-8" aria-hidden="true" tabindex="-1"></a><span class="co">        mode: str: 'train' or 'eval'</span></span>
<span id="cb31-9"><a href="#cb31-9" aria-hidden="true" tabindex="-1"></a><span class="co">        activation: the non-linearity in feed-forward layer</span></span>
<span id="cb31-10"><a href="#cb31-10" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb31-11"><a href="#cb31-11" aria-hidden="true" tabindex="-1"></a><span class="co">        A list of layers which maps vectors to vectors.</span></span>
<span id="cb31-12"><a href="#cb31-12" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb31-13"><a href="#cb31-13" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb31-14"><a href="#cb31-14" aria-hidden="true" tabindex="-1"></a>    dropout_middle <span class="op">=</span> tl.Dropout(rate<span class="op">=</span>dropout,</span>
<span id="cb31-15"><a href="#cb31-15" aria-hidden="true" tabindex="-1"></a>                                shared_axes<span class="op">=</span>dropout_shared_axes, </span>
<span id="cb31-16"><a href="#cb31-16" aria-hidden="true" tabindex="-1"></a>                                mode<span class="op">=</span>mode)</span>
<span id="cb31-17"><a href="#cb31-17" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb31-18"><a href="#cb31-18" aria-hidden="true" tabindex="-1"></a>    dropout_final <span class="op">=</span> tl.Dropout(rate<span class="op">=</span>dropout, </span>
<span id="cb31-19"><a href="#cb31-19" aria-hidden="true" tabindex="-1"></a>                               shared_axes<span class="op">=</span>dropout_shared_axes, </span>
<span id="cb31-20"><a href="#cb31-20" aria-hidden="true" tabindex="-1"></a>                               mode<span class="op">=</span>mode)</span>
<span id="cb31-21"><a href="#cb31-21" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb31-22"><a href="#cb31-22" aria-hidden="true" tabindex="-1"></a>    ff_block <span class="op">=</span> [ </span>
<span id="cb31-23"><a href="#cb31-23" aria-hidden="true" tabindex="-1"></a>        <span class="co"># trax Layer normalization </span></span>
<span id="cb31-24"><a href="#cb31-24" aria-hidden="true" tabindex="-1"></a>        tl.LayerNorm(),</span>
<span id="cb31-25"><a href="#cb31-25" aria-hidden="true" tabindex="-1"></a>        <span class="co"># trax Dense layer using `d_ff`</span></span>
<span id="cb31-26"><a href="#cb31-26" aria-hidden="true" tabindex="-1"></a>        tl.Dense(d_ff),</span>
<span id="cb31-27"><a href="#cb31-27" aria-hidden="true" tabindex="-1"></a>        <span class="co"># activation() layer - you need to call (use parentheses) this func!</span></span>
<span id="cb31-28"><a href="#cb31-28" aria-hidden="true" tabindex="-1"></a>        activation(),</span>
<span id="cb31-29"><a href="#cb31-29" aria-hidden="true" tabindex="-1"></a>        <span class="co"># dropout middle layer</span></span>
<span id="cb31-30"><a href="#cb31-30" aria-hidden="true" tabindex="-1"></a>        dropout_middle,</span>
<span id="cb31-31"><a href="#cb31-31" aria-hidden="true" tabindex="-1"></a>        <span class="co"># trax Dense layer using `d_model`</span></span>
<span id="cb31-32"><a href="#cb31-32" aria-hidden="true" tabindex="-1"></a>        tl.Dense(d_model),</span>
<span id="cb31-33"><a href="#cb31-33" aria-hidden="true" tabindex="-1"></a>        <span class="co"># dropout final layer</span></span>
<span id="cb31-34"><a href="#cb31-34" aria-hidden="true" tabindex="-1"></a>        dropout_final,</span>
<span id="cb31-35"><a href="#cb31-35" aria-hidden="true" tabindex="-1"></a>    ]</span>
<span id="cb31-36"><a href="#cb31-36" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb31-37"><a href="#cb31-37" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> ff_block</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-outputid="0ea9ddf6-f2e0-4b96-edb7-3b04d869295a" data-execution_count="22">
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the block layout</span></span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a>feed_forward_example <span class="op">=</span> FeedForwardBlock(d_model<span class="op">=</span><span class="dv">512</span>, d_ff<span class="op">=</span><span class="dv">2048</span>, dropout<span class="op">=</span><span class="fl">0.8</span>, dropout_shared_axes<span class="op">=</span><span class="dv">0</span>, mode <span class="op">=</span> <span class="st">'train'</span>, activation <span class="op">=</span> tl.Relu)</span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(feed_forward_example)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[LayerNorm, Dense_2048, Serial[
  Relu
], Dropout, Dense_512, Dropout]</code></pre>
</div>
</div>
<div class="cell" data-execution_count="23">
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a>FeedForwardBlock(d_model<span class="op">=</span><span class="dv">16</span>, d_ff<span class="op">=</span><span class="dv">64</span>, dropout<span class="op">=</span><span class="fl">0.1</span>, dropout_shared_axes<span class="op">=</span><span class="dv">0</span>, mode <span class="op">=</span> <span class="st">'train'</span>, activation <span class="op">=</span> tl.Relu)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="23">
<pre><code>[LayerNorm,
 Dense_64,
 Serial[
   Relu
 ],
 Dropout,
 Dense_16,
 Dropout]</code></pre>
</div>
</div>
<div class="cell" data-execution_count="24">
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a>test_func <span class="op">=</span> <span class="kw">lambda</span> x: <span class="bu">list</span>((<span class="bu">map</span>(<span class="bu">type</span>, x)))</span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a>test_func(FeedForwardBlock(d_model<span class="op">=</span><span class="dv">16</span>, d_ff<span class="op">=</span><span class="dv">64</span>, dropout<span class="op">=</span><span class="fl">0.1</span>, dropout_shared_axes<span class="op">=</span><span class="dv">0</span>, mode <span class="op">=</span> <span class="st">'train'</span>, activation <span class="op">=</span> tl.Relu))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="24">
<pre><code>[trax.layers.normalization.LayerNorm,
 trax.layers.core.Dense,
 trax.layers.combinators.Serial,
 trax.layers.core.Dropout,
 trax.layers.core.Dense,
 trax.layers.core.Dropout]</code></pre>
</div>
</div>
</section>
<section id="the-encoder-block" class="level3" data-number="5.2">
<h3 data-number="5.2" class="anchored" data-anchor-id="the-encoder-block"><span class="header-section-number">5.2</span> The Encoder Block</h3>
<p>The encoder block will use the <code>FeedForwardBlock</code>.</p>
<p>We will have to build two residual connections. Inside the first residual connection we will have the <code>tl.LayerNorm()</code>, <code>attention</code>, and <code>dropout_</code> layers. The second residual connection will have the <code>feed_forward</code>.</p>
<p>We will also need to implement <code>feed_forward</code>, <code>attention</code> and <code>dropout_</code> blocks.</p>
<p>So far we haven’t seen the <a href="https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.attention.Attention"><code>tl.Attention()</code></a> and <a href="https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.combinators.Residual"><code>tl.Residual()</code></a> layers so we can check the docs by clicking on them.</p>
<div class="cell" data-execution_count="26">
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> EncoderBlock(d_model, d_ff, n_heads, dropout, dropout_shared_axes,</span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a>                  mode, ff_activation, FeedForwardBlock<span class="op">=</span>FeedForwardBlock):</span>
<span id="cb38-3"><a href="#cb38-3" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb38-4"><a href="#cb38-4" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns a list of layers that implements a Transformer encoder block.</span></span>
<span id="cb38-5"><a href="#cb38-5" aria-hidden="true" tabindex="-1"></a><span class="co">    The input to the layer is a pair, (activations, mask), where the mask was</span></span>
<span id="cb38-6"><a href="#cb38-6" aria-hidden="true" tabindex="-1"></a><span class="co">    created from the original source tokens to prevent attending to the padding</span></span>
<span id="cb38-7"><a href="#cb38-7" aria-hidden="true" tabindex="-1"></a><span class="co">    part of the input.</span></span>
<span id="cb38-8"><a href="#cb38-8" aria-hidden="true" tabindex="-1"></a><span class="co">    </span></span>
<span id="cb38-9"><a href="#cb38-9" aria-hidden="true" tabindex="-1"></a><span class="co">    Args:</span></span>
<span id="cb38-10"><a href="#cb38-10" aria-hidden="true" tabindex="-1"></a><span class="co">        d_model (int): depth of embedding.</span></span>
<span id="cb38-11"><a href="#cb38-11" aria-hidden="true" tabindex="-1"></a><span class="co">        d_ff (int): depth of feed-forward layer.</span></span>
<span id="cb38-12"><a href="#cb38-12" aria-hidden="true" tabindex="-1"></a><span class="co">        n_heads (int): number of attention heads.</span></span>
<span id="cb38-13"><a href="#cb38-13" aria-hidden="true" tabindex="-1"></a><span class="co">        dropout (float): dropout rate (how much to drop out).</span></span>
<span id="cb38-14"><a href="#cb38-14" aria-hidden="true" tabindex="-1"></a><span class="co">        dropout_shared_axes (int): axes on which to share dropout mask.</span></span>
<span id="cb38-15"><a href="#cb38-15" aria-hidden="true" tabindex="-1"></a><span class="co">        mode (str): 'train' or 'eval'.</span></span>
<span id="cb38-16"><a href="#cb38-16" aria-hidden="true" tabindex="-1"></a><span class="co">        ff_activation (function): the non-linearity in feed-forward layer.</span></span>
<span id="cb38-17"><a href="#cb38-17" aria-hidden="true" tabindex="-1"></a><span class="co">        FeedForwardBlock (function): A function that returns the feed forward block.</span></span>
<span id="cb38-18"><a href="#cb38-18" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb38-19"><a href="#cb38-19" aria-hidden="true" tabindex="-1"></a><span class="co">        list: A list of layers that maps (activations, mask) to (activations, mask).</span></span>
<span id="cb38-20"><a href="#cb38-20" aria-hidden="true" tabindex="-1"></a><span class="co">        </span></span>
<span id="cb38-21"><a href="#cb38-21" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb38-22"><a href="#cb38-22" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb38-23"><a href="#cb38-23" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Attention block</span></span>
<span id="cb38-24"><a href="#cb38-24" aria-hidden="true" tabindex="-1"></a>    attention <span class="op">=</span> tl.Attention( </span>
<span id="cb38-25"><a href="#cb38-25" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Use dimension of the model</span></span>
<span id="cb38-26"><a href="#cb38-26" aria-hidden="true" tabindex="-1"></a>        d_feature<span class="op">=</span>d_model,</span>
<span id="cb38-27"><a href="#cb38-27" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Set it equal to number of attention heads</span></span>
<span id="cb38-28"><a href="#cb38-28" aria-hidden="true" tabindex="-1"></a>        n_heads<span class="op">=</span>n_heads,</span>
<span id="cb38-29"><a href="#cb38-29" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Set it equal `dropout`</span></span>
<span id="cb38-30"><a href="#cb38-30" aria-hidden="true" tabindex="-1"></a>        dropout<span class="op">=</span>dropout,</span>
<span id="cb38-31"><a href="#cb38-31" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Set it equal `mode`</span></span>
<span id="cb38-32"><a href="#cb38-32" aria-hidden="true" tabindex="-1"></a>        mode<span class="op">=</span>mode</span>
<span id="cb38-33"><a href="#cb38-33" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb38-34"><a href="#cb38-34" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb38-35"><a href="#cb38-35" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Call the function `FeedForwardBlock` (implemented before) and pass in the parameters</span></span>
<span id="cb38-36"><a href="#cb38-36" aria-hidden="true" tabindex="-1"></a>    feed_forward <span class="op">=</span> FeedForwardBlock( </span>
<span id="cb38-37"><a href="#cb38-37" aria-hidden="true" tabindex="-1"></a>        d_model,</span>
<span id="cb38-38"><a href="#cb38-38" aria-hidden="true" tabindex="-1"></a>        d_ff,</span>
<span id="cb38-39"><a href="#cb38-39" aria-hidden="true" tabindex="-1"></a>        dropout,</span>
<span id="cb38-40"><a href="#cb38-40" aria-hidden="true" tabindex="-1"></a>        dropout_shared_axes,</span>
<span id="cb38-41"><a href="#cb38-41" aria-hidden="true" tabindex="-1"></a>        mode,</span>
<span id="cb38-42"><a href="#cb38-42" aria-hidden="true" tabindex="-1"></a>        ff_activation</span>
<span id="cb38-43"><a href="#cb38-43" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb38-44"><a href="#cb38-44" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb38-45"><a href="#cb38-45" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Dropout block</span></span>
<span id="cb38-46"><a href="#cb38-46" aria-hidden="true" tabindex="-1"></a>    dropout_ <span class="op">=</span> tl.Dropout( </span>
<span id="cb38-47"><a href="#cb38-47" aria-hidden="true" tabindex="-1"></a>        <span class="co"># set it equal to `dropout`</span></span>
<span id="cb38-48"><a href="#cb38-48" aria-hidden="true" tabindex="-1"></a>        rate<span class="op">=</span>dropout,</span>
<span id="cb38-49"><a href="#cb38-49" aria-hidden="true" tabindex="-1"></a>        <span class="co"># set it equal to the axes on which to share dropout mask</span></span>
<span id="cb38-50"><a href="#cb38-50" aria-hidden="true" tabindex="-1"></a>        shared_axes<span class="op">=</span>dropout_shared_axes,</span>
<span id="cb38-51"><a href="#cb38-51" aria-hidden="true" tabindex="-1"></a>        <span class="co"># set it equal to `mode`</span></span>
<span id="cb38-52"><a href="#cb38-52" aria-hidden="true" tabindex="-1"></a>        mode<span class="op">=</span>mode</span>
<span id="cb38-53"><a href="#cb38-53" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb38-54"><a href="#cb38-54" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb38-55"><a href="#cb38-55" aria-hidden="true" tabindex="-1"></a>    encoder_block <span class="op">=</span> [ </span>
<span id="cb38-56"><a href="#cb38-56" aria-hidden="true" tabindex="-1"></a>        <span class="co"># add `Residual` layer</span></span>
<span id="cb38-57"><a href="#cb38-57" aria-hidden="true" tabindex="-1"></a>        tl.Residual(</span>
<span id="cb38-58"><a href="#cb38-58" aria-hidden="true" tabindex="-1"></a>            <span class="co"># add norm layer</span></span>
<span id="cb38-59"><a href="#cb38-59" aria-hidden="true" tabindex="-1"></a>            tl.LayerNorm(),</span>
<span id="cb38-60"><a href="#cb38-60" aria-hidden="true" tabindex="-1"></a>            <span class="co"># add attention</span></span>
<span id="cb38-61"><a href="#cb38-61" aria-hidden="true" tabindex="-1"></a>            attention,</span>
<span id="cb38-62"><a href="#cb38-62" aria-hidden="true" tabindex="-1"></a>            <span class="co"># add dropout</span></span>
<span id="cb38-63"><a href="#cb38-63" aria-hidden="true" tabindex="-1"></a>            dropout_,</span>
<span id="cb38-64"><a href="#cb38-64" aria-hidden="true" tabindex="-1"></a>        ),</span>
<span id="cb38-65"><a href="#cb38-65" aria-hidden="true" tabindex="-1"></a>        <span class="co"># add another `Residual` layer</span></span>
<span id="cb38-66"><a href="#cb38-66" aria-hidden="true" tabindex="-1"></a>        tl.Residual(</span>
<span id="cb38-67"><a href="#cb38-67" aria-hidden="true" tabindex="-1"></a>            <span class="co"># add feed forward</span></span>
<span id="cb38-68"><a href="#cb38-68" aria-hidden="true" tabindex="-1"></a>            feed_forward,</span>
<span id="cb38-69"><a href="#cb38-69" aria-hidden="true" tabindex="-1"></a>        ),</span>
<span id="cb38-70"><a href="#cb38-70" aria-hidden="true" tabindex="-1"></a>    ]</span>
<span id="cb38-71"><a href="#cb38-71" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb38-72"><a href="#cb38-72" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> encoder_block</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="27">
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the block layout</span></span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a>encoder_example <span class="op">=</span> EncoderBlock(d_model<span class="op">=</span><span class="dv">512</span>, d_ff<span class="op">=</span><span class="dv">2048</span>, n_heads<span class="op">=</span><span class="dv">6</span>, dropout<span class="op">=</span><span class="fl">0.8</span>, dropout_shared_axes<span class="op">=</span><span class="dv">0</span>, mode <span class="op">=</span> <span class="st">'train'</span>, ff_activation<span class="op">=</span>tl.Relu)</span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(encoder_example)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[Serial_in2_out2[
  Branch_in2_out3[
    None
    Serial_in2_out2[
      LayerNorm
      Serial_in2_out2[
        _in2_out2
        Serial_in2_out2[
          Select[0,0,0]_out3
          Serial_in4_out2[
            _in4_out4
            Serial_in4_out2[
              Parallel_in3_out3[
                Dense_512
                Dense_512
                Dense_512
              ]
              PureAttention_in4_out2
              Dense_512
            ]
            _in2_out2
          ]
        ]
        _in2_out2
      ]
      Dropout
    ]
  ]
  Add_in2
], Serial[
  Branch_out2[
    None
    Serial[
      LayerNorm
      Dense_2048
      Serial[
        Relu
      ]
      Dropout
      Dense_512
      Dropout
    ]
  ]
  Add_in2
]]</code></pre>
</div>
</div>
</section>
<section id="the-transformer-encoder" class="level3" data-number="5.3">
<h3 data-number="5.3" class="anchored" data-anchor-id="the-transformer-encoder"><span class="header-section-number">5.3</span> The Transformer Encoder</h3>
<p>Now that we have implemented the <code>EncoderBlock</code>, it is time to build the full encoder. BERT, or Bidirectional Encoder Representations from Transformers is one such encoder.</p>
<p>We will implement its core code in the function below by using the functions we have coded so far.</p>
<p>The model takes in many hyperparameters, such as the <code>vocab_size</code>, the number of classes, the dimension of your model, etc. We want to build a generic function that will take in many parameters, so we can use it later. At the end of the day, anyone can just load in an API and call transformer, but it is helpful to understand how it is built. Let’s get started.</p>
<p>For this encoder we will need a <code>positional_encoder</code> first (which is already provided) followed by <code>n_layers</code> encoder blocks, which are the same encoder blocks we previously built. Once we store the <code>n_layers</code> <code>EncoderBlock</code> in a list, we are going to encode a <code>Serial</code> layer with the following sublayers:</p>
<ul>
<li><a href="https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.combinators.Branch"><code>tl.Branch</code></a>: helps with the branching and has the following sublayers:
<ul>
<li><code>positional_encoder</code>.</li>
<li><a href="https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.attention.PaddingMask"><code>tl.PaddingMask()</code></a>: layer that maps integer sequences to padding masks.</li>
</ul></li>
<li>Your list of <code>EncoderBlock</code>s</li>
<li><a href="https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.combinators.Select"><code>tl.Select([0], n_in=2)</code></a>: Copies, reorders, or deletes stack elements according to indices.</li>
<li><a href="https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.normalization.LayerNorm"><code>tl.LayerNorm()</code></a>.</li>
<li><a href="https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.core.Mean"><code>tl.Mean()</code></a>: Mean along the first axis.</li>
<li><code>tl.Dense()</code> with n_units set to n_classes.</li>
<li><code>tl.LogSoftmax()</code></li>
</ul>
<p>Please refer to the <a href="https://trax-ml.readthedocs.io/en/latest/">trax documentation</a> for further information.</p>
<div class="cell" data-execution_count="29">
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> TransformerEncoder(vocab_size<span class="op">=</span><span class="dv">32000</span>,</span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a>                       n_classes<span class="op">=</span><span class="dv">10</span>,</span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a>                       d_model<span class="op">=</span><span class="dv">512</span>,</span>
<span id="cb41-4"><a href="#cb41-4" aria-hidden="true" tabindex="-1"></a>                       d_ff<span class="op">=</span><span class="dv">2048</span>,</span>
<span id="cb41-5"><a href="#cb41-5" aria-hidden="true" tabindex="-1"></a>                       n_layers<span class="op">=</span><span class="dv">6</span>,</span>
<span id="cb41-6"><a href="#cb41-6" aria-hidden="true" tabindex="-1"></a>                       n_heads<span class="op">=</span><span class="dv">8</span>,</span>
<span id="cb41-7"><a href="#cb41-7" aria-hidden="true" tabindex="-1"></a>                       dropout<span class="op">=</span><span class="fl">0.1</span>,</span>
<span id="cb41-8"><a href="#cb41-8" aria-hidden="true" tabindex="-1"></a>                       dropout_shared_axes<span class="op">=</span><span class="va">None</span>,</span>
<span id="cb41-9"><a href="#cb41-9" aria-hidden="true" tabindex="-1"></a>                       max_len<span class="op">=</span><span class="dv">2048</span>,</span>
<span id="cb41-10"><a href="#cb41-10" aria-hidden="true" tabindex="-1"></a>                       mode<span class="op">=</span><span class="st">'train'</span>,</span>
<span id="cb41-11"><a href="#cb41-11" aria-hidden="true" tabindex="-1"></a>                       ff_activation<span class="op">=</span>tl.Relu,</span>
<span id="cb41-12"><a href="#cb41-12" aria-hidden="true" tabindex="-1"></a>                      EncoderBlock<span class="op">=</span>EncoderBlock):</span>
<span id="cb41-13"><a href="#cb41-13" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb41-14"><a href="#cb41-14" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb41-15"><a href="#cb41-15" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns a Transformer encoder model.</span></span>
<span id="cb41-16"><a href="#cb41-16" aria-hidden="true" tabindex="-1"></a><span class="co">    The input to the model is a tensor of tokens.</span></span>
<span id="cb41-17"><a href="#cb41-17" aria-hidden="true" tabindex="-1"></a><span class="co">  </span></span>
<span id="cb41-18"><a href="#cb41-18" aria-hidden="true" tabindex="-1"></a><span class="co">    Args:</span></span>
<span id="cb41-19"><a href="#cb41-19" aria-hidden="true" tabindex="-1"></a><span class="co">        vocab_size (int): vocab size. Defaults to vocab_size.</span></span>
<span id="cb41-20"><a href="#cb41-20" aria-hidden="true" tabindex="-1"></a><span class="co">        n_classes (int): how many classes on output. Defaults to 10.</span></span>
<span id="cb41-21"><a href="#cb41-21" aria-hidden="true" tabindex="-1"></a><span class="co">        d_model (int): depth of embedding. Defaults to 512.</span></span>
<span id="cb41-22"><a href="#cb41-22" aria-hidden="true" tabindex="-1"></a><span class="co">        d_ff (int): depth of feed-forward layer. Defaults to 2048.</span></span>
<span id="cb41-23"><a href="#cb41-23" aria-hidden="true" tabindex="-1"></a><span class="co">        n_layers (int): number of encoder/decoder layers. Defaults to 6.</span></span>
<span id="cb41-24"><a href="#cb41-24" aria-hidden="true" tabindex="-1"></a><span class="co">        n_heads (int): number of attention heads. Defaults to 8.</span></span>
<span id="cb41-25"><a href="#cb41-25" aria-hidden="true" tabindex="-1"></a><span class="co">        dropout (float): dropout rate (how much to drop out). Defaults to 0.1.</span></span>
<span id="cb41-26"><a href="#cb41-26" aria-hidden="true" tabindex="-1"></a><span class="co">        dropout_shared_axes (int): axes on which to share dropout mask. Defaults to None.</span></span>
<span id="cb41-27"><a href="#cb41-27" aria-hidden="true" tabindex="-1"></a><span class="co">        max_len (int): maximum symbol length for positional encoding. Defaults to 2048.</span></span>
<span id="cb41-28"><a href="#cb41-28" aria-hidden="true" tabindex="-1"></a><span class="co">        mode (str): 'train' or 'eval'. Defaults to 'train'.</span></span>
<span id="cb41-29"><a href="#cb41-29" aria-hidden="true" tabindex="-1"></a><span class="co">        ff_activation (function): the non-linearity in feed-forward layer. Defaults to tl.Relu.</span></span>
<span id="cb41-30"><a href="#cb41-30" aria-hidden="true" tabindex="-1"></a><span class="co">        EncoderBlock (function): Returns the encoder block. Defaults to EncoderBlock.</span></span>
<span id="cb41-31"><a href="#cb41-31" aria-hidden="true" tabindex="-1"></a><span class="co">  </span></span>
<span id="cb41-32"><a href="#cb41-32" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb41-33"><a href="#cb41-33" aria-hidden="true" tabindex="-1"></a><span class="co">        trax.layers.combinators.Serial: A Transformer model as a layer that maps</span></span>
<span id="cb41-34"><a href="#cb41-34" aria-hidden="true" tabindex="-1"></a><span class="co">        from a tensor of tokens to activations over a set of output classes.</span></span>
<span id="cb41-35"><a href="#cb41-35" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb41-36"><a href="#cb41-36" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb41-37"><a href="#cb41-37" aria-hidden="true" tabindex="-1"></a>    positional_encoder <span class="op">=</span> [</span>
<span id="cb41-38"><a href="#cb41-38" aria-hidden="true" tabindex="-1"></a>        tl.Embedding(vocab_size, d_model),</span>
<span id="cb41-39"><a href="#cb41-39" aria-hidden="true" tabindex="-1"></a>        tl.Dropout(rate<span class="op">=</span>dropout, shared_axes<span class="op">=</span>dropout_shared_axes, mode<span class="op">=</span>mode),</span>
<span id="cb41-40"><a href="#cb41-40" aria-hidden="true" tabindex="-1"></a>        tl.PositionalEncoding(max_len<span class="op">=</span>max_len)</span>
<span id="cb41-41"><a href="#cb41-41" aria-hidden="true" tabindex="-1"></a>    ]</span>
<span id="cb41-42"><a href="#cb41-42" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb41-43"><a href="#cb41-43" aria-hidden="true" tabindex="-1"></a>    <span class="co"># We use the function `EncoderBlock` (implemented above) and pass in the parameters over `n_layers`</span></span>
<span id="cb41-44"><a href="#cb41-44" aria-hidden="true" tabindex="-1"></a>    encoder_blocks <span class="op">=</span> [EncoderBlock(d_model, d_ff, n_heads, dropout, dropout_shared_axes,</span>
<span id="cb41-45"><a href="#cb41-45" aria-hidden="true" tabindex="-1"></a>                  mode, ff_activation, FeedForwardBlock<span class="op">=</span>FeedForwardBlock) <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(n_layers)]</span>
<span id="cb41-46"><a href="#cb41-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-47"><a href="#cb41-47" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Assemble and return the model.</span></span>
<span id="cb41-48"><a href="#cb41-48" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> tl.Serial(</span>
<span id="cb41-49"><a href="#cb41-49" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Encode</span></span>
<span id="cb41-50"><a href="#cb41-50" aria-hidden="true" tabindex="-1"></a>        tl.Branch(</span>
<span id="cb41-51"><a href="#cb41-51" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Use `positional_encoder`</span></span>
<span id="cb41-52"><a href="#cb41-52" aria-hidden="true" tabindex="-1"></a>            positional_encoder,</span>
<span id="cb41-53"><a href="#cb41-53" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Use trax padding mask</span></span>
<span id="cb41-54"><a href="#cb41-54" aria-hidden="true" tabindex="-1"></a>            tl.PaddingMask(),</span>
<span id="cb41-55"><a href="#cb41-55" aria-hidden="true" tabindex="-1"></a>        ),</span>
<span id="cb41-56"><a href="#cb41-56" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Use `encoder_blocks`</span></span>
<span id="cb41-57"><a href="#cb41-57" aria-hidden="true" tabindex="-1"></a>        encoder_blocks,</span>
<span id="cb41-58"><a href="#cb41-58" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Use select layer</span></span>
<span id="cb41-59"><a href="#cb41-59" aria-hidden="true" tabindex="-1"></a>        tl.Select([<span class="dv">0</span>], n_in<span class="op">=</span><span class="dv">2</span>),</span>
<span id="cb41-60"><a href="#cb41-60" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Use trax layer normalization</span></span>
<span id="cb41-61"><a href="#cb41-61" aria-hidden="true" tabindex="-1"></a>        tl.LayerNorm(),</span>
<span id="cb41-62"><a href="#cb41-62" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Map to output categories.</span></span>
<span id="cb41-63"><a href="#cb41-63" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Use trax mean. set axis to 1</span></span>
<span id="cb41-64"><a href="#cb41-64" aria-hidden="true" tabindex="-1"></a>        tl.Mean(axis<span class="op">=</span><span class="dv">1</span>),</span>
<span id="cb41-65"><a href="#cb41-65" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Use trax Dense using `n_classes`</span></span>
<span id="cb41-66"><a href="#cb41-66" aria-hidden="true" tabindex="-1"></a>        tl.Dense(n_classes),</span>
<span id="cb41-67"><a href="#cb41-67" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Use trax log softmax</span></span>
<span id="cb41-68"><a href="#cb41-68" aria-hidden="true" tabindex="-1"></a>        tl.LogSoftmax(),</span>
<span id="cb41-69"><a href="#cb41-69" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb41-70"><a href="#cb41-70" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-71"><a href="#cb41-71" aria-hidden="true" tabindex="-1"></a>    <span class="co">### </span><span class="re">END</span><span class="co"> CODE HERE </span><span class="al">###</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-outputid="65d3d76a-96fd-44ea-9353-c89e6d8c0e1e" data-execution_count="30">
<div class="sourceCode cell-code" id="cb42"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="co"># See the structure of our model</span></span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Only 1 layer is used to keep the output readable</span></span>
<span id="cb42-3"><a href="#cb42-3" aria-hidden="true" tabindex="-1"></a>TransformerEncoder(n_layers<span class="op">=</span><span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="30">
<pre><code>Serial[
  Branch_out2[
    [Embedding_32000_512, Dropout, PositionalEncoding]
    Serial[
      PaddingMask(0)
    ]
  ]
  Serial_in2_out2[
    Branch_in2_out3[
      None
      Serial_in2_out2[
        LayerNorm
        Serial_in2_out2[
          _in2_out2
          Serial_in2_out2[
            Select[0,0,0]_out3
            Serial_in4_out2[
              _in4_out4
              Serial_in4_out2[
                Parallel_in3_out3[
                  Dense_512
                  Dense_512
                  Dense_512
                ]
                PureAttention_in4_out2
                Dense_512
              ]
              _in2_out2
            ]
          ]
          _in2_out2
        ]
        Dropout
      ]
    ]
    Add_in2
  ]
  Serial[
    Branch_out2[
      None
      Serial[
        LayerNorm
        Dense_2048
        Serial[
          Relu
        ]
        Dropout
        Dense_512
        Dropout
      ]
    ]
    Add_in2
  ]
  Select[0]_in2
  LayerNorm
  Mean
  Dense_10
  LogSoftmax
]</code></pre>
</div>
</div>
</section>
</section>
<section id="acknowledgements" class="level2" data-number="6">
<h2 data-number="6" class="anchored" data-anchor-id="acknowledgements"><span class="header-section-number">6</span> Acknowledgements</h2>
<p>I’d like to express my thanks to the great <a href="https://www.coursera.org/learn/attention-models-in-nlp">Natural Language Processing with Attention Models Course</a> which i completed, and acknowledge the use of some images and other materials from the course in this article.</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>