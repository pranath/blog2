<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.335">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Pranath Fernando">
<meta name="dcterms.date" content="2023-03-28">
<meta name="description" content="Here we are going to use the Reformer aka the efficient Transformer to create a more advanced conversational chatbot. It will learn how to understand context to better answer questions and it will also know how to ask questions if it needs more info, which could be useful for customer service applications.">

<title>LivingDataLab - Using an efficient transformer to create an interactive and more complex chatbot</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>

<script type="text/javascript">

(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
ga('create', 'UA-91568149-1', 'auto');

ga('send', {
  hitType: 'pageview',
  'anonymizeIp': true,
});
</script>

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="../styles.css">
<meta property="og:title" content="LivingDataLab - Using an efficient transformer to create an interactive and more complex chatbot">
<meta property="og:description" content="Here we are going to use the Reformer aka the efficient Transformer to create a more advanced conversational chatbot.">
<meta property="og:image" content="https://github.com/pranath/blog/raw/master/images/cbot.jpg">
<meta property="og:site-name" content="LivingDataLab">
<meta name="twitter:title" content="LivingDataLab - Using an efficient transformer to create an interactive and more complex chatbot">
<meta name="twitter:description" content="Here we are going to use the Reformer aka the efficient Transformer to create a more advanced conversational chatbot.">
<meta name="twitter:image" content="https://github.com/pranath/blog/raw/master/images/cbot.jpg">
<meta name="twitter:card" content="summary_large_image">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">LivingDataLab</span>
    </a>
  </div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../about.html">
 <span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/pranath"><i class="bi bi-github" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/LivingDataLab"><i class="bi bi-twitter" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
              <div id="quarto-search" class="" title="Search"></div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Using an efficient transformer to create an interactive and more complex chatbot</h1>
                  <div>
        <div class="description">
          Here we are going to use the Reformer aka the efficient Transformer to create a more advanced conversational chatbot. It will learn how to understand context to better answer questions and it will also know how to ask questions if it needs more info, which could be useful for customer service applications.
        </div>
      </div>
                          <div class="quarto-categories">
                <div class="quarto-category">natural-language-processing</div>
                <div class="quarto-category">deep-learning</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Pranath Fernando </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">March 28, 2023</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction"><span class="toc-section-number">1</span>  Introduction</a></li>
  <li><a href="#exploring-the-multiwoz-dataset" id="toc-exploring-the-multiwoz-dataset" class="nav-link" data-scroll-target="#exploring-the-multiwoz-dataset"><span class="toc-section-number">2</span>  Exploring the MultiWoz Dataset</a>
  <ul class="collapse">
  <li><a href="#get_conversation" id="toc-get_conversation" class="nav-link" data-scroll-target="#get_conversation"><span class="toc-section-number">2.1</span>  get_conversation</a></li>
  </ul></li>
  <li><a href="#processing-the-data-for-reformer-inputs" id="toc-processing-the-data-for-reformer-inputs" class="nav-link" data-scroll-target="#processing-the-data-for-reformer-inputs"><span class="toc-section-number">3</span>  Processing the Data for Reformer Inputs</a>
  <ul class="collapse">
  <li><a href="#tokenizing-batching-with-bucketing" id="toc-tokenizing-batching-with-bucketing" class="nav-link" data-scroll-target="#tokenizing-batching-with-bucketing"><span class="toc-section-number">3.1</span>  Tokenizing, Batching with Bucketing</a></li>
  </ul></li>
  <li><a href="#reversible-layers" id="toc-reversible-layers" class="nav-link" data-scroll-target="#reversible-layers"><span class="toc-section-number">4</span>  Reversible Layers</a>
  <ul class="collapse">
  <li><a href="#reversible_layer_reverse" id="toc-reversible_layer_reverse" class="nav-link" data-scroll-target="#reversible_layer_reverse"><span class="toc-section-number">4.1</span>  reversible_layer_reverse</a></li>
  <li><a href="#reversible-layers-and-randomness" id="toc-reversible-layers-and-randomness" class="nav-link" data-scroll-target="#reversible-layers-and-randomness"><span class="toc-section-number">4.2</span>  Reversible Layers and Randomness</a></li>
  </ul></li>
  <li><a href="#reformerlm-training" id="toc-reformerlm-training" class="nav-link" data-scroll-target="#reformerlm-training"><span class="toc-section-number">5</span>  ReformerLM Training</a>
  <ul class="collapse">
  <li><a href="#reformerlm" id="toc-reformerlm" class="nav-link" data-scroll-target="#reformerlm"><span class="toc-section-number">5.1</span>  ReformerLM</a></li>
  <li><a href="#training_loop" id="toc-training_loop" class="nav-link" data-scroll-target="#training_loop"><span class="toc-section-number">5.2</span>  training_loop</a></li>
  </ul></li>
  <li><a href="#decode-from-a-pretrained-model" id="toc-decode-from-a-pretrained-model" class="nav-link" data-scroll-target="#decode-from-a-pretrained-model"><span class="toc-section-number">6</span>  Decode from a Pretrained Model</a>
  <ul class="collapse">
  <li><a href="#reformerlm_output_gen" id="toc-reformerlm_output_gen" class="nav-link" data-scroll-target="#reformerlm_output_gen"><span class="toc-section-number">6.1</span>  ReformerLM_output_gen</a></li>
  </ul></li>
  <li><a href="#acknowledgements" id="toc-acknowledgements" class="nav-link" data-scroll-target="#acknowledgements"><span class="toc-section-number">7</span>  Acknowledgements</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">




<section id="introduction" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="introduction"><span class="header-section-number">1</span> Introduction</h2>
<p>In this project, we are going to use the <a href="https://arxiv.org/abs/2001.04451">Reformer</a>, also known as the efficient Transformer, to generate a dialogue between two bots. We will feed conversations to our model and it will learn how to understand the context of each one. Not only will it learn how to answer questions but it will also know how to ask questions if it needs more info. For example, after a customer asks for a train ticket, the chatbot can ask what time the said customer wants to leave. You could use this concept to automate call centers, hotel receptions, personal trainers, or any type of customer service.</p>
<p>We will:</p>
<ul>
<li>Understand how the Reformer works</li>
<li>Explore the <a href="https://arxiv.org/abs/1810.00278">MultiWoz</a> dataset</li>
<li>Process the data to feed it into the model</li>
<li>Train our model</li>
<li>Generate a dialogue by feeding a question to the model</li>
</ul>
</section>
<section id="exploring-the-multiwoz-dataset" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="exploring-the-multiwoz-dataset"><span class="header-section-number">2</span> Exploring the MultiWoz Dataset</h2>
<p>We will start by exploring the MultiWoz dataset. The dataset we are about to use has more than 10,000 human annotated dialogues and spans multiple domains and topics. Some dialogues include multiple domains and others include single domains. In this section, we will load and explore this dataset, as well as develop a function to extract the dialogues.</p>
<p>Let’s first import the modules we will be using:</p>
<div class="cell" data-outputid="e3a85dd1-e375-4636-ea62-b9b403f0952a" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> json</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> random</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> termcolor <span class="im">import</span> colored</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> trax   </span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> trax <span class="im">import</span> layers <span class="im">as</span> tl</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> trax.supervised <span class="im">import</span> training</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> w4_unittest</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Let’s also declare some constants we will be using in the exercises.</p>
<div class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co"># filename of the MultiWOZ dialogue dataset</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>DATA_FILE <span class="op">=</span> <span class="st">'data.json'</span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="co"># data directory</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>DATA_DIR <span class="op">=</span> <span class="st">'./data'</span></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a><span class="co"># dictionary where we will load the dialogue dataset</span></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>DIALOGUE_DB <span class="op">=</span> {}</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a><span class="co"># vocabulary filename</span></span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>VOCAB_FILE <span class="op">=</span> <span class="st">'en_32k.subword'</span></span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a><span class="co"># vocabulary file directory</span></span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>VOCAB_DIR <span class="op">=</span> <span class="st">'data/vocabs'</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Let’s now load the MultiWOZ 2.1 dataset already downloaded.</p>
<div class="cell" data-outputid="3d086ea4-7898-4870-b52f-f362cb02e118" data-execution_count="3">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># help function to load a JSON file</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> load_json(directory, <span class="bu">file</span>):</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> <span class="bu">open</span>(<span class="ss">f'</span><span class="sc">{</span>directory<span class="sc">}</span><span class="ss">/</span><span class="sc">{</span><span class="bu">file</span><span class="sc">}</span><span class="ss">'</span>) <span class="im">as</span> <span class="bu">file</span>: </span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>        db <span class="op">=</span> json.load(<span class="bu">file</span>)</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> db</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a><span class="co"># load the dialogue data set into our dictionary</span></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>DIALOGUE_DB <span class="op">=</span> load_json(DATA_DIR, DATA_FILE)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Let’s see how many dialogues we have in the dictionary. 1 key-value pair is one dialogue so we can just get the dictionary’s length.</p>
<div class="cell" data-outputid="4b364506-1088-4f00-be0c-4fefa892dc4e" data-execution_count="4">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'The number of dialogues is: </span><span class="sc">{</span><span class="bu">len</span>(DIALOGUE_DB)<span class="sc">}</span><span class="ss">'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>The number of dialogues is: 10438</code></pre>
</div>
</div>
<p>The dialogues are composed of multiple files and the filenames are used as keys in our dictionary. Those with multi-domain dialogues have “MUL” in their filenames while single domain dialogues have either “SNG” or “WOZ”.</p>
<div class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co"># print 7 keys from the dataset to see the filenames</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="bu">list</span>(DIALOGUE_DB.keys())[<span class="dv">0</span>:<span class="dv">7</span>]) </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>['SNG01856.json', 'SNG0129.json', 'PMUL1635.json', 'MUL2168.json', 'SNG0073.json', 'SNG01445.json', 'MUL2105.json']</code></pre>
</div>
</div>
<p>As we can see from the cells above, there are 10,438 conversations, each in its own file. We will train your model on all those conversations. Each file is also loaded into a dictionary and each has two keys which are the following:</p>
<div class="cell" data-outputid="b22f570d-a7b0-4b92-ba68-0b7236e61051" data-execution_count="6">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co"># get keys of the fifth file in the list above</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(DIALOGUE_DB[<span class="st">'SNG0073.json'</span>].keys())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>dict_keys(['goal', 'log'])</code></pre>
</div>
</div>
<p>The <code>goal</code> also points to a dictionary and it contains several keys pertaining to the objectives of the conversation. For example below, we can see that the conversation will be about booking a taxi.</p>
<div class="cell" data-outputid="7e8efa2d-821a-44c8-902d-2c722baf5b4c" data-execution_count="7">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>DIALOGUE_DB[<span class="st">'SNG0073.json'</span>][<span class="st">'goal'</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="7">
<pre><code>{'taxi': {'info': {'leaveAt': '17:15',
   'destination': 'pizza hut fen ditton',
   'departure': "saint john's college"},
  'reqt': ['car type', 'phone'],
  'fail_info': {}},
 'police': {},
 'hospital': {},
 'hotel': {},
 'attraction': {},
 'train': {},
 'message': ["You want to book a &lt;span class='emphasis'&gt;taxi&lt;/span&gt;. The taxi should go to &lt;span class='emphasis'&gt;pizza hut fen ditton&lt;/span&gt; and should depart from &lt;span class='emphasis'&gt;saint john's college&lt;/span&gt;",
  "The taxi should &lt;span class='emphasis'&gt;leave after 17:15&lt;/span&gt;",
  "Make sure you get &lt;span class='emphasis'&gt;car type&lt;/span&gt; and &lt;span class='emphasis'&gt;contact number&lt;/span&gt;"],
 'restaurant': {}}</code></pre>
</div>
</div>
<p>The <code>log</code> on the other hand contains the dialog. It is a list of dictionaries and each element of this list contains several descriptions as well. Let’s look at an example:</p>
<div class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="co"># get first element of the log list</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>DIALOGUE_DB[<span class="st">'SNG0073.json'</span>][<span class="st">'log'</span>][<span class="dv">0</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="8">
<pre><code>{'text': "I would like a taxi from Saint John's college to Pizza Hut Fen Ditton.",
 'metadata': {},
 'dialog_act': {'Taxi-Inform': [['Dest', 'pizza hut fen ditton'],
   ['Depart', "saint john 's college"]]},
 'span_info': [['Taxi-Inform', 'Dest', 'pizza hut fen ditton', 11, 14],
  ['Taxi-Inform', 'Depart', "saint john 's college", 6, 9]]}</code></pre>
</div>
</div>
<p>For this project, we are only interested in the conversation which is in the <code>text</code> field. The conversation goes back and forth between two persons. Let’s call them ‘Person 1’ and ‘Person 2’. This implies that data[‘SNG0073.json’][‘log’][0][‘text’] is ‘Person 1’ and data[‘SNG0073.json’][‘log’][1][‘text’] is ‘Person 2’ and so on. The even offsets are ‘Person 1’ and the odd offsets are ‘Person 2’.</p>
<div class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">' Person 1: '</span>, DIALOGUE_DB[<span class="st">'SNG0073.json'</span>][<span class="st">'log'</span>][<span class="dv">0</span>][<span class="st">'text'</span>])</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">' Person 2: '</span>,DIALOGUE_DB[<span class="st">'SNG0073.json'</span>][<span class="st">'log'</span>][<span class="dv">1</span>][<span class="st">'text'</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code> Person 1:  I would like a taxi from Saint John's college to Pizza Hut Fen Ditton.
 Person 2:  What time do you want to leave and what time do you want to arrive by?</code></pre>
</div>
</div>
<section id="get_conversation" class="level3" data-number="2.1">
<h3 data-number="2.1" class="anchored" data-anchor-id="get_conversation"><span class="header-section-number">2.1</span> get_conversation</h3>
<p>We will now implement the <code>get_conversation()</code> function that will extract the conversations from the dataset’s file.</p>
<p>We will implement a function to extract conversations from the input file.<br>
As described above, the conversation is in the <code>text</code> field in each of the elements in the <code>log</code> list of the file. If the log list has <code>x</code> number of elements, then the function will get the <code>text</code> entries of each of those elements. Our function should return the conversation, prepending each field with either ’ Person 1: ’ if ‘x’ is even or ’ Person 2: ’ if ‘x’ is odd. We can use the Python modulus operator ‘%’ to help select the even/odd entries. Important note: Do not print a newline character (i.e.&nbsp;<code>\n</code>) when generating the string. For example, in the code cell above, your function should output something like:</p>
<pre><code> Person 1: I would like a taxi from Saint John's college to Pizza Hut Fen Ditton. Person 2: What time do you want to leave and what time do you want to arrive by?</code></pre>
<p>and <strong>not</strong>:</p>
<pre><code> Person 1:  I would like a taxi from Saint John's college to Pizza Hut Fen Ditton.
 Person 2:  What time do you want to leave and what time do you want to arrive by?</code></pre>
<div class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_conversation(<span class="bu">file</span>, data_db):</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">'''</span></span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Args:</span></span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a><span class="co">        file (string): filename of the dialogue file saved as json</span></span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a><span class="co">        data_db (dict): dialogue database</span></span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a><span class="co">    </span></span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a><span class="co">        string: A string containing the 'text' fields of  data[file]['log'][x]</span></span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a><span class="co">    '''</span></span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a>    <span class="co"># initialize empty string</span></span>
<span id="cb18-12"><a href="#cb18-12" aria-hidden="true" tabindex="-1"></a>    result <span class="op">=</span> <span class="st">''</span></span>
<span id="cb18-13"><a href="#cb18-13" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb18-14"><a href="#cb18-14" aria-hidden="true" tabindex="-1"></a>    <span class="co"># get length of file's log list</span></span>
<span id="cb18-15"><a href="#cb18-15" aria-hidden="true" tabindex="-1"></a>    len_msg_log <span class="op">=</span> <span class="bu">len</span>(data_db[<span class="bu">file</span>][<span class="st">'log'</span>])</span>
<span id="cb18-16"><a href="#cb18-16" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb18-17"><a href="#cb18-17" aria-hidden="true" tabindex="-1"></a>    <span class="co"># set the delimiter strings</span></span>
<span id="cb18-18"><a href="#cb18-18" aria-hidden="true" tabindex="-1"></a>    delimiter_1 <span class="op">=</span> <span class="st">' Person 1: '</span></span>
<span id="cb18-19"><a href="#cb18-19" aria-hidden="true" tabindex="-1"></a>    delimiter_2 <span class="op">=</span> <span class="st">' Person 2: '</span></span>
<span id="cb18-20"><a href="#cb18-20" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb18-21"><a href="#cb18-21" aria-hidden="true" tabindex="-1"></a>    <span class="co"># loop over the file's log list</span></span>
<span id="cb18-22"><a href="#cb18-22" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(len_msg_log):</span>
<span id="cb18-23"><a href="#cb18-23" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb18-24"><a href="#cb18-24" aria-hidden="true" tabindex="-1"></a>        <span class="co"># get i'th element of file log list</span></span>
<span id="cb18-25"><a href="#cb18-25" aria-hidden="true" tabindex="-1"></a>        cur_log <span class="op">=</span> data_db[<span class="bu">file</span>][<span class="st">'log'</span>][i]</span>
<span id="cb18-26"><a href="#cb18-26" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb18-27"><a href="#cb18-27" aria-hidden="true" tabindex="-1"></a>        <span class="co"># check if i is even</span></span>
<span id="cb18-28"><a href="#cb18-28" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> i<span class="op">%</span><span class="dv">2</span> <span class="op">==</span> <span class="dv">0</span>:                   </span>
<span id="cb18-29"><a href="#cb18-29" aria-hidden="true" tabindex="-1"></a>            <span class="co"># append the 1st delimiter string</span></span>
<span id="cb18-30"><a href="#cb18-30" aria-hidden="true" tabindex="-1"></a>            result <span class="op">+=</span> delimiter_1</span>
<span id="cb18-31"><a href="#cb18-31" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>: </span>
<span id="cb18-32"><a href="#cb18-32" aria-hidden="true" tabindex="-1"></a>            <span class="co"># append the 2nd delimiter string</span></span>
<span id="cb18-33"><a href="#cb18-33" aria-hidden="true" tabindex="-1"></a>            result <span class="op">+=</span> delimiter_2</span>
<span id="cb18-34"><a href="#cb18-34" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb18-35"><a href="#cb18-35" aria-hidden="true" tabindex="-1"></a>        <span class="co"># append the message text from the log</span></span>
<span id="cb18-36"><a href="#cb18-36" aria-hidden="true" tabindex="-1"></a>        result <span class="op">+=</span> cur_log[<span class="st">'text'</span>]</span>
<span id="cb18-37"><a href="#cb18-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-38"><a href="#cb18-38" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> result</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="bu">file</span> <span class="op">=</span> <span class="st">'SNG01856.json'</span></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>conversation <span class="op">=</span> get_conversation(<span class="bu">file</span>, DIALOGUE_DB)</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a><span class="co"># print raw output</span></span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(conversation)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code> Person 1: am looking for a place to to stay that has cheap price range it should be in a type of hotel Person 2: Okay, do you have a specific area you want to stay in? Person 1: no, i just need to make sure it's cheap. oh, and i need parking Person 2: I found 1 cheap hotel for you that includes parking. Do you like me to book it? Person 1: Yes, please. 6 people 3 nights starting on tuesday. Person 2: I am sorry but I wasn't able to book that for you for Tuesday. Is there another day you would like to stay or perhaps a shorter stay? Person 1: how about only 2 nights. Person 2: Booking was successful.
Reference number is : 7GAWK763. Anything else I can do for you? Person 1: No, that will be all. Good bye. Person 2: Thank you for using our services.</code></pre>
</div>
</div>
<p>We can have a utility pretty print function just so we can visually follow the conversation more easily.</p>
<div class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> print_conversation(conversation):</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a>    delimiter_1 <span class="op">=</span> <span class="st">'Person 1: '</span></span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a>    delimiter_2 <span class="op">=</span> <span class="st">'Person 2: '</span></span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a>    split_list_d1 <span class="op">=</span> conversation.split(delimiter_1)</span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> sublist <span class="kw">in</span> split_list_d1[<span class="dv">1</span>:]:</span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a>        split_list_d2 <span class="op">=</span> sublist.split(delimiter_2)</span>
<span id="cb21-10"><a href="#cb21-10" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(colored(<span class="ss">f'Person 1: </span><span class="sc">{</span>split_list_d2[<span class="dv">0</span>]<span class="sc">}</span><span class="ss">'</span>, <span class="st">'red'</span>))</span>
<span id="cb21-11"><a href="#cb21-11" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb21-12"><a href="#cb21-12" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="bu">len</span>(split_list_d2) <span class="op">&gt;</span> <span class="dv">1</span>:</span>
<span id="cb21-13"><a href="#cb21-13" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(colored(<span class="ss">f'Person 2: </span><span class="sc">{</span>split_list_d2[<span class="dv">1</span>]<span class="sc">}</span><span class="ss">'</span>, <span class="st">'green'</span>))</span>
<span id="cb21-14"><a href="#cb21-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-15"><a href="#cb21-15" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb21-16"><a href="#cb21-16" aria-hidden="true" tabindex="-1"></a>print_conversation(conversation)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Person 1: am looking for a place to to stay that has cheap price range it should be in a type of hotel 
Person 2: Okay, do you have a specific area you want to stay in? 
Person 1: no, i just need to make sure it's cheap. oh, and i need parking 
Person 2: I found 1 cheap hotel for you that includes parking. Do you like me to book it? 
Person 1: Yes, please. 6 people 3 nights starting on tuesday. 
Person 2: I am sorry but I wasn't able to book that for you for Tuesday. Is there another day you would like to stay or perhaps a shorter stay? 
Person 1: how about only 2 nights. 
Person 2: Booking was successful.
Reference number is : 7GAWK763. Anything else I can do for you? 
Person 1: No, that will be all. Good bye. 
Person 2: Thank you for using our services.</code></pre>
</div>
</div>
<p>For this project, we will just use the outputs of the calls to <code>get_conversation</code> to train the model. But just to expound, there is also other information in the MultiWoz dataset that can be useful in other contexts. Each element of the log list has more information about it. For example, above, if you were to look at the other fields for the following, “am looking for a place to stay that has cheap price range it should be in a type of hotel”, you will get the following.</p>
<div class="cell" data-outputid="8a2f4e3f-4516-449f-9648-a5970707cfc9" data-execution_count="14">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a>DIALOGUE_DB[<span class="st">'SNG01856.json'</span>][<span class="st">'log'</span>][<span class="dv">0</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="14">
<pre><code>{'text': 'am looking for a place to to stay that has cheap price range it should be in a type of hotel',
 'metadata': {},
 'dialog_act': {'Hotel-Inform': [['Type', 'hotel'], ['Price', 'cheap']]},
 'span_info': [['Hotel-Inform', 'Type', 'hotel', 20, 20],
  ['Hotel-Inform', 'Price', 'cheap', 10, 10]]}</code></pre>
</div>
</div>
<p>The dataset also comes with hotel, hospital, taxi, train, police, and restaurant databases. For example, in case you need to call a doctor, or a hotel, or a taxi, this will allow you to automate the entire conversation.</p>
<div class="cell" data-outputid="5730c55f-63da-42a8-935e-6eeb17f6f791" data-execution_count="15">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="co"># this is an example of the attractions file</span></span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a>attraction_file <span class="op">=</span> <span class="bu">open</span>(<span class="st">'data/attraction_db.json'</span>)</span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a>attractions <span class="op">=</span> json.load(attraction_file)</span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(attractions[<span class="dv">0</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>{'address': 'pool way, whitehill road, off newmarket road', 'area': 'east', 'entrance fee': '?', 'id': '1', 'location': [52.208789, 0.154883], 'name': 'abbey pool and astroturf pitch', 'openhours': '?', 'phone': '01223902088', 'postcode': 'cb58nt', 'pricerange': '?', 'type': 'swimmingpool'}</code></pre>
</div>
</div>
<div class="cell" data-outputid="3dacc4ff-4f05-4ae6-d099-33d1b3a6fa2a" data-execution_count="16">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="co"># this is an example of the hospital file</span></span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>hospital_file <span class="op">=</span> <span class="bu">open</span>(<span class="st">'data/hospital_db.json'</span>)</span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a>hospitals <span class="op">=</span> json.load(hospital_file)</span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(hospitals[<span class="dv">0</span>]) <span class="co"># feel free to index into other indices</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>{'department': 'neurosciences critical care unit', 'id': 0, 'phone': '01223216297'}</code></pre>
</div>
</div>
<div class="cell" data-outputid="ee0110c2-b2c2-4584-bd42-21f75109a579" data-execution_count="17">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="co"># this is an example of the hotel file</span></span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a>hotel_file <span class="op">=</span> <span class="bu">open</span>(<span class="st">'data/hotel_db.json'</span>)</span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a>hotels <span class="op">=</span> json.load(hotel_file)</span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(hotels[<span class="dv">0</span>]) <span class="co"># feel free to index into other indices</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>{'address': '124 tenison road', 'area': 'east', 'internet': 'yes', 'parking': 'no', 'id': '0', 'location': [52.1963733, 0.1987426], 'name': 'a and b guest house', 'phone': '01223315702', 'postcode': 'cb12dp', 'price': {'double': '70', 'family': '90', 'single': '50'}, 'pricerange': 'moderate', 'stars': '4', 'takesbookings': 'yes', 'type': 'guesthouse'}</code></pre>
</div>
</div>
<div class="cell" data-outputid="8977e17e-2fc3-4073-abb8-fcf5cef3cfaf" data-execution_count="18">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="co"># this is an example of the police file</span></span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a>police_file <span class="op">=</span> <span class="bu">open</span>(<span class="st">'data/police_db.json'</span>)</span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a>police <span class="op">=</span> json.load(police_file)</span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(police[<span class="dv">0</span>]) <span class="co"># feel free to index into other indices</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>{'name': 'Parkside Police Station', 'address': 'Parkside, Cambridge', 'id': 0, 'phone': '01223358966'}</code></pre>
</div>
</div>
<div class="cell" data-outputid="1dba6598-b9b6-4fc8-91d2-f844b98e45fa" data-execution_count="19">
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="co"># this is an example of a restaurant file</span></span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a>restaurant_file <span class="op">=</span> <span class="bu">open</span>(<span class="st">'data/restaurant_db.json'</span>)</span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a>restaurants <span class="op">=</span> json.load(restaurant_file)</span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(restaurants[<span class="dv">0</span>]) <span class="co"># feel free to index into other indices</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>{'address': 'Regent Street City Centre', 'area': 'centre', 'food': 'italian', 'id': '19210', 'introduction': 'Pizza hut is a large chain with restaurants nationwide offering convenience pizzas pasta and salads to eat in or take away', 'location': [52.20103, 0.126023], 'name': 'pizza hut city centre', 'phone': '01223323737', 'postcode': 'cb21ab', 'pricerange': 'cheap', 'type': 'restaurant'}</code></pre>
</div>
</div>
<p>For more information about the multiwoz 2.1 data set, please run the cell below to read the <code>ReadMe.txt</code> file.</p>
<div class="cell" data-outputid="aa039a49-3ed3-4f4d-fa4f-c2619de3dc99" data-execution_count="20">
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> <span class="bu">open</span>(<span class="st">'data/README'</span>) <span class="im">as</span> <span class="bu">file</span>:</span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="bu">file</span>.read())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>#####################################################
#####################################################
#  Copyright Cambridge Dialogue Systems Group, 2018 #
#####################################################
#####################################################

Dataset contains the following files:
1. data.json: the woz dialogue dataset, which contains the conversation  users and wizards, as well as a set of coarse labels for each user turn. This file contains both system and user dialogue acts annotated at the turn level. Files with multi-domain dialogues have "MUL" in their names. Single domain dialogues have either "SNG" or "WOZ" in their names.
2. restaurant_db.json: the Cambridge restaurant database file, containing restaurants in the Cambridge UK area and a set of attributes.
3. attraction_db.json: the Cambridge attraction database file, contining attractions in the Cambridge UK area and a set of attributes.
4. hotel_db.json: the Cambridge hotel database file, containing hotels in the Cambridge UK area and a set of attributes.
5. train_db.json: the Cambridge train (with artificial connections) database file, containing trains in the Cambridge UK area and a set of attributes.
6. hospital_db.json: the Cambridge hospital database file, contatining information about departments.
7. police_db.json: the Cambridge police station information.
8. taxi_db.json: slot-value list for taxi domain.
9. valListFile.txt: list of dialogues for validation.
10. testListFile.txt: list of dialogues for testing.
11. system_acts.json:
  There are 6 domains ('Booking', 'Restaurant', 'Hotel', 'Attraction', 'Taxi', 'Train') and 1 dummy domain ('general').
  A domain-dependent dialogue act is defined as a domain token followed by a domain-independent dialogue act, e.g. 'Hotel-inform' means it is an 'inform' act in the Hotel domain.
  Dialogue acts which cannot take slots, e.g., 'good bye', are defined under the 'general' domain.
  A slot-value pair defined as a list with two elements. The first element is slot token and the second one is its value.
  If a dialogue act takes no slots, e.g., dialogue act 'offer booking' for an utterance 'would you like to take a reservation?', its slot-value pair is ['none', 'none']
  There are four types of values:
  1) If a slot takes a binary value, e.g., 'has Internet' or 'has park', the value is either 'yes' or 'no'.
  2) If a slot is under the act 'request', e.g., 'request' about 'area', the value is expressed as '?'.
  3) The value that appears in the utterance e.g., the name of a restaurant.
  4) If for some reason the turn does not have an annotation then it is labeled as "No Annotation."
12. ontology.json: Data-based ontology containing all the values for the different slots in the domains.
13. slot_descriptions.json: A collection of human-written slot descriptions for each slot in the dataset. Each slot has at least two descriptions.
14. tokenization.md: A description of the tokenization preprocessing we had to perform to maintain consistency between the dialogue act annotations of DSTC 8 Track 1 and the existing MultiWOZ 2.0 data. 
</code></pre>
</div>
</div>
<p>As we can see, there are many other aspects of the MultiWoz dataset. Nonetheless, we’ll see that even with just the conversations, our model will still be able to generate useful responses. This concludes our exploration of the dataset. In the next section, we will do some preprocessing before we feed it into our model for training.</p>
</section>
</section>
<section id="processing-the-data-for-reformer-inputs" class="level2" data-number="3">
<h2 data-number="3" class="anchored" data-anchor-id="processing-the-data-for-reformer-inputs"><span class="header-section-number">3</span> Processing the Data for Reformer Inputs</h2>
<p>We will now use the <code>get_conversation()</code> function to process the data. The Reformer expects inputs of this form:</p>
<p><strong>Person 1: Why am I so happy? Person 2: Because you are learning NLP Person 1: … Person 2: …</strong>*</p>
<p>And the conversation keeps going with some text. As we can see ‘Person 1’ and ‘Person 2’ act as delimiters so the model automatically recognizes the person and who is talking. It can then come up with the corresponding text responses for each person. Let’s proceed to process the text in this fashion for the Reformer. First, let’s grab all the conversation strings from all dialogue files and put them in a list.</p>
<div class="cell" data-outputid="2b159dae-78be-4a19-df41-b9e620216d43" data-execution_count="21">
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="co"># the keys are the file names</span></span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a>all_files <span class="op">=</span> DIALOGUE_DB.keys()</span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-4"><a href="#cb37-4" aria-hidden="true" tabindex="-1"></a><span class="co"># initialize empty list</span></span>
<span id="cb37-5"><a href="#cb37-5" aria-hidden="true" tabindex="-1"></a>untokenized_data <span class="op">=</span> []</span>
<span id="cb37-6"><a href="#cb37-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-7"><a href="#cb37-7" aria-hidden="true" tabindex="-1"></a><span class="co"># loop over all files</span></span>
<span id="cb37-8"><a href="#cb37-8" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> <span class="bu">file</span> <span class="kw">in</span> all_files:</span>
<span id="cb37-9"><a href="#cb37-9" aria-hidden="true" tabindex="-1"></a>    <span class="co"># this is the graded function you coded</span></span>
<span id="cb37-10"><a href="#cb37-10" aria-hidden="true" tabindex="-1"></a>    <span class="co"># returns a string delimited by Person 1 and Person 2</span></span>
<span id="cb37-11"><a href="#cb37-11" aria-hidden="true" tabindex="-1"></a>    result <span class="op">=</span> get_conversation(<span class="bu">file</span>, DIALOGUE_DB)</span>
<span id="cb37-12"><a href="#cb37-12" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb37-13"><a href="#cb37-13" aria-hidden="true" tabindex="-1"></a>    <span class="co"># append to the list</span></span>
<span id="cb37-14"><a href="#cb37-14" aria-hidden="true" tabindex="-1"></a>    untokenized_data.append(result)</span>
<span id="cb37-15"><a href="#cb37-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-16"><a href="#cb37-16" aria-hidden="true" tabindex="-1"></a><span class="co"># print the first element to check if it's the same as the one we got before</span></span>
<span id="cb37-17"><a href="#cb37-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(untokenized_data[<span class="dv">0</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code> Person 1: am looking for a place to to stay that has cheap price range it should be in a type of hotel Person 2: Okay, do you have a specific area you want to stay in? Person 1: no, i just need to make sure it's cheap. oh, and i need parking Person 2: I found 1 cheap hotel for you that includes parking. Do you like me to book it? Person 1: Yes, please. 6 people 3 nights starting on tuesday. Person 2: I am sorry but I wasn't able to book that for you for Tuesday. Is there another day you would like to stay or perhaps a shorter stay? Person 1: how about only 2 nights. Person 2: Booking was successful.
Reference number is : 7GAWK763. Anything else I can do for you? Person 1: No, that will be all. Good bye. Person 2: Thank you for using our services.</code></pre>
</div>
</div>
<p>Now let us split the list to a train and eval dataset.</p>
<div class="cell" data-outputid="cb73a95b-488b-4d1d-9c20-5e98ca71f9d5" data-execution_count="22">
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="co"># shuffle the list we generated above</span></span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a>random.shuffle(untokenized_data)</span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-4"><a href="#cb39-4" aria-hidden="true" tabindex="-1"></a><span class="co"># define a cutoff (5% of the total length for this assignment)</span></span>
<span id="cb39-5"><a href="#cb39-5" aria-hidden="true" tabindex="-1"></a><span class="co"># convert to int because we will use it as a list index</span></span>
<span id="cb39-6"><a href="#cb39-6" aria-hidden="true" tabindex="-1"></a>cut_off <span class="op">=</span> <span class="bu">int</span>(<span class="bu">len</span>(untokenized_data) <span class="op">*</span> <span class="fl">.05</span>)</span>
<span id="cb39-7"><a href="#cb39-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-8"><a href="#cb39-8" aria-hidden="true" tabindex="-1"></a><span class="co"># slice the list. the last elements after the cut_off value will be the eval set. the rest is for training. </span></span>
<span id="cb39-9"><a href="#cb39-9" aria-hidden="true" tabindex="-1"></a>train_data, eval_data <span class="op">=</span> untokenized_data[:<span class="op">-</span>cut_off], untokenized_data[<span class="op">-</span>cut_off:]</span>
<span id="cb39-10"><a href="#cb39-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-11"><a href="#cb39-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'number of conversations in the data set: </span><span class="sc">{</span><span class="bu">len</span>(untokenized_data)<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb39-12"><a href="#cb39-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'number of conversations in train set: </span><span class="sc">{</span><span class="bu">len</span>(train_data)<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb39-13"><a href="#cb39-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'number of conversations in eval set: </span><span class="sc">{</span><span class="bu">len</span>(eval_data)<span class="sc">}</span><span class="ss">'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>number of conversations in the data set: 10438
number of conversations in train set: 9917
number of conversations in eval set: 521</code></pre>
</div>
</div>
<section id="tokenizing-batching-with-bucketing" class="level3" data-number="3.1">
<h3 data-number="3.1" class="anchored" data-anchor-id="tokenizing-batching-with-bucketing"><span class="header-section-number">3.1</span> Tokenizing, Batching with Bucketing</h3>
<p>We can now proceed in generating tokenized batches of our data. Let’s first define a utility generator function to yield elements from our data sets:</p>
<div class="cell" data-execution_count="23">
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> stream(data):</span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a>    <span class="co"># loop over the entire data</span></span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">while</span> <span class="va">True</span>:</span>
<span id="cb41-4"><a href="#cb41-4" aria-hidden="true" tabindex="-1"></a>        <span class="co"># get a random element</span></span>
<span id="cb41-5"><a href="#cb41-5" aria-hidden="true" tabindex="-1"></a>        d <span class="op">=</span> random.choice(data)</span>
<span id="cb41-6"><a href="#cb41-6" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb41-7"><a href="#cb41-7" aria-hidden="true" tabindex="-1"></a>        <span class="co"># yield a tuple pair of identical values </span></span>
<span id="cb41-8"><a href="#cb41-8" aria-hidden="true" tabindex="-1"></a>        <span class="co"># (i.e. our inputs to the model will also be our targets during training)</span></span>
<span id="cb41-9"><a href="#cb41-9" aria-hidden="true" tabindex="-1"></a>        <span class="cf">yield</span> (d, d)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Now let’s define our data pipeline for tokenizing and batching our data. We will bucket by length and also have an upper bound on the token length.</p>
<div class="cell" data-execution_count="24">
<div class="sourceCode cell-code" id="cb42"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="co"># trax allows us to use combinators to generate our data pipeline</span></span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a>data_pipeline <span class="op">=</span> trax.data.Serial(</span>
<span id="cb42-3"><a href="#cb42-3" aria-hidden="true" tabindex="-1"></a>    <span class="co"># randomize the stream</span></span>
<span id="cb42-4"><a href="#cb42-4" aria-hidden="true" tabindex="-1"></a>    trax.data.Shuffle(),</span>
<span id="cb42-5"><a href="#cb42-5" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb42-6"><a href="#cb42-6" aria-hidden="true" tabindex="-1"></a>    <span class="co"># tokenize the data</span></span>
<span id="cb42-7"><a href="#cb42-7" aria-hidden="true" tabindex="-1"></a>    trax.data.Tokenize(vocab_dir<span class="op">=</span>VOCAB_DIR,</span>
<span id="cb42-8"><a href="#cb42-8" aria-hidden="true" tabindex="-1"></a>                       vocab_file<span class="op">=</span>VOCAB_FILE),</span>
<span id="cb42-9"><a href="#cb42-9" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb42-10"><a href="#cb42-10" aria-hidden="true" tabindex="-1"></a>    <span class="co"># filter too long sequences</span></span>
<span id="cb42-11"><a href="#cb42-11" aria-hidden="true" tabindex="-1"></a>    trax.data.FilterByLength(<span class="dv">2048</span>),</span>
<span id="cb42-12"><a href="#cb42-12" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb42-13"><a href="#cb42-13" aria-hidden="true" tabindex="-1"></a>    <span class="co"># bucket by length</span></span>
<span id="cb42-14"><a href="#cb42-14" aria-hidden="true" tabindex="-1"></a>    trax.data.BucketByLength(boundaries<span class="op">=</span>[<span class="dv">128</span>, <span class="dv">256</span>,  <span class="dv">512</span>, <span class="dv">1024</span>],</span>
<span id="cb42-15"><a href="#cb42-15" aria-hidden="true" tabindex="-1"></a>                             batch_sizes<span class="op">=</span>[<span class="dv">16</span>,    <span class="dv">8</span>,    <span class="dv">4</span>,   <span class="dv">2</span>, <span class="dv">1</span>]),</span>
<span id="cb42-16"><a href="#cb42-16" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb42-17"><a href="#cb42-17" aria-hidden="true" tabindex="-1"></a>    <span class="co"># add loss weights but do not add it to the padding tokens (i.e. 0)</span></span>
<span id="cb42-18"><a href="#cb42-18" aria-hidden="true" tabindex="-1"></a>    trax.data.AddLossWeights(id_to_mask<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb42-19"><a href="#cb42-19" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb42-20"><a href="#cb42-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-21"><a href="#cb42-21" aria-hidden="true" tabindex="-1"></a><span class="co"># apply the data pipeline to our train and eval sets</span></span>
<span id="cb42-22"><a href="#cb42-22" aria-hidden="true" tabindex="-1"></a>train_stream <span class="op">=</span> data_pipeline(stream(train_data))</span>
<span id="cb42-23"><a href="#cb42-23" aria-hidden="true" tabindex="-1"></a>eval_stream <span class="op">=</span> data_pipeline(stream(eval_data))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Peek into the train stream.</p>
<div class="cell" data-outputid="78659fd2-4633-47bc-ebe8-3ae3a6e2eab3" data-execution_count="25">
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a><span class="co"># the stream generators will yield (input, target, weights). let's just grab the input for inspection</span></span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a>inp, _, _ <span class="op">=</span> <span class="bu">next</span>(train_stream)</span>
<span id="cb43-3"><a href="#cb43-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-4"><a href="#cb43-4" aria-hidden="true" tabindex="-1"></a><span class="co"># print the shape. format is (batch size, token length)</span></span>
<span id="cb43-5"><a href="#cb43-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"input shape: "</span>, inp.shape)</span>
<span id="cb43-6"><a href="#cb43-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-7"><a href="#cb43-7" aria-hidden="true" tabindex="-1"></a><span class="co"># detokenize the first element</span></span>
<span id="cb43-8"><a href="#cb43-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(trax.data.detokenize(inp[<span class="dv">0</span>], vocab_dir<span class="op">=</span>VOCAB_DIR, vocab_file<span class="op">=</span>VOCAB_FILE))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>input shape:  (4, 512)
 Person 1: Hello- I would like some information about visiting Corpus Christi please Person 2: Corpus christi is a college located in the centre of town. The phone number is 01223338000 and is located at king's parade.  Person 1: Can I have the post code please? Person 2: The postcode is cb21rh. Person 1: Is there an entrance fee? Person 2: the admission is 2 pounds. Person 1: Can you also find me a place to stay in the centre? Person 2: There are several places that are located in the same area, can you give me some more preferences? Person 1: I'd like a moderately priced hotel with free wifi and parking. Person 2: I have 4 available hotels in the centre. Two of them have a cheap price range, and two have an expensive range. Would one of these do? Person 1: I'm looking for a moderate priced hotel for 6 people and 5 nights from Sunday.  Person 2: I'm sorry, I'm not pulling up any matches.  Person 1: Okay, how about a moderately-priced hotel in the south area instead that has free wifi and free parking? Person 2: I have two guesthouses that match your request; the Aylesbray Lodge and Bridge Guesthouse. Aylesbray has 4 stars and Bridge Guesthouse has 3. Which would you prefer? Person 1: Aylesbray sounds good. I need a booking for six, five nights starting from sunday. Person 2: Booking was successful reference number is GS1J7NYI. Is there anything else I can help you with today? Person 1: That is all I need today, thank you for your help.  Person 2: You are welcome, have a blessed day.</code></pre>
</div>
</div>
</section>
</section>
<section id="reversible-layers" class="level2" data-number="4">
<h2 data-number="4" class="anchored" data-anchor-id="reversible-layers"><span class="header-section-number">4</span> Reversible Layers</h2>
<p>When running large deep models, you will often run out of memory as each layer allocates memory to store activations for use in backpropagation. To save this resource, we need to be able to recompute these activations during the backward pass without storing them during the forward pass. Lets take a look first at the leftmost diagram below.</p>
<p><img src="https://github.com/pranath/blog/raw/master/images/reversible2.png" height="400" width="600"></p>
<dl>
<dt>This is how the residual networks are implemented in the standard Transformer. It follows that, given <code>F()</code> is Attention and <code>G()</code> is Feed-forward(FF).</dt>
<dd>

</dd>
</dl>
<p><span class="math display">\[\begin{align}  
\mathrm{y}_\mathrm{a} &amp;= \mathrm{x} + \mathrm{F}\left(\mathrm{x}\right)\tag{1} \\
\mathrm{y}_{b}&amp;=\mathrm{y}_{a}+\mathrm{G}\left(\mathrm{y}_{a}\right)\tag{2}\\
\end{align}\]</span></p>
<p>As we can see, it requires that <span class="math inline">\(\mathrm{x}\)</span> and <span class="math inline">\(\mathrm{y}_{a}\)</span> be saved so it can be used during backpropagation. We want to avoid this to conserve memory and this is where reversible residual connections come in. They are shown in the middle and rightmost diagrams above. The key idea is that we will start with two copies of the input to the model and at each layer we will only update one of them. The activations that we <em>don’t</em> update are the ones that will be used to compute the residuals.</p>
<p>Now in this reversible set up you get the following instead:</p>
<p><span class="math display">\[\begin{align}  
\mathrm{y}_{1}&amp;=\mathrm{x}_{1}+\mathrm{F}\left(\mathrm{x}_{2}\right)\tag{3}\\
\mathrm{y}_{2}&amp;=\mathrm{x}_{2}+\mathrm{G}\left(\mathrm{y}_{1}\right)\tag{4}\\
\end{align}\]</span> To recover <span class="math inline">\(\mathrm{(x_1,x_2)}\)</span> from <span class="math inline">\(\mathrm{(y_1, y_2)}\)</span></p>
<p><span class="math display">\[\begin{align}  
\mathrm{x}_{2}&amp;=\mathrm{y}_{2}-\mathrm{G}\left(\mathrm{y}_{1}\right)\tag{5}\\
\mathrm{x}_{1}&amp;=\mathrm{y}_{1}-\mathrm{F}\left(\mathrm{x}_{2}\right)\tag{6}\\
\end{align}\]</span></p>
<p>With this configuration, we’re now able to run the network fully in reverse. You’ll notice that during the backward pass, <span class="math inline">\(\mathrm{x2}\)</span> and <span class="math inline">\(\mathrm{x1}\)</span> can be recomputed based solely on the values of <span class="math inline">\(\mathrm{y2}\)</span> and <span class="math inline">\(\mathrm{y1}\)</span>. No need to save it during the forward pass.</p>
<p>We will implement the <code>reversible_layer_forward</code> function using equations 3 and 4 above. This function takes in the input vector <code>x</code> and the functions <code>f</code> and <code>g</code> and returns the concatenation of <span class="math inline">\(y_1 and y_2\)</span>. For this, we will be splitting <code>x</code> before going through the reversible residual steps<span class="math inline">\(\mathrm{^1}\)</span>. We can then use those two vectors for the <code>reversible_layer_reverse</code> function. Utilize <code>np.concatenate()</code> to form the output being careful to match the axis of the <code>np.split()</code>.</p>
<p><span class="math inline">\(\mathrm{^1}\)</span><em>Take note that this is just for demonstrating the concept in this exercise and there are other ways of processing the input. As we’ll see in the Reformer architecture later, the initial input (i.e.&nbsp;<code>x</code>) can instead be duplicated instead of split.</em></p>
<div class="cell" data-execution_count="26">
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> reversible_layer_forward(x, f, g):</span>
<span id="cb45-2"><a href="#cb45-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb45-3"><a href="#cb45-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Args: </span></span>
<span id="cb45-4"><a href="#cb45-4" aria-hidden="true" tabindex="-1"></a><span class="co">        x (np.array): an input vector or matrix</span></span>
<span id="cb45-5"><a href="#cb45-5" aria-hidden="true" tabindex="-1"></a><span class="co">        f (function): a function which operates on a vector/matrix</span></span>
<span id="cb45-6"><a href="#cb45-6" aria-hidden="true" tabindex="-1"></a><span class="co">        g (function): a function which operates on a vector/matrix</span></span>
<span id="cb45-7"><a href="#cb45-7" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns: </span></span>
<span id="cb45-8"><a href="#cb45-8" aria-hidden="true" tabindex="-1"></a><span class="co">        y (np.array): an output vector or matrix whose form is determined by 'x', f and g</span></span>
<span id="cb45-9"><a href="#cb45-9" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb45-10"><a href="#cb45-10" aria-hidden="true" tabindex="-1"></a>    <span class="co"># split the input vector into two (* along the last axis because it is the depth dimension)</span></span>
<span id="cb45-11"><a href="#cb45-11" aria-hidden="true" tabindex="-1"></a>    x1, x2 <span class="op">=</span> np.split(x, <span class="dv">2</span>, axis<span class="op">=-</span><span class="dv">1</span>) </span>
<span id="cb45-12"><a href="#cb45-12" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb45-13"><a href="#cb45-13" aria-hidden="true" tabindex="-1"></a>    <span class="co"># get y1 using equation 3</span></span>
<span id="cb45-14"><a href="#cb45-14" aria-hidden="true" tabindex="-1"></a>    y1 <span class="op">=</span> x1 <span class="op">+</span> f(x2)</span>
<span id="cb45-15"><a href="#cb45-15" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb45-16"><a href="#cb45-16" aria-hidden="true" tabindex="-1"></a>    <span class="co"># get y2 using equation 4</span></span>
<span id="cb45-17"><a href="#cb45-17" aria-hidden="true" tabindex="-1"></a>    y2 <span class="op">=</span> x2 <span class="op">+</span> g(y1)</span>
<span id="cb45-18"><a href="#cb45-18" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb45-19"><a href="#cb45-19" aria-hidden="true" tabindex="-1"></a>    <span class="co"># concatenate y1 and y2 along the depth dimension. be sure output is of type np.ndarray</span></span>
<span id="cb45-20"><a href="#cb45-20" aria-hidden="true" tabindex="-1"></a>    y <span class="op">=</span> np.concatenate([y1, y2], axis<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb45-21"><a href="#cb45-21" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb45-22"><a href="#cb45-22" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> y</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<section id="reversible_layer_reverse" class="level3" data-number="4.1">
<h3 data-number="4.1" class="anchored" data-anchor-id="reversible_layer_reverse"><span class="header-section-number">4.1</span> reversible_layer_reverse</h3>
<p>We will now implement the <code>reversible_layer_reverse</code> function which is possible because at every time step you have <span class="math inline">\(x_1\)</span> and <span class="math inline">\(x_2\)</span> and <span class="math inline">\(y_2\)</span> and <span class="math inline">\(y_1\)</span>, along with the function <code>f</code>, and <code>g</code>. Where <code>f</code> is the attention and <code>g</code> is the feedforward. This allows you to compute equations 5 and 6.</p>
<p>We will now implement the <code>reversible_layer_reverse</code>. Our function takes in the output vector from <code>reversible_layer_forward</code> and functions f and g. Using equations 5 and 6 above, it computes the inputs to the layer, <span class="math inline">\(x_1\)</span> and <span class="math inline">\(x_2\)</span>. The output, x, is the concatenation of <span class="math inline">\(x_1, x_2\)</span>. Utilize <code>np.concatenate()</code> to form the output being careful to match the axis of the <code>np.split()</code>.</p>
<div class="cell" data-execution_count="28">
<div class="sourceCode cell-code" id="cb46"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> reversible_layer_reverse(y, f, g):</span>
<span id="cb46-2"><a href="#cb46-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb46-3"><a href="#cb46-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Args: </span></span>
<span id="cb46-4"><a href="#cb46-4" aria-hidden="true" tabindex="-1"></a><span class="co">        y (np.array): an input vector or matrix</span></span>
<span id="cb46-5"><a href="#cb46-5" aria-hidden="true" tabindex="-1"></a><span class="co">        f (function): a function which operates on a vector/matrix of the form of 'y'</span></span>
<span id="cb46-6"><a href="#cb46-6" aria-hidden="true" tabindex="-1"></a><span class="co">        g (function): a function which operates on a vector/matrix of the form of 'y'</span></span>
<span id="cb46-7"><a href="#cb46-7" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns: </span></span>
<span id="cb46-8"><a href="#cb46-8" aria-hidden="true" tabindex="-1"></a><span class="co">        y (np.array): an output vector or matrix whose form is determined by 'y', f and g</span></span>
<span id="cb46-9"><a href="#cb46-9" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb46-10"><a href="#cb46-10" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb46-11"><a href="#cb46-11" aria-hidden="true" tabindex="-1"></a>    <span class="co"># split the input vector into two (* along the last axis because it is the depth dimension)</span></span>
<span id="cb46-12"><a href="#cb46-12" aria-hidden="true" tabindex="-1"></a>    y1, y2 <span class="op">=</span> np.split(y, <span class="dv">2</span>, axis<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb46-13"><a href="#cb46-13" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb46-14"><a href="#cb46-14" aria-hidden="true" tabindex="-1"></a>    <span class="co"># compute x2 using equation 5</span></span>
<span id="cb46-15"><a href="#cb46-15" aria-hidden="true" tabindex="-1"></a>    x2 <span class="op">=</span> y2 <span class="op">-</span> g(y1)</span>
<span id="cb46-16"><a href="#cb46-16" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb46-17"><a href="#cb46-17" aria-hidden="true" tabindex="-1"></a>    <span class="co"># compute x1 using equation 6</span></span>
<span id="cb46-18"><a href="#cb46-18" aria-hidden="true" tabindex="-1"></a>    x1 <span class="op">=</span> y1 <span class="op">-</span> f(x2)</span>
<span id="cb46-19"><a href="#cb46-19" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb46-20"><a href="#cb46-20" aria-hidden="true" tabindex="-1"></a>    <span class="co"># concatenate x1 and x2 along the depth dimension</span></span>
<span id="cb46-21"><a href="#cb46-21" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> np.concatenate([x1, x2], axis<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb46-22"><a href="#cb46-22" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb46-23"><a href="#cb46-23" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> x</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="29">
<div class="sourceCode cell-code" id="cb47"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a><span class="co"># UNIT </span><span class="al">TEST</span></span>
<span id="cb47-2"><a href="#cb47-2" aria-hidden="true" tabindex="-1"></a>f <span class="op">=</span> <span class="kw">lambda</span> x: x <span class="op">+</span> <span class="dv">2</span></span>
<span id="cb47-3"><a href="#cb47-3" aria-hidden="true" tabindex="-1"></a>g <span class="op">=</span> <span class="kw">lambda</span> x: x <span class="op">*</span> <span class="dv">3</span></span>
<span id="cb47-4"><a href="#cb47-4" aria-hidden="true" tabindex="-1"></a>input_vector <span class="op">=</span> np.random.uniform(size<span class="op">=</span>(<span class="dv">32</span>,))</span>
<span id="cb47-5"><a href="#cb47-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-6"><a href="#cb47-6" aria-hidden="true" tabindex="-1"></a>output_vector <span class="op">=</span> reversible_layer_forward(input_vector, f, g)</span>
<span id="cb47-7"><a href="#cb47-7" aria-hidden="true" tabindex="-1"></a>reversed_vector <span class="op">=</span> reversible_layer_reverse(output_vector, f, g)</span>
<span id="cb47-8"><a href="#cb47-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-9"><a href="#cb47-9" aria-hidden="true" tabindex="-1"></a><span class="cf">assert</span> np.allclose(reversed_vector, input_vector)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="reversible-layers-and-randomness" class="level3" data-number="4.2">
<h3 data-number="4.2" class="anchored" data-anchor-id="reversible-layers-and-randomness"><span class="header-section-number">4.2</span> Reversible Layers and Randomness</h3>
<p>Utilizing the same key, <code>trax.fastmath.random.uniform()</code> will return the same values. This is required for the backward pass to return the correct layer inputs when random noise is introduced in the layer.</p>
<div class="cell" data-execution_count="31">
<div class="sourceCode cell-code" id="cb48"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Layers like dropout have noise, so let's simulate it here:</span></span>
<span id="cb48-2"><a href="#cb48-2" aria-hidden="true" tabindex="-1"></a>f <span class="op">=</span> <span class="kw">lambda</span> x: x <span class="op">+</span> np.random.uniform(size<span class="op">=</span>x.shape)</span>
<span id="cb48-3"><a href="#cb48-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-4"><a href="#cb48-4" aria-hidden="true" tabindex="-1"></a><span class="co"># See that the above doesn't work any more:</span></span>
<span id="cb48-5"><a href="#cb48-5" aria-hidden="true" tabindex="-1"></a>output_vector <span class="op">=</span> reversible_layer_forward(input_vector, f, g)</span>
<span id="cb48-6"><a href="#cb48-6" aria-hidden="true" tabindex="-1"></a>reversed_vector <span class="op">=</span> reversible_layer_reverse(output_vector, f, g)</span>
<span id="cb48-7"><a href="#cb48-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-8"><a href="#cb48-8" aria-hidden="true" tabindex="-1"></a><span class="cf">assert</span> <span class="kw">not</span> np.allclose(reversed_vector, input_vector)  <span class="co"># Fails!!</span></span>
<span id="cb48-9"><a href="#cb48-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-10"><a href="#cb48-10" aria-hidden="true" tabindex="-1"></a><span class="co"># It failed because the noise when reversing used a different random seed.</span></span>
<span id="cb48-11"><a href="#cb48-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-12"><a href="#cb48-12" aria-hidden="true" tabindex="-1"></a>random_seed <span class="op">=</span> <span class="dv">27686</span></span>
<span id="cb48-13"><a href="#cb48-13" aria-hidden="true" tabindex="-1"></a>rng <span class="op">=</span> trax.fastmath.random.get_prng(random_seed)</span>
<span id="cb48-14"><a href="#cb48-14" aria-hidden="true" tabindex="-1"></a>f <span class="op">=</span> <span class="kw">lambda</span> x: x <span class="op">+</span> trax.fastmath.random.uniform(key<span class="op">=</span>rng, shape<span class="op">=</span>x.shape)</span>
<span id="cb48-15"><a href="#cb48-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-16"><a href="#cb48-16" aria-hidden="true" tabindex="-1"></a><span class="co"># See that it works now as the same rng is used on forward and reverse.</span></span>
<span id="cb48-17"><a href="#cb48-17" aria-hidden="true" tabindex="-1"></a>output_vector <span class="op">=</span> reversible_layer_forward(input_vector, f, g)</span>
<span id="cb48-18"><a href="#cb48-18" aria-hidden="true" tabindex="-1"></a>reversed_vector <span class="op">=</span> reversible_layer_reverse(output_vector, f, g)</span>
<span id="cb48-19"><a href="#cb48-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-20"><a href="#cb48-20" aria-hidden="true" tabindex="-1"></a><span class="cf">assert</span> np.allclose(reversed_vector, input_vector,  atol<span class="op">=</span><span class="fl">1e-07</span>) </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)</code></pre>
</div>
</div>
</section>
</section>
<section id="reformerlm-training" class="level2" data-number="5">
<h2 data-number="5" class="anchored" data-anchor-id="reformerlm-training"><span class="header-section-number">5</span> ReformerLM Training</h2>
<p>We will now proceed to training our model. Since we have already know the two main components that differentiates it from the standard Transformer, LSH and reversible layers above, we can just use the pre-built model already implemented in Trax. It will have this architecture:</p>
<p><img src="https://github.com/pranath/blog/raw/master/images/Reformer.jpg"></p>
<p>Similar to the Transformer we learned earlier, we want to apply an attention and feed forward layer to our inputs. For the Reformer, we improve the memory efficiency by using <strong>reversible decoder blocks</strong> and we can picture its implementation in Trax like below:</p>
<p><img src="https://github.com/pranath/blog/raw/master/images/ReversibleDecoder.png"></p>
<p>We can see that it takes the initial inputs <code>x1</code> and <code>x2</code> and does the first equation of the reversible networks we learned in earlier articles. As we’ve also learned, the reversible residual has two equations for the forward-pass so doing just one of them will just constitute half of the reversible decoder block. Before doing the second equation (i.e.&nbsp;second half of the reversible residual), it first needs to swap the elements to take into account the stack semantics in Trax. It simply puts <code>x2</code> on top of the stack so it can be fed to the add block of the half-residual layer. It then swaps the two outputs again so it can be fed to the next layer of the network. All of these arrives at the two equations it can be used to recompute the activations during the backward pass.</p>
<section id="reformerlm" class="level3" data-number="5.1">
<h3 data-number="5.1" class="anchored" data-anchor-id="reformerlm"><span class="header-section-number">5.1</span> ReformerLM</h3>
<p>We will now implement a wrapper function that returns a Reformer Language Model. We can use Trax’s <a href="https://trax-ml.readthedocs.io/en/latest/trax.models.html#trax.models.reformer.reformer.ReformerLM">ReformerLM</a> to do this quickly. It will have the same architecture as shown above.</p>
<div class="cell" data-execution_count="32">
<div class="sourceCode cell-code" id="cb50"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> ReformerLM(vocab_size<span class="op">=</span><span class="dv">33000</span>, n_layers<span class="op">=</span><span class="dv">2</span>, mode<span class="op">=</span><span class="st">'train'</span>, attention_type<span class="op">=</span>tl.SelfAttention):</span>
<span id="cb50-2"><a href="#cb50-2" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb50-3"><a href="#cb50-3" aria-hidden="true" tabindex="-1"></a>    <span class="co"># initialize an instance of Trax's ReformerLM class</span></span>
<span id="cb50-4"><a href="#cb50-4" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> tl.Serial( </span>
<span id="cb50-5"><a href="#cb50-5" aria-hidden="true" tabindex="-1"></a>                trax.models.reformer.ReformerLM( </span>
<span id="cb50-6"><a href="#cb50-6" aria-hidden="true" tabindex="-1"></a>                    <span class="co"># set vocab size</span></span>
<span id="cb50-7"><a href="#cb50-7" aria-hidden="true" tabindex="-1"></a>                    vocab_size<span class="op">=</span>vocab_size,</span>
<span id="cb50-8"><a href="#cb50-8" aria-hidden="true" tabindex="-1"></a>                    <span class="co"># set number of layers</span></span>
<span id="cb50-9"><a href="#cb50-9" aria-hidden="true" tabindex="-1"></a>                    n_layers<span class="op">=</span>n_layers,</span>
<span id="cb50-10"><a href="#cb50-10" aria-hidden="true" tabindex="-1"></a>                    <span class="co"># set mode</span></span>
<span id="cb50-11"><a href="#cb50-11" aria-hidden="true" tabindex="-1"></a>                    mode<span class="op">=</span>mode,</span>
<span id="cb50-12"><a href="#cb50-12" aria-hidden="true" tabindex="-1"></a>                    <span class="co"># set attention type</span></span>
<span id="cb50-13"><a href="#cb50-13" aria-hidden="true" tabindex="-1"></a>                    attention_type<span class="op">=</span>attention_type</span>
<span id="cb50-14"><a href="#cb50-14" aria-hidden="true" tabindex="-1"></a>            )</span>
<span id="cb50-15"><a href="#cb50-15" aria-hidden="true" tabindex="-1"></a>            , tl.LogSoftmax() </span>
<span id="cb50-16"><a href="#cb50-16" aria-hidden="true" tabindex="-1"></a>        )        </span>
<span id="cb50-17"><a href="#cb50-17" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> model <span class="co"># tl.Serial(model, tl.LogSoftmax(),)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="33">
<div class="sourceCode cell-code" id="cb51"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a><span class="co"># display the model</span></span>
<span id="cb51-2"><a href="#cb51-2" aria-hidden="true" tabindex="-1"></a>temp_model <span class="op">=</span> ReformerLM(<span class="st">'train'</span>)</span>
<span id="cb51-3"><a href="#cb51-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="bu">str</span>(temp_model))</span>
<span id="cb51-4"><a href="#cb51-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-5"><a href="#cb51-5" aria-hidden="true" tabindex="-1"></a><span class="co"># free memory</span></span>
<span id="cb51-6"><a href="#cb51-6" aria-hidden="true" tabindex="-1"></a><span class="co">#del temp_model </span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Serial[
  Serial[
    Serial[
      ShiftRight(1)
    ]
    Embedding_train_512
    Dropout
    Serial[
      PositionalEncoding
    ]
    Dup_out2
    ReversibleSerial_in2_out2[
      ReversibleHalfResidualDecoderAttn_in2_out2[
        Serial[
          LayerNorm
        ]
        SelfAttention
      ]
      ReversibleSwap_in2_out2
      ReversibleHalfResidualDecoderFF_in2_out2[
        Serial[
          LayerNorm
          Dense_2048
          Dropout
          Serial[
            FastGelu
          ]
          Dense_512
          Dropout
        ]
      ]
      ReversibleSwap_in2_out2
      ReversibleHalfResidualDecoderAttn_in2_out2[
        Serial[
          LayerNorm
        ]
        SelfAttention
      ]
      ReversibleSwap_in2_out2
      ReversibleHalfResidualDecoderFF_in2_out2[
        Serial[
          LayerNorm
          Dense_2048
          Dropout
          Serial[
            FastGelu
          ]
          Dense_512
          Dropout
        ]
      ]
      ReversibleSwap_in2_out2
    ]
    Concatenate_in2
    LayerNorm
    Dropout
    Serial[
      Dense_train
    ]
  ]
  LogSoftmax
]</code></pre>
</div>
</div>
</section>
<section id="training_loop" class="level3" data-number="5.2">
<h3 data-number="5.2" class="anchored" data-anchor-id="training_loop"><span class="header-section-number">5.2</span> training_loop</h3>
<p>We will now write a function that takes in our model and trains it.</p>
<p>We will implement the <code>training_loop</code> below to train the neural network above. Here is a list of things we should do:</p>
<ul>
<li>Create <code>TrainTask</code> and <code>EvalTask</code></li>
<li>Create the training loop <code>trax.supervised.training.Loop</code></li>
<li>Pass in the following depending to train_task :
<ul>
<li><code>labeled_data=train_gen</code></li>
<li><code>loss_layer=tl.CrossEntropyLoss()</code></li>
<li><code>optimizer=trax.optimizers.Adam(0.01)</code></li>
<li><code>lr_schedule=lr_schedule</code></li>
<li><code>n_steps_per_checkpoint=10</code></li>
</ul></li>
</ul>
<p>We will be using our CrossEntropyLoss loss function with Adam optimizer. Please read the <a href="https://trax-ml.readthedocs.io/en/latest/trax.optimizers.html?highlight=adam#trax.optimizers.adam.Adam">trax</a> documentation to get a full understanding.</p>
<ul>
<li>Pass in the following to eval_task:
<ul>
<li><code>labeled_data=eval_gen</code></li>
<li><code>metrics=[tl.CrossEntropyLoss(), tl.Accuracy()]</code></li>
</ul></li>
</ul>
<p>This function should return a <code>training.Loop</code> object. To read more about this check the <a href="https://trax-ml.readthedocs.io/en/latest/trax.supervised.html?highlight=loop#trax.supervised.training.Loop">docs</a>.</p>
<div class="cell" data-execution_count="35">
<div class="sourceCode cell-code" id="cb53"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> training_loop(ReformerLM, train_gen, eval_gen, output_dir <span class="op">=</span> <span class="st">"./model/"</span>):</span>
<span id="cb53-2"><a href="#cb53-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb53-3"><a href="#cb53-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Args:</span></span>
<span id="cb53-4"><a href="#cb53-4" aria-hidden="true" tabindex="-1"></a><span class="co">        ReformerLM:  the Reformer language model you are building</span></span>
<span id="cb53-5"><a href="#cb53-5" aria-hidden="true" tabindex="-1"></a><span class="co">        train_gen (generator): train data generator.</span></span>
<span id="cb53-6"><a href="#cb53-6" aria-hidden="true" tabindex="-1"></a><span class="co">        eval_gen (generator): Validation generator. </span></span>
<span id="cb53-7"><a href="#cb53-7" aria-hidden="true" tabindex="-1"></a><span class="co">        output_dir (string): Path to save the model output. Defaults to './model/'.</span></span>
<span id="cb53-8"><a href="#cb53-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-9"><a href="#cb53-9" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb53-10"><a href="#cb53-10" aria-hidden="true" tabindex="-1"></a><span class="co">        trax.supervised.training.Loop: Training loop for the model.</span></span>
<span id="cb53-11"><a href="#cb53-11" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb53-12"><a href="#cb53-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-13"><a href="#cb53-13" aria-hidden="true" tabindex="-1"></a>    <span class="co"># use the warmup_and_rsqrt_decay learning rate schedule</span></span>
<span id="cb53-14"><a href="#cb53-14" aria-hidden="true" tabindex="-1"></a>    lr_schedule <span class="op">=</span> trax.lr.warmup_and_rsqrt_decay(</span>
<span id="cb53-15"><a href="#cb53-15" aria-hidden="true" tabindex="-1"></a>        n_warmup_steps<span class="op">=</span><span class="dv">1000</span>, max_value<span class="op">=</span><span class="fl">0.01</span>)</span>
<span id="cb53-16"><a href="#cb53-16" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb53-17"><a href="#cb53-17" aria-hidden="true" tabindex="-1"></a>    <span class="co"># define the train task</span></span>
<span id="cb53-18"><a href="#cb53-18" aria-hidden="true" tabindex="-1"></a>    train_task <span class="op">=</span> training.TrainTask(            </span>
<span id="cb53-19"><a href="#cb53-19" aria-hidden="true" tabindex="-1"></a>        <span class="co"># labeled data</span></span>
<span id="cb53-20"><a href="#cb53-20" aria-hidden="true" tabindex="-1"></a>        labeled_data<span class="op">=</span>train_gen,</span>
<span id="cb53-21"><a href="#cb53-21" aria-hidden="true" tabindex="-1"></a>        <span class="co"># loss layer</span></span>
<span id="cb53-22"><a href="#cb53-22" aria-hidden="true" tabindex="-1"></a>        loss_layer<span class="op">=</span>tl.CrossEntropyLoss(),</span>
<span id="cb53-23"><a href="#cb53-23" aria-hidden="true" tabindex="-1"></a>        <span class="co"># optimizer</span></span>
<span id="cb53-24"><a href="#cb53-24" aria-hidden="true" tabindex="-1"></a>        optimizer<span class="op">=</span>trax.optimizers.Adam(<span class="fl">0.01</span>),</span>
<span id="cb53-25"><a href="#cb53-25" aria-hidden="true" tabindex="-1"></a>        <span class="co"># lr_schedule</span></span>
<span id="cb53-26"><a href="#cb53-26" aria-hidden="true" tabindex="-1"></a>        lr_schedule<span class="op">=</span>lr_schedule,</span>
<span id="cb53-27"><a href="#cb53-27" aria-hidden="true" tabindex="-1"></a>        <span class="co"># n_steps</span></span>
<span id="cb53-28"><a href="#cb53-28" aria-hidden="true" tabindex="-1"></a>        n_steps_per_checkpoint<span class="op">=</span><span class="dv">10</span></span>
<span id="cb53-29"><a href="#cb53-29" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb53-30"><a href="#cb53-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-31"><a href="#cb53-31" aria-hidden="true" tabindex="-1"></a>    <span class="co"># define the eval task</span></span>
<span id="cb53-32"><a href="#cb53-32" aria-hidden="true" tabindex="-1"></a>    eval_task <span class="op">=</span> training.EvalTask(                      </span>
<span id="cb53-33"><a href="#cb53-33" aria-hidden="true" tabindex="-1"></a>        <span class="co"># labeled data</span></span>
<span id="cb53-34"><a href="#cb53-34" aria-hidden="true" tabindex="-1"></a>        labeled_data<span class="op">=</span>eval_gen,</span>
<span id="cb53-35"><a href="#cb53-35" aria-hidden="true" tabindex="-1"></a>        <span class="co"># metrics</span></span>
<span id="cb53-36"><a href="#cb53-36" aria-hidden="true" tabindex="-1"></a>        metrics<span class="op">=</span>[tl.CrossEntropyLoss(), tl.Accuracy()]</span>
<span id="cb53-37"><a href="#cb53-37" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb53-38"><a href="#cb53-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-39"><a href="#cb53-39" aria-hidden="true" tabindex="-1"></a>    loop <span class="op">=</span> training.Loop(ReformerLM(mode<span class="op">=</span><span class="st">'train'</span>),</span>
<span id="cb53-40"><a href="#cb53-40" aria-hidden="true" tabindex="-1"></a>                         train_task,</span>
<span id="cb53-41"><a href="#cb53-41" aria-hidden="true" tabindex="-1"></a>                         eval_tasks<span class="op">=</span>[eval_task],</span>
<span id="cb53-42"><a href="#cb53-42" aria-hidden="true" tabindex="-1"></a>                         output_dir<span class="op">=</span>output_dir)</span>
<span id="cb53-43"><a href="#cb53-43" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> loop</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-outputid="b6e00b37-6f13-486d-ba49-2d4542b0d398" data-execution_count="38">
<div class="sourceCode cell-code" id="cb54"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a><span class="co"># we will now test our function</span></span>
<span id="cb54-2"><a href="#cb54-2" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>rm <span class="op">-</span>f model<span class="op">/</span>model.pkl.gz</span>
<span id="cb54-3"><a href="#cb54-3" aria-hidden="true" tabindex="-1"></a>loop <span class="op">=</span> training_loop(ReformerLM, train_stream, eval_stream)</span>
<span id="cb54-4"><a href="#cb54-4" aria-hidden="true" tabindex="-1"></a>loop.run(<span class="dv">10</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Step      1: Total number of trainable weights: 58072296
Step      1: Ran 1 train steps in 53.39 secs
Step      1: train CrossEntropyLoss |  10.45205879
Step      1: eval  CrossEntropyLoss |  10.43009472
Step      1: eval          Accuracy |  0.00000000

Step     10: Ran 9 train steps in 116.91 secs
Step     10: train CrossEntropyLoss |  10.23098850
Step     10: eval  CrossEntropyLoss |  9.81040001
Step     10: eval          Accuracy |  0.05645161</code></pre>
</div>
</div>
</section>
</section>
<section id="decode-from-a-pretrained-model" class="level2" data-number="6">
<h2 data-number="6" class="anchored" data-anchor-id="decode-from-a-pretrained-model"><span class="header-section-number">6</span> Decode from a Pretrained Model</h2>
<p>We will now proceed on decoding using the model architecture we just implemented. As previously, we will be using a pretrained model so we can observe meaningful output during inference. We will be using the <a href="https://trax-ml.readthedocs.io/en/latest/trax.supervised.html#trax.supervised.decoding.autoregressive_sample_stream">autoregressive_sample_stream()</a> decoding method from Trax to do fast inference. Let’s define a few parameters to initialize our model.</p>
<div class="cell" data-execution_count="39">
<div class="sourceCode cell-code" id="cb56"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a><span class="co"># define the `predict_mem_len` and `predict_drop_len` of tl.SelfAttention</span></span>
<span id="cb56-2"><a href="#cb56-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> attention(<span class="op">*</span>args, <span class="op">**</span>kwargs):</span>
<span id="cb56-3"><a href="#cb56-3" aria-hidden="true" tabindex="-1"></a>    <span class="co"># number of input positions to remember in a cache when doing fast inference. </span></span>
<span id="cb56-4"><a href="#cb56-4" aria-hidden="true" tabindex="-1"></a>    kwargs[<span class="st">'predict_mem_len'</span>] <span class="op">=</span> <span class="dv">120</span></span>
<span id="cb56-5"><a href="#cb56-5" aria-hidden="true" tabindex="-1"></a>    <span class="co"># number of input elements to drop once the fast inference input cache fills up.</span></span>
<span id="cb56-6"><a href="#cb56-6" aria-hidden="true" tabindex="-1"></a>    kwargs[<span class="st">'predict_drop_len'</span>] <span class="op">=</span> <span class="dv">120</span></span>
<span id="cb56-7"><a href="#cb56-7" aria-hidden="true" tabindex="-1"></a>    <span class="co"># return the attention layer with the parameters defined above</span></span>
<span id="cb56-8"><a href="#cb56-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> tl.SelfAttention(<span class="op">*</span>args, <span class="op">**</span>kwargs)</span>
<span id="cb56-9"><a href="#cb56-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-10"><a href="#cb56-10" aria-hidden="true" tabindex="-1"></a><span class="co"># define the model using the ReformerLM function you implemented earlier.</span></span>
<span id="cb56-11"><a href="#cb56-11" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> ReformerLM(</span>
<span id="cb56-12"><a href="#cb56-12" aria-hidden="true" tabindex="-1"></a>    vocab_size<span class="op">=</span><span class="dv">33000</span>,</span>
<span id="cb56-13"><a href="#cb56-13" aria-hidden="true" tabindex="-1"></a>    n_layers<span class="op">=</span><span class="dv">6</span>,</span>
<span id="cb56-14"><a href="#cb56-14" aria-hidden="true" tabindex="-1"></a>    mode<span class="op">=</span><span class="st">'predict'</span>,</span>
<span id="cb56-15"><a href="#cb56-15" aria-hidden="true" tabindex="-1"></a>    attention_type<span class="op">=</span>attention,</span>
<span id="cb56-16"><a href="#cb56-16" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb56-17"><a href="#cb56-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-18"><a href="#cb56-18" aria-hidden="true" tabindex="-1"></a><span class="co"># define an input signature so we can initialize our model. shape will be (1, 1) and the data type is int32.</span></span>
<span id="cb56-19"><a href="#cb56-19" aria-hidden="true" tabindex="-1"></a>shape11 <span class="op">=</span> trax.shapes.ShapeDtype((<span class="dv">1</span>, <span class="dv">1</span>), dtype<span class="op">=</span>np.int32)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We can now initialize our model from a file containing the pretrained weights. We will save this starting state so we can reset the model state when we generate a new conversation. This will become clearer in the <code>generate_dialogue()</code> function later.</p>
<div class="cell" data-execution_count="40">
<div class="sourceCode cell-code" id="cb57"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb57-1"><a href="#cb57-1" aria-hidden="true" tabindex="-1"></a><span class="co"># initialize from file</span></span>
<span id="cb57-2"><a href="#cb57-2" aria-hidden="true" tabindex="-1"></a>model.init_from_file(<span class="st">'chatbot_model1.pkl.gz'</span>,</span>
<span id="cb57-3"><a href="#cb57-3" aria-hidden="true" tabindex="-1"></a>                     weights_only<span class="op">=</span><span class="va">True</span>, input_signature<span class="op">=</span>shape11)</span>
<span id="cb57-4"><a href="#cb57-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-5"><a href="#cb57-5" aria-hidden="true" tabindex="-1"></a><span class="co"># save the starting state</span></span>
<span id="cb57-6"><a href="#cb57-6" aria-hidden="true" tabindex="-1"></a>STARTING_STATE <span class="op">=</span> model.state</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Let’s define a few utility functions as well to help us tokenize and detokenize. We can use the <a href="https://trax-ml.readthedocs.io/en/latest/trax.data.html#trax.data.tf_inputs.tokenize">tokenize()</a> and <a href="https://trax-ml.readthedocs.io/en/latest/trax.data.html#trax.data.tf_inputs.detokenize">detokenize()</a> from <code>trax.data.tf_inputs</code> to do this.</p>
<div class="cell" data-execution_count="41">
<div class="sourceCode cell-code" id="cb58"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> tokenize(sentence, vocab_file, vocab_dir):</span>
<span id="cb58-2"><a href="#cb58-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="bu">list</span>(trax.data.tokenize(<span class="bu">iter</span>([sentence]), vocab_file<span class="op">=</span>vocab_file, vocab_dir<span class="op">=</span>vocab_dir))[<span class="dv">0</span>]</span>
<span id="cb58-3"><a href="#cb58-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-4"><a href="#cb58-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> detokenize(tokens, vocab_file, vocab_dir):</span>
<span id="cb58-5"><a href="#cb58-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> trax.data.detokenize(tokens, vocab_file<span class="op">=</span>vocab_file, vocab_dir<span class="op">=</span>vocab_dir)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We are now ready to define our decoding function. This will return a generator that yields that next symbol output by the model. It will be able to predict the next words by just feeding it a starting sentence.</p>
<section id="reformerlm_output_gen" class="level3" data-number="6.1">
<h3 data-number="6.1" class="anchored" data-anchor-id="reformerlm_output_gen"><span class="header-section-number">6.1</span> ReformerLM_output_gen</h3>
<p>We will implement the function below to return a generator that predicts the next word of the conversation.</p>
<div class="cell" data-execution_count="42">
<div class="sourceCode cell-code" id="cb59"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb59-1"><a href="#cb59-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> ReformerLM_output_gen(ReformerLM, start_sentence, vocab_file, vocab_dir, temperature, tokenize<span class="op">=</span>tokenize):</span>
<span id="cb59-2"><a href="#cb59-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb59-3"><a href="#cb59-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Args:</span></span>
<span id="cb59-4"><a href="#cb59-4" aria-hidden="true" tabindex="-1"></a><span class="co">        ReformerLM:  the Reformer language model you just trained</span></span>
<span id="cb59-5"><a href="#cb59-5" aria-hidden="true" tabindex="-1"></a><span class="co">        start_sentence (string): starting sentence of the conversation</span></span>
<span id="cb59-6"><a href="#cb59-6" aria-hidden="true" tabindex="-1"></a><span class="co">        vocab_file (string): vocabulary filename</span></span>
<span id="cb59-7"><a href="#cb59-7" aria-hidden="true" tabindex="-1"></a><span class="co">        vocab_dir (string): directory of the vocabulary file</span></span>
<span id="cb59-8"><a href="#cb59-8" aria-hidden="true" tabindex="-1"></a><span class="co">        temperature (float): parameter for sampling ranging from 0.0 to 1.0.</span></span>
<span id="cb59-9"><a href="#cb59-9" aria-hidden="true" tabindex="-1"></a><span class="co">            0.0: same as argmax, always pick the most probable token</span></span>
<span id="cb59-10"><a href="#cb59-10" aria-hidden="true" tabindex="-1"></a><span class="co">            1.0: sampling from the distribution (can sometimes say random things)</span></span>
<span id="cb59-11"><a href="#cb59-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-12"><a href="#cb59-12" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb59-13"><a href="#cb59-13" aria-hidden="true" tabindex="-1"></a><span class="co">        generator: yields the next symbol generated by the model</span></span>
<span id="cb59-14"><a href="#cb59-14" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb59-15"><a href="#cb59-15" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb59-16"><a href="#cb59-16" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create input tokens using the the tokenize function</span></span>
<span id="cb59-17"><a href="#cb59-17" aria-hidden="true" tabindex="-1"></a>    input_tokens <span class="op">=</span> tokenize(start_sentence, vocab_file<span class="op">=</span>vocab_file, vocab_dir<span class="op">=</span>vocab_dir)</span>
<span id="cb59-18"><a href="#cb59-18" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb59-19"><a href="#cb59-19" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Add batch dimension to array. Convert from (n,) to (x, n) where </span></span>
<span id="cb59-20"><a href="#cb59-20" aria-hidden="true" tabindex="-1"></a>    <span class="co"># x is the batch size. Default is 1. (hint: you can use np.expand_dims() with axis=0)</span></span>
<span id="cb59-21"><a href="#cb59-21" aria-hidden="true" tabindex="-1"></a>    input_tokens_with_batch <span class="op">=</span> np.array(input_tokens)[<span class="va">None</span>, :]</span>
<span id="cb59-22"><a href="#cb59-22" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb59-23"><a href="#cb59-23" aria-hidden="true" tabindex="-1"></a>    <span class="co"># call the autoregressive_sample_stream function from trax</span></span>
<span id="cb59-24"><a href="#cb59-24" aria-hidden="true" tabindex="-1"></a>    output_gen <span class="op">=</span> trax.supervised.decoding.autoregressive_sample_stream( </span>
<span id="cb59-25"><a href="#cb59-25" aria-hidden="true" tabindex="-1"></a>        <span class="co"># model</span></span>
<span id="cb59-26"><a href="#cb59-26" aria-hidden="true" tabindex="-1"></a>        ReformerLM,</span>
<span id="cb59-27"><a href="#cb59-27" aria-hidden="true" tabindex="-1"></a>        <span class="co"># inputs will be the tokens with batch dimension</span></span>
<span id="cb59-28"><a href="#cb59-28" aria-hidden="true" tabindex="-1"></a>        inputs<span class="op">=</span>input_tokens_with_batch,</span>
<span id="cb59-29"><a href="#cb59-29" aria-hidden="true" tabindex="-1"></a>        <span class="co"># temperature</span></span>
<span id="cb59-30"><a href="#cb59-30" aria-hidden="true" tabindex="-1"></a>        temperature<span class="op">=</span>temperature</span>
<span id="cb59-31"><a href="#cb59-31" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb59-32"><a href="#cb59-32" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb59-33"><a href="#cb59-33" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> output_gen</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Now we will be able to see the model in action. The utility function below will call the generator we just implemented and will just format the output to be easier to read.</p>
<div class="cell" data-execution_count="44">
<div class="sourceCode cell-code" id="cb60"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb60-1"><a href="#cb60-1" aria-hidden="true" tabindex="-1"></a>shape11 <span class="op">=</span> trax.shapes.ShapeDtype((<span class="dv">1</span>, <span class="dv">1</span>), dtype<span class="op">=</span>np.int32)</span>
<span id="cb60-2"><a href="#cb60-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-3"><a href="#cb60-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> attention(<span class="op">*</span>args, <span class="op">**</span>kwargs):</span>
<span id="cb60-4"><a href="#cb60-4" aria-hidden="true" tabindex="-1"></a>    kwargs[<span class="st">'predict_mem_len'</span>] <span class="op">=</span> <span class="dv">120</span>  <span class="co"># max length for predictions</span></span>
<span id="cb60-5"><a href="#cb60-5" aria-hidden="true" tabindex="-1"></a>    kwargs[<span class="st">'predict_drop_len'</span>] <span class="op">=</span> <span class="dv">120</span>  <span class="co"># never drop old stuff</span></span>
<span id="cb60-6"><a href="#cb60-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> tl.SelfAttention(<span class="op">*</span>args, <span class="op">**</span>kwargs)</span>
<span id="cb60-7"><a href="#cb60-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-8"><a href="#cb60-8" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> ReformerLM(</span>
<span id="cb60-9"><a href="#cb60-9" aria-hidden="true" tabindex="-1"></a>    vocab_size<span class="op">=</span><span class="dv">33000</span>,</span>
<span id="cb60-10"><a href="#cb60-10" aria-hidden="true" tabindex="-1"></a>    n_layers<span class="op">=</span><span class="dv">6</span>,</span>
<span id="cb60-11"><a href="#cb60-11" aria-hidden="true" tabindex="-1"></a>    mode<span class="op">=</span><span class="st">'predict'</span>,</span>
<span id="cb60-12"><a href="#cb60-12" aria-hidden="true" tabindex="-1"></a>    attention_type<span class="op">=</span>attention,</span>
<span id="cb60-13"><a href="#cb60-13" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="45">
<div class="sourceCode cell-code" id="cb61"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb61-1"><a href="#cb61-1" aria-hidden="true" tabindex="-1"></a>model.init_from_file(<span class="st">'chatbot_model1.pkl.gz'</span>,</span>
<span id="cb61-2"><a href="#cb61-2" aria-hidden="true" tabindex="-1"></a>                     weights_only<span class="op">=</span><span class="va">True</span>, input_signature<span class="op">=</span>shape11)</span>
<span id="cb61-3"><a href="#cb61-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-4"><a href="#cb61-4" aria-hidden="true" tabindex="-1"></a>STARTING_STATE <span class="op">=</span> model.state</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="46">
<div class="sourceCode cell-code" id="cb62"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb62-1"><a href="#cb62-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> generate_dialogue(ReformerLM, model_state, start_sentence, vocab_file, vocab_dir, max_len, temperature):</span>
<span id="cb62-2"><a href="#cb62-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb62-3"><a href="#cb62-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Args:</span></span>
<span id="cb62-4"><a href="#cb62-4" aria-hidden="true" tabindex="-1"></a><span class="co">        ReformerLM:  the Reformer language model you just trained</span></span>
<span id="cb62-5"><a href="#cb62-5" aria-hidden="true" tabindex="-1"></a><span class="co">        model_state (np.array): initial state of the model before decoding</span></span>
<span id="cb62-6"><a href="#cb62-6" aria-hidden="true" tabindex="-1"></a><span class="co">        start_sentence (string): starting sentence of the conversation</span></span>
<span id="cb62-7"><a href="#cb62-7" aria-hidden="true" tabindex="-1"></a><span class="co">        vocab_file (string): vocabulary filename</span></span>
<span id="cb62-8"><a href="#cb62-8" aria-hidden="true" tabindex="-1"></a><span class="co">        vocab_dir (string): directory of the vocabulary file</span></span>
<span id="cb62-9"><a href="#cb62-9" aria-hidden="true" tabindex="-1"></a><span class="co">        max_len (int): maximum number of tokens to generate </span></span>
<span id="cb62-10"><a href="#cb62-10" aria-hidden="true" tabindex="-1"></a><span class="co">        temperature (float): parameter for sampling ranging from 0.0 to 1.0.</span></span>
<span id="cb62-11"><a href="#cb62-11" aria-hidden="true" tabindex="-1"></a><span class="co">            0.0: same as argmax, always pick the most probable token</span></span>
<span id="cb62-12"><a href="#cb62-12" aria-hidden="true" tabindex="-1"></a><span class="co">            1.0: sampling from the distribution (can sometimes say random things)</span></span>
<span id="cb62-13"><a href="#cb62-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb62-14"><a href="#cb62-14" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb62-15"><a href="#cb62-15" aria-hidden="true" tabindex="-1"></a><span class="co">        generator: yields the next symbol generated by the model</span></span>
<span id="cb62-16"><a href="#cb62-16" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span>  </span>
<span id="cb62-17"><a href="#cb62-17" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb62-18"><a href="#cb62-18" aria-hidden="true" tabindex="-1"></a>    <span class="co"># define the delimiters we used during training</span></span>
<span id="cb62-19"><a href="#cb62-19" aria-hidden="true" tabindex="-1"></a>    delimiter_1 <span class="op">=</span> <span class="st">'Person 1: '</span> </span>
<span id="cb62-20"><a href="#cb62-20" aria-hidden="true" tabindex="-1"></a>    delimiter_2 <span class="op">=</span> <span class="st">'Person 2: '</span></span>
<span id="cb62-21"><a href="#cb62-21" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb62-22"><a href="#cb62-22" aria-hidden="true" tabindex="-1"></a>    <span class="co"># initialize detokenized output</span></span>
<span id="cb62-23"><a href="#cb62-23" aria-hidden="true" tabindex="-1"></a>    sentence <span class="op">=</span> <span class="st">''</span></span>
<span id="cb62-24"><a href="#cb62-24" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb62-25"><a href="#cb62-25" aria-hidden="true" tabindex="-1"></a>    <span class="co"># token counter</span></span>
<span id="cb62-26"><a href="#cb62-26" aria-hidden="true" tabindex="-1"></a>    counter <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb62-27"><a href="#cb62-27" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb62-28"><a href="#cb62-28" aria-hidden="true" tabindex="-1"></a>    <span class="co"># output tokens. we insert a ': ' for formatting</span></span>
<span id="cb62-29"><a href="#cb62-29" aria-hidden="true" tabindex="-1"></a>    result <span class="op">=</span> [tokenize(<span class="st">': '</span>, vocab_file<span class="op">=</span>vocab_file, vocab_dir<span class="op">=</span>vocab_dir)]</span>
<span id="cb62-30"><a href="#cb62-30" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb62-31"><a href="#cb62-31" aria-hidden="true" tabindex="-1"></a>    <span class="co"># reset the model state when starting a new dialogue</span></span>
<span id="cb62-32"><a href="#cb62-32" aria-hidden="true" tabindex="-1"></a>    ReformerLM.state <span class="op">=</span> model_state</span>
<span id="cb62-33"><a href="#cb62-33" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb62-34"><a href="#cb62-34" aria-hidden="true" tabindex="-1"></a>    <span class="co"># calls the output generator implemented earlier</span></span>
<span id="cb62-35"><a href="#cb62-35" aria-hidden="true" tabindex="-1"></a>    output <span class="op">=</span> ReformerLM_output_gen(ReformerLM, start_sentence, vocab_file<span class="op">=</span>VOCAB_FILE, vocab_dir<span class="op">=</span>VOCAB_DIR, temperature<span class="op">=</span>temperature)</span>
<span id="cb62-36"><a href="#cb62-36" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb62-37"><a href="#cb62-37" aria-hidden="true" tabindex="-1"></a>    <span class="co"># print the starting sentence</span></span>
<span id="cb62-38"><a href="#cb62-38" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(start_sentence.split(delimiter_2)[<span class="dv">0</span>].strip())</span>
<span id="cb62-39"><a href="#cb62-39" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb62-40"><a href="#cb62-40" aria-hidden="true" tabindex="-1"></a>    <span class="co"># loop below yields the next tokens until max_len is reached. the if-elif is just for prettifying the output.</span></span>
<span id="cb62-41"><a href="#cb62-41" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> o <span class="kw">in</span> output:</span>
<span id="cb62-42"><a href="#cb62-42" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb62-43"><a href="#cb62-43" aria-hidden="true" tabindex="-1"></a>        result.append(o)</span>
<span id="cb62-44"><a href="#cb62-44" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb62-45"><a href="#cb62-45" aria-hidden="true" tabindex="-1"></a>        sentence <span class="op">=</span> detokenize(np.concatenate(result, axis<span class="op">=</span><span class="dv">0</span>), vocab_file<span class="op">=</span>VOCAB_FILE, vocab_dir<span class="op">=</span>VOCAB_DIR)</span>
<span id="cb62-46"><a href="#cb62-46" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb62-47"><a href="#cb62-47" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> sentence.endswith(delimiter_1):</span>
<span id="cb62-48"><a href="#cb62-48" aria-hidden="true" tabindex="-1"></a>            sentence <span class="op">=</span> sentence.split(delimiter_1)[<span class="dv">0</span>]</span>
<span id="cb62-49"><a href="#cb62-49" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f'</span><span class="sc">{</span>delimiter_2<span class="sc">}{</span>sentence<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb62-50"><a href="#cb62-50" aria-hidden="true" tabindex="-1"></a>            sentence <span class="op">=</span> <span class="st">''</span></span>
<span id="cb62-51"><a href="#cb62-51" aria-hidden="true" tabindex="-1"></a>            result.clear()</span>
<span id="cb62-52"><a href="#cb62-52" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb62-53"><a href="#cb62-53" aria-hidden="true" tabindex="-1"></a>        <span class="cf">elif</span> sentence.endswith(delimiter_2):</span>
<span id="cb62-54"><a href="#cb62-54" aria-hidden="true" tabindex="-1"></a>            sentence <span class="op">=</span> sentence.split(delimiter_2)[<span class="dv">0</span>]</span>
<span id="cb62-55"><a href="#cb62-55" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f'</span><span class="sc">{</span>delimiter_1<span class="sc">}{</span>sentence<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb62-56"><a href="#cb62-56" aria-hidden="true" tabindex="-1"></a>            sentence <span class="op">=</span> <span class="st">''</span></span>
<span id="cb62-57"><a href="#cb62-57" aria-hidden="true" tabindex="-1"></a>            result.clear()</span>
<span id="cb62-58"><a href="#cb62-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb62-59"><a href="#cb62-59" aria-hidden="true" tabindex="-1"></a>        counter <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb62-60"><a href="#cb62-60" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb62-61"><a href="#cb62-61" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> counter <span class="op">&gt;</span> max_len:</span>
<span id="cb62-62"><a href="#cb62-62" aria-hidden="true" tabindex="-1"></a>            <span class="cf">break</span>    </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We can now feed in different starting sentences and see how the model generates the dialogue. We can even input our own starting sentence. Just remember to ask a question that covers the topics in the Multiwoz dataset so you can generate a meaningful conversation.</p>
<div class="cell" data-execution_count="47">
<div class="sourceCode cell-code" id="cb63"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb63-1"><a href="#cb63-1" aria-hidden="true" tabindex="-1"></a>sample_sentence <span class="op">=</span> <span class="st">' Person 1: Are there theatres in town? Person 2: '</span></span>
<span id="cb63-2"><a href="#cb63-2" aria-hidden="true" tabindex="-1"></a>generate_dialogue(ReformerLM<span class="op">=</span>model, model_state<span class="op">=</span>STARTING_STATE, start_sentence<span class="op">=</span>sample_sentence, vocab_file<span class="op">=</span>VOCAB_FILE, vocab_dir<span class="op">=</span>VOCAB_DIR, max_len<span class="op">=</span><span class="dv">120</span>, temperature<span class="op">=</span><span class="fl">0.2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Person 1: Are there theatres in town?
Person 2: : There are 4 theatres in town. Do you have a specific area in mind? 
Person 1: No, I don't have a preference. Which one do you recommend? 
Person 2: I would recommend the Mumford Theatre. Would you like their phone number? 
Person 1: Yes, please. I would also like to find a train to cambridge on thursday. 
Person 1: There are 202 trains that meet your criteria. Do you have a specific you would like to go to a cinema? </code></pre>
</div>
</div>
<div class="cell" data-execution_count="48">
<div class="sourceCode cell-code" id="cb65"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb65-1"><a href="#cb65-1" aria-hidden="true" tabindex="-1"></a>sample_sentence <span class="op">=</span> <span class="st">' Person 1: Is there a hospital nearby? Person 2: '</span></span>
<span id="cb65-2"><a href="#cb65-2" aria-hidden="true" tabindex="-1"></a>generate_dialogue(ReformerLM<span class="op">=</span>model, model_state<span class="op">=</span>STARTING_STATE, start_sentence<span class="op">=</span>sample_sentence, vocab_file<span class="op">=</span>VOCAB_FILE, vocab_dir<span class="op">=</span>VOCAB_DIR, max_len<span class="op">=</span><span class="dv">120</span>, temperature<span class="op">=</span><span class="fl">0.2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Person 1: Is there a hospital nearby?
Person 2: : Addensbrookes Hospital is located at Hills Rd, Cambridge, postcode CB20QQ. Do you need the phone number? 
Person 1: No, that's all I needed. Thank you. 
Person 2: You're welcome. Have a good day.m.Thanks for contacting the Cambridge TownInfo centre. Goodbye.
Person 1: Thank you for your help. 
Person 1: You're welcome. Have a good day.I can find something. </code></pre>
</div>
</div>
<div class="cell" data-execution_count="49">
<div class="sourceCode cell-code" id="cb67"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb67-1"><a href="#cb67-1" aria-hidden="true" tabindex="-1"></a>sample_sentence <span class="op">=</span> <span class="st">' Person 1: Can you book a taxi? Person 2: '</span></span>
<span id="cb67-2"><a href="#cb67-2" aria-hidden="true" tabindex="-1"></a>generate_dialogue(ReformerLM<span class="op">=</span>model, model_state<span class="op">=</span>STARTING_STATE, start_sentence<span class="op">=</span>sample_sentence, vocab_file<span class="op">=</span>VOCAB_FILE, vocab_dir<span class="op">=</span>VOCAB_DIR, max_len<span class="op">=</span><span class="dv">120</span>, temperature<span class="op">=</span><span class="fl">0.2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Person 1: Can you book a taxi?
Person 2: : I sure can. When would you like to arrive? 
Person 1: I need to leave after 13:00. 
Person 2: I'm sorry, but I'm not able to book that for you. Would you like to try a different time? 
Person 1: Yes, let's try for 13:00. 
Person 2: I was able to book you a table for 1 at 13:00 on Saturday. Your reference number is YYYOOO </code></pre>
</div>
</div>
</section>
</section>
<section id="acknowledgements" class="level2" data-number="7">
<h2 data-number="7" class="anchored" data-anchor-id="acknowledgements"><span class="header-section-number">7</span> Acknowledgements</h2>
<p>I’d like to express my thanks to the great <a href="https://www.coursera.org/learn/attention-models-in-nlp">Natural Language Processing with Attention Models Course</a> which i completed, and acknowledge the use of some images and other materials from the course in this article.</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>