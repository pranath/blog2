<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>LivingDataLab</title>
<link>http://livingdatalab.com/index.html</link>
<atom:link href="http://livingdatalab.com/index.xml" rel="self" type="application/rss+xml"/>
<description>LivingDataLab Data Science &amp; AI Blog</description>
<generator>quarto-1.2.335</generator>
<lastBuildDate>Mon, 24 Jul 2023 23:00:00 GMT</lastBuildDate>
<item>
  <title>Chat with Your Data using Memory and Langchain</title>
  <dc:creator>Pranath Fernando</dc:creator>
  <link>http://livingdatalab.com/posts/2023-07-25-chat-with-your-data-using-memory-and-langchain.html</link>
  <description><![CDATA[ In this article we are going to give a chatbot memory to help it better ask questions about data using langchain. ]]></description>
  <category>natural-language-processing</category>
  <category>deep-learning</category>
  <category>langchain</category>
  <guid>http://livingdatalab.com/posts/2023-07-25-chat-with-your-data-using-memory-and-langchain.html</guid>
  <pubDate>Mon, 24 Jul 2023 23:00:00 GMT</pubDate>
  <media:content url="https://github.com/pranath/blog/raw/master/images/langchain1.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Questioning and Answering over Data with LangChain</title>
  <dc:creator>Pranath Fernando</dc:creator>
  <link>http://livingdatalab.com/posts/2023-07-24-question-answering-over-data-with-langchain.html</link>
  <description><![CDATA[ In this article we look at how you can split documents, extract the relevant data, take a question, pass them both to a language model, and ask it to answer the question using Langchain. ]]></description>
  <category>natural-language-processing</category>
  <category>deep-learning</category>
  <category>langchain</category>
  <guid>http://livingdatalab.com/posts/2023-07-24-question-answering-over-data-with-langchain.html</guid>
  <pubDate>Sun, 23 Jul 2023 23:00:00 GMT</pubDate>
  <media:content url="https://github.com/pranath/blog/raw/master/images/langchain2.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Advanced Vectorstore Retrieval using LangChain</title>
  <dc:creator>Pranath Fernando</dc:creator>
  <link>http://livingdatalab.com/posts/2023-07-23-retrieval-using-langchain.html</link>
  <description><![CDATA[ In this article we look at how you can retrieve content from a vectorstore using state-of-the-art methods to ensure only the most relevant content is made available for Large Language Models. ]]></description>
  <category>natural-language-processing</category>
  <category>deep-learning</category>
  <category>langchain</category>
  <guid>http://livingdatalab.com/posts/2023-07-23-retrieval-using-langchain.html</guid>
  <pubDate>Sat, 22 Jul 2023 23:00:00 GMT</pubDate>
  <media:content url="https://github.com/pranath/blog/raw/master/images/langchain3.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Vectorstores and Embeddings with LangChain</title>
  <dc:creator>Pranath Fernando</dc:creator>
  <link>http://livingdatalab.com/posts/2023-07-22-vectorstores-and-embeddings-with-langchain.html</link>
  <description><![CDATA[ In this article we look at how to convert documents into vector stores an embeddings as an important step in making content available for Large Language Models. ]]></description>
  <category>natural-language-processing</category>
  <category>deep-learning</category>
  <category>langchain</category>
  <guid>http://livingdatalab.com/posts/2023-07-22-vectorstores-and-embeddings-with-langchain.html</guid>
  <pubDate>Fri, 21 Jul 2023 23:00:00 GMT</pubDate>
  <media:content url="https://github.com/pranath/blog/raw/master/images/langchain2.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Document Splitting with LangChain</title>
  <dc:creator>Pranath Fernando</dc:creator>
  <link>http://livingdatalab.com/posts/2023-07-21-document-splitting-with-langchain.html</link>
  <description><![CDATA[ In this article we look at how you can split documents as an important step in making content available for Large Language Models. ]]></description>
  <category>natural-language-processing</category>
  <category>deep-learning</category>
  <category>langchain</category>
  <guid>http://livingdatalab.com/posts/2023-07-21-document-splitting-with-langchain.html</guid>
  <pubDate>Thu, 20 Jul 2023 23:00:00 GMT</pubDate>
  <media:content url="https://github.com/pranath/blog/raw/master/images/langchain1.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>LLM Application Considerations - Part 2</title>
  <dc:creator>Pranath Fernando</dc:creator>
  <link>http://livingdatalab.com/posts/2023-07-20-llm-application-considerations-2.html</link>
  <description><![CDATA[ In this second article in the series we will look at several aspects to consider when deploying a Large Language Model (LLM) into an application. We will look at chain-of-thought reasoning, program-aided language models (PAL), the REAct framework combining reason and action, application architectures, and responsible AI. ]]></description>
  <category>natural-language-processing</category>
  <category>deep-learning</category>
  <category>langchain</category>
  <category>aws</category>
  <guid>http://livingdatalab.com/posts/2023-07-20-llm-application-considerations-2.html</guid>
  <pubDate>Wed, 19 Jul 2023 23:00:00 GMT</pubDate>
  <media:content url="https://github.com/pranath/blog/raw/master/images/genai4.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>LLM Application Considerations - Part 1</title>
  <dc:creator>Pranath Fernando</dc:creator>
  <link>http://livingdatalab.com/posts/2023-07-19-llm-application-considerations-1.html</link>
  <description><![CDATA[ In this article we will look at several aspects to consider when deploying a Large Language Model (LLM) into an application. We will look at Model optimizations, a Generative AI project lifecycle cheat sheet, and how LLM’s can be turned into useful applications using external data sources and services. ]]></description>
  <category>natural-language-processing</category>
  <category>deep-learning</category>
  <category>langchain</category>
  <guid>http://livingdatalab.com/posts/2023-07-19-llm-application-considerations-1.html</guid>
  <pubDate>Tue, 18 Jul 2023 23:00:00 GMT</pubDate>
  <media:content url="https://github.com/pranath/blog/raw/master/images/genai3.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Fine-Tuning FLAN-T5 with Reinforcement Learning (PPO) and PEFT to Generate Less-Toxic Summaries</title>
  <dc:creator>Pranath Fernando</dc:creator>
  <link>http://livingdatalab.com/posts/2023-07-18-fine-tune-llm-to-detoxify-text-summaries.html</link>
  <description><![CDATA[ In this project, we will fine-tune a FLAN-T5 model to generate less toxic content with Meta AI’s hate speech reward model. The reward model is a binary classifier that predicts either “not hate” or “hate” for the given text. We will use Proximal Policy Optimization (PPO) to fine-tune and reduce the model’s toxicity. ]]></description>
  <category>natural-language-processing</category>
  <category>deep-learning</category>
  <category>aws</category>
  <category>hugging-face</category>
  <guid>http://livingdatalab.com/posts/2023-07-18-fine-tune-llm-to-detoxify-text-summaries.html</guid>
  <pubDate>Mon, 17 Jul 2023 23:00:00 GMT</pubDate>
  <media:content url="https://github.com/pranath/blog/raw/master/images/genai2.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Reinforcement learning from human feedback (RLHF) using Proximal Policy Optimisation</title>
  <dc:creator>Pranath Fernando</dc:creator>
  <link>http://livingdatalab.com/posts/2023-07-17-proximal-policy-optimisation.html</link>
  <description><![CDATA[ In an <a href="https://livingdatalab.com/posts/2023-07-15-reinforcement-learning-with-human-feedback-1.html">earlier articles</a> we introduced Reinforcement learning from human feedback (RLHF) which is an important method used in modern large language models to help improve the performance and alignment of large language models. ]]></description>
  <category>natural-language-processing</category>
  <category>deep-learning</category>
  <guid>http://livingdatalab.com/posts/2023-07-17-proximal-policy-optimisation.html</guid>
  <pubDate>Sun, 16 Jul 2023 23:00:00 GMT</pubDate>
  <media:content url="https://github.com/pranath/blog/raw/master/images/genai1.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Reinforcement learning from human feedback (RLHF) For LLMs - Part 2</title>
  <dc:creator>Pranath Fernando</dc:creator>
  <link>http://livingdatalab.com/posts/2023-07-16-reinforcement-learning-with-human-feedback-2.html</link>
  <description><![CDATA[ In an <a href="https://livingdatalab.com/posts/2023-07-15-reinforcement-learning-with-human-feedback-1.html">earlier article</a> we introduced Reinforcement learning from human feedback (RLHF) which is an important method used in modern large language models to help improve the performance and alignment of large language models. ]]></description>
  <category>natural-language-processing</category>
  <category>deep-learning</category>
  <guid>http://livingdatalab.com/posts/2023-07-16-reinforcement-learning-with-human-feedback-2.html</guid>
  <pubDate>Sat, 15 Jul 2023 23:00:00 GMT</pubDate>
  <media:content url="https://github.com/pranath/blog/raw/master/images/genai4.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Reinforcement learning from human feedback (RLHF) For LLMs - Part 1</title>
  <dc:creator>Pranath Fernando</dc:creator>
  <link>http://livingdatalab.com/posts/2023-07-15-reinforcement-learning-with-human-feedback-1.html</link>
  <description><![CDATA[ In this post we will introduce Reinforcement learning from human feedback (RLHF) which is an important method used in modern large language models to help improve the performance and alignment of large language models. ]]></description>
  <category>natural-language-processing</category>
  <category>deep-learning</category>
  <guid>http://livingdatalab.com/posts/2023-07-15-reinforcement-learning-with-human-feedback-1.html</guid>
  <pubDate>Fri, 14 Jul 2023 23:00:00 GMT</pubDate>
  <media:content url="https://github.com/pranath/blog/raw/master/images/genai3.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Fine-Tuning a Generative AI Model for Dialogue Summarization</title>
  <dc:creator>Pranath Fernando</dc:creator>
  <link>http://livingdatalab.com/posts/2023-07-14-finetune-generative-ai-model-summarisation.html</link>
  <description><![CDATA[ In this project I will fine-tune an existing LLM from Hugging Face for enhanced dialogue summarization. We will use the <a href="https://huggingface.co/docs/transformers/model_doc/flan-t5">FLAN-T5</a> model, which provides a high quality instruction tuned model and can summarize text out of the box. To improve the inferences, we will explore a full fine-tuning approach and evaluate the results with ROUGE metrics. Then we will perform Parameter Efficient Fine-Tuning (PEFT), evaluate the resulting model and see that the benefits of PEFT outweigh the slightly-lower performance metrics. ]]></description>
  <category>natural-language-processing</category>
  <category>deep-learning</category>
  <category>aws</category>
  <category>hugging-face</category>
  <guid>http://livingdatalab.com/posts/2023-07-14-finetune-generative-ai-model-summarisation.html</guid>
  <pubDate>Thu, 13 Jul 2023 23:00:00 GMT</pubDate>
  <media:content url="https://github.com/pranath/blog/raw/master/images/genai2.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Parameter Efficient Fine-Tuning (PEFT) for Large Language Models</title>
  <dc:creator>Pranath Fernando</dc:creator>
  <link>http://livingdatalab.com/posts/2023-07-13-parameter-efficient-fine-tuning-of-llms.html</link>
  <description><![CDATA[ It takes a lot of computation to train LLMs. Memory is needed for complete fine-tuning not just to store the model but also a number of other training-related factors. You must be able to allocate memory for optimizer states, gradients, forward activations, and temporary memory throughout the training process even if your computer can hold the model weights, which are currently on the order of hundreds of terabytes for the largest models. These extra parts may be many times bigger than the model and can easily outgrow the capabilities of consumer hardware. ]]></description>
  <category>natural-language-processing</category>
  <category>deep-learning</category>
  <guid>http://livingdatalab.com/posts/2023-07-13-parameter-efficient-fine-tuning-of-llms.html</guid>
  <pubDate>Wed, 12 Jul 2023 23:00:00 GMT</pubDate>
  <media:content url="https://github.com/pranath/blog/raw/master/images/genai1.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Evaluating Fine-Tuned Large Language Models</title>
  <dc:creator>Pranath Fernando</dc:creator>
  <link>http://livingdatalab.com/posts/2023-07-12-evaluating-fine-tuned-large-language-models.html</link>
  <description><![CDATA[ When looking at large language models such as ChatGPT and others we might customise and fine tune to improve, we might often describe it by saying the model demonstrated good performance on this task or this fine-tuned model showed a large improvement in performance over the base model. But what do statements like this mean? How can you formalize the improvement in performance of your fine-tuned model over the pre-trained model you started with? In this article we explore several metrics that are used by developers of large language models that you can use to assess the performance of your own models and compare to other models out in the world. ]]></description>
  <category>natural-language-processing</category>
  <category>deep-learning</category>
  <guid>http://livingdatalab.com/posts/2023-07-12-evaluating-fine-tuned-large-language-models.html</guid>
  <pubDate>Tue, 11 Jul 2023 23:00:00 GMT</pubDate>
  <media:content url="https://github.com/pranath/blog/raw/master/images/genai4.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Multi-task Instruction Fine-Tuning for Large Language Models</title>
  <dc:creator>Pranath Fernando</dc:creator>
  <link>http://livingdatalab.com/posts/2023-07-11-multi-task-instruction-fine-tuning.html</link>
  <description><![CDATA[ In this post, we’ll look at techniques you might employ to make an existing large language model more effective for your particular use case using a method called instruction fine-tuning, and in particular see how this can be used to optimise for multiple tasks as the same time. ]]></description>
  <category>natural-language-processing</category>
  <category>deep-learning</category>
  <guid>http://livingdatalab.com/posts/2023-07-11-multi-task-instruction-fine-tuning.html</guid>
  <pubDate>Mon, 10 Jul 2023 23:00:00 GMT</pubDate>
  <media:content url="https://github.com/pranath/blog/raw/master/images/genai3.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Improve Large Language Models with Instruction Fine-Tuning</title>
  <dc:creator>Pranath Fernando</dc:creator>
  <link>http://livingdatalab.com/posts/2023-07-10-fine-tuning-llms-with-instructions.html</link>
  <description><![CDATA[ In this post, we’ll look at techniques you might employ to make an existing large language model more effective for your particular use case using a method called instruction fine-tuning. We will also see how this differs from using prompts and in-context prompt learning. ]]></description>
  <category>natural-language-processing</category>
  <category>deep-learning</category>
  <guid>http://livingdatalab.com/posts/2023-07-10-fine-tuning-llms-with-instructions.html</guid>
  <pubDate>Sun, 09 Jul 2023 23:00:00 GMT</pubDate>
  <media:content url="https://github.com/pranath/blog/raw/master/images/genai2.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Pre-training Large Language Models for Domain Adaptation</title>
  <dc:creator>Pranath Fernando</dc:creator>
  <link>http://livingdatalab.com/posts/2023-07-09-pretraining-llms-for-domain-adaptation.html</link>
  <description><![CDATA[ Here we will examine particular use cases where it might make sense to train a large language model from scratch. These use cases are often characterised by situations that use language in a very unique way such as legal or medical text. ]]></description>
  <category>natural-language-processing</category>
  <category>deep-learning</category>
  <guid>http://livingdatalab.com/posts/2023-07-09-pretraining-llms-for-domain-adaptation.html</guid>
  <pubDate>Sat, 08 Jul 2023 23:00:00 GMT</pubDate>
  <media:content url="https://github.com/pranath/blog/raw/master/images/genai1.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Scaling Laws and Compute Optimal Large Language Models</title>
  <dc:creator>Pranath Fernando</dc:creator>
  <link>http://livingdatalab.com/posts/2023-07-08-scaling-laws-compute-optimal-llms.html</link>
  <description><![CDATA[ In this article we’ll look at research that has looked at the relationship between model size, training, configuration, and performance to try to pinpoint the optimal size for large language models. It’s important to keep in mind that the objective of pre-training is to maximise the model’s achievement of its learning objective, which is to minimise the loss while predicting tokens. ]]></description>
  <category>natural-language-processing</category>
  <category>deep-learning</category>
  <guid>http://livingdatalab.com/posts/2023-07-08-scaling-laws-compute-optimal-llms.html</guid>
  <pubDate>Fri, 07 Jul 2023 23:00:00 GMT</pubDate>
  <media:content url="https://github.com/pranath/blog/raw/master/images/genai4.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Computational Challenges fo training LLMs</title>
  <dc:creator>Pranath Fernando</dc:creator>
  <link>http://livingdatalab.com/posts/2023-07-07-computational-challenges-of-training-llms.html</link>
  <description><![CDATA[ Running out of memory is one of the most frequent problems you still encounter when trying to train large language models. Compute Unified Device Architecture, or CUDA, is a group of tools and libraries created specifically for Nvidia GPUs. Libraries like PyTorch and TensorFlow make advantage of CUDA to improve performance on deep learning operations like metrics multiplication. Because most LLMs are large and need a lot of memory to store and train all of their parameters, you’ll run across these memory concerns. ]]></description>
  <category>natural-language-processing</category>
  <category>deep-learning</category>
  <guid>http://livingdatalab.com/posts/2023-07-07-computational-challenges-of-training-llms.html</guid>
  <pubDate>Thu, 06 Jul 2023 23:00:00 GMT</pubDate>
  <media:content url="https://github.com/pranath/blog/raw/master/images/genai3.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Choosing a Pre-Trained Large Language Model</title>
  <dc:creator>Pranath Fernando</dc:creator>
  <link>http://livingdatalab.com/posts/2023-07-06-choosing-a-pretrained-llm.html</link>
  <description><![CDATA[ The project life cycle for generative AI was introduced in this <a href="../posts/2023-07-04-generative-ai-project-lifecycle.html">previous article</a>. There are a few tasks to complete before you can launch your generative AI app, as we saw there. Selecting a model to work with comes after you have defined your use case and chosen how the LLM will operate within your application. Working with an existing model or creating your own from scratch will be your first option. In some situations, it may be advantageous to build your own model from scratch. In most cases, though, you’ll use an existing foundation model to start the process of constructing your application. ]]></description>
  <category>natural-language-processing</category>
  <category>deep-learning</category>
  <category>hugging-face</category>
  <guid>http://livingdatalab.com/posts/2023-07-06-choosing-a-pretrained-llm.html</guid>
  <pubDate>Wed, 05 Jul 2023 23:00:00 GMT</pubDate>
  <media:content url="https://github.com/pranath/blog/raw/master/images/genai2.jpg" medium="image" type="image/jpeg"/>
</item>
</channel>
</rss>
