<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>LivingDataLab</title>
<link>http://livingdatalab.com/index.html</link>
<atom:link href="http://livingdatalab.com/index.xml" rel="self" type="application/rss+xml"/>
<description>LivingDataLab Data Science &amp; AI Blog</description>
<generator>quarto-1.2.335</generator>
<lastBuildDate>Sat, 05 Aug 2023 23:00:00 GMT</lastBuildDate>
<item>
  <title>Creating Knowledge Graphs from Textual Data and LLM’s</title>
  <dc:creator>Pranath Fernando</dc:creator>
  <link>http://livingdatalab.com/posts/2023-08-06-creating-knowledge-graphs-from-text-data-with-llms.html</link>
  <description><![CDATA[ Understanding the connections between various types of information is essential in today’s data-driven environment. Unstructured text may now be transformed into a structured network of items and their relationships using knowledge graphs, which have evolved as a potent tool for visualising and exploring these connections. We will walk you through a straightforward method for converting textual data into a knowledge graph, making complex content more approachable and understandable. ]]></description>
  <category>natural-language-processing</category>
  <category>deep-learning</category>
  <category>langchain</category>
  <category>activeloop</category>
  <category>openai</category>
  <category>prompt-engineering</category>
  <category>network-analysis</category>
  <guid>http://livingdatalab.com/posts/2023-08-06-creating-knowledge-graphs-from-text-data-with-llms.html</guid>
  <pubDate>Sat, 05 Aug 2023 23:00:00 GMT</pubDate>
  <media:content url="https://github.com/pranath/blog/raw/master/images/langchain-deeplake2.png" medium="image" type="image/png"/>
</item>
<item>
  <title>An Improved News Articles Summarizer</title>
  <dc:creator>Pranath Fernando</dc:creator>
  <link>http://livingdatalab.com/posts/2023-08-05-an-improved-news-articles-summariser.html</link>
  <description><![CDATA[ This article aims to improve our earlier News Article Summarizer implementation. Our goal is to improve our tool’s ability to extract the most important information from lengthy news items and display it in an easy-to-read, bulleted list format. With this improvement, consumers will be able to quickly and clearly understand the essential ideas of an article, saving time and improving the reading experience. ]]></description>
  <category>natural-language-processing</category>
  <category>deep-learning</category>
  <category>langchain</category>
  <category>activeloop</category>
  <category>openai</category>
  <category>prompt-engineering</category>
  <guid>http://livingdatalab.com/posts/2023-08-05-an-improved-news-articles-summariser.html</guid>
  <pubDate>Fri, 04 Aug 2023 23:00:00 GMT</pubDate>
  <media:content url="https://github.com/pranath/blog/raw/master/images/langchain-deeplake1.png" medium="image" type="image/png"/>
</item>
<item>
  <title>Managing Large Language Model Outputs with Parsers</title>
  <dc:creator>Pranath Fernando</dc:creator>
  <link>http://livingdatalab.com/posts/2023-08-04-managing-llm-outputs-with-parsers.html</link>
  <description><![CDATA[ In a production setting, a predictable data structure is always desired even when language models can only produce textual outputs. Imagine, for instance, that you are developing a thesaurus application and want to provide a list of potential synonyms depending on the context. The LLMs are strong enough to produce a lot of proposals quickly. ]]></description>
  <category>natural-language-processing</category>
  <category>deep-learning</category>
  <category>langchain</category>
  <category>activeloop</category>
  <category>openai</category>
  <category>prompt-engineering</category>
  <guid>http://livingdatalab.com/posts/2023-08-04-managing-llm-outputs-with-parsers.html</guid>
  <pubDate>Thu, 03 Aug 2023 23:00:00 GMT</pubDate>
  <media:content url="https://github.com/pranath/blog/raw/master/images/langchain-deeplake4.png" medium="image" type="image/png"/>
</item>
<item>
  <title>Getting the Best of Few Shot Prompts and Example Selectors for LLMs</title>
  <dc:creator>Pranath Fernando</dc:creator>
  <link>http://livingdatalab.com/posts/2023-08-03-getting-the-best-of-few-shot-prompts-and-example-selectors.html</link>
  <description><![CDATA[ In this article, we’ll examine how example selectors and few-shot prompts might improve LangChain’s language model performance. There are several ways to implement Few-shot prompting and Example selection in LangChain. To help you get the most of your language model, we’ll go through three different strategies and weigh their benefits and drawbacks. ]]></description>
  <category>natural-language-processing</category>
  <category>deep-learning</category>
  <category>langchain</category>
  <category>activeloop</category>
  <category>openai</category>
  <category>prompt-engineering</category>
  <guid>http://livingdatalab.com/posts/2023-08-03-getting-the-best-of-few-shot-prompts-and-example-selectors.html</guid>
  <pubDate>Wed, 02 Aug 2023 23:00:00 GMT</pubDate>
  <media:content url="https://github.com/pranath/blog/raw/master/images/langchain-deeplake3.png" medium="image" type="image/png"/>
</item>
<item>
  <title>Using Prompt Templates with Large Language Models</title>
  <dc:creator>Pranath Fernando</dc:creator>
  <link>http://livingdatalab.com/posts/2023-08-02-using-prompt-templates-for-llms.html</link>
  <description><![CDATA[ We can do a variety of jobs thanks to large language models. These models work on the simple premise that they take a text input sequence and produce a text output sequence. The prompt or input text is the most important element in this process. ]]></description>
  <category>natural-language-processing</category>
  <category>deep-learning</category>
  <category>langchain</category>
  <category>activeloop</category>
  <category>openai</category>
  <category>prompt-engineering</category>
  <guid>http://livingdatalab.com/posts/2023-08-02-using-prompt-templates-for-llms.html</guid>
  <pubDate>Tue, 01 Aug 2023 23:00:00 GMT</pubDate>
  <media:content url="https://github.com/pranath/blog/raw/master/images/langchain-deeplake2.png" medium="image" type="image/png"/>
</item>
<item>
  <title>Prompt Engineering Tips and Tricks for Large Language Models</title>
  <dc:creator>Pranath Fernando</dc:creator>
  <link>http://livingdatalab.com/posts/2023-08-01-prompt-engineering-tips-and-tricks.html</link>
  <description><![CDATA[ In the relatively young field of prompt engineering, prompts are created and improved in order to make efficient use of language models for a variety of applications and research areas. It is necessary for many NLP tasks and aids in a better understanding of the strengths and weaknesses of LLMs. To assist you better comprehend the subtleties of prompt engineering, we will use real-world examples to contrast good and terrible prompts. ]]></description>
  <category>natural-language-processing</category>
  <category>deep-learning</category>
  <category>langchain</category>
  <category>activeloop</category>
  <category>openai</category>
  <category>prompt-engineering</category>
  <guid>http://livingdatalab.com/posts/2023-08-01-prompt-engineering-tips-and-tricks.html</guid>
  <pubDate>Mon, 31 Jul 2023 23:00:00 GMT</pubDate>
  <media:content url="https://github.com/pranath/blog/raw/master/images/langchain-deeplake1.png" medium="image" type="image/png"/>
</item>
<item>
  <title>Popular Large Language Models Compared</title>
  <dc:creator>Pranath Fernando</dc:creator>
  <link>http://livingdatalab.com/posts/2023-07-31-popular-large-language-models-compared.html</link>
  <description><![CDATA[ We will examine the integration of various LLM models in LangChain in this article. We will look at and contrast the aspects of the platforms that enable these LLM types. Some of the most well-liked pre-trained models that are publicly accessible are already supported by LangChain. We have previously covered a number of alternatives in earlier posts, including ChatGPT, GPT-4, GPT-3, and GPT4ALL. ]]></description>
  <category>natural-language-processing</category>
  <category>deep-learning</category>
  <category>langchain</category>
  <category>activeloop</category>
  <guid>http://livingdatalab.com/posts/2023-07-31-popular-large-language-models-compared.html</guid>
  <pubDate>Sun, 30 Jul 2023 23:00:00 GMT</pubDate>
  <media:content url="https://github.com/pranath/blog/raw/master/images/langchain-deeplake4.png" medium="image" type="image/png"/>
</item>
<item>
  <title>Using the Open Source GPT4All Large Language Model</title>
  <dc:creator>Pranath Fernando</dc:creator>
  <link>http://livingdatalab.com/posts/2023-07-30-using-open-source-gpt4all-llm.html</link>
  <description><![CDATA[ The OpenAI GPT-family models that we have discussed in previous articles are without a doubt effective. However, access to the weights and architecture of these models is limited, and even if one does, it requires a large amount of resources to carry out any activity. It is important to note that, according to a number of benchmarks, the most recent CPU generation from Intel® Xeon® 4s can perform language models more effectively. ]]></description>
  <category>natural-language-processing</category>
  <category>deep-learning</category>
  <category>langchain</category>
  <category>activeloop</category>
  <guid>http://livingdatalab.com/posts/2023-07-30-using-open-source-gpt4all-llm.html</guid>
  <pubDate>Sat, 29 Jul 2023 23:00:00 GMT</pubDate>
  <media:content url="https://github.com/pranath/blog/raw/master/images/langchain-deeplake3.png" medium="image" type="image/png"/>
</item>
<item>
  <title>A News Article Summariser with OpenAI and Langchain</title>
  <dc:creator>Pranath Fernando</dc:creator>
  <link>http://livingdatalab.com/posts/2023-07-29-news-article-summariser-with-openai-and-langchain.html</link>
  <description><![CDATA[ It’s critical to stay current on news and information in the fast-paced world of today. However, reading through numerous news pieces might take time. Let’s create a News Articles Summarizer application utilising ChatGPT and LangChain to help you save time and receive a brief overview of the key points. We can scrape articles from the internet, extract their titles and text, and produce succinct summaries using this robust programme. We will walk you through the process of creating a summarizer in this lecture. We will apply the ideas we covered in past sessions, showing how they would be used in a practical situation. ]]></description>
  <category>natural-language-processing</category>
  <category>deep-learning</category>
  <category>langchain</category>
  <category>activeloop</category>
  <category>openai</category>
  <category>prompt-engineering</category>
  <guid>http://livingdatalab.com/posts/2023-07-29-news-article-summariser-with-openai-and-langchain.html</guid>
  <pubDate>Fri, 28 Jul 2023 23:00:00 GMT</pubDate>
  <media:content url="https://github.com/pranath/blog/raw/master/images/langchain-deeplake2.png" medium="image" type="image/png"/>
</item>
<item>
  <title>Large Language Models v Chat Models</title>
  <dc:creator>Pranath Fernando</dc:creator>
  <link>http://livingdatalab.com/posts/2023-07-28-llms-v-chat-models.html</link>
  <description><![CDATA[ Large Language Models have significantly advanced Natural Language Processing (NLP), allowing AI systems to comprehend and produce prose that is human-like. Based on the Transformers architecture, ChatGPT is a well-known language model that can comprehend lengthy texts and determine the relationships between words or concepts. It excels in predicting linguistic patterns and word associations. ]]></description>
  <category>natural-language-processing</category>
  <category>deep-learning</category>
  <category>langchain</category>
  <category>activeloop</category>
  <category>openai</category>
  <guid>http://livingdatalab.com/posts/2023-07-28-llms-v-chat-models.html</guid>
  <pubDate>Thu, 27 Jul 2023 23:00:00 GMT</pubDate>
  <media:content url="https://github.com/pranath/blog/raw/master/images/langchain-deeplake1.png" medium="image" type="image/png"/>
</item>
<item>
  <title>The Activeloop Deep Lake Vector Store for Agents &amp; Large Language Models</title>
  <dc:creator>Pranath Fernando</dc:creator>
  <link>http://livingdatalab.com/posts/2023-07-27-activeloop-deeplake-vectorstore-llms-agents.html</link>
  <description><![CDATA[ Activeloop Deep Lake provides storage for embeddings and their corresponding metadata in the context of LLM apps . It enables hybrid searches on these embeddings and their attributes for efficient data retrieval. It also integrates with LangChain &amp; Agents, facilitating the development and deployment of applications. ]]></description>
  <category>natural-language-processing</category>
  <category>deep-learning</category>
  <category>langchain</category>
  <category>activeloop</category>
  <category>openai</category>
  <guid>http://livingdatalab.com/posts/2023-07-27-activeloop-deeplake-vectorstore-llms-agents.html</guid>
  <pubDate>Wed, 26 Jul 2023 23:00:00 GMT</pubDate>
  <media:content url="https://github.com/pranath/blog/raw/master/images/langchain-deeplake4.png" medium="image" type="image/png"/>
</item>
<item>
  <title>LLaMa-2 70B Chatbot in Hugging Face and LangChain</title>
  <dc:creator>Pranath Fernando</dc:creator>
  <link>http://livingdatalab.com/posts/2023-07-26-generation-llm-field-guide_llama-2-70b-chat-agent.html</link>
  <description><![CDATA[ In this article we’ll explore how we can use the open source <strong>Llama-70b-chat</strong> model in both Hugging Face transformers and LangChain. ]]></description>
  <category>natural-language-processing</category>
  <category>deep-learning</category>
  <category>langchain</category>
  <category>hugging-face</category>
  <guid>http://livingdatalab.com/posts/2023-07-26-generation-llm-field-guide_llama-2-70b-chat-agent.html</guid>
  <pubDate>Tue, 25 Jul 2023 23:00:00 GMT</pubDate>
  <media:content url="https://github.com/pranath/blog/raw/master/images/llama2.png" medium="image" type="image/png"/>
</item>
<item>
  <title>Chat with Your Data using Memory and Langchain</title>
  <dc:creator>Pranath Fernando</dc:creator>
  <link>http://livingdatalab.com/posts/2023-07-25-chat-with-your-data-using-memory-and-langchain.html</link>
  <description><![CDATA[ In this article we are going to give a chatbot memory to help it better ask questions about data using langchain. ]]></description>
  <category>natural-language-processing</category>
  <category>deep-learning</category>
  <category>langchain</category>
  <guid>http://livingdatalab.com/posts/2023-07-25-chat-with-your-data-using-memory-and-langchain.html</guid>
  <pubDate>Mon, 24 Jul 2023 23:00:00 GMT</pubDate>
  <media:content url="https://github.com/pranath/blog/raw/master/images/langchain1.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Questioning and Answering over Data with LangChain</title>
  <dc:creator>Pranath Fernando</dc:creator>
  <link>http://livingdatalab.com/posts/2023-07-24-question-answering-over-data-with-langchain.html</link>
  <description><![CDATA[ In this article we look at how you can split documents, extract the relevant data, take a question, pass them both to a language model, and ask it to answer the question using Langchain. ]]></description>
  <category>natural-language-processing</category>
  <category>deep-learning</category>
  <category>langchain</category>
  <category>prompt-engineering</category>
  <guid>http://livingdatalab.com/posts/2023-07-24-question-answering-over-data-with-langchain.html</guid>
  <pubDate>Sun, 23 Jul 2023 23:00:00 GMT</pubDate>
  <media:content url="https://github.com/pranath/blog/raw/master/images/langchain2.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Advanced Vectorstore Retrieval using LangChain</title>
  <dc:creator>Pranath Fernando</dc:creator>
  <link>http://livingdatalab.com/posts/2023-07-23-retrieval-using-langchain.html</link>
  <description><![CDATA[ In this article we look at how you can retrieve content from a vectorstore using state-of-the-art methods to ensure only the most relevant content is made available for Large Language Models. ]]></description>
  <category>natural-language-processing</category>
  <category>deep-learning</category>
  <category>langchain</category>
  <guid>http://livingdatalab.com/posts/2023-07-23-retrieval-using-langchain.html</guid>
  <pubDate>Sat, 22 Jul 2023 23:00:00 GMT</pubDate>
  <media:content url="https://github.com/pranath/blog/raw/master/images/langchain3.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Vectorstores and Embeddings with LangChain</title>
  <dc:creator>Pranath Fernando</dc:creator>
  <link>http://livingdatalab.com/posts/2023-07-22-vectorstores-and-embeddings-with-langchain.html</link>
  <description><![CDATA[ In this article we look at how to convert documents into vector stores an embeddings as an important step in making content available for Large Language Models. ]]></description>
  <category>natural-language-processing</category>
  <category>deep-learning</category>
  <category>langchain</category>
  <guid>http://livingdatalab.com/posts/2023-07-22-vectorstores-and-embeddings-with-langchain.html</guid>
  <pubDate>Fri, 21 Jul 2023 23:00:00 GMT</pubDate>
  <media:content url="https://github.com/pranath/blog/raw/master/images/langchain2.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Document Splitting with LangChain</title>
  <dc:creator>Pranath Fernando</dc:creator>
  <link>http://livingdatalab.com/posts/2023-07-21-document-splitting-with-langchain.html</link>
  <description><![CDATA[ In this article we look at how you can split documents as an important step in making content available for Large Language Models. ]]></description>
  <category>natural-language-processing</category>
  <category>deep-learning</category>
  <category>langchain</category>
  <guid>http://livingdatalab.com/posts/2023-07-21-document-splitting-with-langchain.html</guid>
  <pubDate>Thu, 20 Jul 2023 23:00:00 GMT</pubDate>
  <media:content url="https://github.com/pranath/blog/raw/master/images/langchain1.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>LLM Application Considerations - Part 2</title>
  <dc:creator>Pranath Fernando</dc:creator>
  <link>http://livingdatalab.com/posts/2023-07-20-llm-application-considerations-2.html</link>
  <description><![CDATA[ In this second article in the series we will look at several aspects to consider when deploying a Large Language Model (LLM) into an application. We will look at chain-of-thought reasoning, program-aided language models (PAL), the REAct framework combining reason and action, application architectures, and responsible AI. ]]></description>
  <category>natural-language-processing</category>
  <category>deep-learning</category>
  <category>langchain</category>
  <category>aws</category>
  <guid>http://livingdatalab.com/posts/2023-07-20-llm-application-considerations-2.html</guid>
  <pubDate>Wed, 19 Jul 2023 23:00:00 GMT</pubDate>
  <media:content url="https://github.com/pranath/blog/raw/master/images/genai4.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>LLM Application Considerations - Part 1</title>
  <dc:creator>Pranath Fernando</dc:creator>
  <link>http://livingdatalab.com/posts/2023-07-19-llm-application-considerations-1.html</link>
  <description><![CDATA[ In this article we will look at several aspects to consider when deploying a Large Language Model (LLM) into an application. We will look at Model optimizations, a Generative AI project lifecycle cheat sheet, and how LLM’s can be turned into useful applications using external data sources and services. ]]></description>
  <category>natural-language-processing</category>
  <category>deep-learning</category>
  <category>langchain</category>
  <guid>http://livingdatalab.com/posts/2023-07-19-llm-application-considerations-1.html</guid>
  <pubDate>Tue, 18 Jul 2023 23:00:00 GMT</pubDate>
  <media:content url="https://github.com/pranath/blog/raw/master/images/genai3.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Fine-Tuning FLAN-T5 with Reinforcement Learning (PPO) and PEFT to Generate Less-Toxic Summaries</title>
  <dc:creator>Pranath Fernando</dc:creator>
  <link>http://livingdatalab.com/posts/2023-07-18-fine-tune-llm-to-detoxify-text-summaries.html</link>
  <description><![CDATA[ In this project, we will fine-tune a FLAN-T5 model to generate less toxic content with Meta AI’s hate speech reward model. The reward model is a binary classifier that predicts either “not hate” or “hate” for the given text. We will use Proximal Policy Optimization (PPO) to fine-tune and reduce the model’s toxicity. ]]></description>
  <category>natural-language-processing</category>
  <category>deep-learning</category>
  <category>aws</category>
  <category>hugging-face</category>
  <category>fine-tuning</category>
  <guid>http://livingdatalab.com/posts/2023-07-18-fine-tune-llm-to-detoxify-text-summaries.html</guid>
  <pubDate>Mon, 17 Jul 2023 23:00:00 GMT</pubDate>
  <media:content url="https://github.com/pranath/blog/raw/master/images/genai2.jpg" medium="image" type="image/jpeg"/>
</item>
</channel>
</rss>
