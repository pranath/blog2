<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>LivingDataLab</title>
<link>http://livingdatalab.com/index.html</link>
<atom:link href="http://livingdatalab.com/index.xml" rel="self" type="application/rss+xml"/>
<description></description>
<generator>quarto-1.2.335</generator>
<lastBuildDate>Sat, 01 Apr 2023 23:00:00 GMT</lastBuildDate>
<item>
  <title>Fine-tuning a pre-trained model with Hugging Face - Fine-tune the Model</title>
  <dc:creator>Pranath Fernando</dc:creator>
  <link>http://livingdatalab.com/posts/2023-04-02-fine-tuning-a-pretrained-model-with-hugging-face.html</link>
  <description><![CDATA[ 




<section id="introduction" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="introduction"><span class="header-section-number">1</span> Introduction</h2>
<p>In <a href="../#category=natural-language-processing">previous articles</a> we have seen how to use transformer models for a wide range of natural language tasks, including machine translation, summarization, and question answering. Transformers have become the standard model for NLP, similar to convolutional models in computer vision.</p>
<p>In practice, you’ll rarely train a transformer model from scratch. Transformers tend to be very large, so they take time, money, and lots of data to train fully. Instead, you’ll want to start with a pre-trained model and fine-tune it with a dataset if you need to for specific needs, which has become the norm in this new but thriving area of AI.</p>
<p><a href="https://huggingface.co/">Hugging Face</a> (🤗) is the best resource for pre-trained transformers. Their open-source libraries simplifies downloading and using transformer models like BERT, T5, and GPT-2. And you can use them alongside libraries such as FastAi, TensorFlow, PyTorch and Flax.</p>
<p>In this article we will look in a bit more detail at what you might need to do to fine-tune a pre-trained model for your task.</p>
</section>
<section id="fine-tuning-a-model-with-hugging-face" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="fine-tuning-a-model-with-hugging-face"><span class="header-section-number">2</span> Fine-tuning a model with Hugging Face</h2>
<p>Hugging Face Transformers provides a Trainer class to help you fine-tune any of the pretrained models it provides on your dataset. Once you’ve done all the data preprocessing work as we saw in the <a href="2023-04-01-fine-tuning-a-pretrained-model-with-hugging-face-dataset-preparation.html">previous article</a>, we have just a few steps left to define the Trainer. The hardest part is likely to be preparing the environment to run Trainer.train(), as it will run very slowly on a CPU. If you don’t have a GPU set up, you can get access to free GPUs or TPUs on Google Colab.</p>
<p>Here is a short summary of where we got to in the previous article preparing the dataset for fine-tuning the model:</p>
<div class="cell" data-outputid="4973de72-0b7d-45ae-81b0-3615084ca8b9" data-execution_count="3">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;">from</span> datasets <span class="im" style="color: #00769E;">import</span> load_dataset</span>
<span id="cb1-2"><span class="im" style="color: #00769E;">from</span> transformers <span class="im" style="color: #00769E;">import</span> AutoTokenizer, DataCollatorWithPadding</span>
<span id="cb1-3"></span>
<span id="cb1-4">raw_datasets <span class="op" style="color: #5E5E5E;">=</span> load_dataset(<span class="st" style="color: #20794D;">"glue"</span>, <span class="st" style="color: #20794D;">"mrpc"</span>)</span>
<span id="cb1-5">checkpoint <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">"bert-base-uncased"</span></span>
<span id="cb1-6">tokenizer <span class="op" style="color: #5E5E5E;">=</span> AutoTokenizer.from_pretrained(checkpoint)</span>
<span id="cb1-7"></span>
<span id="cb1-8"></span>
<span id="cb1-9"><span class="kw" style="color: #003B4F;">def</span> tokenize_function(example):</span>
<span id="cb1-10">    <span class="cf" style="color: #003B4F;">return</span> tokenizer(example[<span class="st" style="color: #20794D;">"sentence1"</span>], example[<span class="st" style="color: #20794D;">"sentence2"</span>], truncation<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>)</span>
<span id="cb1-11"></span>
<span id="cb1-12"></span>
<span id="cb1-13">tokenized_datasets <span class="op" style="color: #5E5E5E;">=</span> raw_datasets.<span class="bu" style="color: null;">map</span>(tokenize_function, batched<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>)</span>
<span id="cb1-14">data_collator <span class="op" style="color: #5E5E5E;">=</span> DataCollatorWithPadding(tokenizer<span class="op" style="color: #5E5E5E;">=</span>tokenizer)</span></code></pre></div>
</div>
</section>
<section id="training-the-model" class="level2" data-number="3">
<h2 data-number="3" class="anchored" data-anchor-id="training-the-model"><span class="header-section-number">3</span> Training the model</h2>
<p>The first step before we can define our <em>Trainer</em> is to define a TrainingArguments class that will contain all the hyperparameters the Trainer will use for training and evaluation. The only argument we have to provide is a directory where the trained model will be saved, as well as the checkpoints along the way. For all the rest, we can leave the defaults, which should work pretty well for a basic fine-tuning.</p>
<div class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="im" style="color: #00769E;">from</span> transformers <span class="im" style="color: #00769E;">import</span> TrainingArguments</span>
<span id="cb2-2"></span>
<span id="cb2-3">training_args <span class="op" style="color: #5E5E5E;">=</span> TrainingArguments(<span class="st" style="color: #20794D;">"test-trainer"</span>)</span></code></pre></div>
</div>
<p>The second step is to define our model. As in the previous article, we will use the AutoModelForSequenceClassification class, with two labels:</p>
<div class="cell" data-outputid="35b54c6c-0e21-43cc-e5b1-e86b4d221589" data-execution_count="5">
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><span class="im" style="color: #00769E;">from</span> transformers <span class="im" style="color: #00769E;">import</span> AutoModelForSequenceClassification</span>
<span id="cb3-2"></span>
<span id="cb3-3">model <span class="op" style="color: #5E5E5E;">=</span> AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">2</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"ef52063bdb8a4f9a96d56ed03c9d5d70","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.</code></pre>
</div>
</div>
<p>We can notice that you get a warning after instantiating this pretrained model. This is because BERT has not been pretrained to classifying pairs of sentences, so the head of the pretrained model has been discarded and a new head suitable for sequence classification has been added instead. The warnings indicate that some weights were not used (the ones corresponding to the dropped pretraining head) and that some others were randomly initialized (the ones for the new head). It concludes by encouraging you to train the model, which is exactly what we are going to do now.</p>
<p>Once we have our model, we can define a Trainer by passing it all the objects constructed up to now — the model, the training_args, the training and validation datasets, our data_collator, and our tokenizer:</p>
<div class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><span class="im" style="color: #00769E;">from</span> transformers <span class="im" style="color: #00769E;">import</span> Trainer</span>
<span id="cb5-2"></span>
<span id="cb5-3">trainer <span class="op" style="color: #5E5E5E;">=</span> Trainer(</span>
<span id="cb5-4">    model,</span>
<span id="cb5-5">    training_args,</span>
<span id="cb5-6">    train_dataset<span class="op" style="color: #5E5E5E;">=</span>tokenized_datasets[<span class="st" style="color: #20794D;">"train"</span>],</span>
<span id="cb5-7">    eval_dataset<span class="op" style="color: #5E5E5E;">=</span>tokenized_datasets[<span class="st" style="color: #20794D;">"validation"</span>],</span>
<span id="cb5-8">    data_collator<span class="op" style="color: #5E5E5E;">=</span>data_collator,</span>
<span id="cb5-9">    tokenizer<span class="op" style="color: #5E5E5E;">=</span>tokenizer,</span>
<span id="cb5-10">)</span></code></pre></div>
</div>
<p>Note that when we pass the tokenizer as we did here, the default data_collator used by the Trainer will be a DataCollatorWithPadding as defined previously, so we can skip the line data_collator=data_collator in this call.</p>
<p>To fine-tune the model on our dataset, we just have to call the train() method of our Trainer:</p>
<div class="cell" data-outputid="fb16b3c7-b4c9-4056-aa16-09017966b03d" data-execution_count="7">
<div class="sourceCode cell-code" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1">trainer.train()</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.</code></pre>
</div>
<div class="cell-output cell-output-display">


    <div>
      
      <progress value="1377" max="1377" style="width:300px; height:20px; vertical-align: middle;"></progress>
      [1377/1377 03:28, Epoch 3/3]
    </div>
    <table class="dataframe table table-sm table-striped">
  <thead>
 <tr>
      <th>Step</th>
      <th>Training Loss</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>500</td>
      <td>0.536100</td>
    </tr>
    <tr>
      <td>1000</td>
      <td>0.289800</td>
    </tr>
  </tbody>
</table><p>
</p></div>
<div class="cell-output cell-output-display" data-execution_count="7">
<pre><code>TrainOutput(global_step=1377, training_loss=0.33254354971426503, metrics={'train_runtime': 212.0857, 'train_samples_per_second': 51.885, 'train_steps_per_second': 6.493, 'total_flos': 406183858377360.0, 'train_loss': 0.33254354971426503, 'epoch': 3.0})</code></pre>
</div>
</div>
<p>This will start the fine-tuning (which should take a couple of minutes on a GPU) and report the training loss every 500 steps. It won’t, however, tell us how well (or badly) your model is performing. This is because:</p>
<ol type="1">
<li>We didn’t tell the Trainer to evaluate during training by setting evaluation_strategy to either “steps” (evaluate every eval_steps) or “epoch” (evaluate at the end of each epoch).</li>
<li>We didn’t provide the Trainer with a compute_metrics() function to calculate a metric during said evaluation (otherwise the evaluation would just have printed the loss, which is not a very intuitive number).</li>
</ol>
</section>
<section id="model-evaluation" class="level2" data-number="4">
<h2 data-number="4" class="anchored" data-anchor-id="model-evaluation"><span class="header-section-number">4</span> Model Evaluation</h2>
<p>Let’s see how we can build a useful compute_metrics() function and use it the next time we train. The function must take an EvalPrediction object (which is a named tuple with a predictions field and a label_ids field) and will return a dictionary mapping strings to floats (the strings being the names of the metrics returned, and the floats their values). To get some predictions from our model, we can use the Trainer.predict() command:</p>
<div class="cell" data-outputid="41ce62a5-b8ce-4cd0-cda5-026587a76335" data-execution_count="8">
<div class="sourceCode cell-code" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1">predictions <span class="op" style="color: #5E5E5E;">=</span> trainer.predict(tokenized_datasets[<span class="st" style="color: #20794D;">"validation"</span>])</span>
<span id="cb9-2"><span class="bu" style="color: null;">print</span>(predictions.predictions.shape, predictions.label_ids.shape)</span></code></pre></div>
<div class="cell-output cell-output-display">

</div>
<div class="cell-output cell-output-stdout">
<pre><code>(408, 2) (408,)</code></pre>
</div>
</div>
<p>The output of the predict() method is another named tuple with three fields: predictions, label_ids, and metrics. The metrics field will just contain the loss on the dataset passed, as well as some time metrics (how long it took to predict, in total and on average). Once we complete our compute_metrics() function and pass it to the Trainer, that field will also contain the metrics returned by compute_metrics().</p>
<p>As we can see, predictions is a two-dimensional array with shape 408 x 2 (408 being the number of elements in the dataset we used). Those are the logits for each element of the dataset we passed to predict() (all Transformer models return logits). To transform them into predictions that we can compare to our labels, we need to take the index with the maximum value on the second axis:</p>
<div class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb11" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><span class="im" style="color: #00769E;">import</span> numpy <span class="im" style="color: #00769E;">as</span> np</span>
<span id="cb11-2"></span>
<span id="cb11-3">preds <span class="op" style="color: #5E5E5E;">=</span> np.argmax(predictions.predictions, axis<span class="op" style="color: #5E5E5E;">=-</span><span class="dv" style="color: #AD0000;">1</span>)</span></code></pre></div>
</div>
<p>We can now compare those preds to the labels. To build our compute_metric() function, we will rely on the metrics from the Hugging Face Evaluate library. We can load the metrics associated with the MRPC dataset as easily as we loaded the dataset, this time with the evaluate.load() function. The object returned has a compute() method we can use to do the metric calculation:</p>
<div class="cell" data-outputid="289bdc0b-e2e9-49fc-dc68-b0d3308bf7fa" data-execution_count="10">
<div class="sourceCode cell-code" id="cb12" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><span class="im" style="color: #00769E;">import</span> evaluate</span>
<span id="cb12-2"></span>
<span id="cb12-3">metric <span class="op" style="color: #5E5E5E;">=</span> evaluate.load(<span class="st" style="color: #20794D;">"glue"</span>, <span class="st" style="color: #20794D;">"mrpc"</span>)</span>
<span id="cb12-4">metric.compute(predictions<span class="op" style="color: #5E5E5E;">=</span>preds, references<span class="op" style="color: #5E5E5E;">=</span>predictions.label_ids)</span></code></pre></div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"4270ea0f4616480f92d92282eafdc5d3","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-display" data-execution_count="10">
<pre><code>{'accuracy': 0.8529411764705882, 'f1': 0.8989898989898989}</code></pre>
</div>
</div>
<p>The exact results we get may vary, as the random initialization of the model head might change the metrics it achieved. Here, we can see our model has an accuracy of 85.78% on the validation set and an F1 score of 89.97. Those are the two metrics used to evaluate results on the MRPC dataset for the GLUE benchmark. The table in the BERT paper reported an F1 score of 88.9 for the base model. That was the uncased model while we are currently using the cased model, which explains the better result.</p>
<p>Wrapping everything together, we get our compute_metrics() function:</p>
<div class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb14" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><span class="kw" style="color: #003B4F;">def</span> compute_metrics(eval_preds):</span>
<span id="cb14-2">    metric <span class="op" style="color: #5E5E5E;">=</span> evaluate.load(<span class="st" style="color: #20794D;">"glue"</span>, <span class="st" style="color: #20794D;">"mrpc"</span>)</span>
<span id="cb14-3">    logits, labels <span class="op" style="color: #5E5E5E;">=</span> eval_preds</span>
<span id="cb14-4">    predictions <span class="op" style="color: #5E5E5E;">=</span> np.argmax(logits, axis<span class="op" style="color: #5E5E5E;">=-</span><span class="dv" style="color: #AD0000;">1</span>)</span>
<span id="cb14-5">    <span class="cf" style="color: #003B4F;">return</span> metric.compute(predictions<span class="op" style="color: #5E5E5E;">=</span>predictions, references<span class="op" style="color: #5E5E5E;">=</span>labels)</span></code></pre></div>
</div>
<p>And to see it used in action to report metrics at the end of each epoch, here is how we define a new Trainer with this compute_metrics() function:</p>
<div class="cell" data-outputid="4a53f8c1-3355-4794-9294-ba81c48231b9" data-execution_count="12">
<div class="sourceCode cell-code" id="cb15" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1">training_args <span class="op" style="color: #5E5E5E;">=</span> TrainingArguments(<span class="st" style="color: #20794D;">"test-trainer"</span>, evaluation_strategy<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"epoch"</span>)</span>
<span id="cb15-2">model <span class="op" style="color: #5E5E5E;">=</span> AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">2</span>)</span>
<span id="cb15-3"></span>
<span id="cb15-4">trainer <span class="op" style="color: #5E5E5E;">=</span> Trainer(</span>
<span id="cb15-5">    model,</span>
<span id="cb15-6">    training_args,</span>
<span id="cb15-7">    train_dataset<span class="op" style="color: #5E5E5E;">=</span>tokenized_datasets[<span class="st" style="color: #20794D;">"train"</span>],</span>
<span id="cb15-8">    eval_dataset<span class="op" style="color: #5E5E5E;">=</span>tokenized_datasets[<span class="st" style="color: #20794D;">"validation"</span>],</span>
<span id="cb15-9">    data_collator<span class="op" style="color: #5E5E5E;">=</span>data_collator,</span>
<span id="cb15-10">    tokenizer<span class="op" style="color: #5E5E5E;">=</span>tokenizer,</span>
<span id="cb15-11">    compute_metrics<span class="op" style="color: #5E5E5E;">=</span>compute_metrics,</span>
<span id="cb15-12">)</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.</code></pre>
</div>
</div>
<p>Note that we create a new TrainingArguments with its evaluation_strategy set to “epoch” and a new model — otherwise, we would just be continuing the training of the model we have already trained. To launch a new training run, we execute:</p>
<div class="cell" data-outputid="252c254a-4b59-406c-e755-d928f43da2e5" data-execution_count="13">
<div class="sourceCode cell-code" id="cb17" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1">trainer.train()</span></code></pre></div>
<div class="cell-output cell-output-display">


    <div>
      
      <progress value="1377" max="1377" style="width:300px; height:20px; vertical-align: middle;"></progress>
      [1377/1377 03:33, Epoch 3/3]
    </div>
    <table class="dataframe table table-sm table-striped">
  <thead>
 <tr>
      <th>Epoch</th>
      <th>Training Loss</th>
      <th>Validation Loss</th>
      <th>Accuracy</th>
      <th>F1</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>1</td>
      <td>No log</td>
      <td>0.365379</td>
      <td>0.835784</td>
      <td>0.884283</td>
    </tr>
    <tr>
      <td>2</td>
      <td>0.533500</td>
      <td>0.435071</td>
      <td>0.850490</td>
      <td>0.898164</td>
    </tr>
    <tr>
      <td>3</td>
      <td>0.340100</td>
      <td>0.565466</td>
      <td>0.855392</td>
      <td>0.900840</td>
    </tr>
  </tbody>
</table><p>
</p></div>
<div class="cell-output cell-output-display" data-execution_count="13">
<pre><code>TrainOutput(global_step=1377, training_loss=0.3655698079515733, metrics={'train_runtime': 214.1758, 'train_samples_per_second': 51.378, 'train_steps_per_second': 6.429, 'total_flos': 406183858377360.0, 'train_loss': 0.3655698079515733, 'epoch': 3.0})</code></pre>
</div>
</div>
<p>This time, it will report the validation loss and metrics at the end of each epoch on top of the training loss as we see above. Again, the exact accuracy/F1 score we reach might be a bit different from what we found before, because of the random head initialization of the model, but it should be in the same ballpark.</p>
<p>The Trainer will work out of the box on multiple GPUs or TPUs and provides lots of options, like mixed-precision training (use fp16 = True in your training arguments).</p>
</section>
<section id="acknowledgements" class="level2" data-number="5">
<h2 data-number="5" class="anchored" data-anchor-id="acknowledgements"><span class="header-section-number">5</span> Acknowledgements</h2>
<p>I’d like to express my thanks to the great <a href="https://huggingface.co/course/">Hugging Face Course</a> which i completed, and acknowledge the use of some images, content and other materials from the course in this article.</p>


</section>

 ]]></description>
  <category>natural-language-processing</category>
  <category>deep-learning</category>
  <category>hugging-face</category>
  <guid>http://livingdatalab.com/posts/2023-04-02-fine-tuning-a-pretrained-model-with-hugging-face.html</guid>
  <pubDate>Sat, 01 Apr 2023 23:00:00 GMT</pubDate>
  <media:content url="https://github.com/pranath/blog/raw/master/images/hugging_face_course.png" medium="image" type="image/png"/>
</item>
<item>
  <title>Fine-tuning a pre-trained model with Hugging Face - Dataset Preparation</title>
  <dc:creator>Pranath Fernando</dc:creator>
  <link>http://livingdatalab.com/posts/2023-04-01-fine-tuning-a-pretrained-model-with-hugging-face-dataset-preparation.html</link>
  <description><![CDATA[ 




<section id="introduction" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="introduction"><span class="header-section-number">1</span> Introduction</h2>
<p>In <a href="../#category=natural-language-processing">previous articles</a> we have seen how to use transformer models for a wide range of natural language tasks, including machine translation, summarization, and question answering. Transformers have become the standard model for NLP, similar to convolutional models in computer vision.</p>
<p>In practice, you’ll rarely train a transformer model from scratch. Transformers tend to be very large, so they take time, money, and lots of data to train fully. Instead, you’ll want to start with a pre-trained model and fine-tune it with a dataset if you need to for specific needs, which has become the norm in this new but thriving area of AI.</p>
<p><a href="https://huggingface.co/">Hugging Face</a> (🤗) is the best resource for pre-trained transformers. Their open-source libraries simplifies downloading and using transformer models like BERT, T5, and GPT-2. And you can use them alongside libraries such as FastAi, TensorFlow, PyTorch and Flax.</p>
<p>In this article we will look in a bit more detail at what you might need to do to prepare your data for fine-tuning a pre-trained model for your task.</p>
</section>
<section id="fine-tuning-a-model-on-a-batch-of-data" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="fine-tuning-a-model-on-a-batch-of-data"><span class="header-section-number">2</span> Fine-tuning a model on a batch of data</h2>
<p>Here is how we would train a BERT based pre-trained sequence classifier on one batch in PyTorch on a task to predict if two sentances mean the same thing:</p>
<div class="cell" data-outputid="49354e0c-8b23-4b9d-9463-8e72ccbf90ec" data-execution_count="18">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;">import</span> torch</span>
<span id="cb1-2"><span class="im" style="color: #00769E;">from</span> transformers <span class="im" style="color: #00769E;">import</span> AdamW, AutoTokenizer, AutoModelForSequenceClassification</span>
<span id="cb1-3"></span>
<span id="cb1-4"><span class="co" style="color: #5E5E5E;"># Set checkpoint</span></span>
<span id="cb1-5">checkpoint <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">"bert-base-uncased"</span></span>
<span id="cb1-6"><span class="co" style="color: #5E5E5E;"># Use same checkpoint so we get matched tokeniser &amp; model</span></span>
<span id="cb1-7">tokenizer <span class="op" style="color: #5E5E5E;">=</span> AutoTokenizer.from_pretrained(checkpoint)</span>
<span id="cb1-8">model <span class="op" style="color: #5E5E5E;">=</span> AutoModelForSequenceClassification.from_pretrained(checkpoint)</span>
<span id="cb1-9">sequences <span class="op" style="color: #5E5E5E;">=</span> [</span>
<span id="cb1-10">    <span class="st" style="color: #20794D;">"I've been waiting for a HuggingFace course my whole life."</span>,</span>
<span id="cb1-11">    <span class="st" style="color: #20794D;">"This course is amazing!"</span>,</span>
<span id="cb1-12">]</span>
<span id="cb1-13">batch <span class="op" style="color: #5E5E5E;">=</span> tokenizer(sequences, padding<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>, truncation<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>, return_tensors<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"pt"</span>)</span>
<span id="cb1-14"></span>
<span id="cb1-15"><span class="co" style="color: #5E5E5E;"># Set some labels to predict</span></span>
<span id="cb1-16">batch[<span class="st" style="color: #20794D;">"labels"</span>] <span class="op" style="color: #5E5E5E;">=</span> torch.tensor([<span class="dv" style="color: #AD0000;">1</span>, <span class="dv" style="color: #AD0000;">1</span>])</span>
<span id="cb1-17"></span>
<span id="cb1-18">optimizer <span class="op" style="color: #5E5E5E;">=</span> AdamW(model.parameters())</span>
<span id="cb1-19">loss <span class="op" style="color: #5E5E5E;">=</span> model(<span class="op" style="color: #5E5E5E;">**</span>batch).loss</span>
<span id="cb1-20">loss.backward()</span>
<span id="cb1-21">optimizer.step()</span></code></pre></div>
</div>
<p>However, just training the model on two sentences is not going to yield very good results. To get better results, we will need to prepare a bigger dataset.</p>
<p>In this article we will use as an example the MRPC (Microsoft Research Paraphrase Corpus) dataset, introduced in a <a href="https://aclanthology.org/I05-5002.pdf">paper</a> by William B. Dolan and Chris Brockett. The dataset consists of 5,801 pairs of sentences, with a label indicating if they are paraphrases or not (i.e., if both sentences mean the same thing).</p>
</section>
<section id="load-mrpc-dataset" class="level2" data-number="3">
<h2 data-number="3" class="anchored" data-anchor-id="load-mrpc-dataset"><span class="header-section-number">3</span> Load MRPC Dataset</h2>
<p>We can load the MRPC dataset from the Hugging Face Hub. The Hub doesn’t just contain models; it also has multiple datasets in lots of different languages. For now, let’s focus on the MRPC dataset. This is one of the 10 datasets composing the GLUE benchmark, which is an academic benchmark that is used to measure the performance of ML models across 10 different text classification tasks.</p>
<p>The 🤗 Datasets library provides a very simple command to download and cache a dataset on the Hub. We can download the MRPC dataset like this:</p>
<div class="cell" data-outputid="bf0b76b5-a766-4b10-ed51-71271834454a" data-execution_count="19">
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="im" style="color: #00769E;">from</span> datasets <span class="im" style="color: #00769E;">import</span> load_dataset</span>
<span id="cb2-2"></span>
<span id="cb2-3">raw_datasets <span class="op" style="color: #5E5E5E;">=</span> load_dataset(<span class="st" style="color: #20794D;">"glue"</span>, <span class="st" style="color: #20794D;">"mrpc"</span>)</span>
<span id="cb2-4">raw_datasets</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>WARNING:datasets.builder:Found cached dataset glue (/root/.cache/huggingface/datasets/glue/mrpc/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"5951a8c7ef3a499eb39ddcb8f23a78b6","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-display" data-execution_count="19">
<pre><code>DatasetDict({
    train: Dataset({
        features: ['sentence1', 'sentence2', 'label', 'idx'],
        num_rows: 3668
    })
    validation: Dataset({
        features: ['sentence1', 'sentence2', 'label', 'idx'],
        num_rows: 408
    })
    test: Dataset({
        features: ['sentence1', 'sentence2', 'label', 'idx'],
        num_rows: 1725
    })
})</code></pre>
</div>
</div>
<p>As we can see, we get a DatasetDict object which contains the training set, the validation set, and the test set. Each of those contains several columns (sentence1, sentence2, label, and idx) and a variable number of rows, which are the number of elements in each set (so, there are 3,668 pairs of sentences in the training set, 408 in the validation set, and 1,725 in the test set).</p>
<p>This command downloads and caches the dataset, by default in ~/.cache/huggingface/datasets.</p>
<p>We can access each pair of sentences in our raw_datasets object by indexing, like with a dictionary:</p>
<div class="cell" data-outputid="a83c0d68-278b-4c02-d238-f6bf36b82822" data-execution_count="20">
<div class="sourceCode cell-code" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1">raw_train_dataset <span class="op" style="color: #5E5E5E;">=</span> raw_datasets[<span class="st" style="color: #20794D;">"train"</span>]</span>
<span id="cb5-2">raw_train_dataset[<span class="dv" style="color: #AD0000;">0</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="20">
<pre><code>{'sentence1': 'Amrozi accused his brother , whom he called " the witness " , of deliberately distorting his evidence .',
 'sentence2': 'Referring to him as only " the witness " , Amrozi accused his brother of deliberately distorting his evidence .',
 'label': 1,
 'idx': 0}</code></pre>
</div>
</div>
<p>We can see the labels are already integers, so we won’t have to do any preprocessing there. To know which integer corresponds to which label, we can inspect the features of our raw_train_dataset. This will tell us the type of each column:</p>
<div class="cell" data-outputid="db197d43-72b4-452c-ca75-899bbc1627ae" data-execution_count="21">
<div class="sourceCode cell-code" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1">raw_train_dataset.features</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="21">
<pre><code>{'sentence1': Value(dtype='string', id=None),
 'sentence2': Value(dtype='string', id=None),
 'label': ClassLabel(names=['not_equivalent', 'equivalent'], id=None),
 'idx': Value(dtype='int32', id=None)}</code></pre>
</div>
</div>
<p>Behind the scenes, label is of type ClassLabel, and the mapping of integers to label name is stored in the names folder. 0 corresponds to not_equivalent, and 1 corresponds to equivalent.</p>
</section>
<section id="preprocessing-the-dataset" class="level2" data-number="4">
<h2 data-number="4" class="anchored" data-anchor-id="preprocessing-the-dataset"><span class="header-section-number">4</span> Preprocessing the dataset</h2>
<p>To preprocess the dataset, we need to convert the text to numbers the model can make sense of. This is done with a tokenizer. We can feed the tokenizer one sentence or a list of sentences, so we can directly tokenize all the first sentences and all the second sentences of each pair like this:</p>
<div class="cell" data-execution_count="22">
<div class="sourceCode cell-code" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><span class="im" style="color: #00769E;">from</span> transformers <span class="im" style="color: #00769E;">import</span> AutoTokenizer</span>
<span id="cb9-2"></span>
<span id="cb9-3">checkpoint <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">"bert-base-uncased"</span></span>
<span id="cb9-4">tokenizer <span class="op" style="color: #5E5E5E;">=</span> AutoTokenizer.from_pretrained(checkpoint)</span>
<span id="cb9-5">tokenized_sentences_1 <span class="op" style="color: #5E5E5E;">=</span> tokenizer(raw_datasets[<span class="st" style="color: #20794D;">"train"</span>][<span class="st" style="color: #20794D;">"sentence1"</span>])</span>
<span id="cb9-6">tokenized_sentences_2 <span class="op" style="color: #5E5E5E;">=</span> tokenizer(raw_datasets[<span class="st" style="color: #20794D;">"train"</span>][<span class="st" style="color: #20794D;">"sentence2"</span>])</span></code></pre></div>
</div>
<p>However, we can’t just pass two sequences to the model and get a prediction of whether the two sentences are paraphrases or not. We need to handle the two sequences as a pair, and apply the appropriate preprocessing. Fortunately, the tokenizer can also take a pair of sequences and prepare it the way our BERT model expects:</p>
<div class="cell" data-outputid="d21bfff7-4a33-407f-8889-8b28907c4348" data-execution_count="23">
<div class="sourceCode cell-code" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1">inputs <span class="op" style="color: #5E5E5E;">=</span> tokenizer(<span class="st" style="color: #20794D;">"This is the first sentence."</span>, <span class="st" style="color: #20794D;">"This is the second one."</span>)</span>
<span id="cb10-2">inputs</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="23">
<pre><code>{'input_ids': [101, 2023, 2003, 1996, 2034, 6251, 1012, 102, 2023, 2003, 1996, 2117, 2028, 1012, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}</code></pre>
</div>
</div>
<p>In this example, <em>token_type_ids</em> is what tells the model which part of the input is the first sentence and which is the second sentence.</p>
<p>If we decode the IDs inside input_ids back to words we get:</p>
<div class="cell" data-outputid="9dfe73eb-f464-4381-a09a-21a8184cdf20" data-execution_count="24">
<div class="sourceCode cell-code" id="cb12" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1">tokenizer.convert_ids_to_tokens(inputs[<span class="st" style="color: #20794D;">"input_ids"</span>])</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="24">
<pre><code>['[CLS]',
 'this',
 'is',
 'the',
 'first',
 'sentence',
 '.',
 '[SEP]',
 'this',
 'is',
 'the',
 'second',
 'one',
 '.',
 '[SEP]']</code></pre>
</div>
</div>
<p>So we see the model expects the inputs to be of the form [CLS] sentence1 [SEP] sentence2 [SEP] when there are two sentences.</p>
<p>The parts of the input corresponding to [CLS] sentence1 [SEP] all have a token type ID of 0, while the other parts, corresponding to sentence2 [SEP], all have a token type ID of 1.</p>
<p>Note that if you select a different checkpoint, you won’t necessarily have the token_type_ids in your tokenized inputs (for instance, they’re not returned if you use a DistilBERT model). They are only returned when the model will know what to do with them, because it has seen them during its pretraining.</p>
<p>Here, BERT is pretrained with token type IDs, and on top of the masked language modeling objective, it has an additional objective called next sentence prediction. The goal with this task is to model the relationship between pairs of sentences.</p>
<p>With next sentence prediction, the model is provided pairs of sentences (with randomly masked tokens) and asked to predict whether the second sentence follows the first. To make the task non-trivial, half of the time the sentences follow each other in the original document they were extracted from, and the other half of the time the two sentences come from two different documents.</p>
<p>In general, we don’t need to worry about whether or not there are token_type_ids in our tokenized inputs: as long as we use the same checkpoint for the tokenizer and the model, everything will be fine as the tokenizer knows what to provide to its model.</p>
<p>Now that we have seen how our tokenizer can deal with one pair of sentences, we can use it to tokenize our whole dataset, we can feed the tokenizer a list of pairs of sentences by giving it the list of first sentences, then the list of second sentences. So, one way to preprocess the training dataset is:</p>
<div class="cell" data-execution_count="25">
<div class="sourceCode cell-code" id="cb14" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1">tokenized_dataset <span class="op" style="color: #5E5E5E;">=</span> tokenizer(</span>
<span id="cb14-2">    raw_datasets[<span class="st" style="color: #20794D;">"train"</span>][<span class="st" style="color: #20794D;">"sentence1"</span>],</span>
<span id="cb14-3">    raw_datasets[<span class="st" style="color: #20794D;">"train"</span>][<span class="st" style="color: #20794D;">"sentence2"</span>],</span>
<span id="cb14-4">    padding<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>,</span>
<span id="cb14-5">    truncation<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>,</span>
<span id="cb14-6">)</span></code></pre></div>
</div>
<p>This works well, but it has the disadvantage of returning a dictionary (with our keys, input_ids, attention_mask, and token_type_ids, and values that are lists of lists). It will also only work if we have enough RAM to store your whole dataset during the tokenization (whereas the datasets from the 🤗 Datasets library are Apache Arrow files stored on the disk, so we only keep the samples you ask for loaded in memory).</p>
<p>To keep the data as a dataset, we will use the Dataset.map() method. This also allows us some extra flexibility, if we need more preprocessing done than just tokenization. The map() method works by applying a function on each element of the dataset, so let’s define a function that tokenizes our inputs:</p>
<div class="cell" data-execution_count="26">
<div class="sourceCode cell-code" id="cb15" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><span class="kw" style="color: #003B4F;">def</span> tokenize_function(example):</span>
<span id="cb15-2">    <span class="cf" style="color: #003B4F;">return</span> tokenizer(example[<span class="st" style="color: #20794D;">"sentence1"</span>], example[<span class="st" style="color: #20794D;">"sentence2"</span>], truncation<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>)</span></code></pre></div>
</div>
<p>This function takes a dictionary (like the items of our dataset) and returns a new dictionary with the keys input_ids, attention_mask, and token_type_ids. Note that it also works if the example dictionary contains several samples (each key as a list of sentences) since the tokenizer works on lists of pairs of sentences, as seen before. This will allow us to use the option batched=True in our call to map(), which will greatly speed up the tokenization. The tokenizer is backed by a tokenizer written in Rust from the 🤗 Tokenizers library. This tokenizer can be very fast, but only if we give it lots of inputs at once.</p>
<p>Here is how we apply the tokenization function on all our datasets at once. We’re using batched=True in our call to map so the function is applied to multiple elements of our dataset at once, and not on each element separately. This allows for faster preprocessing.</p>
<div class="cell" data-outputid="6b5052b8-f1a5-4951-e0e5-c573da24eee3" data-execution_count="27">
<div class="sourceCode cell-code" id="cb16" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1">tokenized_datasets <span class="op" style="color: #5E5E5E;">=</span> raw_datasets.<span class="bu" style="color: null;">map</span>(tokenize_function, batched<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>)</span>
<span id="cb16-2">tokenized_datasets</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/glue/mrpc/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-cc233c4ca650f8a4.arrow</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"ca2a667fc04146eca114fdce7f6f9f8d","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/glue/mrpc/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-4bdce1e2012c301e.arrow</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="27">
<pre><code>DatasetDict({
    train: Dataset({
        features: ['sentence1', 'sentence2', 'label', 'idx', 'input_ids', 'token_type_ids', 'attention_mask'],
        num_rows: 3668
    })
    validation: Dataset({
        features: ['sentence1', 'sentence2', 'label', 'idx', 'input_ids', 'token_type_ids', 'attention_mask'],
        num_rows: 408
    })
    test: Dataset({
        features: ['sentence1', 'sentence2', 'label', 'idx', 'input_ids', 'token_type_ids', 'attention_mask'],
        num_rows: 1725
    })
})</code></pre>
</div>
</div>
<p>The way the 🤗 Datasets library applies this processing is by adding new fields to the datasets, one for each key in the dictionary returned by the preprocessing function.</p>
<p>Our tokenize_function returns a dictionary with the keys input_ids, attention_mask, and token_type_ids, so those three fields are added to all splits of our dataset. Note that we could also have changed existing fields if our preprocessing function returned a new value for an existing key in the dataset to which we applied map().</p>
<p>The last thing we will need to do is pad all the examples to the length of the longest element when we batch elements together — a technique we refer to as dynamic padding.</p>
</section>
<section id="dynamic-padding" class="level2" data-number="5">
<h2 data-number="5" class="anchored" data-anchor-id="dynamic-padding"><span class="header-section-number">5</span> Dynamic Padding</h2>
<p>The function that is responsible for putting together samples inside a batch is called a collate function. It’s an argument you can pass when you build a DataLoader, the default being a function that will just convert your samples to PyTorch tensors and concatenate them (recursively if your elements are lists, tuples, or dictionaries). This won’t be possible in our case since the inputs we have won’t all be of the same size. We have deliberately postponed the padding, to only apply it as necessary on each batch and avoid having over-long inputs with a lot of padding. This will speed up training by quite a bit, but note that if you’re training on a TPU it can cause problems — TPUs prefer fixed shapes, even when that requires extra padding.</p>
<p>To do this in practice, we have to define a collate function that will apply the correct amount of padding to the items of the dataset we want to batch together. Fortunately, the 🤗 Transformers library provides us with such a function via DataCollatorWithPadding. It takes a tokenizer when you instantiate it (to know which padding token to use, and whether the model expects padding to be on the left or on the right of the inputs) and will do everything you need:</p>
<div class="cell" data-execution_count="28">
<div class="sourceCode cell-code" id="cb20" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><span class="im" style="color: #00769E;">from</span> transformers <span class="im" style="color: #00769E;">import</span> DataCollatorWithPadding</span>
<span id="cb20-2"></span>
<span id="cb20-3">data_collator <span class="op" style="color: #5E5E5E;">=</span> DataCollatorWithPadding(tokenizer<span class="op" style="color: #5E5E5E;">=</span>tokenizer)</span></code></pre></div>
</div>
<p>To test this, let’s grab a few samples from our training set that we would like to batch together. Here, we remove the columns idx, sentence1, and sentence2 as they won’t be needed and contain strings (and we can’t create tensors with strings) and have a look at the lengths of each entry in the batch:</p>
<div class="cell" data-outputid="ce53b175-f333-4434-f66c-70342fc39e34" data-execution_count="29">
<div class="sourceCode cell-code" id="cb21" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1">samples <span class="op" style="color: #5E5E5E;">=</span> tokenized_datasets[<span class="st" style="color: #20794D;">"train"</span>][:<span class="dv" style="color: #AD0000;">8</span>]</span>
<span id="cb21-2">samples <span class="op" style="color: #5E5E5E;">=</span> {k: v <span class="cf" style="color: #003B4F;">for</span> k, v <span class="kw" style="color: #003B4F;">in</span> samples.items() <span class="cf" style="color: #003B4F;">if</span> k <span class="kw" style="color: #003B4F;">not</span> <span class="kw" style="color: #003B4F;">in</span> [<span class="st" style="color: #20794D;">"idx"</span>, <span class="st" style="color: #20794D;">"sentence1"</span>, <span class="st" style="color: #20794D;">"sentence2"</span>]}</span>
<span id="cb21-3">[<span class="bu" style="color: null;">len</span>(x) <span class="cf" style="color: #003B4F;">for</span> x <span class="kw" style="color: #003B4F;">in</span> samples[<span class="st" style="color: #20794D;">"input_ids"</span>]]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="29">
<pre><code>[50, 59, 47, 67, 59, 50, 62, 32]</code></pre>
</div>
</div>
<p>So we get samples of varying length, from 32 to 67. Dynamic padding means the samples in this batch should all be padded to a length of 67, the maximum length inside the batch. Without dynamic padding, all of the samples would have to be padded to the maximum length in the whole dataset, or the maximum length the model can accept. Let’s double-check that our data_collator is dynamically padding the batch properly:</p>
<div class="cell" data-outputid="664d9b2d-ca98-4da0-f26c-c70823e05481" data-execution_count="30">
<div class="sourceCode cell-code" id="cb23" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1">batch <span class="op" style="color: #5E5E5E;">=</span> data_collator(samples)</span>
<span id="cb23-2">{k: v.shape <span class="cf" style="color: #003B4F;">for</span> k, v <span class="kw" style="color: #003B4F;">in</span> batch.items()}</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="30">
<pre><code>{'input_ids': torch.Size([8, 67]),
 'token_type_ids': torch.Size([8, 67]),
 'attention_mask': torch.Size([8, 67]),
 'labels': torch.Size([8])}</code></pre>
</div>
</div>
<p>Now that we’ve gone from raw text to batches a model can deal with, we’re ready to fine-tune it</p>
</section>
<section id="acknowledgements" class="level2" data-number="6">
<h2 data-number="6" class="anchored" data-anchor-id="acknowledgements"><span class="header-section-number">6</span> Acknowledgements</h2>
<p>I’d like to express my thanks to the great <a href="https://huggingface.co/course/">Hugging Face Course</a> which i completed, and acknowledge the use of some images, content and other materials from the course in this article.</p>


</section>

 ]]></description>
  <category>natural-language-processing</category>
  <category>deep-learning</category>
  <category>hugging-face</category>
  <guid>http://livingdatalab.com/posts/2023-04-01-fine-tuning-a-pretrained-model-with-hugging-face-dataset-preparation.html</guid>
  <pubDate>Fri, 31 Mar 2023 23:00:00 GMT</pubDate>
  <media:content url="https://github.com/pranath/blog/raw/master/images/hugging_face_course.png" medium="image" type="image/png"/>
</item>
<item>
  <title>An Introduction to the Transformer Model - The power behind recent advances in AI</title>
  <dc:creator>Pranath Fernando</dc:creator>
  <link>http://livingdatalab.com/posts/2023-03-29-a-basic-overview-of-transfomer-models.html</link>
  <description><![CDATA[ 




<section id="introduction" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="introduction"><span class="header-section-number">1</span> Introduction</h2>
<p>AI and Deep Learning Models are behind recent applications such as Chat-GPT and GPT-4 which have amazed the world, and have created exciting possibilities for applications for business and society. But how do these models actually work? Most of the explanations online are deeply techincal which can make these models hard to understand for many people. Admitedly, most of my own previous articles on <a href="../#category=natural-language-processing">this topic</a> have also gone more into the technical details of how these models work, yet I also believe the essence of these models can be explained without any technical details or code. The main technology behind these recent advances is something called the <em>Transfomer Model</em> which was first created in 2017.</p>
<p>In this article, I aim to give a high-level and non-technical overview of how transfomer models work, and the types of tasks they can peform.</p>
</section>
<section id="where-did-transfomer-models-come-from" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="where-did-transfomer-models-come-from"><span class="header-section-number">2</span> Where did Transfomer Models come from</h2>
<p>Transfomer models came from within a sub-discipline of AI called <strong>Natural Language Processing</strong>. Its the part of AI concerned with <a href="https://www.ibm.com/uk-en/topics/natural-language-processing">giving computers the ability to understand text and spoken words in much the same way human beings</a> which has been an active area of research <a href="https://en.wikipedia.org/wiki/Natural_language_processing">since the 1950’s</a>.</p>
<p>In 2015 the team behind Google Translate <a href="https://acutrans.com/history-of-google-translate/#:~:text=However%2C%20in%202006%20Google%20launched,good%2C%20but%20they%20were%20convenient">started using Neural Networks for machine translation for human languages</a> which did much better than previous methods. Yet even this method had some limitations, most notably something called the <a href="https://livingdatalab.com/posts/2023-03-01-improving-seq2seq-language-models-using-basic-attention.html">information bottleneck</a> issue that basically meant as the text you wanted to translate got longer it became more difficult to translate the text well.</p>
<p>In 2017 the Google Brain team announced the creation of a new Transfomer architecture in the now famous research paper <a href="https://arxiv.org/abs/1706.03762">Attention Is All You Need</a>. They developed this specically to solve the problem with Google Translate and the ‘information bottlneck’ that had issues translating longer texts. The new Transformer model was easily able to translate longer and longer texts with no problems, and its important to understand that the original intention of this research was to solve this problem.</p>
<p>Yet this radically new model in AI created great excitement in the field, and many other researchers started to try it out to solve different types of problems such as in computer vision, voice recognition and more with great success - including most recently Chat-GPT and GPT-4. In fact it has now been so successful in so many areas, some are starting to consider if Transfomers could even be a general purpose problem solving model. It’s certainly worth noting this is one of the greatest examples of the value of free, open and collaberative scientific research, which enables researchers to build on and experiment with the work of others, leading to unexpected benefits.</p>
</section>
<section id="what-can-transformer-models-do" class="level2" data-number="3">
<h2 data-number="3" class="anchored" data-anchor-id="what-can-transformer-models-do"><span class="header-section-number">3</span> What can Transformer Models do</h2>
<p>Transfomer models are being used for many tasks and problems currently including:</p>
<ul>
<li>Text Classification</li>
<li>Sentiment Analysis</li>
<li>Machine translation</li>
<li>Named entity recognition (NER)</li>
<li>Text summarization</li>
<li>Text generation</li>
<li>Question &amp; answering</li>
<li>Biological sequence analysis</li>
<li>Computer Vision</li>
<li>Time Series Analysis</li>
<li>Video understanding</li>
</ul>
</section>
<section id="what-is-a-transfomer-model" class="level2" data-number="4">
<h2 data-number="4" class="anchored" data-anchor-id="what-is-a-transfomer-model"><span class="header-section-number">4</span> What is a Transfomer Model</h2>
<p>Recall that Transfomers were orginally created to help improve machine translation, so translating from one sequence of text to another sequence of text.</p>
<p>A Transfomer model is primarily composed of two blocks:</p>
<ul>
<li>Encoder (left): The encoder receives an input and builds a representation of it (its features). This means that the model is optimized to acquire understanding from the input.</li>
<li>Decoder (right): The decoder uses the encoder’s representation (features) along with other inputs to generate a target sequence. This means that the model is optimized for generating outputs.</li>
</ul>
<p>Each of these parts can be used independently or together, depending on the task:</p>
<p><img src="http://livingdatalab.com/posts/https:/github.com/pranath/blog/raw/master/images/hf_transfomers1.png"></p>
<ul>
<li><strong>Encoder-only models:</strong> Good for tasks that require understanding of the input, such as sentence classification and named entity recognition.</li>
<li><strong>Decoder-only models:</strong> Good for generative tasks such as text generation.</li>
<li><strong>Encoder-decoder models or sequence-to-sequence models:</strong> Good for generative tasks that require an input, such as translation or summarization.</li>
</ul>
<p>The original use of this for machine translation - so was therefore an encoder-decoder type transformer model.</p>
</section>
<section id="attention-layers" class="level2" data-number="5">
<h2 data-number="5" class="anchored" data-anchor-id="attention-layers"><span class="header-section-number">5</span> Attention Layers</h2>
<p>A key feature of Transformer models is that they are built with special layers called attention layers. In fact, the title of the paper introducing the Transformer architecture was “Attention Is All You Need”. Here, all we need to know is that this layer will tell the model to pay specific attention to certain words in the sentence you passed it (and more or less ignore the others) when dealing with the representation of each word.</p>
<p>To put this into context, consider the task of translating text from English to French. Given the input “You like this course”, a translation model will need to also attend to the adjacent word “You” to get the proper translation for the word “like”, because in French the verb “like” is conjugated differently depending on the subject. The rest of the sentence, however, is not useful for the translation of that word. In the same vein, when translating “this” the model will also need to pay attention to the word “course”, because “this” translates differently depending on whether the associated noun is masculine or feminine. Again, the other words in the sentence will not matter for the translation of “this”. With more complex sentences (and more complex grammar rules), the model would need to pay special attention to words that might appear farther away in the sentence to properly translate each word.</p>
<p>The same concept applies to any task associated with natural language: a word by itself has a meaning, but that meaning is deeply affected by the context, which can be any other word (or words) before or after the word being studied.</p>
<p>Now that we have an idea of what attention layers are all about, let’s take a closer look at the Transformer architecture.</p>
</section>
<section id="the-original-architecture" class="level2" data-number="6">
<h2 data-number="6" class="anchored" data-anchor-id="the-original-architecture"><span class="header-section-number">6</span> The Original Architecture</h2>
<p>The Transformer architecture was originally designed for translation as we described previously. During training, the encoder receives inputs (sentences) in a certain language, while the decoder receives the same sentences in the desired target language. In the encoder, the attention layers can use all the words in a sentence (since, as we just saw, the translation of a given word can be dependent on what is after as well as before it in the sentence). The decoder, however, works sequentially and can only pay attention to the words in the sentence that it has already translated (so, only the words before the word currently being generated). For example, when we have predicted the first three words of the translated target, we give them to the decoder which then uses all the inputs of the encoder to try to predict the fourth word.</p>
<p>To speed things up during training (when the model has access to target sentences), the decoder is fed the whole target, but it is not allowed to use future words (if it had access to the word at position 2 when trying to predict the word at position 2, the problem would not be very hard!). For instance, when trying to predict the fourth word, the attention layer will only have access to the words in positions 1 to 3.</p>
<p>The original Transformer architecture looked like this, with the encoder on the left and the decoder on the right:</p>
<p><img src="http://livingdatalab.com/posts/https:/github.com/pranath/blog/raw/master/images/hf_transformers2.png"></p>
<p>Note that the first attention layer in a decoder block pays attention to all (past) inputs to the decoder, but the second attention layer uses the output of the encoder. It can thus access the whole input sentence to best predict the current word, also known as <strong>Bi-directional Attention</strong>. This is very useful as different languages can have grammatical rules that put the words in different orders, or some context provided later in the sentence may be helpful to determine the best translation of a given word.</p>
<p>The attention mask can also be used in the encoder/decoder to prevent the model from paying attention to some special words — for instance, the special padding word used to make all the inputs the same length when batching together sentences.</p>
</section>
<section id="encoder-models" class="level2" data-number="7">
<h2 data-number="7" class="anchored" data-anchor-id="encoder-models"><span class="header-section-number">7</span> Encoder Models</h2>
<p>Encoder models use only the encoder of a Transformer model. At each stage, the attention layers can access all the words in the initial sentence. These models are often characterized as having “bi-directional” attention, and are often called <strong>auto-encoding models</strong>.</p>
<p>The pretraining of these models usually revolves around somehow corrupting a given sentence (for instance, by masking random words in it) and tasking the model with finding or reconstructing the initial sentence.</p>
<p>Encoder models are best suited for tasks requiring an understanding of the full sentence, such as sentence classification, named entity recognition (and more generally word classification), and extractive question answering.</p>
<p>Representatives of this family of models include:</p>
<ul>
<li>ALBERT</li>
<li>BERT</li>
<li>DistilBERT</li>
<li>ELECTRA</li>
<li>RoBERTa</li>
</ul>
</section>
<section id="decoder-models" class="level2" data-number="8">
<h2 data-number="8" class="anchored" data-anchor-id="decoder-models"><span class="header-section-number">8</span> Decoder Models</h2>
<p>Decoder models use only the decoder of a Transformer model. At each stage, for a given word the attention layers can only access the words positioned before it in the sentence. These models are often called <strong>auto-regressive models</strong>.</p>
<p>The pretraining of decoder models usually revolves around predicting the next word in the sentence.</p>
<p>These models are best suited for tasks involving text generation.</p>
<p>Representatives of this family of models include:</p>
<ul>
<li>CTRL</li>
<li>GPT</li>
<li>GPT-2</li>
<li>Transformer XL</li>
</ul>
</section>
<section id="encoder-decoder-models" class="level2" data-number="9">
<h2 data-number="9" class="anchored" data-anchor-id="encoder-decoder-models"><span class="header-section-number">9</span> Encoder-Decoder Models</h2>
<p>Encoder-decoder models (also called sequence-to-sequence models) use both parts of the Transformer architecture. At each stage, the attention layers of the encoder can access all the words in the initial sentence, whereas the attention layers of the decoder can only access the words positioned before a given word in the input.</p>
<p>The pretraining of these models can be done using the objectives of encoder or decoder models, but usually involves something a bit more complex. For instance, T5 is pretrained by replacing random spans of text (that can contain several words) with a single mask special word, and the objective is then to predict the text that this mask word replaces.</p>
<p>Sequence-to-sequence models are best suited for tasks revolving around generating new sentences depending on a given input, such as summarization, translation, or generative question answering.</p>
<p>Representatives of this family of models include:</p>
<ul>
<li>BART</li>
<li>mBART</li>
<li>Marian</li>
<li>T5</li>
</ul>
<p>This completes our basic overview of the Transfomer model, I hope you found it insightful !</p>
</section>
<section id="acknowledgements" class="level2" data-number="10">
<h2 data-number="10" class="anchored" data-anchor-id="acknowledgements"><span class="header-section-number">10</span> Acknowledgements</h2>
<p>I’d like to express my thanks to the great <a href="https://huggingface.co/course/">Hugging Face Course</a> which i completed, and acknowledge the use of some images, content and other materials from the course in this article.</p>


</section>

 ]]></description>
  <category>natural-language-processing</category>
  <category>deep-learning</category>
  <category>hugging-face</category>
  <guid>http://livingdatalab.com/posts/2023-03-29-a-basic-overview-of-transfomer-models.html</guid>
  <pubDate>Tue, 28 Mar 2023 23:00:00 GMT</pubDate>
  <media:content url="https://github.com/pranath/blog/raw/master/images/aihuman.jpeg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Using an efficient transformer to create an interactive and more complex chatbot</title>
  <dc:creator>Pranath Fernando</dc:creator>
  <link>http://livingdatalab.com/posts/2023-03-28-using-an-efficient-transformer-to-create-an-interactive-complex-chatbot.html</link>
  <description><![CDATA[ 




<section id="introduction" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="introduction"><span class="header-section-number">1</span> Introduction</h2>
<p>In this project, we are going to use the <a href="https://arxiv.org/abs/2001.04451">Reformer</a>, also known as the efficient Transformer, to generate a dialogue between two bots. We will feed conversations to our model and it will learn how to understand the context of each one. Not only will it learn how to answer questions but it will also know how to ask questions if it needs more info. For example, after a customer asks for a train ticket, the chatbot can ask what time the said customer wants to leave. You could use this concept to automate call centers, hotel receptions, personal trainers, or any type of customer service.</p>
<p>We will:</p>
<ul>
<li>Understand how the Reformer works</li>
<li>Explore the <a href="https://arxiv.org/abs/1810.00278">MultiWoz</a> dataset</li>
<li>Process the data to feed it into the model</li>
<li>Train our model</li>
<li>Generate a dialogue by feeding a question to the model</li>
</ul>
</section>
<section id="exploring-the-multiwoz-dataset" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="exploring-the-multiwoz-dataset"><span class="header-section-number">2</span> Exploring the MultiWoz Dataset</h2>
<p>We will start by exploring the MultiWoz dataset. The dataset we are about to use has more than 10,000 human annotated dialogues and spans multiple domains and topics. Some dialogues include multiple domains and others include single domains. In this section, we will load and explore this dataset, as well as develop a function to extract the dialogues.</p>
<p>Let’s first import the modules we will be using:</p>
<div class="cell" data-outputid="e3a85dd1-e375-4636-ea62-b9b403f0952a" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;">import</span> json</span>
<span id="cb1-2"><span class="im" style="color: #00769E;">import</span> random</span>
<span id="cb1-3"><span class="im" style="color: #00769E;">import</span> numpy <span class="im" style="color: #00769E;">as</span> np</span>
<span id="cb1-4"><span class="im" style="color: #00769E;">from</span> termcolor <span class="im" style="color: #00769E;">import</span> colored</span>
<span id="cb1-5"></span>
<span id="cb1-6"><span class="im" style="color: #00769E;">import</span> trax   </span>
<span id="cb1-7"><span class="im" style="color: #00769E;">from</span> trax <span class="im" style="color: #00769E;">import</span> layers <span class="im" style="color: #00769E;">as</span> tl</span>
<span id="cb1-8"><span class="im" style="color: #00769E;">from</span> trax.supervised <span class="im" style="color: #00769E;">import</span> training</span>
<span id="cb1-9"></span>
<span id="cb1-10"><span class="im" style="color: #00769E;">import</span> w4_unittest</span></code></pre></div>
</div>
<p>Let’s also declare some constants we will be using in the exercises.</p>
<div class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="co" style="color: #5E5E5E;"># filename of the MultiWOZ dialogue dataset</span></span>
<span id="cb2-2">DATA_FILE <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">'data.json'</span></span>
<span id="cb2-3"></span>
<span id="cb2-4"><span class="co" style="color: #5E5E5E;"># data directory</span></span>
<span id="cb2-5">DATA_DIR <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">'./data'</span></span>
<span id="cb2-6"></span>
<span id="cb2-7"><span class="co" style="color: #5E5E5E;"># dictionary where we will load the dialogue dataset</span></span>
<span id="cb2-8">DIALOGUE_DB <span class="op" style="color: #5E5E5E;">=</span> {}</span>
<span id="cb2-9"></span>
<span id="cb2-10"><span class="co" style="color: #5E5E5E;"># vocabulary filename</span></span>
<span id="cb2-11">VOCAB_FILE <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">'en_32k.subword'</span></span>
<span id="cb2-12"></span>
<span id="cb2-13"><span class="co" style="color: #5E5E5E;"># vocabulary file directory</span></span>
<span id="cb2-14">VOCAB_DIR <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">'data/vocabs'</span></span></code></pre></div>
</div>
<p>Let’s now load the MultiWOZ 2.1 dataset already downloaded.</p>
<div class="cell" data-outputid="3d086ea4-7898-4870-b52f-f362cb02e118" data-execution_count="3">
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><span class="co" style="color: #5E5E5E;"># help function to load a JSON file</span></span>
<span id="cb3-2"><span class="kw" style="color: #003B4F;">def</span> load_json(directory, <span class="bu" style="color: null;">file</span>):</span>
<span id="cb3-3">    <span class="cf" style="color: #003B4F;">with</span> <span class="bu" style="color: null;">open</span>(<span class="ss" style="color: #20794D;">f'</span><span class="sc" style="color: #5E5E5E;">{</span>directory<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">/</span><span class="sc" style="color: #5E5E5E;">{</span><span class="bu" style="color: null;">file</span><span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">'</span>) <span class="im" style="color: #00769E;">as</span> <span class="bu" style="color: null;">file</span>: </span>
<span id="cb3-4">        db <span class="op" style="color: #5E5E5E;">=</span> json.load(<span class="bu" style="color: null;">file</span>)</span>
<span id="cb3-5">    <span class="cf" style="color: #003B4F;">return</span> db</span>
<span id="cb3-6"></span>
<span id="cb3-7"><span class="co" style="color: #5E5E5E;"># load the dialogue data set into our dictionary</span></span>
<span id="cb3-8">DIALOGUE_DB <span class="op" style="color: #5E5E5E;">=</span> load_json(DATA_DIR, DATA_FILE)</span></code></pre></div>
</div>
<p>Let’s see how many dialogues we have in the dictionary. 1 key-value pair is one dialogue so we can just get the dictionary’s length.</p>
<div class="cell" data-outputid="4b364506-1088-4f00-be0c-4fefa892dc4e" data-execution_count="4">
<div class="sourceCode cell-code" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><span class="bu" style="color: null;">print</span>(<span class="ss" style="color: #20794D;">f'The number of dialogues is: </span><span class="sc" style="color: #5E5E5E;">{</span><span class="bu" style="color: null;">len</span>(DIALOGUE_DB)<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">'</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>The number of dialogues is: 10438</code></pre>
</div>
</div>
<p>The dialogues are composed of multiple files and the filenames are used as keys in our dictionary. Those with multi-domain dialogues have “MUL” in their filenames while single domain dialogues have either “SNG” or “WOZ”.</p>
<div class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><span class="co" style="color: #5E5E5E;"># print 7 keys from the dataset to see the filenames</span></span>
<span id="cb6-2"><span class="bu" style="color: null;">print</span>(<span class="bu" style="color: null;">list</span>(DIALOGUE_DB.keys())[<span class="dv" style="color: #AD0000;">0</span>:<span class="dv" style="color: #AD0000;">7</span>]) </span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>['SNG01856.json', 'SNG0129.json', 'PMUL1635.json', 'MUL2168.json', 'SNG0073.json', 'SNG01445.json', 'MUL2105.json']</code></pre>
</div>
</div>
<p>As we can see from the cells above, there are 10,438 conversations, each in its own file. We will train your model on all those conversations. Each file is also loaded into a dictionary and each has two keys which are the following:</p>
<div class="cell" data-outputid="b22f570d-a7b0-4b92-ba68-0b7236e61051" data-execution_count="6">
<div class="sourceCode cell-code" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><span class="co" style="color: #5E5E5E;"># get keys of the fifth file in the list above</span></span>
<span id="cb8-2"><span class="bu" style="color: null;">print</span>(DIALOGUE_DB[<span class="st" style="color: #20794D;">'SNG0073.json'</span>].keys())</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>dict_keys(['goal', 'log'])</code></pre>
</div>
</div>
<p>The <code>goal</code> also points to a dictionary and it contains several keys pertaining to the objectives of the conversation. For example below, we can see that the conversation will be about booking a taxi.</p>
<div class="cell" data-outputid="7e8efa2d-821a-44c8-902d-2c722baf5b4c" data-execution_count="7">
<div class="sourceCode cell-code" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1">DIALOGUE_DB[<span class="st" style="color: #20794D;">'SNG0073.json'</span>][<span class="st" style="color: #20794D;">'goal'</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="7">
<pre><code>{'taxi': {'info': {'leaveAt': '17:15',
   'destination': 'pizza hut fen ditton',
   'departure': "saint john's college"},
  'reqt': ['car type', 'phone'],
  'fail_info': {}},
 'police': {},
 'hospital': {},
 'hotel': {},
 'attraction': {},
 'train': {},
 'message': ["You want to book a &lt;span class='emphasis'&gt;taxi&lt;/span&gt;. The taxi should go to &lt;span class='emphasis'&gt;pizza hut fen ditton&lt;/span&gt; and should depart from &lt;span class='emphasis'&gt;saint john's college&lt;/span&gt;",
  "The taxi should &lt;span class='emphasis'&gt;leave after 17:15&lt;/span&gt;",
  "Make sure you get &lt;span class='emphasis'&gt;car type&lt;/span&gt; and &lt;span class='emphasis'&gt;contact number&lt;/span&gt;"],
 'restaurant': {}}</code></pre>
</div>
</div>
<p>The <code>log</code> on the other hand contains the dialog. It is a list of dictionaries and each element of this list contains several descriptions as well. Let’s look at an example:</p>
<div class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb12" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><span class="co" style="color: #5E5E5E;"># get first element of the log list</span></span>
<span id="cb12-2">DIALOGUE_DB[<span class="st" style="color: #20794D;">'SNG0073.json'</span>][<span class="st" style="color: #20794D;">'log'</span>][<span class="dv" style="color: #AD0000;">0</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="8">
<pre><code>{'text': "I would like a taxi from Saint John's college to Pizza Hut Fen Ditton.",
 'metadata': {},
 'dialog_act': {'Taxi-Inform': [['Dest', 'pizza hut fen ditton'],
   ['Depart', "saint john 's college"]]},
 'span_info': [['Taxi-Inform', 'Dest', 'pizza hut fen ditton', 11, 14],
  ['Taxi-Inform', 'Depart', "saint john 's college", 6, 9]]}</code></pre>
</div>
</div>
<p>For this project, we are only interested in the conversation which is in the <code>text</code> field. The conversation goes back and forth between two persons. Let’s call them ‘Person 1’ and ‘Person 2’. This implies that data[‘SNG0073.json’][‘log’][0][‘text’] is ‘Person 1’ and data[‘SNG0073.json’][‘log’][1][‘text’] is ‘Person 2’ and so on. The even offsets are ‘Person 1’ and the odd offsets are ‘Person 2’.</p>
<div class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb14" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">' Person 1: '</span>, DIALOGUE_DB[<span class="st" style="color: #20794D;">'SNG0073.json'</span>][<span class="st" style="color: #20794D;">'log'</span>][<span class="dv" style="color: #AD0000;">0</span>][<span class="st" style="color: #20794D;">'text'</span>])</span>
<span id="cb14-2"><span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">' Person 2: '</span>,DIALOGUE_DB[<span class="st" style="color: #20794D;">'SNG0073.json'</span>][<span class="st" style="color: #20794D;">'log'</span>][<span class="dv" style="color: #AD0000;">1</span>][<span class="st" style="color: #20794D;">'text'</span>])</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code> Person 1:  I would like a taxi from Saint John's college to Pizza Hut Fen Ditton.
 Person 2:  What time do you want to leave and what time do you want to arrive by?</code></pre>
</div>
</div>
<section id="get_conversation" class="level3" data-number="2.1">
<h3 data-number="2.1" class="anchored" data-anchor-id="get_conversation"><span class="header-section-number">2.1</span> get_conversation</h3>
<p>We will now implement the <code>get_conversation()</code> function that will extract the conversations from the dataset’s file.</p>
<p>We will implement a function to extract conversations from the input file.<br>
As described above, the conversation is in the <code>text</code> field in each of the elements in the <code>log</code> list of the file. If the log list has <code>x</code> number of elements, then the function will get the <code>text</code> entries of each of those elements. Our function should return the conversation, prepending each field with either ’ Person 1: ’ if ‘x’ is even or ’ Person 2: ’ if ‘x’ is odd. We can use the Python modulus operator ‘%’ to help select the even/odd entries. Important note: Do not print a newline character (i.e.&nbsp;<code>\n</code>) when generating the string. For example, in the code cell above, your function should output something like:</p>
<pre><code> Person 1: I would like a taxi from Saint John's college to Pizza Hut Fen Ditton. Person 2: What time do you want to leave and what time do you want to arrive by?</code></pre>
<p>and <strong>not</strong>:</p>
<pre><code> Person 1:  I would like a taxi from Saint John's college to Pizza Hut Fen Ditton.
 Person 2:  What time do you want to leave and what time do you want to arrive by?</code></pre>
<div class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb18" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><span class="kw" style="color: #003B4F;">def</span> get_conversation(<span class="bu" style="color: null;">file</span>, data_db):</span>
<span id="cb18-2">    <span class="co" style="color: #5E5E5E;">'''</span></span>
<span id="cb18-3"><span class="co" style="color: #5E5E5E;">    Args:</span></span>
<span id="cb18-4"><span class="co" style="color: #5E5E5E;">        file (string): filename of the dialogue file saved as json</span></span>
<span id="cb18-5"><span class="co" style="color: #5E5E5E;">        data_db (dict): dialogue database</span></span>
<span id="cb18-6"><span class="co" style="color: #5E5E5E;">    </span></span>
<span id="cb18-7"><span class="co" style="color: #5E5E5E;">    Returns:</span></span>
<span id="cb18-8"><span class="co" style="color: #5E5E5E;">        string: A string containing the 'text' fields of  data[file]['log'][x]</span></span>
<span id="cb18-9"><span class="co" style="color: #5E5E5E;">    '''</span></span>
<span id="cb18-10">    </span>
<span id="cb18-11">    <span class="co" style="color: #5E5E5E;"># initialize empty string</span></span>
<span id="cb18-12">    result <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">''</span></span>
<span id="cb18-13">    </span>
<span id="cb18-14">    <span class="co" style="color: #5E5E5E;"># get length of file's log list</span></span>
<span id="cb18-15">    len_msg_log <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">len</span>(data_db[<span class="bu" style="color: null;">file</span>][<span class="st" style="color: #20794D;">'log'</span>])</span>
<span id="cb18-16">    </span>
<span id="cb18-17">    <span class="co" style="color: #5E5E5E;"># set the delimiter strings</span></span>
<span id="cb18-18">    delimiter_1 <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">' Person 1: '</span></span>
<span id="cb18-19">    delimiter_2 <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">' Person 2: '</span></span>
<span id="cb18-20">    </span>
<span id="cb18-21">    <span class="co" style="color: #5E5E5E;"># loop over the file's log list</span></span>
<span id="cb18-22">    <span class="cf" style="color: #003B4F;">for</span> i <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">range</span>(len_msg_log):</span>
<span id="cb18-23">    </span>
<span id="cb18-24">        <span class="co" style="color: #5E5E5E;"># get i'th element of file log list</span></span>
<span id="cb18-25">        cur_log <span class="op" style="color: #5E5E5E;">=</span> data_db[<span class="bu" style="color: null;">file</span>][<span class="st" style="color: #20794D;">'log'</span>][i]</span>
<span id="cb18-26">        </span>
<span id="cb18-27">        <span class="co" style="color: #5E5E5E;"># check if i is even</span></span>
<span id="cb18-28">        <span class="cf" style="color: #003B4F;">if</span> i<span class="op" style="color: #5E5E5E;">%</span><span class="dv" style="color: #AD0000;">2</span> <span class="op" style="color: #5E5E5E;">==</span> <span class="dv" style="color: #AD0000;">0</span>:                   </span>
<span id="cb18-29">            <span class="co" style="color: #5E5E5E;"># append the 1st delimiter string</span></span>
<span id="cb18-30">            result <span class="op" style="color: #5E5E5E;">+=</span> delimiter_1</span>
<span id="cb18-31">        <span class="cf" style="color: #003B4F;">else</span>: </span>
<span id="cb18-32">            <span class="co" style="color: #5E5E5E;"># append the 2nd delimiter string</span></span>
<span id="cb18-33">            result <span class="op" style="color: #5E5E5E;">+=</span> delimiter_2</span>
<span id="cb18-34">        </span>
<span id="cb18-35">        <span class="co" style="color: #5E5E5E;"># append the message text from the log</span></span>
<span id="cb18-36">        result <span class="op" style="color: #5E5E5E;">+=</span> cur_log[<span class="st" style="color: #20794D;">'text'</span>]</span>
<span id="cb18-37"></span>
<span id="cb18-38">    <span class="cf" style="color: #003B4F;">return</span> result</span></code></pre></div>
</div>
<div class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb19" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><span class="bu" style="color: null;">file</span> <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">'SNG01856.json'</span></span>
<span id="cb19-2">conversation <span class="op" style="color: #5E5E5E;">=</span> get_conversation(<span class="bu" style="color: null;">file</span>, DIALOGUE_DB)</span>
<span id="cb19-3"></span>
<span id="cb19-4"><span class="co" style="color: #5E5E5E;"># print raw output</span></span>
<span id="cb19-5"><span class="bu" style="color: null;">print</span>(conversation)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code> Person 1: am looking for a place to to stay that has cheap price range it should be in a type of hotel Person 2: Okay, do you have a specific area you want to stay in? Person 1: no, i just need to make sure it's cheap. oh, and i need parking Person 2: I found 1 cheap hotel for you that includes parking. Do you like me to book it? Person 1: Yes, please. 6 people 3 nights starting on tuesday. Person 2: I am sorry but I wasn't able to book that for you for Tuesday. Is there another day you would like to stay or perhaps a shorter stay? Person 1: how about only 2 nights. Person 2: Booking was successful.
Reference number is : 7GAWK763. Anything else I can do for you? Person 1: No, that will be all. Good bye. Person 2: Thank you for using our services.</code></pre>
</div>
</div>
<p>We can have a utility pretty print function just so we can visually follow the conversation more easily.</p>
<div class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb21" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><span class="kw" style="color: #003B4F;">def</span> print_conversation(conversation):</span>
<span id="cb21-2">    </span>
<span id="cb21-3">    delimiter_1 <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">'Person 1: '</span></span>
<span id="cb21-4">    delimiter_2 <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">'Person 2: '</span></span>
<span id="cb21-5">    </span>
<span id="cb21-6">    split_list_d1 <span class="op" style="color: #5E5E5E;">=</span> conversation.split(delimiter_1)</span>
<span id="cb21-7">    </span>
<span id="cb21-8">    <span class="cf" style="color: #003B4F;">for</span> sublist <span class="kw" style="color: #003B4F;">in</span> split_list_d1[<span class="dv" style="color: #AD0000;">1</span>:]:</span>
<span id="cb21-9">        split_list_d2 <span class="op" style="color: #5E5E5E;">=</span> sublist.split(delimiter_2)</span>
<span id="cb21-10">        <span class="bu" style="color: null;">print</span>(colored(<span class="ss" style="color: #20794D;">f'Person 1: </span><span class="sc" style="color: #5E5E5E;">{</span>split_list_d2[<span class="dv" style="color: #AD0000;">0</span>]<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">'</span>, <span class="st" style="color: #20794D;">'red'</span>))</span>
<span id="cb21-11">        </span>
<span id="cb21-12">        <span class="cf" style="color: #003B4F;">if</span> <span class="bu" style="color: null;">len</span>(split_list_d2) <span class="op" style="color: #5E5E5E;">&gt;</span> <span class="dv" style="color: #AD0000;">1</span>:</span>
<span id="cb21-13">            <span class="bu" style="color: null;">print</span>(colored(<span class="ss" style="color: #20794D;">f'Person 2: </span><span class="sc" style="color: #5E5E5E;">{</span>split_list_d2[<span class="dv" style="color: #AD0000;">1</span>]<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">'</span>, <span class="st" style="color: #20794D;">'green'</span>))</span>
<span id="cb21-14"></span>
<span id="cb21-15">            </span>
<span id="cb21-16">print_conversation(conversation)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Person 1: am looking for a place to to stay that has cheap price range it should be in a type of hotel 
Person 2: Okay, do you have a specific area you want to stay in? 
Person 1: no, i just need to make sure it's cheap. oh, and i need parking 
Person 2: I found 1 cheap hotel for you that includes parking. Do you like me to book it? 
Person 1: Yes, please. 6 people 3 nights starting on tuesday. 
Person 2: I am sorry but I wasn't able to book that for you for Tuesday. Is there another day you would like to stay or perhaps a shorter stay? 
Person 1: how about only 2 nights. 
Person 2: Booking was successful.
Reference number is : 7GAWK763. Anything else I can do for you? 
Person 1: No, that will be all. Good bye. 
Person 2: Thank you for using our services.</code></pre>
</div>
</div>
<p>For this project, we will just use the outputs of the calls to <code>get_conversation</code> to train the model. But just to expound, there is also other information in the MultiWoz dataset that can be useful in other contexts. Each element of the log list has more information about it. For example, above, if you were to look at the other fields for the following, “am looking for a place to stay that has cheap price range it should be in a type of hotel”, you will get the following.</p>
<div class="cell" data-outputid="8a2f4e3f-4516-449f-9648-a5970707cfc9" data-execution_count="14">
<div class="sourceCode cell-code" id="cb23" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1">DIALOGUE_DB[<span class="st" style="color: #20794D;">'SNG01856.json'</span>][<span class="st" style="color: #20794D;">'log'</span>][<span class="dv" style="color: #AD0000;">0</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="14">
<pre><code>{'text': 'am looking for a place to to stay that has cheap price range it should be in a type of hotel',
 'metadata': {},
 'dialog_act': {'Hotel-Inform': [['Type', 'hotel'], ['Price', 'cheap']]},
 'span_info': [['Hotel-Inform', 'Type', 'hotel', 20, 20],
  ['Hotel-Inform', 'Price', 'cheap', 10, 10]]}</code></pre>
</div>
</div>
<p>The dataset also comes with hotel, hospital, taxi, train, police, and restaurant databases. For example, in case you need to call a doctor, or a hotel, or a taxi, this will allow you to automate the entire conversation.</p>
<div class="cell" data-outputid="5730c55f-63da-42a8-935e-6eeb17f6f791" data-execution_count="15">
<div class="sourceCode cell-code" id="cb25" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><span class="co" style="color: #5E5E5E;"># this is an example of the attractions file</span></span>
<span id="cb25-2">attraction_file <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">open</span>(<span class="st" style="color: #20794D;">'data/attraction_db.json'</span>)</span>
<span id="cb25-3">attractions <span class="op" style="color: #5E5E5E;">=</span> json.load(attraction_file)</span>
<span id="cb25-4"><span class="bu" style="color: null;">print</span>(attractions[<span class="dv" style="color: #AD0000;">0</span>])</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>{'address': 'pool way, whitehill road, off newmarket road', 'area': 'east', 'entrance fee': '?', 'id': '1', 'location': [52.208789, 0.154883], 'name': 'abbey pool and astroturf pitch', 'openhours': '?', 'phone': '01223902088', 'postcode': 'cb58nt', 'pricerange': '?', 'type': 'swimmingpool'}</code></pre>
</div>
</div>
<div class="cell" data-outputid="3dacc4ff-4f05-4ae6-d099-33d1b3a6fa2a" data-execution_count="16">
<div class="sourceCode cell-code" id="cb27" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><span class="co" style="color: #5E5E5E;"># this is an example of the hospital file</span></span>
<span id="cb27-2">hospital_file <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">open</span>(<span class="st" style="color: #20794D;">'data/hospital_db.json'</span>)</span>
<span id="cb27-3">hospitals <span class="op" style="color: #5E5E5E;">=</span> json.load(hospital_file)</span>
<span id="cb27-4"><span class="bu" style="color: null;">print</span>(hospitals[<span class="dv" style="color: #AD0000;">0</span>]) <span class="co" style="color: #5E5E5E;"># feel free to index into other indices</span></span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>{'department': 'neurosciences critical care unit', 'id': 0, 'phone': '01223216297'}</code></pre>
</div>
</div>
<div class="cell" data-outputid="ee0110c2-b2c2-4584-bd42-21f75109a579" data-execution_count="17">
<div class="sourceCode cell-code" id="cb29" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><span class="co" style="color: #5E5E5E;"># this is an example of the hotel file</span></span>
<span id="cb29-2">hotel_file <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">open</span>(<span class="st" style="color: #20794D;">'data/hotel_db.json'</span>)</span>
<span id="cb29-3">hotels <span class="op" style="color: #5E5E5E;">=</span> json.load(hotel_file)</span>
<span id="cb29-4"><span class="bu" style="color: null;">print</span>(hotels[<span class="dv" style="color: #AD0000;">0</span>]) <span class="co" style="color: #5E5E5E;"># feel free to index into other indices</span></span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>{'address': '124 tenison road', 'area': 'east', 'internet': 'yes', 'parking': 'no', 'id': '0', 'location': [52.1963733, 0.1987426], 'name': 'a and b guest house', 'phone': '01223315702', 'postcode': 'cb12dp', 'price': {'double': '70', 'family': '90', 'single': '50'}, 'pricerange': 'moderate', 'stars': '4', 'takesbookings': 'yes', 'type': 'guesthouse'}</code></pre>
</div>
</div>
<div class="cell" data-outputid="8977e17e-2fc3-4073-abb8-fcf5cef3cfaf" data-execution_count="18">
<div class="sourceCode cell-code" id="cb31" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><span class="co" style="color: #5E5E5E;"># this is an example of the police file</span></span>
<span id="cb31-2">police_file <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">open</span>(<span class="st" style="color: #20794D;">'data/police_db.json'</span>)</span>
<span id="cb31-3">police <span class="op" style="color: #5E5E5E;">=</span> json.load(police_file)</span>
<span id="cb31-4"><span class="bu" style="color: null;">print</span>(police[<span class="dv" style="color: #AD0000;">0</span>]) <span class="co" style="color: #5E5E5E;"># feel free to index into other indices</span></span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>{'name': 'Parkside Police Station', 'address': 'Parkside, Cambridge', 'id': 0, 'phone': '01223358966'}</code></pre>
</div>
</div>
<div class="cell" data-outputid="1dba6598-b9b6-4fc8-91d2-f844b98e45fa" data-execution_count="19">
<div class="sourceCode cell-code" id="cb33" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><span class="co" style="color: #5E5E5E;"># this is an example of a restaurant file</span></span>
<span id="cb33-2">restaurant_file <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">open</span>(<span class="st" style="color: #20794D;">'data/restaurant_db.json'</span>)</span>
<span id="cb33-3">restaurants <span class="op" style="color: #5E5E5E;">=</span> json.load(restaurant_file)</span>
<span id="cb33-4"><span class="bu" style="color: null;">print</span>(restaurants[<span class="dv" style="color: #AD0000;">0</span>]) <span class="co" style="color: #5E5E5E;"># feel free to index into other indices</span></span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>{'address': 'Regent Street City Centre', 'area': 'centre', 'food': 'italian', 'id': '19210', 'introduction': 'Pizza hut is a large chain with restaurants nationwide offering convenience pizzas pasta and salads to eat in or take away', 'location': [52.20103, 0.126023], 'name': 'pizza hut city centre', 'phone': '01223323737', 'postcode': 'cb21ab', 'pricerange': 'cheap', 'type': 'restaurant'}</code></pre>
</div>
</div>
<p>For more information about the multiwoz 2.1 data set, please run the cell below to read the <code>ReadMe.txt</code> file.</p>
<div class="cell" data-outputid="aa039a49-3ed3-4f4d-fa4f-c2619de3dc99" data-execution_count="20">
<div class="sourceCode cell-code" id="cb35" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><span class="cf" style="color: #003B4F;">with</span> <span class="bu" style="color: null;">open</span>(<span class="st" style="color: #20794D;">'data/README'</span>) <span class="im" style="color: #00769E;">as</span> <span class="bu" style="color: null;">file</span>:</span>
<span id="cb35-2">    <span class="bu" style="color: null;">print</span>(<span class="bu" style="color: null;">file</span>.read())</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>#####################################################
#####################################################
#  Copyright Cambridge Dialogue Systems Group, 2018 #
#####################################################
#####################################################

Dataset contains the following files:
1. data.json: the woz dialogue dataset, which contains the conversation  users and wizards, as well as a set of coarse labels for each user turn. This file contains both system and user dialogue acts annotated at the turn level. Files with multi-domain dialogues have "MUL" in their names. Single domain dialogues have either "SNG" or "WOZ" in their names.
2. restaurant_db.json: the Cambridge restaurant database file, containing restaurants in the Cambridge UK area and a set of attributes.
3. attraction_db.json: the Cambridge attraction database file, contining attractions in the Cambridge UK area and a set of attributes.
4. hotel_db.json: the Cambridge hotel database file, containing hotels in the Cambridge UK area and a set of attributes.
5. train_db.json: the Cambridge train (with artificial connections) database file, containing trains in the Cambridge UK area and a set of attributes.
6. hospital_db.json: the Cambridge hospital database file, contatining information about departments.
7. police_db.json: the Cambridge police station information.
8. taxi_db.json: slot-value list for taxi domain.
9. valListFile.txt: list of dialogues for validation.
10. testListFile.txt: list of dialogues for testing.
11. system_acts.json:
  There are 6 domains ('Booking', 'Restaurant', 'Hotel', 'Attraction', 'Taxi', 'Train') and 1 dummy domain ('general').
  A domain-dependent dialogue act is defined as a domain token followed by a domain-independent dialogue act, e.g. 'Hotel-inform' means it is an 'inform' act in the Hotel domain.
  Dialogue acts which cannot take slots, e.g., 'good bye', are defined under the 'general' domain.
  A slot-value pair defined as a list with two elements. The first element is slot token and the second one is its value.
  If a dialogue act takes no slots, e.g., dialogue act 'offer booking' for an utterance 'would you like to take a reservation?', its slot-value pair is ['none', 'none']
  There are four types of values:
  1) If a slot takes a binary value, e.g., 'has Internet' or 'has park', the value is either 'yes' or 'no'.
  2) If a slot is under the act 'request', e.g., 'request' about 'area', the value is expressed as '?'.
  3) The value that appears in the utterance e.g., the name of a restaurant.
  4) If for some reason the turn does not have an annotation then it is labeled as "No Annotation."
12. ontology.json: Data-based ontology containing all the values for the different slots in the domains.
13. slot_descriptions.json: A collection of human-written slot descriptions for each slot in the dataset. Each slot has at least two descriptions.
14. tokenization.md: A description of the tokenization preprocessing we had to perform to maintain consistency between the dialogue act annotations of DSTC 8 Track 1 and the existing MultiWOZ 2.0 data. 
</code></pre>
</div>
</div>
<p>As we can see, there are many other aspects of the MultiWoz dataset. Nonetheless, we’ll see that even with just the conversations, our model will still be able to generate useful responses. This concludes our exploration of the dataset. In the next section, we will do some preprocessing before we feed it into our model for training.</p>
</section>
</section>
<section id="processing-the-data-for-reformer-inputs" class="level2" data-number="3">
<h2 data-number="3" class="anchored" data-anchor-id="processing-the-data-for-reformer-inputs"><span class="header-section-number">3</span> Processing the Data for Reformer Inputs</h2>
<p>We will now use the <code>get_conversation()</code> function to process the data. The Reformer expects inputs of this form:</p>
<p><strong>Person 1: Why am I so happy? Person 2: Because you are learning NLP Person 1: … Person 2: …</strong>*</p>
<p>And the conversation keeps going with some text. As we can see ‘Person 1’ and ‘Person 2’ act as delimiters so the model automatically recognizes the person and who is talking. It can then come up with the corresponding text responses for each person. Let’s proceed to process the text in this fashion for the Reformer. First, let’s grab all the conversation strings from all dialogue files and put them in a list.</p>
<div class="cell" data-outputid="2b159dae-78be-4a19-df41-b9e620216d43" data-execution_count="21">
<div class="sourceCode cell-code" id="cb37" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb37-1"><span class="co" style="color: #5E5E5E;"># the keys are the file names</span></span>
<span id="cb37-2">all_files <span class="op" style="color: #5E5E5E;">=</span> DIALOGUE_DB.keys()</span>
<span id="cb37-3"></span>
<span id="cb37-4"><span class="co" style="color: #5E5E5E;"># initialize empty list</span></span>
<span id="cb37-5">untokenized_data <span class="op" style="color: #5E5E5E;">=</span> []</span>
<span id="cb37-6"></span>
<span id="cb37-7"><span class="co" style="color: #5E5E5E;"># loop over all files</span></span>
<span id="cb37-8"><span class="cf" style="color: #003B4F;">for</span> <span class="bu" style="color: null;">file</span> <span class="kw" style="color: #003B4F;">in</span> all_files:</span>
<span id="cb37-9">    <span class="co" style="color: #5E5E5E;"># this is the graded function you coded</span></span>
<span id="cb37-10">    <span class="co" style="color: #5E5E5E;"># returns a string delimited by Person 1 and Person 2</span></span>
<span id="cb37-11">    result <span class="op" style="color: #5E5E5E;">=</span> get_conversation(<span class="bu" style="color: null;">file</span>, DIALOGUE_DB)</span>
<span id="cb37-12">    </span>
<span id="cb37-13">    <span class="co" style="color: #5E5E5E;"># append to the list</span></span>
<span id="cb37-14">    untokenized_data.append(result)</span>
<span id="cb37-15"></span>
<span id="cb37-16"><span class="co" style="color: #5E5E5E;"># print the first element to check if it's the same as the one we got before</span></span>
<span id="cb37-17"><span class="bu" style="color: null;">print</span>(untokenized_data[<span class="dv" style="color: #AD0000;">0</span>])</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code> Person 1: am looking for a place to to stay that has cheap price range it should be in a type of hotel Person 2: Okay, do you have a specific area you want to stay in? Person 1: no, i just need to make sure it's cheap. oh, and i need parking Person 2: I found 1 cheap hotel for you that includes parking. Do you like me to book it? Person 1: Yes, please. 6 people 3 nights starting on tuesday. Person 2: I am sorry but I wasn't able to book that for you for Tuesday. Is there another day you would like to stay or perhaps a shorter stay? Person 1: how about only 2 nights. Person 2: Booking was successful.
Reference number is : 7GAWK763. Anything else I can do for you? Person 1: No, that will be all. Good bye. Person 2: Thank you for using our services.</code></pre>
</div>
</div>
<p>Now let us split the list to a train and eval dataset.</p>
<div class="cell" data-outputid="cb73a95b-488b-4d1d-9c20-5e98ca71f9d5" data-execution_count="22">
<div class="sourceCode cell-code" id="cb39" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1"><span class="co" style="color: #5E5E5E;"># shuffle the list we generated above</span></span>
<span id="cb39-2">random.shuffle(untokenized_data)</span>
<span id="cb39-3"></span>
<span id="cb39-4"><span class="co" style="color: #5E5E5E;"># define a cutoff (5% of the total length for this assignment)</span></span>
<span id="cb39-5"><span class="co" style="color: #5E5E5E;"># convert to int because we will use it as a list index</span></span>
<span id="cb39-6">cut_off <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">int</span>(<span class="bu" style="color: null;">len</span>(untokenized_data) <span class="op" style="color: #5E5E5E;">*</span> <span class="fl" style="color: #AD0000;">.05</span>)</span>
<span id="cb39-7"></span>
<span id="cb39-8"><span class="co" style="color: #5E5E5E;"># slice the list. the last elements after the cut_off value will be the eval set. the rest is for training. </span></span>
<span id="cb39-9">train_data, eval_data <span class="op" style="color: #5E5E5E;">=</span> untokenized_data[:<span class="op" style="color: #5E5E5E;">-</span>cut_off], untokenized_data[<span class="op" style="color: #5E5E5E;">-</span>cut_off:]</span>
<span id="cb39-10"></span>
<span id="cb39-11"><span class="bu" style="color: null;">print</span>(<span class="ss" style="color: #20794D;">f'number of conversations in the data set: </span><span class="sc" style="color: #5E5E5E;">{</span><span class="bu" style="color: null;">len</span>(untokenized_data)<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">'</span>)</span>
<span id="cb39-12"><span class="bu" style="color: null;">print</span>(<span class="ss" style="color: #20794D;">f'number of conversations in train set: </span><span class="sc" style="color: #5E5E5E;">{</span><span class="bu" style="color: null;">len</span>(train_data)<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">'</span>)</span>
<span id="cb39-13"><span class="bu" style="color: null;">print</span>(<span class="ss" style="color: #20794D;">f'number of conversations in eval set: </span><span class="sc" style="color: #5E5E5E;">{</span><span class="bu" style="color: null;">len</span>(eval_data)<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">'</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>number of conversations in the data set: 10438
number of conversations in train set: 9917
number of conversations in eval set: 521</code></pre>
</div>
</div>
<section id="tokenizing-batching-with-bucketing" class="level3" data-number="3.1">
<h3 data-number="3.1" class="anchored" data-anchor-id="tokenizing-batching-with-bucketing"><span class="header-section-number">3.1</span> Tokenizing, Batching with Bucketing</h3>
<p>We can now proceed in generating tokenized batches of our data. Let’s first define a utility generator function to yield elements from our data sets:</p>
<div class="cell" data-execution_count="23">
<div class="sourceCode cell-code" id="cb41" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1"><span class="kw" style="color: #003B4F;">def</span> stream(data):</span>
<span id="cb41-2">    <span class="co" style="color: #5E5E5E;"># loop over the entire data</span></span>
<span id="cb41-3">    <span class="cf" style="color: #003B4F;">while</span> <span class="va" style="color: #111111;">True</span>:</span>
<span id="cb41-4">        <span class="co" style="color: #5E5E5E;"># get a random element</span></span>
<span id="cb41-5">        d <span class="op" style="color: #5E5E5E;">=</span> random.choice(data)</span>
<span id="cb41-6">        </span>
<span id="cb41-7">        <span class="co" style="color: #5E5E5E;"># yield a tuple pair of identical values </span></span>
<span id="cb41-8">        <span class="co" style="color: #5E5E5E;"># (i.e. our inputs to the model will also be our targets during training)</span></span>
<span id="cb41-9">        <span class="cf" style="color: #003B4F;">yield</span> (d, d)</span></code></pre></div>
</div>
<p>Now let’s define our data pipeline for tokenizing and batching our data. We will bucket by length and also have an upper bound on the token length.</p>
<div class="cell" data-execution_count="24">
<div class="sourceCode cell-code" id="cb42" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb42-1"><span class="co" style="color: #5E5E5E;"># trax allows us to use combinators to generate our data pipeline</span></span>
<span id="cb42-2">data_pipeline <span class="op" style="color: #5E5E5E;">=</span> trax.data.Serial(</span>
<span id="cb42-3">    <span class="co" style="color: #5E5E5E;"># randomize the stream</span></span>
<span id="cb42-4">    trax.data.Shuffle(),</span>
<span id="cb42-5">    </span>
<span id="cb42-6">    <span class="co" style="color: #5E5E5E;"># tokenize the data</span></span>
<span id="cb42-7">    trax.data.Tokenize(vocab_dir<span class="op" style="color: #5E5E5E;">=</span>VOCAB_DIR,</span>
<span id="cb42-8">                       vocab_file<span class="op" style="color: #5E5E5E;">=</span>VOCAB_FILE),</span>
<span id="cb42-9">    </span>
<span id="cb42-10">    <span class="co" style="color: #5E5E5E;"># filter too long sequences</span></span>
<span id="cb42-11">    trax.data.FilterByLength(<span class="dv" style="color: #AD0000;">2048</span>),</span>
<span id="cb42-12">    </span>
<span id="cb42-13">    <span class="co" style="color: #5E5E5E;"># bucket by length</span></span>
<span id="cb42-14">    trax.data.BucketByLength(boundaries<span class="op" style="color: #5E5E5E;">=</span>[<span class="dv" style="color: #AD0000;">128</span>, <span class="dv" style="color: #AD0000;">256</span>,  <span class="dv" style="color: #AD0000;">512</span>, <span class="dv" style="color: #AD0000;">1024</span>],</span>
<span id="cb42-15">                             batch_sizes<span class="op" style="color: #5E5E5E;">=</span>[<span class="dv" style="color: #AD0000;">16</span>,    <span class="dv" style="color: #AD0000;">8</span>,    <span class="dv" style="color: #AD0000;">4</span>,   <span class="dv" style="color: #AD0000;">2</span>, <span class="dv" style="color: #AD0000;">1</span>]),</span>
<span id="cb42-16">    </span>
<span id="cb42-17">    <span class="co" style="color: #5E5E5E;"># add loss weights but do not add it to the padding tokens (i.e. 0)</span></span>
<span id="cb42-18">    trax.data.AddLossWeights(id_to_mask<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">0</span>)</span>
<span id="cb42-19">)</span>
<span id="cb42-20"></span>
<span id="cb42-21"><span class="co" style="color: #5E5E5E;"># apply the data pipeline to our train and eval sets</span></span>
<span id="cb42-22">train_stream <span class="op" style="color: #5E5E5E;">=</span> data_pipeline(stream(train_data))</span>
<span id="cb42-23">eval_stream <span class="op" style="color: #5E5E5E;">=</span> data_pipeline(stream(eval_data))</span></code></pre></div>
</div>
<p>Peek into the train stream.</p>
<div class="cell" data-outputid="78659fd2-4633-47bc-ebe8-3ae3a6e2eab3" data-execution_count="25">
<div class="sourceCode cell-code" id="cb43" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb43-1"><span class="co" style="color: #5E5E5E;"># the stream generators will yield (input, target, weights). let's just grab the input for inspection</span></span>
<span id="cb43-2">inp, _, _ <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">next</span>(train_stream)</span>
<span id="cb43-3"></span>
<span id="cb43-4"><span class="co" style="color: #5E5E5E;"># print the shape. format is (batch size, token length)</span></span>
<span id="cb43-5"><span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">"input shape: "</span>, inp.shape)</span>
<span id="cb43-6"></span>
<span id="cb43-7"><span class="co" style="color: #5E5E5E;"># detokenize the first element</span></span>
<span id="cb43-8"><span class="bu" style="color: null;">print</span>(trax.data.detokenize(inp[<span class="dv" style="color: #AD0000;">0</span>], vocab_dir<span class="op" style="color: #5E5E5E;">=</span>VOCAB_DIR, vocab_file<span class="op" style="color: #5E5E5E;">=</span>VOCAB_FILE))</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>input shape:  (4, 512)
 Person 1: Hello- I would like some information about visiting Corpus Christi please Person 2: Corpus christi is a college located in the centre of town. The phone number is 01223338000 and is located at king's parade.  Person 1: Can I have the post code please? Person 2: The postcode is cb21rh. Person 1: Is there an entrance fee? Person 2: the admission is 2 pounds. Person 1: Can you also find me a place to stay in the centre? Person 2: There are several places that are located in the same area, can you give me some more preferences? Person 1: I'd like a moderately priced hotel with free wifi and parking. Person 2: I have 4 available hotels in the centre. Two of them have a cheap price range, and two have an expensive range. Would one of these do? Person 1: I'm looking for a moderate priced hotel for 6 people and 5 nights from Sunday.  Person 2: I'm sorry, I'm not pulling up any matches.  Person 1: Okay, how about a moderately-priced hotel in the south area instead that has free wifi and free parking? Person 2: I have two guesthouses that match your request; the Aylesbray Lodge and Bridge Guesthouse. Aylesbray has 4 stars and Bridge Guesthouse has 3. Which would you prefer? Person 1: Aylesbray sounds good. I need a booking for six, five nights starting from sunday. Person 2: Booking was successful reference number is GS1J7NYI. Is there anything else I can help you with today? Person 1: That is all I need today, thank you for your help.  Person 2: You are welcome, have a blessed day.</code></pre>
</div>
</div>
</section>
</section>
<section id="reversible-layers" class="level2" data-number="4">
<h2 data-number="4" class="anchored" data-anchor-id="reversible-layers"><span class="header-section-number">4</span> Reversible Layers</h2>
<p>When running large deep models, you will often run out of memory as each layer allocates memory to store activations for use in backpropagation. To save this resource, we need to be able to recompute these activations during the backward pass without storing them during the forward pass. Lets take a look first at the leftmost diagram below.</p>
<p><img src="http://livingdatalab.com/posts/https:/github.com/pranath/blog/raw/master/images/reversible2.png" height="400" width="600"></p>
<dl>
<dt>This is how the residual networks are implemented in the standard Transformer. It follows that, given <code>F()</code> is Attention and <code>G()</code> is Feed-forward(FF).</dt>
<dd>

</dd>
</dl>
<p><img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Balign%7D%20%20%0A%5Cmathrm%7By%7D_%5Cmathrm%7Ba%7D%20&amp;=%20%5Cmathrm%7Bx%7D%20+%20%5Cmathrm%7BF%7D%5Cleft(%5Cmathrm%7Bx%7D%5Cright)%5Ctag%7B1%7D%20%5C%5C%0A%5Cmathrm%7By%7D_%7Bb%7D&amp;=%5Cmathrm%7By%7D_%7Ba%7D+%5Cmathrm%7BG%7D%5Cleft(%5Cmathrm%7By%7D_%7Ba%7D%5Cright)%5Ctag%7B2%7D%5C%5C%0A%5Cend%7Balign%7D"></p>
<p>As we can see, it requires that <img src="https://latex.codecogs.com/png.latex?%5Cmathrm%7Bx%7D"> and <img src="https://latex.codecogs.com/png.latex?%5Cmathrm%7By%7D_%7Ba%7D"> be saved so it can be used during backpropagation. We want to avoid this to conserve memory and this is where reversible residual connections come in. They are shown in the middle and rightmost diagrams above. The key idea is that we will start with two copies of the input to the model and at each layer we will only update one of them. The activations that we <em>don’t</em> update are the ones that will be used to compute the residuals.</p>
<p>Now in this reversible set up you get the following instead:</p>
<p><img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Balign%7D%20%20%0A%5Cmathrm%7By%7D_%7B1%7D&amp;=%5Cmathrm%7Bx%7D_%7B1%7D+%5Cmathrm%7BF%7D%5Cleft(%5Cmathrm%7Bx%7D_%7B2%7D%5Cright)%5Ctag%7B3%7D%5C%5C%0A%5Cmathrm%7By%7D_%7B2%7D&amp;=%5Cmathrm%7Bx%7D_%7B2%7D+%5Cmathrm%7BG%7D%5Cleft(%5Cmathrm%7By%7D_%7B1%7D%5Cright)%5Ctag%7B4%7D%5C%5C%0A%5Cend%7Balign%7D"> To recover <img src="https://latex.codecogs.com/png.latex?%5Cmathrm%7B(x_1,x_2)%7D"> from <img src="https://latex.codecogs.com/png.latex?%5Cmathrm%7B(y_1,%20y_2)%7D"></p>
<p><img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Balign%7D%20%20%0A%5Cmathrm%7Bx%7D_%7B2%7D&amp;=%5Cmathrm%7By%7D_%7B2%7D-%5Cmathrm%7BG%7D%5Cleft(%5Cmathrm%7By%7D_%7B1%7D%5Cright)%5Ctag%7B5%7D%5C%5C%0A%5Cmathrm%7Bx%7D_%7B1%7D&amp;=%5Cmathrm%7By%7D_%7B1%7D-%5Cmathrm%7BF%7D%5Cleft(%5Cmathrm%7Bx%7D_%7B2%7D%5Cright)%5Ctag%7B6%7D%5C%5C%0A%5Cend%7Balign%7D"></p>
<p>With this configuration, we’re now able to run the network fully in reverse. You’ll notice that during the backward pass, <img src="https://latex.codecogs.com/png.latex?%5Cmathrm%7Bx2%7D"> and <img src="https://latex.codecogs.com/png.latex?%5Cmathrm%7Bx1%7D"> can be recomputed based solely on the values of <img src="https://latex.codecogs.com/png.latex?%5Cmathrm%7By2%7D"> and <img src="https://latex.codecogs.com/png.latex?%5Cmathrm%7By1%7D">. No need to save it during the forward pass.</p>
<p>We will implement the <code>reversible_layer_forward</code> function using equations 3 and 4 above. This function takes in the input vector <code>x</code> and the functions <code>f</code> and <code>g</code> and returns the concatenation of <img src="https://latex.codecogs.com/png.latex?y_1%20and%20y_2">. For this, we will be splitting <code>x</code> before going through the reversible residual steps<img src="https://latex.codecogs.com/png.latex?%5Cmathrm%7B%5E1%7D">. We can then use those two vectors for the <code>reversible_layer_reverse</code> function. Utilize <code>np.concatenate()</code> to form the output being careful to match the axis of the <code>np.split()</code>.</p>
<p><img src="https://latex.codecogs.com/png.latex?%5Cmathrm%7B%5E1%7D"><em>Take note that this is just for demonstrating the concept in this exercise and there are other ways of processing the input. As we’ll see in the Reformer architecture later, the initial input (i.e.&nbsp;<code>x</code>) can instead be duplicated instead of split.</em></p>
<div class="cell" data-execution_count="26">
<div class="sourceCode cell-code" id="cb45" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb45-1"><span class="kw" style="color: #003B4F;">def</span> reversible_layer_forward(x, f, g):</span>
<span id="cb45-2">    <span class="co" style="color: #5E5E5E;">"""</span></span>
<span id="cb45-3"><span class="co" style="color: #5E5E5E;">    Args: </span></span>
<span id="cb45-4"><span class="co" style="color: #5E5E5E;">        x (np.array): an input vector or matrix</span></span>
<span id="cb45-5"><span class="co" style="color: #5E5E5E;">        f (function): a function which operates on a vector/matrix</span></span>
<span id="cb45-6"><span class="co" style="color: #5E5E5E;">        g (function): a function which operates on a vector/matrix</span></span>
<span id="cb45-7"><span class="co" style="color: #5E5E5E;">    Returns: </span></span>
<span id="cb45-8"><span class="co" style="color: #5E5E5E;">        y (np.array): an output vector or matrix whose form is determined by 'x', f and g</span></span>
<span id="cb45-9"><span class="co" style="color: #5E5E5E;">    """</span></span>
<span id="cb45-10">    <span class="co" style="color: #5E5E5E;"># split the input vector into two (* along the last axis because it is the depth dimension)</span></span>
<span id="cb45-11">    x1, x2 <span class="op" style="color: #5E5E5E;">=</span> np.split(x, <span class="dv" style="color: #AD0000;">2</span>, axis<span class="op" style="color: #5E5E5E;">=-</span><span class="dv" style="color: #AD0000;">1</span>) </span>
<span id="cb45-12">        </span>
<span id="cb45-13">    <span class="co" style="color: #5E5E5E;"># get y1 using equation 3</span></span>
<span id="cb45-14">    y1 <span class="op" style="color: #5E5E5E;">=</span> x1 <span class="op" style="color: #5E5E5E;">+</span> f(x2)</span>
<span id="cb45-15">    </span>
<span id="cb45-16">    <span class="co" style="color: #5E5E5E;"># get y2 using equation 4</span></span>
<span id="cb45-17">    y2 <span class="op" style="color: #5E5E5E;">=</span> x2 <span class="op" style="color: #5E5E5E;">+</span> g(y1)</span>
<span id="cb45-18">    </span>
<span id="cb45-19">    <span class="co" style="color: #5E5E5E;"># concatenate y1 and y2 along the depth dimension. be sure output is of type np.ndarray</span></span>
<span id="cb45-20">    y <span class="op" style="color: #5E5E5E;">=</span> np.concatenate([y1, y2], axis<span class="op" style="color: #5E5E5E;">=-</span><span class="dv" style="color: #AD0000;">1</span>)</span>
<span id="cb45-21">    </span>
<span id="cb45-22">    <span class="cf" style="color: #003B4F;">return</span> y</span></code></pre></div>
</div>
<section id="reversible_layer_reverse" class="level3" data-number="4.1">
<h3 data-number="4.1" class="anchored" data-anchor-id="reversible_layer_reverse"><span class="header-section-number">4.1</span> reversible_layer_reverse</h3>
<p>We will now implement the <code>reversible_layer_reverse</code> function which is possible because at every time step you have <img src="https://latex.codecogs.com/png.latex?x_1"> and <img src="https://latex.codecogs.com/png.latex?x_2"> and <img src="https://latex.codecogs.com/png.latex?y_2"> and <img src="https://latex.codecogs.com/png.latex?y_1">, along with the function <code>f</code>, and <code>g</code>. Where <code>f</code> is the attention and <code>g</code> is the feedforward. This allows you to compute equations 5 and 6.</p>
<p>We will now implement the <code>reversible_layer_reverse</code>. Our function takes in the output vector from <code>reversible_layer_forward</code> and functions f and g. Using equations 5 and 6 above, it computes the inputs to the layer, <img src="https://latex.codecogs.com/png.latex?x_1"> and <img src="https://latex.codecogs.com/png.latex?x_2">. The output, x, is the concatenation of <img src="https://latex.codecogs.com/png.latex?x_1,%20x_2">. Utilize <code>np.concatenate()</code> to form the output being careful to match the axis of the <code>np.split()</code>.</p>
<div class="cell" data-execution_count="28">
<div class="sourceCode cell-code" id="cb46" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb46-1"><span class="kw" style="color: #003B4F;">def</span> reversible_layer_reverse(y, f, g):</span>
<span id="cb46-2">    <span class="co" style="color: #5E5E5E;">"""</span></span>
<span id="cb46-3"><span class="co" style="color: #5E5E5E;">    Args: </span></span>
<span id="cb46-4"><span class="co" style="color: #5E5E5E;">        y (np.array): an input vector or matrix</span></span>
<span id="cb46-5"><span class="co" style="color: #5E5E5E;">        f (function): a function which operates on a vector/matrix of the form of 'y'</span></span>
<span id="cb46-6"><span class="co" style="color: #5E5E5E;">        g (function): a function which operates on a vector/matrix of the form of 'y'</span></span>
<span id="cb46-7"><span class="co" style="color: #5E5E5E;">    Returns: </span></span>
<span id="cb46-8"><span class="co" style="color: #5E5E5E;">        y (np.array): an output vector or matrix whose form is determined by 'y', f and g</span></span>
<span id="cb46-9"><span class="co" style="color: #5E5E5E;">    """</span></span>
<span id="cb46-10">    </span>
<span id="cb46-11">    <span class="co" style="color: #5E5E5E;"># split the input vector into two (* along the last axis because it is the depth dimension)</span></span>
<span id="cb46-12">    y1, y2 <span class="op" style="color: #5E5E5E;">=</span> np.split(y, <span class="dv" style="color: #AD0000;">2</span>, axis<span class="op" style="color: #5E5E5E;">=-</span><span class="dv" style="color: #AD0000;">1</span>)</span>
<span id="cb46-13">        </span>
<span id="cb46-14">    <span class="co" style="color: #5E5E5E;"># compute x2 using equation 5</span></span>
<span id="cb46-15">    x2 <span class="op" style="color: #5E5E5E;">=</span> y2 <span class="op" style="color: #5E5E5E;">-</span> g(y1)</span>
<span id="cb46-16">    </span>
<span id="cb46-17">    <span class="co" style="color: #5E5E5E;"># compute x1 using equation 6</span></span>
<span id="cb46-18">    x1 <span class="op" style="color: #5E5E5E;">=</span> y1 <span class="op" style="color: #5E5E5E;">-</span> f(x2)</span>
<span id="cb46-19">    </span>
<span id="cb46-20">    <span class="co" style="color: #5E5E5E;"># concatenate x1 and x2 along the depth dimension</span></span>
<span id="cb46-21">    x <span class="op" style="color: #5E5E5E;">=</span> np.concatenate([x1, x2], axis<span class="op" style="color: #5E5E5E;">=-</span><span class="dv" style="color: #AD0000;">1</span>)</span>
<span id="cb46-22">    </span>
<span id="cb46-23">    <span class="cf" style="color: #003B4F;">return</span> x</span></code></pre></div>
</div>
<div class="cell" data-execution_count="29">
<div class="sourceCode cell-code" id="cb47" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb47-1"><span class="co" style="color: #5E5E5E;"># UNIT </span><span class="al" style="color: #AD0000;">TEST</span></span>
<span id="cb47-2">f <span class="op" style="color: #5E5E5E;">=</span> <span class="kw" style="color: #003B4F;">lambda</span> x: x <span class="op" style="color: #5E5E5E;">+</span> <span class="dv" style="color: #AD0000;">2</span></span>
<span id="cb47-3">g <span class="op" style="color: #5E5E5E;">=</span> <span class="kw" style="color: #003B4F;">lambda</span> x: x <span class="op" style="color: #5E5E5E;">*</span> <span class="dv" style="color: #AD0000;">3</span></span>
<span id="cb47-4">input_vector <span class="op" style="color: #5E5E5E;">=</span> np.random.uniform(size<span class="op" style="color: #5E5E5E;">=</span>(<span class="dv" style="color: #AD0000;">32</span>,))</span>
<span id="cb47-5"></span>
<span id="cb47-6">output_vector <span class="op" style="color: #5E5E5E;">=</span> reversible_layer_forward(input_vector, f, g)</span>
<span id="cb47-7">reversed_vector <span class="op" style="color: #5E5E5E;">=</span> reversible_layer_reverse(output_vector, f, g)</span>
<span id="cb47-8"></span>
<span id="cb47-9"><span class="cf" style="color: #003B4F;">assert</span> np.allclose(reversed_vector, input_vector)</span></code></pre></div>
</div>
</section>
<section id="reversible-layers-and-randomness" class="level3" data-number="4.2">
<h3 data-number="4.2" class="anchored" data-anchor-id="reversible-layers-and-randomness"><span class="header-section-number">4.2</span> Reversible Layers and Randomness</h3>
<p>Utilizing the same key, <code>trax.fastmath.random.uniform()</code> will return the same values. This is required for the backward pass to return the correct layer inputs when random noise is introduced in the layer.</p>
<div class="cell" data-execution_count="31">
<div class="sourceCode cell-code" id="cb48" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb48-1"><span class="co" style="color: #5E5E5E;"># Layers like dropout have noise, so let's simulate it here:</span></span>
<span id="cb48-2">f <span class="op" style="color: #5E5E5E;">=</span> <span class="kw" style="color: #003B4F;">lambda</span> x: x <span class="op" style="color: #5E5E5E;">+</span> np.random.uniform(size<span class="op" style="color: #5E5E5E;">=</span>x.shape)</span>
<span id="cb48-3"></span>
<span id="cb48-4"><span class="co" style="color: #5E5E5E;"># See that the above doesn't work any more:</span></span>
<span id="cb48-5">output_vector <span class="op" style="color: #5E5E5E;">=</span> reversible_layer_forward(input_vector, f, g)</span>
<span id="cb48-6">reversed_vector <span class="op" style="color: #5E5E5E;">=</span> reversible_layer_reverse(output_vector, f, g)</span>
<span id="cb48-7"></span>
<span id="cb48-8"><span class="cf" style="color: #003B4F;">assert</span> <span class="kw" style="color: #003B4F;">not</span> np.allclose(reversed_vector, input_vector)  <span class="co" style="color: #5E5E5E;"># Fails!!</span></span>
<span id="cb48-9"></span>
<span id="cb48-10"><span class="co" style="color: #5E5E5E;"># It failed because the noise when reversing used a different random seed.</span></span>
<span id="cb48-11"></span>
<span id="cb48-12">random_seed <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">27686</span></span>
<span id="cb48-13">rng <span class="op" style="color: #5E5E5E;">=</span> trax.fastmath.random.get_prng(random_seed)</span>
<span id="cb48-14">f <span class="op" style="color: #5E5E5E;">=</span> <span class="kw" style="color: #003B4F;">lambda</span> x: x <span class="op" style="color: #5E5E5E;">+</span> trax.fastmath.random.uniform(key<span class="op" style="color: #5E5E5E;">=</span>rng, shape<span class="op" style="color: #5E5E5E;">=</span>x.shape)</span>
<span id="cb48-15"></span>
<span id="cb48-16"><span class="co" style="color: #5E5E5E;"># See that it works now as the same rng is used on forward and reverse.</span></span>
<span id="cb48-17">output_vector <span class="op" style="color: #5E5E5E;">=</span> reversible_layer_forward(input_vector, f, g)</span>
<span id="cb48-18">reversed_vector <span class="op" style="color: #5E5E5E;">=</span> reversible_layer_reverse(output_vector, f, g)</span>
<span id="cb48-19"></span>
<span id="cb48-20"><span class="cf" style="color: #003B4F;">assert</span> np.allclose(reversed_vector, input_vector,  atol<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">1e-07</span>) </span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)</code></pre>
</div>
</div>
</section>
</section>
<section id="reformerlm-training" class="level2" data-number="5">
<h2 data-number="5" class="anchored" data-anchor-id="reformerlm-training"><span class="header-section-number">5</span> ReformerLM Training</h2>
<p>We will now proceed to training our model. Since we have already know the two main components that differentiates it from the standard Transformer, LSH and reversible layers above, we can just use the pre-built model already implemented in Trax. It will have this architecture:</p>
<p><img src="http://livingdatalab.com/posts/https:/github.com/pranath/blog/raw/master/images/Reformer.jpg"></p>
<p>Similar to the Transformer we learned earlier, we want to apply an attention and feed forward layer to our inputs. For the Reformer, we improve the memory efficiency by using <strong>reversible decoder blocks</strong> and we can picture its implementation in Trax like below:</p>
<p><img src="http://livingdatalab.com/posts/https:/github.com/pranath/blog/raw/master/images/ReversibleDecoder.png"></p>
<p>We can see that it takes the initial inputs <code>x1</code> and <code>x2</code> and does the first equation of the reversible networks we learned in earlier articles. As we’ve also learned, the reversible residual has two equations for the forward-pass so doing just one of them will just constitute half of the reversible decoder block. Before doing the second equation (i.e.&nbsp;second half of the reversible residual), it first needs to swap the elements to take into account the stack semantics in Trax. It simply puts <code>x2</code> on top of the stack so it can be fed to the add block of the half-residual layer. It then swaps the two outputs again so it can be fed to the next layer of the network. All of these arrives at the two equations it can be used to recompute the activations during the backward pass.</p>
<section id="reformerlm" class="level3" data-number="5.1">
<h3 data-number="5.1" class="anchored" data-anchor-id="reformerlm"><span class="header-section-number">5.1</span> ReformerLM</h3>
<p>We will now implement a wrapper function that returns a Reformer Language Model. We can use Trax’s <a href="https://trax-ml.readthedocs.io/en/latest/trax.models.html#trax.models.reformer.reformer.ReformerLM">ReformerLM</a> to do this quickly. It will have the same architecture as shown above.</p>
<div class="cell" data-execution_count="32">
<div class="sourceCode cell-code" id="cb50" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb50-1"><span class="kw" style="color: #003B4F;">def</span> ReformerLM(vocab_size<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">33000</span>, n_layers<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">2</span>, mode<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'train'</span>, attention_type<span class="op" style="color: #5E5E5E;">=</span>tl.SelfAttention):</span>
<span id="cb50-2">    </span>
<span id="cb50-3">    <span class="co" style="color: #5E5E5E;"># initialize an instance of Trax's ReformerLM class</span></span>
<span id="cb50-4">    model <span class="op" style="color: #5E5E5E;">=</span> tl.Serial( </span>
<span id="cb50-5">                trax.models.reformer.ReformerLM( </span>
<span id="cb50-6">                    <span class="co" style="color: #5E5E5E;"># set vocab size</span></span>
<span id="cb50-7">                    vocab_size<span class="op" style="color: #5E5E5E;">=</span>vocab_size,</span>
<span id="cb50-8">                    <span class="co" style="color: #5E5E5E;"># set number of layers</span></span>
<span id="cb50-9">                    n_layers<span class="op" style="color: #5E5E5E;">=</span>n_layers,</span>
<span id="cb50-10">                    <span class="co" style="color: #5E5E5E;"># set mode</span></span>
<span id="cb50-11">                    mode<span class="op" style="color: #5E5E5E;">=</span>mode,</span>
<span id="cb50-12">                    <span class="co" style="color: #5E5E5E;"># set attention type</span></span>
<span id="cb50-13">                    attention_type<span class="op" style="color: #5E5E5E;">=</span>attention_type</span>
<span id="cb50-14">            )</span>
<span id="cb50-15">            , tl.LogSoftmax() </span>
<span id="cb50-16">        )        </span>
<span id="cb50-17">    <span class="cf" style="color: #003B4F;">return</span> model <span class="co" style="color: #5E5E5E;"># tl.Serial(model, tl.LogSoftmax(),)</span></span></code></pre></div>
</div>
<div class="cell" data-execution_count="33">
<div class="sourceCode cell-code" id="cb51" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb51-1"><span class="co" style="color: #5E5E5E;"># display the model</span></span>
<span id="cb51-2">temp_model <span class="op" style="color: #5E5E5E;">=</span> ReformerLM(<span class="st" style="color: #20794D;">'train'</span>)</span>
<span id="cb51-3"><span class="bu" style="color: null;">print</span>(<span class="bu" style="color: null;">str</span>(temp_model))</span>
<span id="cb51-4"></span>
<span id="cb51-5"><span class="co" style="color: #5E5E5E;"># free memory</span></span>
<span id="cb51-6"><span class="co" style="color: #5E5E5E;">#del temp_model </span></span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Serial[
  Serial[
    Serial[
      ShiftRight(1)
    ]
    Embedding_train_512
    Dropout
    Serial[
      PositionalEncoding
    ]
    Dup_out2
    ReversibleSerial_in2_out2[
      ReversibleHalfResidualDecoderAttn_in2_out2[
        Serial[
          LayerNorm
        ]
        SelfAttention
      ]
      ReversibleSwap_in2_out2
      ReversibleHalfResidualDecoderFF_in2_out2[
        Serial[
          LayerNorm
          Dense_2048
          Dropout
          Serial[
            FastGelu
          ]
          Dense_512
          Dropout
        ]
      ]
      ReversibleSwap_in2_out2
      ReversibleHalfResidualDecoderAttn_in2_out2[
        Serial[
          LayerNorm
        ]
        SelfAttention
      ]
      ReversibleSwap_in2_out2
      ReversibleHalfResidualDecoderFF_in2_out2[
        Serial[
          LayerNorm
          Dense_2048
          Dropout
          Serial[
            FastGelu
          ]
          Dense_512
          Dropout
        ]
      ]
      ReversibleSwap_in2_out2
    ]
    Concatenate_in2
    LayerNorm
    Dropout
    Serial[
      Dense_train
    ]
  ]
  LogSoftmax
]</code></pre>
</div>
</div>
</section>
<section id="training_loop" class="level3" data-number="5.2">
<h3 data-number="5.2" class="anchored" data-anchor-id="training_loop"><span class="header-section-number">5.2</span> training_loop</h3>
<p>We will now write a function that takes in our model and trains it.</p>
<p>We will implement the <code>training_loop</code> below to train the neural network above. Here is a list of things we should do:</p>
<ul>
<li>Create <code>TrainTask</code> and <code>EvalTask</code></li>
<li>Create the training loop <code>trax.supervised.training.Loop</code></li>
<li>Pass in the following depending to train_task :
<ul>
<li><code>labeled_data=train_gen</code></li>
<li><code>loss_layer=tl.CrossEntropyLoss()</code></li>
<li><code>optimizer=trax.optimizers.Adam(0.01)</code></li>
<li><code>lr_schedule=lr_schedule</code></li>
<li><code>n_steps_per_checkpoint=10</code></li>
</ul></li>
</ul>
<p>We will be using our CrossEntropyLoss loss function with Adam optimizer. Please read the <a href="https://trax-ml.readthedocs.io/en/latest/trax.optimizers.html?highlight=adam#trax.optimizers.adam.Adam">trax</a> documentation to get a full understanding.</p>
<ul>
<li>Pass in the following to eval_task:
<ul>
<li><code>labeled_data=eval_gen</code></li>
<li><code>metrics=[tl.CrossEntropyLoss(), tl.Accuracy()]</code></li>
</ul></li>
</ul>
<p>This function should return a <code>training.Loop</code> object. To read more about this check the <a href="https://trax-ml.readthedocs.io/en/latest/trax.supervised.html?highlight=loop#trax.supervised.training.Loop">docs</a>.</p>
<div class="cell" data-execution_count="35">
<div class="sourceCode cell-code" id="cb53" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb53-1"><span class="kw" style="color: #003B4F;">def</span> training_loop(ReformerLM, train_gen, eval_gen, output_dir <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">"./model/"</span>):</span>
<span id="cb53-2">    <span class="co" style="color: #5E5E5E;">"""</span></span>
<span id="cb53-3"><span class="co" style="color: #5E5E5E;">    Args:</span></span>
<span id="cb53-4"><span class="co" style="color: #5E5E5E;">        ReformerLM:  the Reformer language model you are building</span></span>
<span id="cb53-5"><span class="co" style="color: #5E5E5E;">        train_gen (generator): train data generator.</span></span>
<span id="cb53-6"><span class="co" style="color: #5E5E5E;">        eval_gen (generator): Validation generator. </span></span>
<span id="cb53-7"><span class="co" style="color: #5E5E5E;">        output_dir (string): Path to save the model output. Defaults to './model/'.</span></span>
<span id="cb53-8"></span>
<span id="cb53-9"><span class="co" style="color: #5E5E5E;">    Returns:</span></span>
<span id="cb53-10"><span class="co" style="color: #5E5E5E;">        trax.supervised.training.Loop: Training loop for the model.</span></span>
<span id="cb53-11"><span class="co" style="color: #5E5E5E;">    """</span></span>
<span id="cb53-12"></span>
<span id="cb53-13">    <span class="co" style="color: #5E5E5E;"># use the warmup_and_rsqrt_decay learning rate schedule</span></span>
<span id="cb53-14">    lr_schedule <span class="op" style="color: #5E5E5E;">=</span> trax.lr.warmup_and_rsqrt_decay(</span>
<span id="cb53-15">        n_warmup_steps<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">1000</span>, max_value<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">0.01</span>)</span>
<span id="cb53-16">    </span>
<span id="cb53-17">    <span class="co" style="color: #5E5E5E;"># define the train task</span></span>
<span id="cb53-18">    train_task <span class="op" style="color: #5E5E5E;">=</span> training.TrainTask(            </span>
<span id="cb53-19">        <span class="co" style="color: #5E5E5E;"># labeled data</span></span>
<span id="cb53-20">        labeled_data<span class="op" style="color: #5E5E5E;">=</span>train_gen,</span>
<span id="cb53-21">        <span class="co" style="color: #5E5E5E;"># loss layer</span></span>
<span id="cb53-22">        loss_layer<span class="op" style="color: #5E5E5E;">=</span>tl.CrossEntropyLoss(),</span>
<span id="cb53-23">        <span class="co" style="color: #5E5E5E;"># optimizer</span></span>
<span id="cb53-24">        optimizer<span class="op" style="color: #5E5E5E;">=</span>trax.optimizers.Adam(<span class="fl" style="color: #AD0000;">0.01</span>),</span>
<span id="cb53-25">        <span class="co" style="color: #5E5E5E;"># lr_schedule</span></span>
<span id="cb53-26">        lr_schedule<span class="op" style="color: #5E5E5E;">=</span>lr_schedule,</span>
<span id="cb53-27">        <span class="co" style="color: #5E5E5E;"># n_steps</span></span>
<span id="cb53-28">        n_steps_per_checkpoint<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">10</span></span>
<span id="cb53-29">    )</span>
<span id="cb53-30"></span>
<span id="cb53-31">    <span class="co" style="color: #5E5E5E;"># define the eval task</span></span>
<span id="cb53-32">    eval_task <span class="op" style="color: #5E5E5E;">=</span> training.EvalTask(                      </span>
<span id="cb53-33">        <span class="co" style="color: #5E5E5E;"># labeled data</span></span>
<span id="cb53-34">        labeled_data<span class="op" style="color: #5E5E5E;">=</span>eval_gen,</span>
<span id="cb53-35">        <span class="co" style="color: #5E5E5E;"># metrics</span></span>
<span id="cb53-36">        metrics<span class="op" style="color: #5E5E5E;">=</span>[tl.CrossEntropyLoss(), tl.Accuracy()]</span>
<span id="cb53-37">    )</span>
<span id="cb53-38"></span>
<span id="cb53-39">    loop <span class="op" style="color: #5E5E5E;">=</span> training.Loop(ReformerLM(mode<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'train'</span>),</span>
<span id="cb53-40">                         train_task,</span>
<span id="cb53-41">                         eval_tasks<span class="op" style="color: #5E5E5E;">=</span>[eval_task],</span>
<span id="cb53-42">                         output_dir<span class="op" style="color: #5E5E5E;">=</span>output_dir)</span>
<span id="cb53-43">    <span class="cf" style="color: #003B4F;">return</span> loop</span></code></pre></div>
</div>
<div class="cell" data-outputid="b6e00b37-6f13-486d-ba49-2d4542b0d398" data-execution_count="38">
<div class="sourceCode cell-code" id="cb54" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb54-1"><span class="co" style="color: #5E5E5E;"># we will now test our function</span></span>
<span id="cb54-2"><span class="op" style="color: #5E5E5E;">!</span>rm <span class="op" style="color: #5E5E5E;">-</span>f model<span class="op" style="color: #5E5E5E;">/</span>model.pkl.gz</span>
<span id="cb54-3">loop <span class="op" style="color: #5E5E5E;">=</span> training_loop(ReformerLM, train_stream, eval_stream)</span>
<span id="cb54-4">loop.run(<span class="dv" style="color: #AD0000;">10</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Step      1: Total number of trainable weights: 58072296
Step      1: Ran 1 train steps in 53.39 secs
Step      1: train CrossEntropyLoss |  10.45205879
Step      1: eval  CrossEntropyLoss |  10.43009472
Step      1: eval          Accuracy |  0.00000000

Step     10: Ran 9 train steps in 116.91 secs
Step     10: train CrossEntropyLoss |  10.23098850
Step     10: eval  CrossEntropyLoss |  9.81040001
Step     10: eval          Accuracy |  0.05645161</code></pre>
</div>
</div>
</section>
</section>
<section id="decode-from-a-pretrained-model" class="level2" data-number="6">
<h2 data-number="6" class="anchored" data-anchor-id="decode-from-a-pretrained-model"><span class="header-section-number">6</span> Decode from a Pretrained Model</h2>
<p>We will now proceed on decoding using the model architecture we just implemented. As previously, we will be using a pretrained model so we can observe meaningful output during inference. We will be using the <a href="https://trax-ml.readthedocs.io/en/latest/trax.supervised.html#trax.supervised.decoding.autoregressive_sample_stream">autoregressive_sample_stream()</a> decoding method from Trax to do fast inference. Let’s define a few parameters to initialize our model.</p>
<div class="cell" data-execution_count="39">
<div class="sourceCode cell-code" id="cb56" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb56-1"><span class="co" style="color: #5E5E5E;"># define the `predict_mem_len` and `predict_drop_len` of tl.SelfAttention</span></span>
<span id="cb56-2"><span class="kw" style="color: #003B4F;">def</span> attention(<span class="op" style="color: #5E5E5E;">*</span>args, <span class="op" style="color: #5E5E5E;">**</span>kwargs):</span>
<span id="cb56-3">    <span class="co" style="color: #5E5E5E;"># number of input positions to remember in a cache when doing fast inference. </span></span>
<span id="cb56-4">    kwargs[<span class="st" style="color: #20794D;">'predict_mem_len'</span>] <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">120</span></span>
<span id="cb56-5">    <span class="co" style="color: #5E5E5E;"># number of input elements to drop once the fast inference input cache fills up.</span></span>
<span id="cb56-6">    kwargs[<span class="st" style="color: #20794D;">'predict_drop_len'</span>] <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">120</span></span>
<span id="cb56-7">    <span class="co" style="color: #5E5E5E;"># return the attention layer with the parameters defined above</span></span>
<span id="cb56-8">    <span class="cf" style="color: #003B4F;">return</span> tl.SelfAttention(<span class="op" style="color: #5E5E5E;">*</span>args, <span class="op" style="color: #5E5E5E;">**</span>kwargs)</span>
<span id="cb56-9"></span>
<span id="cb56-10"><span class="co" style="color: #5E5E5E;"># define the model using the ReformerLM function you implemented earlier.</span></span>
<span id="cb56-11">model <span class="op" style="color: #5E5E5E;">=</span> ReformerLM(</span>
<span id="cb56-12">    vocab_size<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">33000</span>,</span>
<span id="cb56-13">    n_layers<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">6</span>,</span>
<span id="cb56-14">    mode<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'predict'</span>,</span>
<span id="cb56-15">    attention_type<span class="op" style="color: #5E5E5E;">=</span>attention,</span>
<span id="cb56-16">)</span>
<span id="cb56-17"></span>
<span id="cb56-18"><span class="co" style="color: #5E5E5E;"># define an input signature so we can initialize our model. shape will be (1, 1) and the data type is int32.</span></span>
<span id="cb56-19">shape11 <span class="op" style="color: #5E5E5E;">=</span> trax.shapes.ShapeDtype((<span class="dv" style="color: #AD0000;">1</span>, <span class="dv" style="color: #AD0000;">1</span>), dtype<span class="op" style="color: #5E5E5E;">=</span>np.int32)</span></code></pre></div>
</div>
<p>We can now initialize our model from a file containing the pretrained weights. We will save this starting state so we can reset the model state when we generate a new conversation. This will become clearer in the <code>generate_dialogue()</code> function later.</p>
<div class="cell" data-execution_count="40">
<div class="sourceCode cell-code" id="cb57" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb57-1"><span class="co" style="color: #5E5E5E;"># initialize from file</span></span>
<span id="cb57-2">model.init_from_file(<span class="st" style="color: #20794D;">'chatbot_model1.pkl.gz'</span>,</span>
<span id="cb57-3">                     weights_only<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>, input_signature<span class="op" style="color: #5E5E5E;">=</span>shape11)</span>
<span id="cb57-4"></span>
<span id="cb57-5"><span class="co" style="color: #5E5E5E;"># save the starting state</span></span>
<span id="cb57-6">STARTING_STATE <span class="op" style="color: #5E5E5E;">=</span> model.state</span></code></pre></div>
</div>
<p>Let’s define a few utility functions as well to help us tokenize and detokenize. We can use the <a href="https://trax-ml.readthedocs.io/en/latest/trax.data.html#trax.data.tf_inputs.tokenize">tokenize()</a> and <a href="https://trax-ml.readthedocs.io/en/latest/trax.data.html#trax.data.tf_inputs.detokenize">detokenize()</a> from <code>trax.data.tf_inputs</code> to do this.</p>
<div class="cell" data-execution_count="41">
<div class="sourceCode cell-code" id="cb58" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb58-1"><span class="kw" style="color: #003B4F;">def</span> tokenize(sentence, vocab_file, vocab_dir):</span>
<span id="cb58-2">    <span class="cf" style="color: #003B4F;">return</span> <span class="bu" style="color: null;">list</span>(trax.data.tokenize(<span class="bu" style="color: null;">iter</span>([sentence]), vocab_file<span class="op" style="color: #5E5E5E;">=</span>vocab_file, vocab_dir<span class="op" style="color: #5E5E5E;">=</span>vocab_dir))[<span class="dv" style="color: #AD0000;">0</span>]</span>
<span id="cb58-3"></span>
<span id="cb58-4"><span class="kw" style="color: #003B4F;">def</span> detokenize(tokens, vocab_file, vocab_dir):</span>
<span id="cb58-5">    <span class="cf" style="color: #003B4F;">return</span> trax.data.detokenize(tokens, vocab_file<span class="op" style="color: #5E5E5E;">=</span>vocab_file, vocab_dir<span class="op" style="color: #5E5E5E;">=</span>vocab_dir)</span></code></pre></div>
</div>
<p>We are now ready to define our decoding function. This will return a generator that yields that next symbol output by the model. It will be able to predict the next words by just feeding it a starting sentence.</p>
<section id="reformerlm_output_gen" class="level3" data-number="6.1">
<h3 data-number="6.1" class="anchored" data-anchor-id="reformerlm_output_gen"><span class="header-section-number">6.1</span> ReformerLM_output_gen</h3>
<p>We will implement the function below to return a generator that predicts the next word of the conversation.</p>
<div class="cell" data-execution_count="42">
<div class="sourceCode cell-code" id="cb59" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb59-1"><span class="kw" style="color: #003B4F;">def</span> ReformerLM_output_gen(ReformerLM, start_sentence, vocab_file, vocab_dir, temperature, tokenize<span class="op" style="color: #5E5E5E;">=</span>tokenize):</span>
<span id="cb59-2">    <span class="co" style="color: #5E5E5E;">"""</span></span>
<span id="cb59-3"><span class="co" style="color: #5E5E5E;">    Args:</span></span>
<span id="cb59-4"><span class="co" style="color: #5E5E5E;">        ReformerLM:  the Reformer language model you just trained</span></span>
<span id="cb59-5"><span class="co" style="color: #5E5E5E;">        start_sentence (string): starting sentence of the conversation</span></span>
<span id="cb59-6"><span class="co" style="color: #5E5E5E;">        vocab_file (string): vocabulary filename</span></span>
<span id="cb59-7"><span class="co" style="color: #5E5E5E;">        vocab_dir (string): directory of the vocabulary file</span></span>
<span id="cb59-8"><span class="co" style="color: #5E5E5E;">        temperature (float): parameter for sampling ranging from 0.0 to 1.0.</span></span>
<span id="cb59-9"><span class="co" style="color: #5E5E5E;">            0.0: same as argmax, always pick the most probable token</span></span>
<span id="cb59-10"><span class="co" style="color: #5E5E5E;">            1.0: sampling from the distribution (can sometimes say random things)</span></span>
<span id="cb59-11"></span>
<span id="cb59-12"><span class="co" style="color: #5E5E5E;">    Returns:</span></span>
<span id="cb59-13"><span class="co" style="color: #5E5E5E;">        generator: yields the next symbol generated by the model</span></span>
<span id="cb59-14"><span class="co" style="color: #5E5E5E;">    """</span></span>
<span id="cb59-15">        </span>
<span id="cb59-16">    <span class="co" style="color: #5E5E5E;"># Create input tokens using the the tokenize function</span></span>
<span id="cb59-17">    input_tokens <span class="op" style="color: #5E5E5E;">=</span> tokenize(start_sentence, vocab_file<span class="op" style="color: #5E5E5E;">=</span>vocab_file, vocab_dir<span class="op" style="color: #5E5E5E;">=</span>vocab_dir)</span>
<span id="cb59-18">    </span>
<span id="cb59-19">    <span class="co" style="color: #5E5E5E;"># Add batch dimension to array. Convert from (n,) to (x, n) where </span></span>
<span id="cb59-20">    <span class="co" style="color: #5E5E5E;"># x is the batch size. Default is 1. (hint: you can use np.expand_dims() with axis=0)</span></span>
<span id="cb59-21">    input_tokens_with_batch <span class="op" style="color: #5E5E5E;">=</span> np.array(input_tokens)[<span class="va" style="color: #111111;">None</span>, :]</span>
<span id="cb59-22">    </span>
<span id="cb59-23">    <span class="co" style="color: #5E5E5E;"># call the autoregressive_sample_stream function from trax</span></span>
<span id="cb59-24">    output_gen <span class="op" style="color: #5E5E5E;">=</span> trax.supervised.decoding.autoregressive_sample_stream( </span>
<span id="cb59-25">        <span class="co" style="color: #5E5E5E;"># model</span></span>
<span id="cb59-26">        ReformerLM,</span>
<span id="cb59-27">        <span class="co" style="color: #5E5E5E;"># inputs will be the tokens with batch dimension</span></span>
<span id="cb59-28">        inputs<span class="op" style="color: #5E5E5E;">=</span>input_tokens_with_batch,</span>
<span id="cb59-29">        <span class="co" style="color: #5E5E5E;"># temperature</span></span>
<span id="cb59-30">        temperature<span class="op" style="color: #5E5E5E;">=</span>temperature</span>
<span id="cb59-31">    )</span>
<span id="cb59-32">        </span>
<span id="cb59-33">    <span class="cf" style="color: #003B4F;">return</span> output_gen</span></code></pre></div>
</div>
<p>Now we will be able to see the model in action. The utility function below will call the generator we just implemented and will just format the output to be easier to read.</p>
<div class="cell" data-execution_count="44">
<div class="sourceCode cell-code" id="cb60" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb60-1">shape11 <span class="op" style="color: #5E5E5E;">=</span> trax.shapes.ShapeDtype((<span class="dv" style="color: #AD0000;">1</span>, <span class="dv" style="color: #AD0000;">1</span>), dtype<span class="op" style="color: #5E5E5E;">=</span>np.int32)</span>
<span id="cb60-2"></span>
<span id="cb60-3"><span class="kw" style="color: #003B4F;">def</span> attention(<span class="op" style="color: #5E5E5E;">*</span>args, <span class="op" style="color: #5E5E5E;">**</span>kwargs):</span>
<span id="cb60-4">    kwargs[<span class="st" style="color: #20794D;">'predict_mem_len'</span>] <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">120</span>  <span class="co" style="color: #5E5E5E;"># max length for predictions</span></span>
<span id="cb60-5">    kwargs[<span class="st" style="color: #20794D;">'predict_drop_len'</span>] <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">120</span>  <span class="co" style="color: #5E5E5E;"># never drop old stuff</span></span>
<span id="cb60-6">    <span class="cf" style="color: #003B4F;">return</span> tl.SelfAttention(<span class="op" style="color: #5E5E5E;">*</span>args, <span class="op" style="color: #5E5E5E;">**</span>kwargs)</span>
<span id="cb60-7"></span>
<span id="cb60-8">model <span class="op" style="color: #5E5E5E;">=</span> ReformerLM(</span>
<span id="cb60-9">    vocab_size<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">33000</span>,</span>
<span id="cb60-10">    n_layers<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">6</span>,</span>
<span id="cb60-11">    mode<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'predict'</span>,</span>
<span id="cb60-12">    attention_type<span class="op" style="color: #5E5E5E;">=</span>attention,</span>
<span id="cb60-13">)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="45">
<div class="sourceCode cell-code" id="cb61" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb61-1">model.init_from_file(<span class="st" style="color: #20794D;">'chatbot_model1.pkl.gz'</span>,</span>
<span id="cb61-2">                     weights_only<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>, input_signature<span class="op" style="color: #5E5E5E;">=</span>shape11)</span>
<span id="cb61-3"></span>
<span id="cb61-4">STARTING_STATE <span class="op" style="color: #5E5E5E;">=</span> model.state</span></code></pre></div>
</div>
<div class="cell" data-execution_count="46">
<div class="sourceCode cell-code" id="cb62" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb62-1"><span class="kw" style="color: #003B4F;">def</span> generate_dialogue(ReformerLM, model_state, start_sentence, vocab_file, vocab_dir, max_len, temperature):</span>
<span id="cb62-2">    <span class="co" style="color: #5E5E5E;">"""</span></span>
<span id="cb62-3"><span class="co" style="color: #5E5E5E;">    Args:</span></span>
<span id="cb62-4"><span class="co" style="color: #5E5E5E;">        ReformerLM:  the Reformer language model you just trained</span></span>
<span id="cb62-5"><span class="co" style="color: #5E5E5E;">        model_state (np.array): initial state of the model before decoding</span></span>
<span id="cb62-6"><span class="co" style="color: #5E5E5E;">        start_sentence (string): starting sentence of the conversation</span></span>
<span id="cb62-7"><span class="co" style="color: #5E5E5E;">        vocab_file (string): vocabulary filename</span></span>
<span id="cb62-8"><span class="co" style="color: #5E5E5E;">        vocab_dir (string): directory of the vocabulary file</span></span>
<span id="cb62-9"><span class="co" style="color: #5E5E5E;">        max_len (int): maximum number of tokens to generate </span></span>
<span id="cb62-10"><span class="co" style="color: #5E5E5E;">        temperature (float): parameter for sampling ranging from 0.0 to 1.0.</span></span>
<span id="cb62-11"><span class="co" style="color: #5E5E5E;">            0.0: same as argmax, always pick the most probable token</span></span>
<span id="cb62-12"><span class="co" style="color: #5E5E5E;">            1.0: sampling from the distribution (can sometimes say random things)</span></span>
<span id="cb62-13"></span>
<span id="cb62-14"><span class="co" style="color: #5E5E5E;">    Returns:</span></span>
<span id="cb62-15"><span class="co" style="color: #5E5E5E;">        generator: yields the next symbol generated by the model</span></span>
<span id="cb62-16"><span class="co" style="color: #5E5E5E;">    """</span>  </span>
<span id="cb62-17">    </span>
<span id="cb62-18">    <span class="co" style="color: #5E5E5E;"># define the delimiters we used during training</span></span>
<span id="cb62-19">    delimiter_1 <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">'Person 1: '</span> </span>
<span id="cb62-20">    delimiter_2 <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">'Person 2: '</span></span>
<span id="cb62-21">    </span>
<span id="cb62-22">    <span class="co" style="color: #5E5E5E;"># initialize detokenized output</span></span>
<span id="cb62-23">    sentence <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">''</span></span>
<span id="cb62-24">    </span>
<span id="cb62-25">    <span class="co" style="color: #5E5E5E;"># token counter</span></span>
<span id="cb62-26">    counter <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">0</span></span>
<span id="cb62-27">    </span>
<span id="cb62-28">    <span class="co" style="color: #5E5E5E;"># output tokens. we insert a ': ' for formatting</span></span>
<span id="cb62-29">    result <span class="op" style="color: #5E5E5E;">=</span> [tokenize(<span class="st" style="color: #20794D;">': '</span>, vocab_file<span class="op" style="color: #5E5E5E;">=</span>vocab_file, vocab_dir<span class="op" style="color: #5E5E5E;">=</span>vocab_dir)]</span>
<span id="cb62-30">    </span>
<span id="cb62-31">    <span class="co" style="color: #5E5E5E;"># reset the model state when starting a new dialogue</span></span>
<span id="cb62-32">    ReformerLM.state <span class="op" style="color: #5E5E5E;">=</span> model_state</span>
<span id="cb62-33">    </span>
<span id="cb62-34">    <span class="co" style="color: #5E5E5E;"># calls the output generator implemented earlier</span></span>
<span id="cb62-35">    output <span class="op" style="color: #5E5E5E;">=</span> ReformerLM_output_gen(ReformerLM, start_sentence, vocab_file<span class="op" style="color: #5E5E5E;">=</span>VOCAB_FILE, vocab_dir<span class="op" style="color: #5E5E5E;">=</span>VOCAB_DIR, temperature<span class="op" style="color: #5E5E5E;">=</span>temperature)</span>
<span id="cb62-36">    </span>
<span id="cb62-37">    <span class="co" style="color: #5E5E5E;"># print the starting sentence</span></span>
<span id="cb62-38">    <span class="bu" style="color: null;">print</span>(start_sentence.split(delimiter_2)[<span class="dv" style="color: #AD0000;">0</span>].strip())</span>
<span id="cb62-39">    </span>
<span id="cb62-40">    <span class="co" style="color: #5E5E5E;"># loop below yields the next tokens until max_len is reached. the if-elif is just for prettifying the output.</span></span>
<span id="cb62-41">    <span class="cf" style="color: #003B4F;">for</span> o <span class="kw" style="color: #003B4F;">in</span> output:</span>
<span id="cb62-42">        </span>
<span id="cb62-43">        result.append(o)</span>
<span id="cb62-44">        </span>
<span id="cb62-45">        sentence <span class="op" style="color: #5E5E5E;">=</span> detokenize(np.concatenate(result, axis<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">0</span>), vocab_file<span class="op" style="color: #5E5E5E;">=</span>VOCAB_FILE, vocab_dir<span class="op" style="color: #5E5E5E;">=</span>VOCAB_DIR)</span>
<span id="cb62-46">        </span>
<span id="cb62-47">        <span class="cf" style="color: #003B4F;">if</span> sentence.endswith(delimiter_1):</span>
<span id="cb62-48">            sentence <span class="op" style="color: #5E5E5E;">=</span> sentence.split(delimiter_1)[<span class="dv" style="color: #AD0000;">0</span>]</span>
<span id="cb62-49">            <span class="bu" style="color: null;">print</span>(<span class="ss" style="color: #20794D;">f'</span><span class="sc" style="color: #5E5E5E;">{</span>delimiter_2<span class="sc" style="color: #5E5E5E;">}{</span>sentence<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">'</span>)</span>
<span id="cb62-50">            sentence <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">''</span></span>
<span id="cb62-51">            result.clear()</span>
<span id="cb62-52">        </span>
<span id="cb62-53">        <span class="cf" style="color: #003B4F;">elif</span> sentence.endswith(delimiter_2):</span>
<span id="cb62-54">            sentence <span class="op" style="color: #5E5E5E;">=</span> sentence.split(delimiter_2)[<span class="dv" style="color: #AD0000;">0</span>]</span>
<span id="cb62-55">            <span class="bu" style="color: null;">print</span>(<span class="ss" style="color: #20794D;">f'</span><span class="sc" style="color: #5E5E5E;">{</span>delimiter_1<span class="sc" style="color: #5E5E5E;">}{</span>sentence<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">'</span>)</span>
<span id="cb62-56">            sentence <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">''</span></span>
<span id="cb62-57">            result.clear()</span>
<span id="cb62-58"></span>
<span id="cb62-59">        counter <span class="op" style="color: #5E5E5E;">+=</span> <span class="dv" style="color: #AD0000;">1</span></span>
<span id="cb62-60">        </span>
<span id="cb62-61">        <span class="cf" style="color: #003B4F;">if</span> counter <span class="op" style="color: #5E5E5E;">&gt;</span> max_len:</span>
<span id="cb62-62">            <span class="cf" style="color: #003B4F;">break</span>    </span></code></pre></div>
</div>
<p>We can now feed in different starting sentences and see how the model generates the dialogue. We can even input our own starting sentence. Just remember to ask a question that covers the topics in the Multiwoz dataset so you can generate a meaningful conversation.</p>
<div class="cell" data-execution_count="47">
<div class="sourceCode cell-code" id="cb63" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb63-1">sample_sentence <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">' Person 1: Are there theatres in town? Person 2: '</span></span>
<span id="cb63-2">generate_dialogue(ReformerLM<span class="op" style="color: #5E5E5E;">=</span>model, model_state<span class="op" style="color: #5E5E5E;">=</span>STARTING_STATE, start_sentence<span class="op" style="color: #5E5E5E;">=</span>sample_sentence, vocab_file<span class="op" style="color: #5E5E5E;">=</span>VOCAB_FILE, vocab_dir<span class="op" style="color: #5E5E5E;">=</span>VOCAB_DIR, max_len<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">120</span>, temperature<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">0.2</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Person 1: Are there theatres in town?
Person 2: : There are 4 theatres in town. Do you have a specific area in mind? 
Person 1: No, I don't have a preference. Which one do you recommend? 
Person 2: I would recommend the Mumford Theatre. Would you like their phone number? 
Person 1: Yes, please. I would also like to find a train to cambridge on thursday. 
Person 1: There are 202 trains that meet your criteria. Do you have a specific you would like to go to a cinema? </code></pre>
</div>
</div>
<div class="cell" data-execution_count="48">
<div class="sourceCode cell-code" id="cb65" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb65-1">sample_sentence <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">' Person 1: Is there a hospital nearby? Person 2: '</span></span>
<span id="cb65-2">generate_dialogue(ReformerLM<span class="op" style="color: #5E5E5E;">=</span>model, model_state<span class="op" style="color: #5E5E5E;">=</span>STARTING_STATE, start_sentence<span class="op" style="color: #5E5E5E;">=</span>sample_sentence, vocab_file<span class="op" style="color: #5E5E5E;">=</span>VOCAB_FILE, vocab_dir<span class="op" style="color: #5E5E5E;">=</span>VOCAB_DIR, max_len<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">120</span>, temperature<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">0.2</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Person 1: Is there a hospital nearby?
Person 2: : Addensbrookes Hospital is located at Hills Rd, Cambridge, postcode CB20QQ. Do you need the phone number? 
Person 1: No, that's all I needed. Thank you. 
Person 2: You're welcome. Have a good day.m.Thanks for contacting the Cambridge TownInfo centre. Goodbye.
Person 1: Thank you for your help. 
Person 1: You're welcome. Have a good day.I can find something. </code></pre>
</div>
</div>
<div class="cell" data-execution_count="49">
<div class="sourceCode cell-code" id="cb67" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb67-1">sample_sentence <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">' Person 1: Can you book a taxi? Person 2: '</span></span>
<span id="cb67-2">generate_dialogue(ReformerLM<span class="op" style="color: #5E5E5E;">=</span>model, model_state<span class="op" style="color: #5E5E5E;">=</span>STARTING_STATE, start_sentence<span class="op" style="color: #5E5E5E;">=</span>sample_sentence, vocab_file<span class="op" style="color: #5E5E5E;">=</span>VOCAB_FILE, vocab_dir<span class="op" style="color: #5E5E5E;">=</span>VOCAB_DIR, max_len<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">120</span>, temperature<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">0.2</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Person 1: Can you book a taxi?
Person 2: : I sure can. When would you like to arrive? 
Person 1: I need to leave after 13:00. 
Person 2: I'm sorry, but I'm not able to book that for you. Would you like to try a different time? 
Person 1: Yes, let's try for 13:00. 
Person 2: I was able to book you a table for 1 at 13:00 on Saturday. Your reference number is YYYOOO </code></pre>
</div>
</div>
</section>
</section>
<section id="acknowledgements" class="level2" data-number="7">
<h2 data-number="7" class="anchored" data-anchor-id="acknowledgements"><span class="header-section-number">7</span> Acknowledgements</h2>
<p>I’d like to express my thanks to the great <a href="https://www.coursera.org/learn/attention-models-in-nlp">Natural Language Processing with Attention Models Course</a> which i completed, and acknowledge the use of some images and other materials from the course in this article.</p>


</section>

 ]]></description>
  <category>natural-language-processing</category>
  <category>deep-learning</category>
  <guid>http://livingdatalab.com/posts/2023-03-28-using-an-efficient-transformer-to-create-an-interactive-complex-chatbot.html</guid>
  <pubDate>Mon, 27 Mar 2023 23:00:00 GMT</pubDate>
  <media:content url="https://github.com/pranath/blog/raw/master/images/cbot.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Reversable residual networks for more efficient transfomer models</title>
  <dc:creator>Pranath Fernando</dc:creator>
  <link>http://livingdatalab.com/posts/2023-03-27-reversable-residual-networks-for-transformer-models.html</link>
  <description><![CDATA[ 




<section id="introduction" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="introduction"><span class="header-section-number">1</span> Introduction</h2>
<p>In an <a href="2021-06-12-resnets-the-key-to-training-deep-neural-networks.html">earlier article</a> we looked at how Resnets help improve model training. In this article we will explore Reversible Residual Networks for Transfomer models. These are based on the Transformer model we already know, but with two unique features.</p>
<ul>
<li>Locality Sensitive Hashing (LSH) Attention to reduce the compute cost of the dot product attention and</li>
<li>Reversible Residual Networks (RevNets) organization to reduce the storage requirements when doing backpropagation in training.</li>
</ul>
<p>We’ll start with a quick review of Residual Networks and their implementation in Trax. Then we will discuss the Revnet architecture and its use in Reformer.</p>
</section>
<section id="residual-networks" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="residual-networks"><span class="header-section-number">2</span> Residual Networks</h2>
<p><a href="https://arxiv.org/abs/1512.03385">Deep Residual Networks</a> (Resnets) were introduced to improve convergence in deep networks. Residual Networks introduce a shortcut connection around one or more layers in a deep network as shown in the diagram below from the original paper.</p>
<center>
<img src="http://livingdatalab.com/posts/https:/github.com/pranath/blog/raw/master/images/Revnet7.png" height="250" width="250">
</center>
<center>
<b>Figure 1: Residual Network diagram from original paper</b>
</center>
<p>The <a href="https://trax-ml.readthedocs.io/en/latest/notebooks/layers_intro.html#2.-Inputs-and-Outputs">Trax documentation</a> describes an implementation of Resnets using <code>branch</code>. We’ll explore that here by implementing a simple resnet built from simple function based layers. Specifically, we’ll build a 4 layer network based on two functions, ‘F’ and ‘G’.</p>
<img src="http://livingdatalab.com/posts/https:/github.com/pranath/blog/raw/master/images/Revnet8.png" height="200" width="1400">
<center>
<b>Figure 2: 4 stage Residual network</b>
</center>
<section id="branch" class="level3" data-number="2.1">
<h3 data-number="2.1" class="anchored" data-anchor-id="branch"><span class="header-section-number">2.1</span> Branch</h3>
<p>Trax <code>branch</code> figures prominently in the residual network layer so we will first examine it. We can see from the figure above that we will need a function that will copy an input and send it down multiple paths. This is accomplished with a <a href="https://trax-ml.readthedocs.io/en/latest/trax.layers.html#module-trax.layers.combinators">branch layer</a>, one of the Trax ‘combinators’. Branch is a combinator that applies a list of layers in parallel to copies of inputs. Lets try it out! First we will need some layers to play with. Let’s build some from functions.</p>
<div class="cell" data-tags="[]" data-execution_count="2">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="co" style="color: #5E5E5E;"># simple function taking one input and one output</span></span>
<span id="cb1-2">bl_add1 <span class="op" style="color: #5E5E5E;">=</span> tl.Fn(<span class="st" style="color: #20794D;">"add1"</span>, <span class="kw" style="color: #003B4F;">lambda</span> x0: (x0 <span class="op" style="color: #5E5E5E;">+</span> <span class="dv" style="color: #AD0000;">1</span>), n_out<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">1</span>)</span>
<span id="cb1-3">bl_add2 <span class="op" style="color: #5E5E5E;">=</span> tl.Fn(<span class="st" style="color: #20794D;">"add2"</span>, <span class="kw" style="color: #003B4F;">lambda</span> x0: (x0 <span class="op" style="color: #5E5E5E;">+</span> <span class="dv" style="color: #AD0000;">2</span>), n_out<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">1</span>)</span>
<span id="cb1-4">bl_add3 <span class="op" style="color: #5E5E5E;">=</span> tl.Fn(<span class="st" style="color: #20794D;">"add3"</span>, <span class="kw" style="color: #003B4F;">lambda</span> x0: (x0 <span class="op" style="color: #5E5E5E;">+</span> <span class="dv" style="color: #AD0000;">3</span>), n_out<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">1</span>)</span>
<span id="cb1-5"><span class="co" style="color: #5E5E5E;"># try them out</span></span>
<span id="cb1-6">x <span class="op" style="color: #5E5E5E;">=</span> np.array([<span class="dv" style="color: #AD0000;">1</span>])</span>
<span id="cb1-7"><span class="bu" style="color: null;">print</span>(bl_add1(x), bl_add2(x), bl_add3(x))</span>
<span id="cb1-8"><span class="co" style="color: #5E5E5E;"># some information about our new layers</span></span>
<span id="cb1-9"><span class="bu" style="color: null;">print</span>(</span>
<span id="cb1-10">    <span class="st" style="color: #20794D;">"name:"</span>,</span>
<span id="cb1-11">    bl_add1.name,</span>
<span id="cb1-12">    <span class="st" style="color: #20794D;">"number of inputs:"</span>,</span>
<span id="cb1-13">    bl_add1.n_in,</span>
<span id="cb1-14">    <span class="st" style="color: #20794D;">"number of outputs:"</span>,</span>
<span id="cb1-15">    bl_add1.n_out,</span>
<span id="cb1-16">)</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>[2] [3] [4]
name: add1 number of inputs: 1 number of outputs: 1</code></pre>
</div>
</div>
<div class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1">bl_3add1s <span class="op" style="color: #5E5E5E;">=</span> tl.Branch(bl_add1, bl_add2, bl_add3)</span>
<span id="cb4-2">bl_3add1s</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="3">
<pre><code>Branch_out3[
  add1
  add2
  add3
]</code></pre>
</div>
</div>
Trax uses the concept of a ‘stack’ to transfer data between layers. For Branch, for each of its layer arguments, it copies the <code>n_in</code> inputs from the stack and provides them to the layer, tracking the max_n_in, or the largest n_in required. It then pops the max_n_in elements from the stack. <img src="http://livingdatalab.com/posts/https:/github.com/pranath/blog/raw/master/images/branch1.png" height="260" width="600">
<center>
<b>Figure 3: One in, one out Branch</b>
</center>
<p>On output, each layer, in succession pushes its results onto the stack. Note that the push/pull operations impact the top of the stack. Elements that are not part of the operation (n, and m in the diagram) remain intact.</p>
<div class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><span class="co" style="color: #5E5E5E;"># n_in = 1, Each bl_addx pushes n_out = 1 elements onto the stack</span></span>
<span id="cb6-2">bl_3add1s(x)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="4">
<pre><code>(array([2]), array([3]), array([4]))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><span class="co" style="color: #5E5E5E;"># n = np.array([10]); m = np.array([20])  # n, m will remain on the stack</span></span>
<span id="cb8-2">n <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">"n"</span></span>
<span id="cb8-3">m <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">"m"</span>  <span class="co" style="color: #5E5E5E;"># n, m will remain on the stack</span></span>
<span id="cb8-4">bl_3add1s([x, n, m]) </span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="5">
<pre><code>(array([2]), array([3]), array([4]), 'n', 'm')</code></pre>
</div>
</div>
<p>Each layer in the input list copies as many inputs from the stack as it needs, and their outputs are successively combined on stack. Put another way, each element of the branch can have differing numbers of inputs and outputs. Let’s try a more complex example.</p>
<div class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1">bl_addab <span class="op" style="color: #5E5E5E;">=</span> tl.Fn(</span>
<span id="cb10-2">    <span class="st" style="color: #20794D;">"addab"</span>, <span class="kw" style="color: #003B4F;">lambda</span> x0, x1: (x0 <span class="op" style="color: #5E5E5E;">+</span> x1), n_out<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">1</span></span>
<span id="cb10-3">)  <span class="co" style="color: #5E5E5E;"># Trax figures out how many inputs there are</span></span>
<span id="cb10-4">bl_rep3x <span class="op" style="color: #5E5E5E;">=</span> tl.Fn(</span>
<span id="cb10-5">    <span class="st" style="color: #20794D;">"add2x"</span>, <span class="kw" style="color: #003B4F;">lambda</span> x0: (x0, x0, x0), n_out<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">3</span></span>
<span id="cb10-6">)  <span class="co" style="color: #5E5E5E;"># but you have to tell it how many outputs there are</span></span>
<span id="cb10-7">bl_3ops <span class="op" style="color: #5E5E5E;">=</span> tl.Branch(bl_add1, bl_addab, bl_rep3x)</span></code></pre></div>
</div>
In this case, the number of inputs being copied from the stack varies with the layer <img src="http://livingdatalab.com/posts/https:/github.com/pranath/blog/raw/master/images/branch2.png" height="260" width="600">
<center>
<b>Figure 4: variable in, variable out Branch</b>
</center>
<p>The stack when the operation is finished is 5 entries reflecting the total from each layer.</p>
<div class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb11" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><span class="co" style="color: #5E5E5E;"># Before Running this cell, what is the output you are expecting?</span></span>
<span id="cb11-2">y <span class="op" style="color: #5E5E5E;">=</span> np.array([<span class="dv" style="color: #AD0000;">3</span>])</span>
<span id="cb11-3">bl_3ops([x, y, n, m])</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="7">
<pre><code>(array([2]), array([4]), array([1]), array([1]), array([1]), 'n', 'm')</code></pre>
</div>
</div>
Branch has a special feature to support Residual Network. If an argument is ‘None’, it will pull the top of stack and push it (at its location in the sequence) onto the output stack <img src="http://livingdatalab.com/posts/https:/github.com/pranath/blog/raw/master/images/branch3.png" height="260" width="600">
<center>
<b>Figure 5: Branch for Residual</b>
</center>
<div class="cell" data-tags="[]" data-execution_count="8">
<div class="sourceCode cell-code" id="cb13" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1">bl_2ops <span class="op" style="color: #5E5E5E;">=</span> tl.Branch(bl_add1, <span class="va" style="color: #111111;">None</span>)</span>
<span id="cb13-2">bl_2ops([x, n, m])</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="8">
<pre><code>(array([2]), array([1]), 'n', 'm')</code></pre>
</div>
</div>
</section>
<section id="residual-model" class="level3" data-number="2.2">
<h3 data-number="2.2" class="anchored" data-anchor-id="residual-model"><span class="header-section-number">2.2</span> Residual Model</h3>
<p>let’s write a function ‘MyResidual’, that uses <code>tl.Branch</code> and <code>tl.Add</code> to build a residual layer. If you are curious about the Trax implementation, you can see the code <a href="https://github.com/google/trax/blob/190ec6c3d941d8a9f30422f27ef0c95dc16d2ab1/trax/layers/combinators.py">here</a>.</p>
<div class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb15" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><span class="kw" style="color: #003B4F;">def</span> MyResidual(layer):</span>
<span id="cb15-2">    <span class="cf" style="color: #003B4F;">return</span> tl.Serial(</span>
<span id="cb15-3">        tl.Branch(layer, <span class="va" style="color: #111111;">None</span>),</span>
<span id="cb15-4">        tl.Add(),</span>
<span id="cb15-5">    )</span></code></pre></div>
</div>
<div class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb16" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><span class="co" style="color: #5E5E5E;"># Lets Try it</span></span>
<span id="cb16-2">mr <span class="op" style="color: #5E5E5E;">=</span> MyResidual(bl_add1)</span>
<span id="cb16-3">x <span class="op" style="color: #5E5E5E;">=</span> np.array([<span class="dv" style="color: #AD0000;">1</span>])</span>
<span id="cb16-4">mr([x, n, m])</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="10">
<pre><code>(array([3]), 'n', 'm')</code></pre>
</div>
</div>
<p>Now, let’s build the 4 layer residual Network in Figure 2. We can use <code>MyResidual</code>, or the tl.Residual in Trax, or a combination.</p>
<div class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb18" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1">Fl <span class="op" style="color: #5E5E5E;">=</span> tl.Fn(<span class="st" style="color: #20794D;">"F"</span>, <span class="kw" style="color: #003B4F;">lambda</span> x0: (<span class="dv" style="color: #AD0000;">2</span> <span class="op" style="color: #5E5E5E;">*</span> x0), n_out<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">1</span>)</span>
<span id="cb18-2">Gl <span class="op" style="color: #5E5E5E;">=</span> tl.Fn(<span class="st" style="color: #20794D;">"G"</span>, <span class="kw" style="color: #003B4F;">lambda</span> x0: (<span class="dv" style="color: #AD0000;">10</span> <span class="op" style="color: #5E5E5E;">*</span> x0), n_out<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">1</span>)</span>
<span id="cb18-3">x1 <span class="op" style="color: #5E5E5E;">=</span> np.array([<span class="dv" style="color: #AD0000;">1</span>])</span></code></pre></div>
</div>
<div class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb19" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1">resfg <span class="op" style="color: #5E5E5E;">=</span> tl.Serial(</span>
<span id="cb19-2">    tl.Residual(Fl),  <span class="co" style="color: #5E5E5E;">#Fl    # x + F(x)</span></span>
<span id="cb19-3">    tl.Residual(Gl),  <span class="co" style="color: #5E5E5E;">#Gl    # x + F(x) + G(x + F(x)) etc</span></span>
<span id="cb19-4">    tl.Residual(Fl),  <span class="co" style="color: #5E5E5E;">#Fl</span></span>
<span id="cb19-5">    tl.Residual(Gl),  <span class="co" style="color: #5E5E5E;">#Gl</span></span>
<span id="cb19-6">)</span>
<span id="cb19-7">resfg <span class="op" style="color: #5E5E5E;">=</span> tl.Serial(</span>
<span id="cb19-8">    MyResidual(Fl),  <span class="co" style="color: #5E5E5E;">#Fl    # x + F(x)</span></span>
<span id="cb19-9">    MyResidual(Gl),  <span class="co" style="color: #5E5E5E;">#Gl    # x + F(x) + G(x + F(x)) etc</span></span>
<span id="cb19-10">    MyResidual(Fl),  <span class="co" style="color: #5E5E5E;">#Fl</span></span>
<span id="cb19-11">    MyResidual(Gl),  <span class="co" style="color: #5E5E5E;">#Gl</span></span>
<span id="cb19-12">)    </span></code></pre></div>
</div>
<div class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb20" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><span class="co" style="color: #5E5E5E;"># Lets try it</span></span>
<span id="cb20-2">resfg([x1, n, m])</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="16">
<pre><code>(array([1089]), 'n', 'm')</code></pre>
</div>
</div>
</section>
</section>
<section id="reversible-residual-networks" class="level2" data-number="3">
<h2 data-number="3" class="anchored" data-anchor-id="reversible-residual-networks"><span class="header-section-number">3</span> Reversible Residual Networks</h2>
The Reformer utilized RevNets to reduce the storage requirements for performing backpropagation. <img src="http://livingdatalab.com/posts/https:/github.com/pranath/blog/raw/master/images/Reversible2.png" height="260" width="600">
<center>
<b>Figure 6: Reversible Residual Networks </b>
</center>
<p>The standard approach on the left above requires one to store the outputs of each stage for use during backprop. By using the organization to the right, one need only store the outputs of the last stage, y1, y2 in the diagram. Using those values and running the algorithm in reverse, one can reproduce the values required for backprop. This trades additional computation for memory space which is at a premium with the current generation of GPU’s/TPU’s.</p>
One thing to note is that the forward functions produced by two networks are similar, but they are not equivalent. Note for example the asymmetry in the output equations after two stages of operation. <img src="http://livingdatalab.com/posts/https:/github.com/pranath/blog/raw/master/images/Revnet1.png" height="340" width="1100">
<center>
<b>Figure 7: ‘Normal’ Residual network (Top) vs REversible Residual Network </b>
</center>
<section id="trax-reversible-layers" class="level3" data-number="3.1">
<h3 data-number="3.1" class="anchored" data-anchor-id="trax-reversible-layers"><span class="header-section-number">3.1</span> Trax Reversible Layers</h3>
<p>Let’s take a look at how this is used in the Reformer.</p>
<div class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb22" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1">refm <span class="op" style="color: #5E5E5E;">=</span> trax.models.reformer.ReformerLM(</span>
<span id="cb22-2">    vocab_size<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">33000</span>, n_layers<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">2</span>, mode<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"train"</span>  <span class="co" style="color: #5E5E5E;"># Add more options.</span></span>
<span id="cb22-3">)</span>
<span id="cb22-4">refm</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="17">
<pre><code>Serial[
  Serial[
    ShiftRight(1)
  ]
  Embedding_33000_512
  Dropout
  Serial[
    PositionalEncoding
  ]
  Dup_out2
  ReversibleSerial_in2_out2[
    ReversibleHalfResidualDecoderAttn_in2_out2[
      Serial[
        LayerNorm
      ]
      SelfAttention
    ]
    ReversibleSwap_in2_out2
    ReversibleHalfResidualDecoderFF_in2_out2[
      Serial[
        LayerNorm
        Dense_2048
        Dropout
        Serial[
          FastGelu
        ]
        Dense_512
        Dropout
      ]
    ]
    ReversibleSwap_in2_out2
    ReversibleHalfResidualDecoderAttn_in2_out2[
      Serial[
        LayerNorm
      ]
      SelfAttention
    ]
    ReversibleSwap_in2_out2
    ReversibleHalfResidualDecoderFF_in2_out2[
      Serial[
        LayerNorm
        Dense_2048
        Dropout
        Serial[
          FastGelu
        ]
        Dense_512
        Dropout
      ]
    ]
    ReversibleSwap_in2_out2
  ]
  Concatenate_in2
  LayerNorm
  Dropout
  Serial[
    Dense_33000
  ]
]</code></pre>
</div>
</div>
<p>Eliminating some of the detail, we can see the structure of the network.</p>
<img src="http://livingdatalab.com/posts/https:/github.com/pranath/blog/raw/master/images/Revnet2.png" height="300" width="350">
<center>
<b>Figure 8: Key Structure of Reformer Reversible Network Layers in Trax </b>
</center>
We’ll review the Trax layers used to implement the Reversible section of the Reformer. First we can note that not all of the reformer is reversible. Only the section in the ReversibleSerial layer is reversible. In a large Reformer model, that section is repeated many times making up the majority of the model. <img src="http://livingdatalab.com/posts/https:/github.com/pranath/blog/raw/master/images/Revnet3.png" height="650" width="1600">
<center>
<b>Figure 9: Functional Diagram of Trax elements in Reformer </b>
</center>
<p>The implementation starts by duplicating the input to allow the two paths that are part of the reversible residual organization with <a href="https://github.com/google/trax/blob/190ec6c3d941d8a9f30422f27ef0c95dc16d2ab1/trax/layers/combinators.py#L666">Dup</a>. Note that this is accomplished by copying the top of stack and pushing two copies of it onto the stack. This then feeds into the ReversibleHalfResidual layer which we’ll review in more detail below. This is followed by <a href="https://github.com/google/trax/blob/190ec6c3d941d8a9f30422f27ef0c95dc16d2ab1/trax/layers/reversible.py#L83">ReversibleSwap</a>. As the name implies, this performs a swap, in this case, the two topmost entries in the stack. This pattern is repeated until we reach the end of the ReversibleSerial section. At that point, the topmost 2 entries of the stack represent the two paths through the network. These are concatenated and pushed onto the stack. The result is an entry that is twice the size of the non-reversible version.</p>
Let’s look more closely at the <a href="https://github.com/google/trax/blob/190ec6c3d941d8a9f30422f27ef0c95dc16d2ab1/trax/layers/reversible.py#L154">ReversibleHalfResidual</a>. This layer is responsible for executing the layer or layers provided as arguments and adding the output of those layers, the ‘residual’, to the top of the stack. Below is the ‘forward’ routine which implements this. <img src="http://livingdatalab.com/posts/https:/github.com/pranath/blog/raw/master/images/Revnet4.png" height="650" width="1600">
<center>
<b>Figure 10: ReversibleHalfResidual code and diagram </b>
</center>
<p>Unlike the previous residual function, the value that is added is from the second path rather than the input to the set of sublayers in this layer. Note that the Layers called by the ReversibleHalfResidual forward function are not modified to support reverse functionality. This layer provides them a ‘normal’ view of the stack and takes care of reverse operation.</p>
<p>Let’s try out some of these layers! We’ll start with the ones that just operate on the stack, Dup() and Swap().</p>
<div class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb24" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1">x1 <span class="op" style="color: #5E5E5E;">=</span> np.array([<span class="dv" style="color: #AD0000;">1</span>])</span>
<span id="cb24-2">x2 <span class="op" style="color: #5E5E5E;">=</span> np.array([<span class="dv" style="color: #AD0000;">5</span>])</span>
<span id="cb24-3"><span class="co" style="color: #5E5E5E;"># Dup() duplicates the Top of Stack and returns the stack</span></span>
<span id="cb24-4">dl <span class="op" style="color: #5E5E5E;">=</span> tl.Dup()</span>
<span id="cb24-5">dl(x1)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="18">
<pre><code>(array([1]), array([1]))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="19">
<div class="sourceCode cell-code" id="cb26" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><span class="co" style="color: #5E5E5E;"># ReversibleSwap() duplicates the Top of Stack and returns the stack</span></span>
<span id="cb26-2">sl <span class="op" style="color: #5E5E5E;">=</span> tl.ReversibleSwap()</span>
<span id="cb26-3">sl([x1, x2])</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="19">
<pre><code>(array([5]), array([1]))</code></pre>
</div>
</div>
You are no doubt wondering “How is ReversibleSwap different from Swap?”. Good question! Lets look: <img src="http://livingdatalab.com/posts/https:/github.com/pranath/blog/raw/master/images/Revnet5.png" height="389" width="1000">
<center>
<b>Figure 11: Two versions of Swap() </b>
</center>
<p>The ReverseXYZ functions include a “reverse” compliment to their “forward” function that provides the functionality to run in reverse when doing backpropagation. It can also be run in reverse by simply calling ‘reverse’.</p>
<div class="cell" data-execution_count="20">
<div class="sourceCode cell-code" id="cb28" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><span class="co" style="color: #5E5E5E;"># Demonstrate reverse swap</span></span>
<span id="cb28-2"><span class="bu" style="color: null;">print</span>(x1, x2, sl.reverse([x1, x2]))</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] [5] (array([5]), array([1]))</code></pre>
</div>
</div>
<p>Let’s try ReversibleHalfResidual, First we’ll need some layers..</p>
<div class="cell" data-execution_count="21">
<div class="sourceCode cell-code" id="cb30" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1">Fl <span class="op" style="color: #5E5E5E;">=</span> tl.Fn(<span class="st" style="color: #20794D;">"F"</span>, <span class="kw" style="color: #003B4F;">lambda</span> x0: (<span class="dv" style="color: #AD0000;">2</span> <span class="op" style="color: #5E5E5E;">*</span> x0), n_out<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">1</span>)</span>
<span id="cb30-2">Gl <span class="op" style="color: #5E5E5E;">=</span> tl.Fn(<span class="st" style="color: #20794D;">"G"</span>, <span class="kw" style="color: #003B4F;">lambda</span> x0: (<span class="dv" style="color: #AD0000;">10</span> <span class="op" style="color: #5E5E5E;">*</span> x0), n_out<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">1</span>)</span></code></pre></div>
</div>
<p>Just a note about ReversibleHalfResidual. As this is written, it resides in the Reformer model and is a layer. It is invoked a bit differently than other layers. Rather than tl.XYZ, it is just ReversibleHalfResidual(layers..) as shown below. This may change in the future.</p>
<div class="cell" data-execution_count="22">
<div class="sourceCode cell-code" id="cb31" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1">half_res_F <span class="op" style="color: #5E5E5E;">=</span> ReversibleHalfResidual(Fl)</span>
<span id="cb31-2"><span class="bu" style="color: null;">print</span>(<span class="bu" style="color: null;">type</span>(half_res_F), <span class="st" style="color: #20794D;">"</span><span class="ch" style="color: #20794D;">\n</span><span class="st" style="color: #20794D;">"</span>, half_res_F)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>&lt;class 'trax.layers.reversible.ReversibleHalfResidual'&gt; 
 ReversibleHalfResidual_in2_out2[
  Serial[
    F
  ]
]</code></pre>
</div>
</div>
<div class="cell" data-execution_count="23">
<div class="sourceCode cell-code" id="cb33" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1">half_res_F([x1, x1])  <span class="co" style="color: #5E5E5E;"># this is going to produce an error - why?</span></span></code></pre></div>
<div class="cell-output cell-output-error">
<pre><code>LayerError: Exception passing through layer ReversibleHalfResidual (in pure_fn):
  layer created in file [...]/&lt;ipython-input-22-7e8a712ea261&gt;, line 1
  layer input shapes: [ShapeDtype{shape:(1,), dtype:int64}, ShapeDtype{shape:(1,), dtype:int64}]

  File [...]/trax/layers/base.py, line 707, in __setattr__
    super().__setattr__(attr, value)

  File [...]/trax/layers/base.py, line 454, in weights
    f'Number of weight elements ({len(weights)}) does not equal the '

ValueError: Number of weight elements (0) does not equal the number of sublayers (1) in: ReversibleHalfResidual_in2_out2[
  Serial[

    F
  ]

].</code></pre>
</div>
</div>
<div class="cell" data-execution_count="24">
<div class="sourceCode cell-code" id="cb35" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><span class="co" style="color: #5E5E5E;"># we have to initialize the ReversibleHalfResidual layer to let it know what the input is going to look like</span></span>
<span id="cb35-2">half_res_F.init(shapes.signature([x1, x1]))</span>
<span id="cb35-3">half_res_F([x1, x1])</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="24">
<pre><code>(array([3]), array([1]))</code></pre>
</div>
</div>
<p>The final layer we need is the ReversibleSerial Layer. This is the reversible equivalent of the Serial layer and is used in the same manner to build a sequence of layers.</p>
</section>
<section id="build-a-reversible-model" class="level3" data-number="3.2">
<h3 data-number="3.2" class="anchored" data-anchor-id="build-a-reversible-model"><span class="header-section-number">3.2</span> Build a reversible model</h3>
We now have all the layers we need to build the model shown below. Let’s build it in two parts. First we’ll build ‘blk’ and then a list of blk’s. And then ‘mod’.
<center>
<img src="http://livingdatalab.com/posts/https:/github.com/pranath/blog/raw/master/images/Revnet6.png" height="800" width="1600">
</center>
<center>
<b>Figure 12: Reversible Model we will build using Trax components </b>
</center>
<div class="cell" data-execution_count="25">
<div class="sourceCode cell-code" id="cb37" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb37-1">blk <span class="op" style="color: #5E5E5E;">=</span> [  <span class="co" style="color: #5E5E5E;"># a list of the 4 layers shown above</span></span>
<span id="cb37-2">    ReversibleHalfResidual(Fl),</span>
<span id="cb37-3">    tl.ReversibleSwap(),</span>
<span id="cb37-4">    ReversibleHalfResidual(Gl),</span>
<span id="cb37-5">    tl.ReversibleSwap(),</span>
<span id="cb37-6">]</span>
<span id="cb37-7">blks <span class="op" style="color: #5E5E5E;">=</span> [blk, blk]</span></code></pre></div>
</div>
<div class="cell" data-execution_count="26">
<div class="sourceCode cell-code" id="cb38" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb38-1">mod <span class="op" style="color: #5E5E5E;">=</span> tl.Serial(</span>
<span id="cb38-2">    tl.Dup(),</span>
<span id="cb38-3">    blks,</span>
<span id="cb38-4">    tl.Concatenate(),</span>
<span id="cb38-5">)</span>
<span id="cb38-6">mod   </span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="26">
<pre><code>Serial[
  Dup_out2
  ReversibleHalfResidual_in2_out2[
    Serial[
      F
    ]
  ]
  ReversibleSwap_in2_out2
  ReversibleHalfResidual_in2_out2[
    Serial[
      G
    ]
  ]
  ReversibleSwap_in2_out2
  ReversibleHalfResidual_in2_out2[
    Serial[
      F
    ]
  ]
  ReversibleSwap_in2_out2
  ReversibleHalfResidual_in2_out2[
    Serial[
      G
    ]
  ]
  ReversibleSwap_in2_out2
  Concatenate_in2
]</code></pre>
</div>
</div>
<div class="cell" data-execution_count="27">
<div class="sourceCode cell-code" id="cb40" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb40-1">mod.init(shapes.signature(x1))</span>
<span id="cb40-2">out <span class="op" style="color: #5E5E5E;">=</span> mod(x1)</span>
<span id="cb40-3">out</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="27">
<pre><code>DeviceArray([ 65, 681], dtype=int32)</code></pre>
</div>
</div>
</section>
</section>
<section id="acknowledgements" class="level2" data-number="4">
<h2 data-number="4" class="anchored" data-anchor-id="acknowledgements"><span class="header-section-number">4</span> Acknowledgements</h2>
<p>I’d like to express my thanks to the great <a href="https://www.coursera.org/learn/attention-models-in-nlp">Natural Language Processing with Attention Models Course</a> which i completed, and acknowledge the use of some images and other materials from the course in this article.</p>


</section>

 ]]></description>
  <category>natural-language-processing</category>
  <category>deep-learning</category>
  <guid>http://livingdatalab.com/posts/2023-03-27-reversable-residual-networks-for-transformer-models.html</guid>
  <pubDate>Sun, 26 Mar 2023 23:00:00 GMT</pubDate>
  <media:content url="https://github.com/pranath/blog/raw/master/images/Revnet7.png" medium="image" type="image/png"/>
</item>
<item>
  <title>Making more efficient attention for transformers with reversable layers and Locality Sensitive Hashing (LSH)</title>
  <dc:creator>Pranath Fernando</dc:creator>
  <link>http://livingdatalab.com/posts/2023-03-26-making-more-efficient-transformers-with-reversable-layers-and-lsh.html</link>
  <description><![CDATA[ 




<section id="introduction" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="introduction"><span class="header-section-number">1</span> Introduction</h2>
<p>Two ‘reforms’ can make the Transformer more memory and compute efficient. The <em>Reversible Layers</em> reduce memory and <em>Locality Sensitive Hashing (LSH)</em> reduces the cost of the Dot Product attention for large input sizes. In this article we will look more closely at LSH and how it is used in the Reformer model.</p>
<p>Specifically, we will look at:</p>
<ul>
<li>review dot-product self attention for reference</li>
<li>examine LSH based self attention</li>
<li>extend our understanding and familiarity with Trax infrastructure</li>
</ul>
</section>
<section id="trax-efficient-attention-classes" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="trax-efficient-attention-classes"><span class="header-section-number">2</span> Trax Efficient Attention classes</h2>
<p>Trax is similar to other popular NN development platforms such as Keras (now integrated into Tensorflow) and Pytorch in that it uses ‘layers’ as a useful level of abstraction. Layers are often represented as <em>classes</em>. We’re going to improve our understanding of Trax by locally extending the classes used in the attention layers. We will extend only the ‘forward’ functions and utilize the existing attention layers as parent classes. The original code can be found at <a href="https://github.com/google/trax/blob/v1.3.9/trax/layers/research/efficient_attention.py">github:trax/layers/Research/Efficient_attention</a>. This link references release 1.3.9 but note that this is under the ‘research’ directory as this is an area of active research. When accessing the code on Github for review on this assignment, be sure you select the 1.3.9 release tag, the master copy may have new changes.</p>
<p><img src="http://livingdatalab.com/posts/https:/github.com/pranath/blog/raw/master/images/C4W4_LN2_image11.png" height="250" width="250"></p>
<center>
<b>Figure 1: Reference Tag 1.3.9 on github</b>
</center>
<p>Let’s spend a few moments reviewing the classes we will be using.</p>
<p><img src="http://livingdatalab.com/posts/https:/github.com/pranath/blog/raw/master/images/C4W4_LN2_image1.png" height="788" width="1561"></p>
<center>
<b>Figure 2: Classes from Trax/layers/Research/Efficient_Attention.py that we will be utilizing.</b>
</center>
<p>Starting on the right in the diagram above you see <code>SelfAttention</code> that is a ‘traditional’ implementation of the dot product attention. The parent to this class is the <code>base.layer</code> which has the routines used by all layers. <code>SelfAttention</code> has an important feature in the <em>Forward</em> routine. It supports a <code>use_reference_code</code> capability that selects implementations that limit some of the complexities to provide a more easily understood version of the algorithms. In particular, it implements a nested loop that treats each <em>‘example, head’</em> independently. This simplifies our work as we need only worry about matrix operations on one <em>‘example, head’</em> at a time. This loop calls <em>forward_unbatched</em>, which is the child process that we will be overriding.</p>
<p>We will be implementing the <em>forward_unbatched</em> version of <code>SelfAttention</code> to highlight the differences between this and the LSH implementation.</p>
<p>On the top left is the <code>LSHSelfAttention</code>. This is the routine used in the Reformer architecture. We will override the <em>forward_unbatched</em> section of this and some of the utility functions it uses to explore its implementation in more detail.</p>
<p>The code we will be working with is from the Trax source, and as such has implementation details that will make it a bit harder to follow. However, it will allow use of the results along with the rest of the Trax infrastructure. I will try to briefly describe these as they arise. The <a href="https://trax-ml.readthedocs.io/en/latest/">Trax documentation</a> can also be referenced.</p>
<section id="trax-details" class="level3" data-number="2.1">
<h3 data-number="2.1" class="anchored" data-anchor-id="trax-details"><span class="header-section-number">2.1</span> Trax Details</h3>
<p>The goal in this article is to override a few routines in the Trax classes with our own versions. To maintain their functionality in a full Trax environment, many of the details we might ignore in example version of routines will be maintained in this code. Here are some of the considerations that may impact our code:</p>
<ul>
<li>Trax operates with multiple back-end libraries, we will see special cases that will utilize unique features.</li>
<li>‘Fancy’ numpy indexing is not supported in all backend environments and must be emulated in other ways.</li>
<li>Some operations don’t have gradients for backprop and must be ignored or include forced re-evaluation.</li>
</ul>
<p>Here are some of the functions we may see:</p>
<ul>
<li>Abstracted as <code>fastmath</code>, Trax supports multiple backends such as <a href="https://github.com/google/jax">Jax</a> and <a href="https://github.com/tensorflow/tensorflow">Tensorflow2</a></li>
<li><a href="https://jax.readthedocs.io/en/latest/_autosummary/jax.lax.tie_in.html">tie_in</a>: Some non-numeric operations must be invoked during backpropagation. Normally, the gradient compute graph would determine invocation but these functions are not included. To force re-evaluation, they are ‘tied’ to other numeric operations using tie_in.</li>
<li><a href="https://trax-ml.readthedocs.io/en/latest/trax.fastmath.html">stop_gradient</a>: Some operations are intentionally excluded from backprop gradient calculations by setting their gradients to zero.</li>
<li>Below we will execute <code>from trax.fastmath import numpy as np</code>, this uses accelerated forms of numpy functions. This is, however a <em>subset</em> of numpy</li>
</ul>
<div class="cell" data-tags="[]" data-execution_count="10">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;">import</span> os</span>
<span id="cb1-2"><span class="im" style="color: #00769E;">import</span> trax</span>
<span id="cb1-3"><span class="im" style="color: #00769E;">from</span> trax <span class="im" style="color: #00769E;">import</span> layers <span class="im" style="color: #00769E;">as</span> tl  <span class="co" style="color: #5E5E5E;"># core building block</span></span>
<span id="cb1-4"><span class="im" style="color: #00769E;">import</span> jax</span>
<span id="cb1-5"><span class="im" style="color: #00769E;">from</span> trax <span class="im" style="color: #00769E;">import</span> fastmath  <span class="co" style="color: #5E5E5E;"># uses jax, offers numpy on steroids</span></span>
<span id="cb1-6"></span>
<span id="cb1-7"></span>
<span id="cb1-8"><span class="co" style="color: #5E5E5E;"># fastmath.use_backend('tensorflow-numpy')</span></span>
<span id="cb1-9"><span class="im" style="color: #00769E;">import</span> functools</span>
<span id="cb1-10"><span class="im" style="color: #00769E;">from</span> trax.fastmath <span class="im" style="color: #00769E;">import</span> numpy <span class="im" style="color: #00769E;">as</span> np  <span class="co" style="color: #5E5E5E;"># note, using fastmath subset of numpy!</span></span>
<span id="cb1-11"><span class="im" style="color: #00769E;">from</span> trax.layers <span class="im" style="color: #00769E;">import</span> (</span>
<span id="cb1-12">    <span class="co" style="color: #5E5E5E;">#tie_in,</span></span>
<span id="cb1-13">    length_normalized,</span>
<span id="cb1-14">    apply_broadcasted_dropout,</span>
<span id="cb1-15">    look_adjacent,</span>
<span id="cb1-16">    permute_via_gather,</span>
<span id="cb1-17">    permute_via_sort,</span>
<span id="cb1-18">)</span>
<span id="cb1-19"></span>
<span id="cb1-20"><span class="im" style="color: #00769E;">from</span> jax.lax <span class="im" style="color: #00769E;">import</span> tie_in</span></code></pre></div>
</div>
</section>
</section>
<section id="full-dot-product-self-attention" class="level2" data-number="3">
<h2 data-number="3" class="anchored" data-anchor-id="full-dot-product-self-attention"><span class="header-section-number">3</span> Full Dot-Product Self Attention</h2>
<section id="description" class="level3" data-number="3.1">
<h3 data-number="3.1" class="anchored" data-anchor-id="description"><span class="header-section-number">3.1</span> Description</h3>
<p><img src="http://livingdatalab.com/posts/https:/github.com/pranath/blog/raw/master/images/C4W4_LN2_image2.png" height="200" width="600"></p>
<center>
<b>Figure 3: Project datapath and primary data structures and where they are implemented</b>
</center>
<p>The diagram above shows many of the familiar data structures and operations related to attention and describes the routines in which they are implemented. We will start by working on <em>our_simple_attend</em> or our simpler version of the original <em>attend</em> function. We will review the steps in performing dot-product attention with more focus on the details of the operations and their significance. This is useful when comparing to LSH attention. Note we will be discussing a single example/head unless otherwise specified.</p>
<p><img src="http://livingdatalab.com/posts/https:/github.com/pranath/blog/raw/master/images/C4W4_LN2_image3.png" height="250" width="700"></p>
<center>
<b>Figure 4: dot-product of Query and Key</b>
</center>
<p>The <em>attend</em> function receives <em>Query</em> and <em>Key</em>. As a reminder, they are produced by a matrix multiply of all the inputs with a single set of weights. We will describe the inputs as <em>embeddings</em> assuming an NLP application, however, this is not required. This matrix multiply works very much like a convolutional network where a set of weights (a filter) slides across the input vectors leaving behind a map of the similarity of the input to the filter. In this case, the filters are the weight matrices <img src="https://latex.codecogs.com/png.latex?W%5EQ"> and <img src="https://latex.codecogs.com/png.latex?W%5EK">. The resulting maps are Q and K. Q and K have the dimensions of (n_seq, n_q) where n_seq is the number of input embeddings and n_q or n_k is the selected size of the Q or K vectors. Note the shading of Q and K, this reflects the fact that each entry is associated with a particular input embedding. You will note later in the code that K is optional. Apparently, similar results can be achieved using Query alone saving the compute and storage associated with K. In that case, the dot-product in <em>attend</em> is matmul(q,q). Note the resulting dot-product (<em>Dot</em>) entries describe a complete (n_seq,n_seq) map of the similarity of all entries of q vs all entries of k. This is reflected in the notation in the dot-product boxes of <img src="https://latex.codecogs.com/png.latex?w_n">,<img src="https://latex.codecogs.com/png.latex?w_m"> representing word_n, word_m. Note that each row of <em>Dot</em> describes the relationship of an input embedding, say <img src="https://latex.codecogs.com/png.latex?w_0">, with every other input.</p>
<p>In some applications some values are masked. This can be used, for example to exclude results that occur later in time (causal) or to mask padding or other inputs. <img src="http://livingdatalab.com/posts/https:/github.com/pranath/blog/raw/master/images/C4W4_LN2_image4.png" height="300" width="900"></p>
<center>
<b>Figure 5: Masking</b>
</center>
<p>The routine below <em>mask_self_attention</em> implements a flexible masking capability. The masking is controlled by the information in q_info and kv_info.</p>
<div class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="kw" style="color: #003B4F;">def</span> mask_self_attention(</span>
<span id="cb2-2">    dots, q_info, kv_info, causal<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>, exclude_self<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>, masked<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">False</span></span>
<span id="cb2-3">):</span>
<span id="cb2-4">    <span class="co" style="color: #5E5E5E;">"""Performs masking for self-attention."""</span></span>
<span id="cb2-5">    <span class="cf" style="color: #003B4F;">if</span> causal:</span>
<span id="cb2-6">        mask <span class="op" style="color: #5E5E5E;">=</span> fastmath.lt(q_info, kv_info).astype(np.float32)</span>
<span id="cb2-7">        dots <span class="op" style="color: #5E5E5E;">=</span> dots <span class="op" style="color: #5E5E5E;">-</span> <span class="fl" style="color: #AD0000;">1e9</span> <span class="op" style="color: #5E5E5E;">*</span> mask</span>
<span id="cb2-8">    <span class="cf" style="color: #003B4F;">if</span> exclude_self:</span>
<span id="cb2-9">        mask <span class="op" style="color: #5E5E5E;">=</span> np.equal(q_info, kv_info).astype(np.float32)</span>
<span id="cb2-10">        dots <span class="op" style="color: #5E5E5E;">=</span> dots <span class="op" style="color: #5E5E5E;">-</span> <span class="fl" style="color: #AD0000;">1e5</span> <span class="op" style="color: #5E5E5E;">*</span> mask</span>
<span id="cb2-11">    <span class="cf" style="color: #003B4F;">if</span> masked:</span>
<span id="cb2-12">        zeros_like_kv_info <span class="op" style="color: #5E5E5E;">=</span> tie_in(kv_info, np.zeros_like(kv_info))</span>
<span id="cb2-13">        mask <span class="op" style="color: #5E5E5E;">=</span> fastmath.lt(kv_info, zeros_like_kv_info).astype(np.float32)</span>
<span id="cb2-14">        dots <span class="op" style="color: #5E5E5E;">=</span> dots <span class="op" style="color: #5E5E5E;">-</span> <span class="fl" style="color: #AD0000;">1e9</span> <span class="op" style="color: #5E5E5E;">*</span> mask</span>
<span id="cb2-15">    <span class="cf" style="color: #003B4F;">return</span> dots</span></code></pre></div>
</div>
<p>A SoftMax is applied per row of the <em>Dot</em> matrix to scale the values in the row between 0 and 1. <img src="http://livingdatalab.com/posts/https:/github.com/pranath/blog/raw/master/images/C4W4_LN2_image5.png" height="300" width="900"></p>
<center>
<b>Figure 6: SoftMax per row of Dot</b>
</center>
</section>
<section id="our_softmax" class="level3" data-number="3.2">
<h3 data-number="3.2" class="anchored" data-anchor-id="our_softmax"><span class="header-section-number">3.2</span> our_softmax</h3>
<p>This code uses a separable form of the softmax calculation. Recall the softmax: <img src="https://latex.codecogs.com/png.latex?%20softmax(x_i)=%5Cfrac%7B%5Cexp(x_i)%7D%7B%5Csum_j%20%5Cexp(x_j)%7D%5Ctag%7B1%7D"> This can be alternately implemented as: <img src="https://latex.codecogs.com/png.latex?%20logsumexp(x)=%5Clog%7B(%7B%5Csum_j%20%5Cexp(x_j)%7D)%7D%5Ctag%7B2%7D"> <img src="https://latex.codecogs.com/png.latex?%20softmax(x_i)=%5Cexp(%7Bx_i%20-%20logsumexp(x)%7D)%5Ctag%7B3%7D"> The work below will maintain a copy of the logsumexp allowing the softmax to be completed in sections. You will see how this is useful later in the LSHSelfAttention class. We’ll create a routine to implement that here with the addition of a passthrough. The matrix operations we will be working on below are easier to follow if we can maintain integer values. So, for tests, we will skip the softmax in some cases.</p>
<div class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><span class="kw" style="color: #003B4F;">def</span> our_softmax(x, passthrough<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">False</span>):</span>
<span id="cb3-2">    <span class="co" style="color: #5E5E5E;">""" softmax with passthrough"""</span></span>
<span id="cb3-3">    logsumexp <span class="op" style="color: #5E5E5E;">=</span> fastmath.logsumexp(x, axis<span class="op" style="color: #5E5E5E;">=-</span><span class="dv" style="color: #AD0000;">1</span>, keepdims<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>)</span>
<span id="cb3-4">    o <span class="op" style="color: #5E5E5E;">=</span> np.exp(x <span class="op" style="color: #5E5E5E;">-</span> logsumexp)</span>
<span id="cb3-5">    <span class="cf" style="color: #003B4F;">if</span> passthrough:</span>
<span id="cb3-6">        <span class="cf" style="color: #003B4F;">return</span> (x, np.zeros_like(logsumexp))</span>
<span id="cb3-7">    <span class="cf" style="color: #003B4F;">else</span>:</span>
<span id="cb3-8">        <span class="cf" style="color: #003B4F;">return</span> (o, logsumexp)</span></code></pre></div>
</div>
<p>Let’s check our implementation.</p>
<div class="cell" data-tags="[]" data-execution_count="13">
<div class="sourceCode cell-code" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><span class="co" style="color: #5E5E5E;">## compare softmax(a) using both methods</span></span>
<span id="cb4-2">a <span class="op" style="color: #5E5E5E;">=</span> np.array([<span class="fl" style="color: #AD0000;">1.0</span>, <span class="fl" style="color: #AD0000;">2.0</span>, <span class="fl" style="color: #AD0000;">3.0</span>, <span class="fl" style="color: #AD0000;">4.0</span>])</span>
<span id="cb4-3">sma <span class="op" style="color: #5E5E5E;">=</span> np.exp(a) <span class="op" style="color: #5E5E5E;">/</span> <span class="bu" style="color: null;">sum</span>(np.exp(a))</span>
<span id="cb4-4"><span class="bu" style="color: null;">print</span>(sma)</span>
<span id="cb4-5">sma2, a_logsumexp <span class="op" style="color: #5E5E5E;">=</span> our_softmax(a)</span>
<span id="cb4-6"><span class="bu" style="color: null;">print</span>(sma2)</span>
<span id="cb4-7"><span class="bu" style="color: null;">print</span>(a_logsumexp)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[0.0320586  0.08714432 0.2368828  0.6439142 ]
[0.0320586  0.08714431 0.23688279 0.64391416]
[4.44019]</code></pre>
</div>
</div>
<p>The purpose of the dot-product is to ‘focus attention’ on some of the inputs. Dot now has entries appropriately scaled to enhance some values and reduce others. These are now applied to the <img src="https://latex.codecogs.com/png.latex?V"> entries. <img src="http://livingdatalab.com/posts/https:/github.com/pranath/blog/raw/master/images/C4W4_LN2_image6.png" height="300" width="900"></p>
<center>
<b>Figure 7: Applying Attention to <img src="https://latex.codecogs.com/png.latex?V"></b>
</center>
<p><img src="https://latex.codecogs.com/png.latex?V"> is of size (n_seq,n_v). Note the shading in the diagram. This is to draw attention to the operation of the matrix multiplication. This is detailed below.</p>
<p><img src="http://livingdatalab.com/posts/https:/github.com/pranath/blog/raw/master/images/C4W4_LN2_image7.png" height="300" width="600"></p>
<center>
<b>Figure 7: The Matrix Multiply applies attention to the values of V</b>
</center>
<p><img src="https://latex.codecogs.com/png.latex?V"> is formed by a matrix multiply of the input embedding with the weight matrix <img src="https://latex.codecogs.com/png.latex?W%5Ev"> whose values were set by backpropagation. The row entries of <img src="https://latex.codecogs.com/png.latex?V"> are then related to the corresponding input embedding. The matrix multiply weights first column of V, representing a section of each of the input embeddings, with the first row of Dot, representing the similarity of <img src="https://latex.codecogs.com/png.latex?W_0"> and each word of the input embedding and deposits the value in <img src="https://latex.codecogs.com/png.latex?Z"></p>
</section>
<section id="our_simple_attend" class="level3" data-number="3.3">
<h3 data-number="3.3" class="anchored" data-anchor-id="our_simple_attend"><span class="header-section-number">3.3</span> our_simple_attend</h3>
<p>In this section we’ll work on an implementation of <em>attend</em> whose operations you can see in figure 3. It is a slightly simplified version of the routine in <a href="https://github.com/google/trax/blob/v1.3.4/trax/layers/research/efficient_attention.py">efficient_attention.py</a>. We will fill in a few lines of code. The main goal is to become familiar with the routine.</p>
<div class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><span class="kw" style="color: #003B4F;">def</span> our_simple_attend(</span>
<span id="cb6-2">    q,</span>
<span id="cb6-3">    k<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">None</span>,</span>
<span id="cb6-4">    v<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">None</span>,</span>
<span id="cb6-5">    mask_fn<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">None</span>,</span>
<span id="cb6-6">    q_info<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">None</span>,</span>
<span id="cb6-7">    kv_info<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">None</span>,</span>
<span id="cb6-8">    dropout<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">0.0</span>,</span>
<span id="cb6-9">    rng<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">None</span>,</span>
<span id="cb6-10">    verbose<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">False</span>,</span>
<span id="cb6-11">    passthrough<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">False</span>,</span>
<span id="cb6-12">):</span>
<span id="cb6-13">    <span class="co" style="color: #5E5E5E;">"""Dot-product attention,  with masking, without optional chunking and/or.</span></span>
<span id="cb6-14"></span>
<span id="cb6-15"><span class="co" style="color: #5E5E5E;">  Args:</span></span>
<span id="cb6-16"><span class="co" style="color: #5E5E5E;">    q: Query vectors, shape [q_len, d_qk]</span></span>
<span id="cb6-17"><span class="co" style="color: #5E5E5E;">    k: Key vectors, shape [kv_len, d_qk]; or None</span></span>
<span id="cb6-18"><span class="co" style="color: #5E5E5E;">    v: Value vectors, shape [kv_len, d_v]</span></span>
<span id="cb6-19"><span class="co" style="color: #5E5E5E;">    mask_fn: a function reference that implements masking (e.g. mask_self_attention)</span></span>
<span id="cb6-20"><span class="co" style="color: #5E5E5E;">    q_info: Query-associated metadata for masking</span></span>
<span id="cb6-21"><span class="co" style="color: #5E5E5E;">    kv_info: Key-associated metadata for masking</span></span>
<span id="cb6-22"><span class="co" style="color: #5E5E5E;">    dropout: Dropout rate</span></span>
<span id="cb6-23"><span class="co" style="color: #5E5E5E;">    rng: RNG for dropout</span></span>
<span id="cb6-24"></span>
<span id="cb6-25"><span class="co" style="color: #5E5E5E;">  Returns:</span></span>
<span id="cb6-26"><span class="co" style="color: #5E5E5E;">    A tuple (output, dots_logsumexp). The output has shape [q_len, d_v], and</span></span>
<span id="cb6-27"><span class="co" style="color: #5E5E5E;">    dots_logsumexp has shape [q_len]. The logsumexp of the attention</span></span>
<span id="cb6-28"><span class="co" style="color: #5E5E5E;">    probabilities is useful for combining multiple rounds of attention (as in</span></span>
<span id="cb6-29"><span class="co" style="color: #5E5E5E;">    LSH attention).</span></span>
<span id="cb6-30"><span class="co" style="color: #5E5E5E;">  """</span></span>
<span id="cb6-31">    <span class="cf" style="color: #003B4F;">assert</span> v <span class="kw" style="color: #003B4F;">is</span> <span class="kw" style="color: #003B4F;">not</span> <span class="va" style="color: #111111;">None</span></span>
<span id="cb6-32">    share_qk <span class="op" style="color: #5E5E5E;">=</span> k <span class="kw" style="color: #003B4F;">is</span> <span class="va" style="color: #111111;">None</span></span>
<span id="cb6-33">    <span class="cf" style="color: #003B4F;">if</span> share_qk:</span>
<span id="cb6-34">        k <span class="op" style="color: #5E5E5E;">=</span> q</span>
<span id="cb6-35">        <span class="cf" style="color: #003B4F;">if</span> kv_info <span class="kw" style="color: #003B4F;">is</span> <span class="va" style="color: #111111;">None</span>:</span>
<span id="cb6-36">            kv_info <span class="op" style="color: #5E5E5E;">=</span> q_info</span>
<span id="cb6-37"></span>
<span id="cb6-38">    <span class="cf" style="color: #003B4F;">if</span> share_qk:</span>
<span id="cb6-39">        k <span class="op" style="color: #5E5E5E;">=</span> length_normalized(k)</span>
<span id="cb6-40">    k <span class="op" style="color: #5E5E5E;">=</span> k <span class="op" style="color: #5E5E5E;">/</span> np.sqrt(k.shape[<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>])</span>
<span id="cb6-41"></span>
<span id="cb6-42">    <span class="co" style="color: #5E5E5E;"># Dot-product attention.</span></span>
<span id="cb6-43">    kr <span class="op" style="color: #5E5E5E;">=</span> np.swapaxes(k, <span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>, <span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">2</span>)  <span class="co" style="color: #5E5E5E;"># note the fancy transpose for later..</span></span>
<span id="cb6-44"></span>
<span id="cb6-45">    <span class="co" style="color: #5E5E5E;">## Step 1  ##</span></span>
<span id="cb6-46">    dots <span class="op" style="color: #5E5E5E;">=</span> np.matmul(q, kr )</span>
<span id="cb6-47">    <span class="cf" style="color: #003B4F;">if</span> verbose:</span>
<span id="cb6-48">        <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">"Our attend dots"</span>, dots.shape)</span>
<span id="cb6-49"></span>
<span id="cb6-50">    <span class="co" style="color: #5E5E5E;"># Masking</span></span>
<span id="cb6-51">    <span class="cf" style="color: #003B4F;">if</span> mask_fn <span class="kw" style="color: #003B4F;">is</span> <span class="kw" style="color: #003B4F;">not</span> <span class="va" style="color: #111111;">None</span>:</span>
<span id="cb6-52">        dots <span class="op" style="color: #5E5E5E;">=</span> mask_fn(dots, q_info[..., :, <span class="va" style="color: #111111;">None</span>], kv_info[..., <span class="va" style="color: #111111;">None</span>, :])</span>
<span id="cb6-53"></span>
<span id="cb6-54">    <span class="co" style="color: #5E5E5E;"># Softmax.</span></span>
<span id="cb6-55">    <span class="co" style="color: #5E5E5E;"># dots_logsumexp = fastmath.logsumexp(dots, axis=-1, keepdims=True)  #original</span></span>
<span id="cb6-56">    <span class="co" style="color: #5E5E5E;"># dots = np.exp(dots - dots_logsumexp)  #original</span></span>
<span id="cb6-57">    <span class="co" style="color: #5E5E5E;">## Step 2  ##</span></span>
<span id="cb6-58">    <span class="co" style="color: #5E5E5E;"># replace with our_softmax()</span></span>
<span id="cb6-59">    dots, dots_logsumexp <span class="op" style="color: #5E5E5E;">=</span> our_softmax(dots, passthrough<span class="op" style="color: #5E5E5E;">=</span>passthrough)</span>
<span id="cb6-60">    <span class="cf" style="color: #003B4F;">if</span> verbose:</span>
<span id="cb6-61">        <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">"Our attend dots post softmax"</span>, dots.shape, dots_logsumexp.shape)</span>
<span id="cb6-62"></span>
<span id="cb6-63">    <span class="cf" style="color: #003B4F;">if</span> dropout <span class="op" style="color: #5E5E5E;">&gt;</span> <span class="fl" style="color: #AD0000;">0.0</span>:</span>
<span id="cb6-64">        <span class="cf" style="color: #003B4F;">assert</span> rng <span class="kw" style="color: #003B4F;">is</span> <span class="kw" style="color: #003B4F;">not</span> <span class="va" style="color: #111111;">None</span></span>
<span id="cb6-65">        <span class="co" style="color: #5E5E5E;"># Dropout is broadcast across the bin dimension</span></span>
<span id="cb6-66">        dropout_shape <span class="op" style="color: #5E5E5E;">=</span> (dots.shape[<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">2</span>], dots.shape[<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>])</span>
<span id="cb6-67">        keep_prob <span class="op" style="color: #5E5E5E;">=</span> tie_in(dots, <span class="fl" style="color: #AD0000;">1.0</span> <span class="op" style="color: #5E5E5E;">-</span> dropout)</span>
<span id="cb6-68">        keep <span class="op" style="color: #5E5E5E;">=</span> fastmath.random.bernoulli(rng, keep_prob, dropout_shape)</span>
<span id="cb6-69">        multiplier <span class="op" style="color: #5E5E5E;">=</span> keep.astype(dots.dtype) <span class="op" style="color: #5E5E5E;">/</span> tie_in(keep, keep_prob)</span>
<span id="cb6-70">        dots <span class="op" style="color: #5E5E5E;">=</span> dots <span class="op" style="color: #5E5E5E;">*</span> multiplier</span>
<span id="cb6-71"></span>
<span id="cb6-72">    <span class="co" style="color: #5E5E5E;">## Step 3  ##</span></span>
<span id="cb6-73">    <span class="co" style="color: #5E5E5E;"># The softmax normalizer (dots_logsumexp) is used by multi-round LSH attn.</span></span>
<span id="cb6-74">    out <span class="op" style="color: #5E5E5E;">=</span> np.matmul(dots, v)</span>
<span id="cb6-75">    <span class="cf" style="color: #003B4F;">if</span> verbose:</span>
<span id="cb6-76">        <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">"Our attend out1"</span>, out.shape)</span>
<span id="cb6-77">    out <span class="op" style="color: #5E5E5E;">=</span> np.reshape(out, (<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>, out.shape[<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>]))</span>
<span id="cb6-78">    <span class="cf" style="color: #003B4F;">if</span> verbose:</span>
<span id="cb6-79">        <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">"Our attend out2"</span>, out.shape)</span>
<span id="cb6-80">    dots_logsumexp <span class="op" style="color: #5E5E5E;">=</span> np.reshape(dots_logsumexp, (<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>,))</span>
<span id="cb6-81">    <span class="cf" style="color: #003B4F;">return</span> out, dots_logsumexp</span></code></pre></div>
</div>
<div class="cell" data-outputid="58a8974e-e3c8-4ec7-92a0-530df96d6d71" data-execution_count="15">
<div class="sourceCode cell-code" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1">seq_len <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">8</span></span>
<span id="cb7-2">emb_len <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">5</span></span>
<span id="cb7-3">d_qk <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">3</span></span>
<span id="cb7-4">d_v <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">4</span></span>
<span id="cb7-5"><span class="cf" style="color: #003B4F;">with</span> fastmath.use_backend(<span class="st" style="color: #20794D;">"jax"</span>):  <span class="co" style="color: #5E5E5E;"># specify the backend for consistency</span></span>
<span id="cb7-6">    rng_attend <span class="op" style="color: #5E5E5E;">=</span> fastmath.random.get_prng(<span class="dv" style="color: #AD0000;">1</span>)</span>
<span id="cb7-7">    q <span class="op" style="color: #5E5E5E;">=</span> k <span class="op" style="color: #5E5E5E;">=</span> jax.random.uniform(rng_attend, (seq_len, d_qk), dtype<span class="op" style="color: #5E5E5E;">=</span>np.float32)</span>
<span id="cb7-8">    v <span class="op" style="color: #5E5E5E;">=</span> jax.random.uniform(rng_attend, (seq_len, d_v), dtype<span class="op" style="color: #5E5E5E;">=</span>np.float32)</span>
<span id="cb7-9">    o, logits <span class="op" style="color: #5E5E5E;">=</span> our_simple_attend(</span>
<span id="cb7-10">        q,</span>
<span id="cb7-11">        k,</span>
<span id="cb7-12">        v,</span>
<span id="cb7-13">        mask_fn<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">None</span>,</span>
<span id="cb7-14">        q_info<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">None</span>,</span>
<span id="cb7-15">        kv_info<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">None</span>,</span>
<span id="cb7-16">        dropout<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">0.0</span>,</span>
<span id="cb7-17">        rng<span class="op" style="color: #5E5E5E;">=</span>rng_attend,</span>
<span id="cb7-18">        verbose<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>,</span>
<span id="cb7-19">    )</span>
<span id="cb7-20"><span class="bu" style="color: null;">print</span>(o, <span class="st" style="color: #20794D;">"</span><span class="ch" style="color: #20794D;">\n</span><span class="st" style="color: #20794D;">"</span>, logits)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Our attend dots (8, 8)
Our attend dots post softmax (8, 8) (8, 1)
Our attend out1 (8, 4)
Our attend out2 (8, 4)
[[0.5606322  0.7290603  0.52512413 0.47101063]
 [0.5713517  0.71991956 0.5033342  0.46975708]
 [0.5622886  0.7288458  0.52172124 0.46318397]
 [0.55683166 0.72234154 0.542236   0.46997216]
 [0.56504494 0.72274375 0.5204978  0.47231334]
 [0.56175965 0.7216782  0.53293145 0.48003793]
 [0.56753993 0.72232544 0.5141734  0.46625748]
 [0.57100445 0.70785505 0.5325362  0.4590797 ]] 
 [2.6512177 2.1914332 2.6630518 2.7792363 2.4583826 2.5421977 2.4145055
 2.5111294]</code></pre>
</div>
</div>
</section>
</section>
<section id="class-ourselfattention" class="level2" data-number="4">
<h2 data-number="4" class="anchored" data-anchor-id="class-ourselfattention"><span class="header-section-number">4</span> Class OurSelfAttention</h2>
<p>Here we create our own self attention layer by creating a class <code>OurSelfAttention</code>. The parent class will be the tl.SelfAttention layer in Trax. We will only override the <code>forward_unbatched</code> routine.</p>
<div class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><span class="kw" style="color: #003B4F;">class</span> OurSelfAttention(tl.SelfAttention):</span>
<span id="cb9-2">    <span class="co" style="color: #5E5E5E;">"""Our self-attention. Just the Forward Function."""</span></span>
<span id="cb9-3"></span>
<span id="cb9-4">    <span class="kw" style="color: #003B4F;">def</span> forward_unbatched(</span>
<span id="cb9-5">        <span class="va" style="color: #111111;">self</span>, x, mask<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">None</span>, <span class="op" style="color: #5E5E5E;">*</span>, weights, state, rng, update_state, verbose<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">False</span></span>
<span id="cb9-6">    ):</span>
<span id="cb9-7">        <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">"ourSelfAttention:forward_unbatched"</span>)</span>
<span id="cb9-8">        <span class="kw" style="color: #003B4F;">del</span> update_state</span>
<span id="cb9-9">        attend_rng, output_rng <span class="op" style="color: #5E5E5E;">=</span> fastmath.random.split(rng)</span>
<span id="cb9-10">        <span class="cf" style="color: #003B4F;">if</span> <span class="va" style="color: #111111;">self</span>._bias:</span>
<span id="cb9-11">            <span class="cf" style="color: #003B4F;">if</span> <span class="va" style="color: #111111;">self</span>._share_qk:</span>
<span id="cb9-12">                w_q, w_v, w_o, b_q, b_v <span class="op" style="color: #5E5E5E;">=</span> weights</span>
<span id="cb9-13">            <span class="cf" style="color: #003B4F;">else</span>:</span>
<span id="cb9-14">                w_q, w_k, w_v, w_o, b_q, b_k, b_v <span class="op" style="color: #5E5E5E;">=</span> weights</span>
<span id="cb9-15">        <span class="cf" style="color: #003B4F;">else</span>:</span>
<span id="cb9-16">            <span class="cf" style="color: #003B4F;">if</span> <span class="va" style="color: #111111;">self</span>._share_qk:</span>
<span id="cb9-17">                w_q, w_v, w_o <span class="op" style="color: #5E5E5E;">=</span> weights</span>
<span id="cb9-18">            <span class="cf" style="color: #003B4F;">else</span>:</span>
<span id="cb9-19">                w_q, w_k, w_v, w_o <span class="op" style="color: #5E5E5E;">=</span> weights</span>
<span id="cb9-20"></span>
<span id="cb9-21">        <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">"x.shape,w_q.shape"</span>, x.shape, w_q.shape)</span>
<span id="cb9-22">        q <span class="op" style="color: #5E5E5E;">=</span> np.matmul(x, w_q)</span>
<span id="cb9-23">        k <span class="op" style="color: #5E5E5E;">=</span> <span class="va" style="color: #111111;">None</span></span>
<span id="cb9-24">        <span class="cf" style="color: #003B4F;">if</span> <span class="kw" style="color: #003B4F;">not</span> <span class="va" style="color: #111111;">self</span>._share_qk:</span>
<span id="cb9-25">            k <span class="op" style="color: #5E5E5E;">=</span> np.matmul(x, w_k)</span>
<span id="cb9-26">        v <span class="op" style="color: #5E5E5E;">=</span> np.matmul(x, w_v)</span>
<span id="cb9-27"></span>
<span id="cb9-28">        <span class="cf" style="color: #003B4F;">if</span> <span class="va" style="color: #111111;">self</span>._bias:</span>
<span id="cb9-29">            q <span class="op" style="color: #5E5E5E;">=</span> q <span class="op" style="color: #5E5E5E;">+</span> b_q</span>
<span id="cb9-30">            <span class="cf" style="color: #003B4F;">if</span> <span class="kw" style="color: #003B4F;">not</span> <span class="va" style="color: #111111;">self</span>._share_qk:</span>
<span id="cb9-31">                k <span class="op" style="color: #5E5E5E;">=</span> k <span class="op" style="color: #5E5E5E;">+</span> b_k</span>
<span id="cb9-32">            v <span class="op" style="color: #5E5E5E;">=</span> v <span class="op" style="color: #5E5E5E;">+</span> b_v</span>
<span id="cb9-33"></span>
<span id="cb9-34">        mask_fn <span class="op" style="color: #5E5E5E;">=</span> functools.partial(</span>
<span id="cb9-35">            mask_self_attention,</span>
<span id="cb9-36">            causal<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">self</span>._causal,</span>
<span id="cb9-37">            exclude_self<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">self</span>._share_qk,</span>
<span id="cb9-38">            masked<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">self</span>._masked,</span>
<span id="cb9-39">        )</span>
<span id="cb9-40">        q_info <span class="op" style="color: #5E5E5E;">=</span> kv_info <span class="op" style="color: #5E5E5E;">=</span> tie_in(x, np.arange(q.shape[<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">2</span>], dtype<span class="op" style="color: #5E5E5E;">=</span>np.int32))</span>
<span id="cb9-41"></span>
<span id="cb9-42">        <span class="cf" style="color: #003B4F;">assert</span> (mask <span class="kw" style="color: #003B4F;">is</span> <span class="kw" style="color: #003B4F;">not</span> <span class="va" style="color: #111111;">None</span>) <span class="op" style="color: #5E5E5E;">==</span> <span class="va" style="color: #111111;">self</span>._masked</span>
<span id="cb9-43">        <span class="cf" style="color: #003B4F;">if</span> <span class="va" style="color: #111111;">self</span>._masked:</span>
<span id="cb9-44">            <span class="co" style="color: #5E5E5E;"># mask is a boolean array (True means "is valid token")</span></span>
<span id="cb9-45">            ones_like_mask <span class="op" style="color: #5E5E5E;">=</span> tie_in(x, np.ones_like(mask, dtype<span class="op" style="color: #5E5E5E;">=</span>np.int32))</span>
<span id="cb9-46">            kv_info <span class="op" style="color: #5E5E5E;">=</span> kv_info <span class="op" style="color: #5E5E5E;">*</span> np.where(mask, ones_like_mask, <span class="op" style="color: #5E5E5E;">-</span>ones_like_mask)</span>
<span id="cb9-47"></span>
<span id="cb9-48">        <span class="co" style="color: #5E5E5E;"># Notice, we are calling our version of attend</span></span>
<span id="cb9-49">        o, _ <span class="op" style="color: #5E5E5E;">=</span> our_simple_attend(</span>
<span id="cb9-50">            q,</span>
<span id="cb9-51">            k,</span>
<span id="cb9-52">            v,</span>
<span id="cb9-53">            mask_fn<span class="op" style="color: #5E5E5E;">=</span>mask_fn,</span>
<span id="cb9-54">            q_info<span class="op" style="color: #5E5E5E;">=</span>q_info,</span>
<span id="cb9-55">            kv_info<span class="op" style="color: #5E5E5E;">=</span>kv_info,</span>
<span id="cb9-56">            dropout<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">self</span>._attention_dropout,</span>
<span id="cb9-57">            rng<span class="op" style="color: #5E5E5E;">=</span>attend_rng,</span>
<span id="cb9-58">            verbose<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>,</span>
<span id="cb9-59">        )</span>
<span id="cb9-60"></span>
<span id="cb9-61">        <span class="co" style="color: #5E5E5E;"># Notice, wo weight matrix applied to output of attend in forward_unbatched</span></span>
<span id="cb9-62">        out <span class="op" style="color: #5E5E5E;">=</span> np.matmul(o, w_o)</span>
<span id="cb9-63">        out <span class="op" style="color: #5E5E5E;">=</span> apply_broadcasted_dropout(out, <span class="va" style="color: #111111;">self</span>._output_dropout, output_rng)</span>
<span id="cb9-64">        <span class="cf" style="color: #003B4F;">return</span> out, state</span></code></pre></div>
</div>
<div class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1">causal <span class="op" style="color: #5E5E5E;">=</span> <span class="va" style="color: #111111;">False</span></span>
<span id="cb10-2">masked <span class="op" style="color: #5E5E5E;">=</span> <span class="va" style="color: #111111;">False</span></span>
<span id="cb10-3">mask <span class="op" style="color: #5E5E5E;">=</span> <span class="va" style="color: #111111;">None</span></span>
<span id="cb10-4">attention_dropout <span class="op" style="color: #5E5E5E;">=</span> <span class="fl" style="color: #AD0000;">0.0</span></span>
<span id="cb10-5">n_heads <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">3</span></span>
<span id="cb10-6">d_qk <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">3</span></span>
<span id="cb10-7">d_v <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">4</span></span>
<span id="cb10-8">seq_len <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">8</span></span>
<span id="cb10-9">emb_len <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">5</span></span>
<span id="cb10-10">batch_size <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">1</span></span>
<span id="cb10-11"></span>
<span id="cb10-12">osa <span class="op" style="color: #5E5E5E;">=</span> OurSelfAttention(</span>
<span id="cb10-13">    n_heads<span class="op" style="color: #5E5E5E;">=</span>n_heads,</span>
<span id="cb10-14">    d_qk<span class="op" style="color: #5E5E5E;">=</span>d_qk,</span>
<span id="cb10-15">    d_v<span class="op" style="color: #5E5E5E;">=</span>d_v,</span>
<span id="cb10-16">    causal<span class="op" style="color: #5E5E5E;">=</span>causal,</span>
<span id="cb10-17">    use_reference_code<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>,</span>
<span id="cb10-18">    attention_dropout<span class="op" style="color: #5E5E5E;">=</span>attention_dropout,</span>
<span id="cb10-19">    mode<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"train"</span>,</span>
<span id="cb10-20">)</span>
<span id="cb10-21"></span>
<span id="cb10-22">rng_osa <span class="op" style="color: #5E5E5E;">=</span> fastmath.random.get_prng(<span class="dv" style="color: #AD0000;">1</span>)</span>
<span id="cb10-23">x <span class="op" style="color: #5E5E5E;">=</span> jax.random.uniform(</span>
<span id="cb10-24">    jax.random.PRNGKey(<span class="dv" style="color: #AD0000;">0</span>), (batch_size, seq_len, emb_len), dtype<span class="op" style="color: #5E5E5E;">=</span>np.float32</span>
<span id="cb10-25">)</span>
<span id="cb10-26">_, _ <span class="op" style="color: #5E5E5E;">=</span> osa.init(tl.shapes.signature(x), rng<span class="op" style="color: #5E5E5E;">=</span>rng_osa)</span></code></pre></div>
</div>
<div class="cell" data-outputid="8a321eb9-09b8-4431-ecad-2290ea2310a3" data-execution_count="18">
<div class="sourceCode cell-code" id="cb11" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1">osa(x)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>ourSelfAttention:forward_unbatched
x.shape,w_q.shape (8, 5) (5, 3)
Our attend dots (8, 8)
Our attend dots post softmax (8, 8) (8, 1)
Our attend out1 (8, 4)
Our attend out2 (8, 4)
ourSelfAttention:forward_unbatched
x.shape,w_q.shape (8, 5) (5, 3)
Our attend dots (8, 8)
Our attend dots post softmax (8, 8) (8, 1)
Our attend out1 (8, 4)
Our attend out2 (8, 4)
ourSelfAttention:forward_unbatched
x.shape,w_q.shape (8, 5) (5, 3)
Our attend dots (8, 8)
Our attend dots post softmax (8, 8) (8, 1)
Our attend out1 (8, 4)
Our attend out2 (8, 4)</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="18">
<pre><code>DeviceArray([[[ 6.70414209e-01, -1.04319841e-01, -5.33822298e-01,
                1.92711830e-01, -4.54187393e-05],
              [ 6.64090097e-01, -1.01875424e-01, -5.35733163e-01,
                1.88311756e-01, -6.30629063e-03],
              [ 6.73380017e-01, -1.06952369e-01, -5.31989932e-01,
                1.90056756e-01,  1.30271912e-03],
              [ 6.84564888e-01, -1.13240272e-01, -5.50182462e-01,
                1.95673436e-01,  5.47638535e-03],
              [ 6.81435883e-01, -1.11068964e-01, -5.32343209e-01,
                1.91912338e-01,  5.69400191e-03],
              [ 6.80724978e-01, -1.08496904e-01, -5.34994125e-01,
                1.96332246e-01,  5.89773059e-03],
              [ 6.80933356e-01, -1.14087075e-01, -5.18659890e-01,
                1.90674111e-01,  1.14096105e-02],
              [ 6.80265009e-01, -1.09031796e-01, -5.38248718e-01,
                1.94203183e-01,  4.23943996e-03]]], dtype=float32)</code></pre>
</div>
</div>
</section>
<section id="trax-lshselfattention" class="level2" data-number="5">
<h2 data-number="5" class="anchored" data-anchor-id="trax-lshselfattention"><span class="header-section-number">5</span> Trax LSHSelfAttention</h2>
<section id="description-1" class="level3" data-number="5.1">
<h3 data-number="5.1" class="anchored" data-anchor-id="description-1"><span class="header-section-number">5.1</span> Description</h3>
<p>The larger the matrix multiply in the previous section is, the more context can be taken into account when making the next decision. However, the self attention dot product grows as the size of the input squared. For example, if one wished to have an input size of 1024, that would result in <img src="https://latex.codecogs.com/png.latex?1024%5E2"> or over a million dot products for each head! As a result, there has been significant research related to reducing the compute requirements. One such approach is Locality Sensitive Hashing (LSH) Self Attention.</p>
<p>We previously utilized LSH to find similar tweets without resorting to calculating cosine similarity for each pair of embeddings. We will use a similar approach here. It may be best described with an example.</p>
<p><img src="http://livingdatalab.com/posts/https:/github.com/pranath/blog/raw/master/images/C4W4_LN2_image8.png" height="400" width="750"></p>
<center>
<b>Figure 9: Example of LSH Self Attention</b>
</center>
<p>LSH Self attention uses Queries only, no Keys. Attention then generates a metric of the similarity of each value of Q relative to all the other values in Q. An earlier article demonstrated that values which hash to the same bucket are likely to be similar. Further, multiple random hashes can improve the chances of finding entries which are similar. This is the approach taken here, though the hash is implemented a bit differently. The values of Q are hashed into buckets using a randomly generated set of hash vectors. Multiple sets of hash vectors are used, generating multiple hash tables. In the figure above, we have 3 hash tables with 4 buckets in each table. Notionally, following the hash, the values of Q have been replicated 3 times and distributed to their appropriate bucket in each of the 3 tables. To find similarity then, one generates dot-products only between members of the buckets. The result of this operation provides information on which entries are similar. As the operation has been distributed over multiple hash tables, these results need to be combined to form a complete picture and this can be used to generate a reduced dot-product attention array. Its clear that because we do not do a compare of every value vs every other value, the size of <em>Dots</em> will be reduced.</p>
<p>The challenge in this approach is getting it to operate efficiently. In earlier projects the buckets were lists of entries and had varying length. This will operate poorly on a vector processing machine such as a GPU or TPU. Ideally, operations are done in large blocks with uniform sizes. While it is straightforward to implement the hash algorithm this way, it is challenging to managed buckets and variable sized dot-products. This will be discussed further below. For now, we will examine and implement the hash function.</p>
</section>
<section id="our_hash_vectors" class="level3" data-number="5.2">
<h3 data-number="5.2" class="anchored" data-anchor-id="our_hash_vectors"><span class="header-section-number">5.2</span> our_hash_vectors</h3>
<p><em>our_hash_vectors</em>, is a reimplementation of Trax <em>hashvector</em>. It takes in an array of vectors, hashes the entries and returns and array assigning each input vector to <code>n_buckets</code> buckets. Hashing is described as creating <em>random rotations</em>, see <a href="https://arxiv.org/pdf/1509.02897.pdf">Practical and Optimal LSH for Angular Distance</a>.</p>
<img src="http://livingdatalab.com/posts/https:/github.com/pranath/blog/raw/master/images/C4W4_LN2_image9.png" height="400" width="750"> <img src="http://livingdatalab.com/posts/https:/github.com/pranath/blog/raw/master/images/C4W4_LN2_image10.png" height="400" width="750">
<center>
<b>Figure 10: Processing steps in our_hash_vectors </b>
</center>
<p>Note, in the diagram, sizes relate to our expected input <img src="https://latex.codecogs.com/png.latex?Q"> while our_hash_vectors is written assuming a generic input vector</p>
<p><strong>Step 1</strong> create an array of random normal vectors which will be our hash vectors. Each vector will be hashed into a hash table and into <code>rot_size//2</code> buckets. We use <code>rot_size//2</code> to reduce computation. Later in the routine we will form the negative rotations with a simple negation and concatenate to get a full <code>rot_size</code> number of rotations.</p>
<ul>
<li>use fastmath.random.normal and create an array of random vectors of shape <code>(vecs.shape[-1],n_hashes, rot_size//2)</code></li>
</ul>
<p><strong>Step 2</strong> In this step we simply do the matrix multiply. <code>jax</code> has an accelerated version of <a href="https://numpy.org/doc/stable/reference/generated/numpy.einsum.html">einsum</a>. Here we will utilize more conventional routines.</p>
<p><strong>Step 2x</strong></p>
<ul>
<li>2a: <code>np.reshape</code> random_rotations into a 2 dimensional array (<code>[-1, n_hashes * (rot_size // 2)]</code>)</li>
<li>2b: <code>np.dot</code> vecs and random_rotations forming our rotated_vecs</li>
<li>2c: back to 3 dimension with <code>np.reshape</code> <code>[-1, n_hashes, rot_size//2]</code></li>
<li>2d: prepare for concatenating by swapping dimensions np.transpose <code>(1, 0, 2)</code></li>
</ul>
<p><strong>Step 3</strong> Here we concatenate our rotation vectors getting a fullrot_size number of buckets (note, n_buckets = rotsize) * use <code>np.concatenate</code>, <code>[rotated_vecs, -rotated_vecs]</code>, <code>axis=-1</code></p>
<p><strong>Step 4</strong> <strong>This is the exciting step!</strong> You have no doubt been wondering how we will turn these vectors into bucket indexes. By performing <code>np.argmax</code> over the rotations for a given entry, you get the index to the best match! We will use this as a bucket index. * <code>np.argmax(...).astype(np.int32)</code>; be sure to use the correct axis!</p>
<p><strong>Step 5</strong> In this style of hashing, items which land in bucket 0 of hash table 0 are not necessarily similar to those landing in bucket 0 of hash table 1, so we keep them separate. We do this by offsetting the bucket numbers by <code>n_buckets</code>. * add buckets and offsets and reshape into a one dimensional array. This will return a 1D array of size <code>n_hashes * vec.shape[0]</code>.</p>
<div class="cell" data-execution_count="19">
<div class="sourceCode cell-code" id="cb14" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><span class="kw" style="color: #003B4F;">def</span> our_hash_vectors(vecs, rng, n_buckets, n_hashes, mask<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">None</span>, verbose<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">False</span>):</span>
<span id="cb14-2">    <span class="co" style="color: #5E5E5E;">"""</span></span>
<span id="cb14-3"><span class="co" style="color: #5E5E5E;">  Args:</span></span>
<span id="cb14-4"><span class="co" style="color: #5E5E5E;">    vecs: tensor of at least 2 dimension,</span></span>
<span id="cb14-5"><span class="co" style="color: #5E5E5E;">    rng: random number generator</span></span>
<span id="cb14-6"><span class="co" style="color: #5E5E5E;">    n_buckets: number of buckets in each hash table</span></span>
<span id="cb14-7"><span class="co" style="color: #5E5E5E;">    n_hashes: the number of hash tables</span></span>
<span id="cb14-8"><span class="co" style="color: #5E5E5E;">    mask: None indicating no mask or a 1D boolean array of length vecs.shape[0], containing the location of padding value</span></span>
<span id="cb14-9"><span class="co" style="color: #5E5E5E;">    verbose: controls prints for debug</span></span>
<span id="cb14-10"><span class="co" style="color: #5E5E5E;">  Returns:</span></span>
<span id="cb14-11"><span class="co" style="color: #5E5E5E;">    A vector of size n_hashes * vecs.shape[0] containing the buckets associated with each input vector per hash table.</span></span>
<span id="cb14-12"></span>
<span id="cb14-13"><span class="co" style="color: #5E5E5E;">    """</span></span>
<span id="cb14-14"></span>
<span id="cb14-15">    <span class="co" style="color: #5E5E5E;"># check for even, integer bucket sizes</span></span>
<span id="cb14-16">    <span class="cf" style="color: #003B4F;">assert</span> <span class="bu" style="color: null;">isinstance</span>(n_buckets, <span class="bu" style="color: null;">int</span>) <span class="kw" style="color: #003B4F;">and</span> n_buckets <span class="op" style="color: #5E5E5E;">%</span> <span class="dv" style="color: #AD0000;">2</span> <span class="op" style="color: #5E5E5E;">==</span> <span class="dv" style="color: #AD0000;">0</span></span>
<span id="cb14-17"></span>
<span id="cb14-18">    rng <span class="op" style="color: #5E5E5E;">=</span> fastmath.stop_gradient(tie_in(vecs, rng))</span>
<span id="cb14-19">    rot_size <span class="op" style="color: #5E5E5E;">=</span> n_buckets</span>
<span id="cb14-20"></span>
<span id="cb14-21">    <span class="co" style="color: #5E5E5E;">### Step 1 </span><span class="al" style="color: #AD0000;">###</span></span>
<span id="cb14-22">    rotations_shape <span class="op" style="color: #5E5E5E;">=</span> (vecs.shape[<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>], n_hashes, rot_size <span class="op" style="color: #5E5E5E;">//</span> <span class="dv" style="color: #AD0000;">2</span>)</span>
<span id="cb14-23">    random_rotations <span class="op" style="color: #5E5E5E;">=</span> fastmath.random.normal(rng, rotations_shape).astype(</span>
<span id="cb14-24">        np.float32)</span>
<span id="cb14-25">    <span class="cf" style="color: #003B4F;">if</span> verbose: <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">"random.rotations.shape"</span>, random_rotations.shape)</span>
<span id="cb14-26"></span>
<span id="cb14-27">    <span class="co" style="color: #5E5E5E;">### Step 2 </span><span class="al" style="color: #AD0000;">###</span></span>
<span id="cb14-28">    <span class="cf" style="color: #003B4F;">if</span> fastmath.backend_name() <span class="op" style="color: #5E5E5E;">==</span> <span class="st" style="color: #20794D;">'jax'</span>:</span>
<span id="cb14-29">        rotated_vecs <span class="op" style="color: #5E5E5E;">=</span> np.einsum(<span class="st" style="color: #20794D;">'tf,fhb-&gt;htb'</span>, vecs, random_rotations)</span>
<span id="cb14-30">        <span class="cf" style="color: #003B4F;">if</span> verbose: <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">"using jax"</span>)</span>
<span id="cb14-31">    <span class="cf" style="color: #003B4F;">else</span>:</span>
<span id="cb14-32">        <span class="co" style="color: #5E5E5E;">#Step 2a</span></span>
<span id="cb14-33">        random_rotations <span class="op" style="color: #5E5E5E;">=</span> np.reshape(random_rotations,</span>
<span id="cb14-34">                                    [<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>, n_hashes <span class="op" style="color: #5E5E5E;">*</span> (rot_size <span class="op" style="color: #5E5E5E;">//</span> <span class="dv" style="color: #AD0000;">2</span>)])</span>
<span id="cb14-35">        <span class="cf" style="color: #003B4F;">if</span> verbose: <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">"random_rotations reshaped"</span>, random_rotations.shape)</span>
<span id="cb14-36">        <span class="co" style="color: #5E5E5E;">#Step 2b</span></span>
<span id="cb14-37">        rotated_vecs <span class="op" style="color: #5E5E5E;">=</span> np.dot(vecs, random_rotations)</span>
<span id="cb14-38">        <span class="cf" style="color: #003B4F;">if</span> verbose: <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">"rotated_vecs1"</span>, rotated_vecs.shape)</span>
<span id="cb14-39">        <span class="co" style="color: #5E5E5E;">#Step 2c</span></span>
<span id="cb14-40">        rotated_vecs <span class="op" style="color: #5E5E5E;">=</span> np.reshape(rotated_vecs, [<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>, n_hashes, rot_size<span class="op" style="color: #5E5E5E;">//</span><span class="dv" style="color: #AD0000;">2</span>])</span>
<span id="cb14-41">        <span class="cf" style="color: #003B4F;">if</span> verbose: <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">"rotated_vecs2"</span>, rotated_vecs.shape)</span>
<span id="cb14-42">        <span class="co" style="color: #5E5E5E;">#Step 2d</span></span>
<span id="cb14-43">        rotated_vecs <span class="op" style="color: #5E5E5E;">=</span> np.transpose(rotated_vecs, (<span class="dv" style="color: #AD0000;">1</span>, <span class="dv" style="color: #AD0000;">0</span>, <span class="dv" style="color: #AD0000;">2</span>))</span>
<span id="cb14-44">        <span class="cf" style="color: #003B4F;">if</span> verbose: <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">"rotated_vecs3"</span>, rotated_vecs.shape)</span>
<span id="cb14-45"></span>
<span id="cb14-46">    <span class="co" style="color: #5E5E5E;">### Step 3 </span><span class="al" style="color: #AD0000;">###</span></span>
<span id="cb14-47">    rotated_vecs <span class="op" style="color: #5E5E5E;">=</span> np.concatenate([rotated_vecs, <span class="op" style="color: #5E5E5E;">-</span>rotated_vecs], axis<span class="op" style="color: #5E5E5E;">=-</span><span class="dv" style="color: #AD0000;">1</span>)</span>
<span id="cb14-48">    <span class="cf" style="color: #003B4F;">if</span> verbose: <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">"rotated_vecs.shape"</span>, rotated_vecs.shape)</span>
<span id="cb14-49">    <span class="co" style="color: #5E5E5E;">### Step 4 </span><span class="al" style="color: #AD0000;">###</span></span>
<span id="cb14-50">    buckets <span class="op" style="color: #5E5E5E;">=</span> np.argmax(rotated_vecs, axis<span class="op" style="color: #5E5E5E;">=-</span><span class="dv" style="color: #AD0000;">1</span>).astype(np.int32)</span>
<span id="cb14-51">    <span class="cf" style="color: #003B4F;">if</span> verbose: <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">"buckets.shape"</span>, buckets.shape)</span>
<span id="cb14-52">    <span class="cf" style="color: #003B4F;">if</span> verbose: <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">"buckets"</span>, buckets)</span>
<span id="cb14-53"></span>
<span id="cb14-54">    <span class="cf" style="color: #003B4F;">if</span> mask <span class="kw" style="color: #003B4F;">is</span> <span class="kw" style="color: #003B4F;">not</span> <span class="va" style="color: #111111;">None</span>:</span>
<span id="cb14-55">        n_buckets <span class="op" style="color: #5E5E5E;">+=</span> <span class="dv" style="color: #AD0000;">1</span>  <span class="co" style="color: #5E5E5E;"># Create an extra bucket for padding tokens only</span></span>
<span id="cb14-56">        buckets <span class="op" style="color: #5E5E5E;">=</span> np.where(mask[<span class="va" style="color: #111111;">None</span>, :], buckets, n_buckets <span class="op" style="color: #5E5E5E;">-</span> <span class="dv" style="color: #AD0000;">1</span>)</span>
<span id="cb14-57"></span>
<span id="cb14-58">    <span class="co" style="color: #5E5E5E;"># buckets is now (n_hashes, seqlen). Next we add offsets so that</span></span>
<span id="cb14-59">    <span class="co" style="color: #5E5E5E;"># bucket numbers from different hashing rounds don't overlap.</span></span>
<span id="cb14-60">    offsets <span class="op" style="color: #5E5E5E;">=</span> tie_in(buckets, np.arange(n_hashes, dtype<span class="op" style="color: #5E5E5E;">=</span>np.int32))</span>
<span id="cb14-61">    offsets <span class="op" style="color: #5E5E5E;">=</span> np.reshape(offsets <span class="op" style="color: #5E5E5E;">*</span> n_buckets, (<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>, <span class="dv" style="color: #AD0000;">1</span>))</span>
<span id="cb14-62">    <span class="co" style="color: #5E5E5E;">### Step 5 </span><span class="al" style="color: #AD0000;">###</span></span>
<span id="cb14-63">    buckets <span class="op" style="color: #5E5E5E;">=</span> np.reshape(buckets <span class="op" style="color: #5E5E5E;">+</span> offsets, (<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>,))</span>
<span id="cb14-64">    <span class="cf" style="color: #003B4F;">if</span> verbose: <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">"buckets with offsets"</span>, buckets.shape, <span class="st" style="color: #20794D;">"</span><span class="ch" style="color: #20794D;">\n</span><span class="st" style="color: #20794D;">"</span>, buckets)</span>
<span id="cb14-65">    <span class="cf" style="color: #003B4F;">return</span> buckets</span></code></pre></div>
</div>
<div class="cell" data-outputid="a5a6a956-30b7-4de7-a5c2-65011a9d3816" data-execution_count="20">
<div class="sourceCode cell-code" id="cb15" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><span class="co" style="color: #5E5E5E;"># example code. Note for reference, the sizes in this example match the values in the diagram above.</span></span>
<span id="cb15-2">ohv_q <span class="op" style="color: #5E5E5E;">=</span> np.ones((<span class="dv" style="color: #AD0000;">8</span>, <span class="dv" style="color: #AD0000;">5</span>))  <span class="co" style="color: #5E5E5E;"># (seq_len=8, n_q=5)</span></span>
<span id="cb15-3">ohv_n_buckets <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">4</span>  <span class="co" style="color: #5E5E5E;"># even number</span></span>
<span id="cb15-4">ohv_n_hashes <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">3</span></span>
<span id="cb15-5"></span>
<span id="cb15-6"><span class="cf" style="color: #003B4F;">with</span> fastmath.use_backend(<span class="st" style="color: #20794D;">"tensorflow-numpy"</span>):</span>
<span id="cb15-7">    ohv_rng <span class="op" style="color: #5E5E5E;">=</span> fastmath.random.get_prng(<span class="dv" style="color: #AD0000;">1</span>)</span>
<span id="cb15-8">    ohv <span class="op" style="color: #5E5E5E;">=</span> our_hash_vectors(</span>
<span id="cb15-9">        ohv_q, ohv_rng, ohv_n_buckets, ohv_n_hashes, mask<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">None</span>, verbose<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span></span>
<span id="cb15-10">    )</span>
<span id="cb15-11">    <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">"ohv shape"</span>, ohv.shape, <span class="st" style="color: #20794D;">"</span><span class="ch" style="color: #20794D;">\n</span><span class="st" style="color: #20794D;">ohv"</span>, ohv)  <span class="co" style="color: #5E5E5E;"># (ohv_n_hashes * ohv_n_buckets)</span></span>
<span id="cb15-12"></span>
<span id="cb15-13"><span class="co" style="color: #5E5E5E;"># note the random number generators do not produce the same results with different backends</span></span>
<span id="cb15-14"><span class="cf" style="color: #003B4F;">with</span> fastmath.use_backend(<span class="st" style="color: #20794D;">"jax"</span>):</span>
<span id="cb15-15">    ohv_rng <span class="op" style="color: #5E5E5E;">=</span> fastmath.random.get_prng(<span class="dv" style="color: #AD0000;">1</span>)</span>
<span id="cb15-16">    ohv <span class="op" style="color: #5E5E5E;">=</span> our_hash_vectors(ohv_q, ohv_rng, ohv_n_buckets, ohv_n_hashes, mask<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">None</span>)</span>
<span id="cb15-17">    <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">"ohv shape"</span>, ohv.shape, <span class="st" style="color: #20794D;">"</span><span class="ch" style="color: #20794D;">\n</span><span class="st" style="color: #20794D;">ohv"</span>, ohv)  <span class="co" style="color: #5E5E5E;"># (ohv_n_hashes * ohv_n_buckets)</span></span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>random.rotations.shape (5, 3, 2)
random_rotations reshaped (5, 6)
rotated_vecs1 (8, 6)
rotated_vecs2 (8, 3, 2)
rotated_vecs3 (3, 8, 2)
rotated_vecs.shape (3, 8, 4)
buckets.shape (3, 8)
buckets tf.Tensor(
[[3 3 3 3 3 3 3 3]
 [3 3 3 3 3 3 3 3]
 [3 3 3 3 3 3 3 3]], shape=(3, 8), dtype=int32)
buckets with offsets (24,) 
 tf.Tensor([ 3  3  3  3  3  3  3  3  7  7  7  7  7  7  7  7 11 11 11 11 11 11 11 11], shape=(24,), dtype=int32)
ohv shape (24,) 
ohv tf.Tensor([ 3  3  3  3  3  3  3  3  7  7  7  7  7  7  7  7 11 11 11 11 11 11 11 11], shape=(24,), dtype=int32)
ohv shape (24,) 
ohv [ 3  3  3  3  3  3  3  3  5  5  5  5  5  5  5  5 11 11 11 11 11 11 11 11]</code></pre>
</div>
</div>
</section>
<section id="sorting-buckets" class="level3" data-number="5.3">
<h3 data-number="5.3" class="anchored" data-anchor-id="sorting-buckets"><span class="header-section-number">5.3</span> Sorting Buckets</h3>
<p>Now that we have a hash function, we can work on sorting our buckets and performing our matrix operations. We’ll walk through this algorithm in small steps: * sort_buckets - we’ll perform the sort * softmax * dotandv - do the matrix math to form the dotproduct and output</p>
<p>These routines will demonstrate a simplified version of the algorithm. We won’t address masking and variable bucket sizes but will consider how they would be handled.</p>
<p><strong>sort_buckets</strong></p>
<p>At this point, we have called the hash function and were returned the associated buckets. For example, if we started with <code>q[n_seq,n_q]</code>, with <code>n_hash = 2; n_buckets = 4; n_seq = 8</code> we might be returned: <code>bucket = [0,1,2,3,0,1,2,3, 4,5,6,7,4,5,6,7]</code>. Note that it is <code>n_hash * n_seq</code> long and that the bucket values for each hash have been offset by <code>n_buckets</code> so the numbers do not overlap. Going forward, we are going to sort this array of buckets to group together members of the same (hash,bucket) pair.</p>
<p><strong>Step 1</strong> Our goal is to sort <img src="https://latex.codecogs.com/png.latex?q"> rather than the bucket list, so we will need to track the association of the buckets to their elements in <img src="https://latex.codecogs.com/png.latex?q">. * using <code>np.arange</code>, create <code>ticker</code>, just a sequence of numbers (0…n_hashes * seqlen) associating members of <img src="https://latex.codecogs.com/png.latex?q"> with their bucket.</p>
<p><strong>Step 2</strong> We want to disambiguate elements that map to the same bucket. When a sorting routine encounters a situation where multiple entries have the same value, it can correctly choose any entry to go first. This makes testing ambiguous. This prevents that. We multiply all the buckets by <code>seqlen</code> and then add <code>ticker % seqlen</code></p>
<p><strong>Step 3</strong> Here we are! Ready to sort. This is the exciting part. * Utilize <a href="https://jax.readthedocs.io/en/latest/_autosummary/jax.lax.sort_key_val.html#jax.lax.sort_key_val">fastmath.sort_key_val</a> and sort <code>buckets_and_t</code> and <code>ticker</code>.</p>
<p><strong>Step 4</strong> We need to be able to undo the sort at the end to get things back into their correct locations * sort <code>sticker</code> and <code>ticker</code> to for the reverse map</p>
<p><strong>Step 5</strong> create our sorted q and sorted v * use <a href="https://numpy.org/doc/stable/reference/generated/numpy.take.html">np.take</a> and <code>st</code> to grab correct values in <code>q</code> for the sorted values, <code>sq</code>. Use <code>axis=0</code>.</p>
<div class="cell" data-execution_count="21">
<div class="sourceCode cell-code" id="cb17" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><span class="kw" style="color: #003B4F;">def</span> sort_buckets(buckets, q, v, n_buckets, n_hashes, seqlen, verbose<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>):</span>
<span id="cb17-2">    <span class="co" style="color: #5E5E5E;">"""</span></span>
<span id="cb17-3"><span class="co" style="color: #5E5E5E;">  Args:</span></span>
<span id="cb17-4"><span class="co" style="color: #5E5E5E;">    buckets: tensor of at least 2 dimension,</span></span>
<span id="cb17-5"><span class="co" style="color: #5E5E5E;">    n_buckets: number of buckets in each hash table</span></span>
<span id="cb17-6"><span class="co" style="color: #5E5E5E;">    n_hashes: the number of hash tables</span></span>
<span id="cb17-7"><span class="co" style="color: #5E5E5E;">    """</span></span>
<span id="cb17-8">    <span class="cf" style="color: #003B4F;">if</span> verbose: <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">"---sort_buckets--"</span>)</span>
<span id="cb17-9">    <span class="co" style="color: #5E5E5E;">## Step 1</span></span>
<span id="cb17-10">    ticker <span class="op" style="color: #5E5E5E;">=</span> np.arange(n_hashes <span class="op" style="color: #5E5E5E;">*</span> seqlen)</span>
<span id="cb17-11">    <span class="cf" style="color: #003B4F;">if</span> verbose: <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">"ticker"</span>,ticker.shape, ticker)</span>
<span id="cb17-12">    <span class="co" style="color: #5E5E5E;">## Step 2</span></span>
<span id="cb17-13">    buckets_and_t <span class="op" style="color: #5E5E5E;">=</span> seqlen <span class="op" style="color: #5E5E5E;">*</span> buckets <span class="op" style="color: #5E5E5E;">+</span> (ticker <span class="op" style="color: #5E5E5E;">%</span> seqlen)</span>
<span id="cb17-14">    <span class="cf" style="color: #003B4F;">if</span> verbose: <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">"buckets_and_t"</span>,buckets_and_t.shape, buckets_and_t)</span>
<span id="cb17-15"></span>
<span id="cb17-16">    <span class="co" style="color: #5E5E5E;"># Hash-based sort ("s" at the start of variable names means "sorted")</span></span>
<span id="cb17-17">    <span class="co" style="color: #5E5E5E;">#Step 3</span></span>
<span id="cb17-18">    sbuckets_and_t, sticker <span class="op" style="color: #5E5E5E;">=</span> fastmath.sort_key_val(</span>
<span id="cb17-19">    buckets_and_t, ticker, dimension<span class="op" style="color: #5E5E5E;">=-</span><span class="dv" style="color: #AD0000;">1</span>)</span>
<span id="cb17-20">    <span class="cf" style="color: #003B4F;">if</span> verbose: <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">"sbuckets_and_t"</span>,sbuckets_and_t.shape, sbuckets_and_t)</span>
<span id="cb17-21">    <span class="cf" style="color: #003B4F;">if</span> verbose: <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">"sticker"</span>,sticker.shape, sticker)</span>
<span id="cb17-22">    <span class="co" style="color: #5E5E5E;">#Step 4</span></span>
<span id="cb17-23">    _, undo_sort <span class="op" style="color: #5E5E5E;">=</span> fastmath.sort_key_val(sticker, ticker, dimension<span class="op" style="color: #5E5E5E;">=-</span><span class="dv" style="color: #AD0000;">1</span>)</span>
<span id="cb17-24">    <span class="cf" style="color: #003B4F;">if</span> verbose: <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">"undo_sort"</span>,undo_sort.shape, undo_sort)</span>
<span id="cb17-25"></span>
<span id="cb17-26">    <span class="co" style="color: #5E5E5E;">#Step 4</span></span>
<span id="cb17-27">    st <span class="op" style="color: #5E5E5E;">=</span> (sticker <span class="op" style="color: #5E5E5E;">%</span> seqlen)</span>
<span id="cb17-28">    sq <span class="op" style="color: #5E5E5E;">=</span> np.take(q, st, axis<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">0</span>)</span>
<span id="cb17-29">    sv <span class="op" style="color: #5E5E5E;">=</span> np.take(v, st, axis<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">0</span>)</span>
<span id="cb17-30">    <span class="cf" style="color: #003B4F;">return</span> sq, sv, sticker, undo_sort</span></code></pre></div>
</div>
<div class="cell" data-execution_count="22">
<div class="sourceCode cell-code" id="cb18" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1">t_n_hashes <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">2</span></span>
<span id="cb18-2">t_n_buckets <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">4</span></span>
<span id="cb18-3">t_n_seq <span class="op" style="color: #5E5E5E;">=</span> t_seqlen <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">8</span></span>
<span id="cb18-4">t_n_q <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">3</span></span>
<span id="cb18-5">n_v <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">5</span></span>
<span id="cb18-6"></span>
<span id="cb18-7">t_q <span class="op" style="color: #5E5E5E;">=</span> (np.array([(j <span class="op" style="color: #5E5E5E;">%</span> t_n_buckets) <span class="cf" style="color: #003B4F;">for</span> j <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">range</span>(t_n_seq)]) <span class="op" style="color: #5E5E5E;">*</span> np.ones((t_n_q, <span class="dv" style="color: #AD0000;">1</span>))).T</span>
<span id="cb18-8">t_v <span class="op" style="color: #5E5E5E;">=</span> np.ones((t_n_seq, n_v))</span>
<span id="cb18-9">t_buckets <span class="op" style="color: #5E5E5E;">=</span> np.array(</span>
<span id="cb18-10">    [</span>
<span id="cb18-11">        (j <span class="op" style="color: #5E5E5E;">%</span> t_n_buckets) <span class="op" style="color: #5E5E5E;">+</span> t_n_buckets <span class="op" style="color: #5E5E5E;">*</span> i</span>
<span id="cb18-12">        <span class="cf" style="color: #003B4F;">for</span> i <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">range</span>(t_n_hashes)</span>
<span id="cb18-13">        <span class="cf" style="color: #003B4F;">for</span> j <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">range</span>(t_n_seq)</span>
<span id="cb18-14">    ]</span>
<span id="cb18-15">)</span>
<span id="cb18-16"><span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">"q</span><span class="ch" style="color: #20794D;">\n</span><span class="st" style="color: #20794D;">"</span>, t_q)</span>
<span id="cb18-17"><span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">"t_buckets: "</span>, t_buckets)</span>
<span id="cb18-18"></span>
<span id="cb18-19">t_sq, t_sv, t_sticker, t_undo_sort <span class="op" style="color: #5E5E5E;">=</span> sort_buckets(</span>
<span id="cb18-20">    t_buckets, t_q, t_v, t_n_buckets, t_n_hashes, t_seqlen, verbose<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span></span>
<span id="cb18-21">)</span>
<span id="cb18-22"></span>
<span id="cb18-23"><span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">"sq.shape"</span>, t_sq.shape, <span class="st" style="color: #20794D;">"sv.shape"</span>, t_sv.shape)</span>
<span id="cb18-24"><span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">"sq</span><span class="ch" style="color: #20794D;">\n</span><span class="st" style="color: #20794D;">"</span>, t_sq)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>q
 [[0. 0. 0.]
 [1. 1. 1.]
 [2. 2. 2.]
 [3. 3. 3.]
 [0. 0. 0.]
 [1. 1. 1.]
 [2. 2. 2.]
 [3. 3. 3.]]
t_buckets:  [0 1 2 3 0 1 2 3 4 5 6 7 4 5 6 7]
---sort_buckets--
ticker (16,) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]
buckets_and_t (16,) [ 0  9 18 27  4 13 22 31 32 41 50 59 36 45 54 63]
sbuckets_and_t (16,) [ 0  4  9 13 18 22 27 31 32 36 41 45 50 54 59 63]
sticker (16,) [ 0  4  1  5  2  6  3  7  8 12  9 13 10 14 11 15]
undo_sort (16,) [ 0  2  4  6  1  3  5  7  8 10 12 14  9 11 13 15]
sq.shape (16, 3) sv.shape (16, 5)
sq
 [[0. 0. 0.]
 [0. 0. 0.]
 [1. 1. 1.]
 [1. 1. 1.]
 [2. 2. 2.]
 [2. 2. 2.]
 [3. 3. 3.]
 [3. 3. 3.]
 [0. 0. 0.]
 [0. 0. 0.]
 [1. 1. 1.]
 [1. 1. 1.]
 [2. 2. 2.]
 [2. 2. 2.]
 [3. 3. 3.]
 [3. 3. 3.]]</code></pre>
</div>
</div>
</section>
<section id="chunked-dot-product-attention" class="level3" data-number="5.4">
<h3 data-number="5.4" class="anchored" data-anchor-id="chunked-dot-product-attention"><span class="header-section-number">5.4</span> Chunked dot product attention</h3>
<p>Now let’s create the dot product attention. We have sorted <img src="https://latex.codecogs.com/png.latex?Q"> so that elements that the hash has determined are likely to be similar are adjacent to each other. We now want to perform the dot-product within those limited regions - in ‘chunks’.</p>
<img src="http://livingdatalab.com/posts/https:/github.com/pranath/blog/raw/master/images/C4W4_LN2_image12.png" height="400" width="750">
<center>
<b>Figure 11: Performing dot product in ‘chunks’ </b>
</center>
<p>The example we have been working on is shown above, with sequences of 8, 2 hashes, 4 buckets and, conveniently, the content of Q was such that when sorted, there were 2 entries in each bucket. If we reshape Q into a (8,2,n_q), we can use numpy matmul to perform the operation. Numpy <a href="https://numpy.org/doc/stable/reference/generated/numpy.matmul.html">matmul</a> will treat the inputs as a stack of matrices residing in the last two indexes. This will allow us to matrix multiply Q with itself in <em>chunks</em> and later can also be used to perform the matrix multiply with v.</p>
<p>We will perform a softmax on the output of the dot product of Q and Q, but in this case, there is a bit more to the story. Recall the output of the hash had multiple hash tables. We will perform softmax on those separately and then must combine them. This is where the form of softmax we defined at the top of the notebook comes into play. The routines below will utilize the <code>logsumexp</code> values that the <code>our_softmax</code> routine calculates.</p>
<p>There is a good deal of <a href="https://numpy.org/doc/stable/reference/generated/numpy.reshape.html">reshaping</a> to get things into the right formats. The code has many <code>print</code> statements that match the expected values below. You can use those to check your work as you go along. If you don’t do a lot of 3-dimensional matrix multiplications in your daily life, it might be worthwhile to open a spare cell and practice a few simple examples to get the hang of it! Here is one to start with:</p>
<div class="cell" data-execution_count="23">
<div class="sourceCode cell-code" id="cb20" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1">a <span class="op" style="color: #5E5E5E;">=</span> np.arange(<span class="dv" style="color: #AD0000;">16</span> <span class="op" style="color: #5E5E5E;">*</span> <span class="dv" style="color: #AD0000;">3</span>).reshape((<span class="dv" style="color: #AD0000;">16</span>, <span class="dv" style="color: #AD0000;">3</span>))</span>
<span id="cb20-2">chunksize <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">2</span></span>
<span id="cb20-3">ar <span class="op" style="color: #5E5E5E;">=</span> np.reshape(</span>
<span id="cb20-4">    a, (<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>, chunksize, a.shape[<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>])</span>
<span id="cb20-5">)  <span class="co" style="color: #5E5E5E;"># the -1 usage is very handy, see numpy reshape</span></span>
<span id="cb20-6"><span class="bu" style="color: null;">print</span>(ar.shape)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>(8, 2, 3)</code></pre>
</div>
</div>
<p><strong>Step 1</strong> Reshaping Q * np.reshape <code>sq</code> (sorted q) to be 3 dimensions. The middle dimension is the size of the ‘chunk’ specified by <code>kv_chunk_len</code> * np.swapaxes to perform a ‘transpose’ on the reshaped <code>sq</code>, <em>but only on the last two dimensions</em> * np.matmul the two values.</p>
<p><strong>Step 2</strong> * use our_softmax to perform the softmax on the dot product. Don’t forget <code>passthrough</code></p>
<p><strong>Step 3</strong> * np.reshape <code>sv</code>. Like <code>sq</code>, the middle dimension is the size of the ‘chunk’ specified by <code>kv_chunk_len</code> * np.matmul dotlike and the reshaped <code>sv</code> * np.reshape <code>so</code> to a two dimensional array with the last dimension stays the same (<code>so.shape[-1]</code>) * <code>logits</code> also needs reshaping, we’ll do that.</p>
<p><strong>Step 4</strong> Now we can undo the sort. * use <a href="https://numpy.org/doc/stable/reference/generated/numpy.take.html">np.take</a> and <code>undo_sort</code> and <code>axis = 0</code> to unsort so * do the same with <code>slogits</code>.</p>
<p><strong>Step 5</strong> This step combines the results of multiple hashes. Recall, the softmax was only over the values in one hash, this extends it to all the hashes. Read through it, the code is provided. Note this is taking place <em>after</em> the matrix multiply with v while the softmax output is used before the multiply.</p>
<div class="cell" data-execution_count="24">
<div class="sourceCode cell-code" id="cb22" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><span class="kw" style="color: #003B4F;">def</span> dotandv(sq, sv, undo_sort, kv_chunk_len, n_hashes, seqlen, passthrough, verbose<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">False</span> ):</span>
<span id="cb22-2">    <span class="co" style="color: #5E5E5E;"># Step 1</span></span>
<span id="cb22-3">    rsq <span class="op" style="color: #5E5E5E;">=</span> np.reshape(sq,(<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>, kv_chunk_len, sq.shape[<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>]))</span>
<span id="cb22-4">    rsqt <span class="op" style="color: #5E5E5E;">=</span>  np.swapaxes(rsq, <span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>, <span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">2</span>)</span>
<span id="cb22-5">    <span class="cf" style="color: #003B4F;">if</span> verbose: <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">"rsq.shape,rsqt.shape: "</span>, rsq.shape,rsqt.shape)</span>
<span id="cb22-6">    dotlike <span class="op" style="color: #5E5E5E;">=</span> np.matmul(rsq, rsqt)</span>
<span id="cb22-7">    <span class="cf" style="color: #003B4F;">if</span> verbose: <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">"dotlike</span><span class="ch" style="color: #20794D;">\n</span><span class="st" style="color: #20794D;">"</span>, dotlike)</span>
<span id="cb22-8"></span>
<span id="cb22-9">    <span class="co" style="color: #5E5E5E;">#Step 2</span></span>
<span id="cb22-10">    dotlike, slogits <span class="op" style="color: #5E5E5E;">=</span> our_softmax(dotlike, passthrough)</span>
<span id="cb22-11">    <span class="cf" style="color: #003B4F;">if</span> verbose: <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">"dotlike post softmax</span><span class="ch" style="color: #20794D;">\n</span><span class="st" style="color: #20794D;">"</span>, dotlike)</span>
<span id="cb22-12"></span>
<span id="cb22-13">    <span class="co" style="color: #5E5E5E;">#Step 3</span></span>
<span id="cb22-14">    vr <span class="op" style="color: #5E5E5E;">=</span> np.reshape(sv, (<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>, kv_chunk_len, sv.shape[<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>]))</span>
<span id="cb22-15">    <span class="cf" style="color: #003B4F;">if</span> verbose:  <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">"dotlike.shape, vr.shape:"</span>, dotlike.shape, vr.shape)</span>
<span id="cb22-16">    so <span class="op" style="color: #5E5E5E;">=</span> np.matmul(dotlike, vr)</span>
<span id="cb22-17">    <span class="cf" style="color: #003B4F;">if</span> verbose: <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">"so.shape:"</span>, so.shape)</span>
<span id="cb22-18">    so <span class="op" style="color: #5E5E5E;">=</span> np.reshape(so, (<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>, so.shape[<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>]))</span>
<span id="cb22-19">    slogits <span class="op" style="color: #5E5E5E;">=</span> np.reshape(slogits, (<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>,))  <span class="co" style="color: #5E5E5E;"># provided</span></span>
<span id="cb22-20">    <span class="cf" style="color: #003B4F;">if</span> verbose: <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">"so.shape,slogits.shape"</span>, so.shape, slogits.shape)</span>
<span id="cb22-21"></span>
<span id="cb22-22">    <span class="co" style="color: #5E5E5E;">#Step 4</span></span>
<span id="cb22-23">    o <span class="op" style="color: #5E5E5E;">=</span> np.take(so, undo_sort, axis<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">0</span>)</span>
<span id="cb22-24">    logits <span class="op" style="color: #5E5E5E;">=</span> np.take(slogits, undo_sort, axis<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">0</span>)</span>
<span id="cb22-25">    <span class="cf" style="color: #003B4F;">if</span> verbose: <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">"o.shape,o"</span>, o.shape, o)</span>
<span id="cb22-26">    <span class="cf" style="color: #003B4F;">if</span> verbose: <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">"logits.shape, logits"</span>, logits.shape, logits)</span>
<span id="cb22-27"></span>
<span id="cb22-28">    <span class="co" style="color: #5E5E5E;">#Step 5 </span></span>
<span id="cb22-29">    <span class="cf" style="color: #003B4F;">if</span> n_hashes <span class="op" style="color: #5E5E5E;">&gt;</span> <span class="dv" style="color: #AD0000;">1</span>:</span>
<span id="cb22-30">        o <span class="op" style="color: #5E5E5E;">=</span> np.reshape(o, (n_hashes, seqlen, o.shape[<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>]))</span>
<span id="cb22-31">        logits <span class="op" style="color: #5E5E5E;">=</span> np.reshape(logits, (n_hashes, seqlen, <span class="dv" style="color: #AD0000;">1</span>))</span>
<span id="cb22-32">        probs <span class="op" style="color: #5E5E5E;">=</span> np.exp(logits <span class="op" style="color: #5E5E5E;">-</span> fastmath.logsumexp(logits, axis<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">0</span>, keepdims<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>))</span>
<span id="cb22-33">        o <span class="op" style="color: #5E5E5E;">=</span> np.<span class="bu" style="color: null;">sum</span>(o <span class="op" style="color: #5E5E5E;">*</span> probs, axis<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">0</span>)</span>
<span id="cb22-34"></span>
<span id="cb22-35">    <span class="cf" style="color: #003B4F;">return</span>(o)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="25">
<div class="sourceCode cell-code" id="cb23" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1">t_kv_chunk_len <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">2</span></span>
<span id="cb23-2">out <span class="op" style="color: #5E5E5E;">=</span> dotandv(</span>
<span id="cb23-3">    t_sq,</span>
<span id="cb23-4">    t_sv,</span>
<span id="cb23-5">    t_undo_sort,</span>
<span id="cb23-6">    t_kv_chunk_len,</span>
<span id="cb23-7">    t_n_hashes,</span>
<span id="cb23-8">    t_seqlen,</span>
<span id="cb23-9">    passthrough<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>,</span>
<span id="cb23-10">    verbose<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>,</span>
<span id="cb23-11">)</span>
<span id="cb23-12"><span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">"out</span><span class="ch" style="color: #20794D;">\n</span><span class="st" style="color: #20794D;">"</span>, out)</span>
<span id="cb23-13"><span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">"</span><span class="ch" style="color: #20794D;">\n</span><span class="st" style="color: #20794D;">-----With softmax enabled----</span><span class="ch" style="color: #20794D;">\n</span><span class="st" style="color: #20794D;">"</span>)</span>
<span id="cb23-14">out <span class="op" style="color: #5E5E5E;">=</span> dotandv(</span>
<span id="cb23-15">    t_sq,</span>
<span id="cb23-16">    t_sv,</span>
<span id="cb23-17">    t_undo_sort,</span>
<span id="cb23-18">    t_kv_chunk_len,</span>
<span id="cb23-19">    t_n_hashes,</span>
<span id="cb23-20">    t_seqlen,</span>
<span id="cb23-21">    passthrough<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">False</span>,</span>
<span id="cb23-22">    verbose<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>,</span>
<span id="cb23-23">)</span>
<span id="cb23-24"><span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">"out</span><span class="ch" style="color: #20794D;">\n</span><span class="st" style="color: #20794D;">"</span>, out)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>rsq.shape,rsqt.shape:  (8, 2, 3) (8, 3, 2)
dotlike
 [[[ 0.  0.]
  [ 0.  0.]]

 [[ 3.  3.]
  [ 3.  3.]]

 [[12. 12.]
  [12. 12.]]

 [[27. 27.]
  [27. 27.]]

 [[ 0.  0.]
  [ 0.  0.]]

 [[ 3.  3.]
  [ 3.  3.]]

 [[12. 12.]
  [12. 12.]]

 [[27. 27.]
  [27. 27.]]]
dotlike post softmax
 [[[ 0.  0.]
  [ 0.  0.]]

 [[ 3.  3.]
  [ 3.  3.]]

 [[12. 12.]
  [12. 12.]]

 [[27. 27.]
  [27. 27.]]

 [[ 0.  0.]
  [ 0.  0.]]

 [[ 3.  3.]
  [ 3.  3.]]

 [[12. 12.]
  [12. 12.]]

 [[27. 27.]
  [27. 27.]]]
dotlike.shape, vr.shape: (8, 2, 2) (8, 2, 5)
so.shape: (8, 2, 5)
so.shape,slogits.shape (16, 5) (16,)
o.shape,o (16, 5) [[ 0.  0.  0.  0.  0.]
 [ 6.  6.  6.  6.  6.]
 [24. 24. 24. 24. 24.]
 [54. 54. 54. 54. 54.]
 [ 0.  0.  0.  0.  0.]
 [ 6.  6.  6.  6.  6.]
 [24. 24. 24. 24. 24.]
 [54. 54. 54. 54. 54.]
 [ 0.  0.  0.  0.  0.]
 [ 6.  6.  6.  6.  6.]
 [24. 24. 24. 24. 24.]
 [54. 54. 54. 54. 54.]
 [ 0.  0.  0.  0.  0.]
 [ 6.  6.  6.  6.  6.]
 [24. 24. 24. 24. 24.]
 [54. 54. 54. 54. 54.]]
logits.shape, logits (16,) [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
out
 [[ 0.  0.  0.  0.  0.]
 [ 6.  6.  6.  6.  6.]
 [24. 24. 24. 24. 24.]
 [54. 54. 54. 54. 54.]
 [ 0.  0.  0.  0.  0.]
 [ 6.  6.  6.  6.  6.]
 [24. 24. 24. 24. 24.]
 [54. 54. 54. 54. 54.]]

-----With softmax enabled----

rsq.shape,rsqt.shape:  (8, 2, 3) (8, 3, 2)
dotlike
 [[[ 0.  0.]
  [ 0.  0.]]

 [[ 3.  3.]
  [ 3.  3.]]

 [[12. 12.]
  [12. 12.]]

 [[27. 27.]
  [27. 27.]]

 [[ 0.  0.]
  [ 0.  0.]]

 [[ 3.  3.]
  [ 3.  3.]]

 [[12. 12.]
  [12. 12.]]

 [[27. 27.]
  [27. 27.]]]
dotlike post softmax
 [[[0.5        0.5       ]
  [0.5        0.5       ]]

 [[0.5        0.5       ]
  [0.5        0.5       ]]

 [[0.49999976 0.49999976]
  [0.49999976 0.49999976]]

 [[0.49999976 0.49999976]
  [0.49999976 0.49999976]]

 [[0.5        0.5       ]
  [0.5        0.5       ]]

 [[0.5        0.5       ]
  [0.5        0.5       ]]

 [[0.49999976 0.49999976]
  [0.49999976 0.49999976]]

 [[0.49999976 0.49999976]
  [0.49999976 0.49999976]]]
dotlike.shape, vr.shape: (8, 2, 2) (8, 2, 5)
so.shape: (8, 2, 5)
so.shape,slogits.shape (16, 5) (16,)
o.shape,o (16, 5) [[1.        1.        1.        1.        1.       ]
 [1.        1.        1.        1.        1.       ]
 [0.9999995 0.9999995 0.9999995 0.9999995 0.9999995]
 [0.9999995 0.9999995 0.9999995 0.9999995 0.9999995]
 [1.        1.        1.        1.        1.       ]
 [1.        1.        1.        1.        1.       ]
 [0.9999995 0.9999995 0.9999995 0.9999995 0.9999995]
 [0.9999995 0.9999995 0.9999995 0.9999995 0.9999995]
 [1.        1.        1.        1.        1.       ]
 [1.        1.        1.        1.        1.       ]
 [0.9999995 0.9999995 0.9999995 0.9999995 0.9999995]
 [0.9999995 0.9999995 0.9999995 0.9999995 0.9999995]
 [1.        1.        1.        1.        1.       ]
 [1.        1.        1.        1.        1.       ]
 [0.9999995 0.9999995 0.9999995 0.9999995 0.9999995]
 [0.9999995 0.9999995 0.9999995 0.9999995 0.9999995]]
logits.shape, logits (16,) [ 0.6931472  3.6931472 12.693148  27.693148   0.6931472  3.6931472
 12.693148  27.693148   0.6931472  3.6931472 12.693148  27.693148
  0.6931472  3.6931472 12.693148  27.693148 ]
out
 [[1.         1.         1.         1.         1.        ]
 [1.         1.         1.         1.         1.        ]
 [0.99999905 0.99999905 0.99999905 0.99999905 0.99999905]
 [0.99999905 0.99999905 0.99999905 0.99999905 0.99999905]
 [1.         1.         1.         1.         1.        ]
 [1.         1.         1.         1.         1.        ]
 [0.99999905 0.99999905 0.99999905 0.99999905 0.99999905]
 [0.99999905 0.99999905 0.99999905 0.99999905 0.99999905]]</code></pre>
</div>
</div>
<p>We have now done examples code for most of the operation that are unique to the LSH version of self-attention. I’m sure at this point you are wondering what happens if the number of entries in a bucket is not evenly distributed the way our example is. It is possible, for example for all of the <code>seqlen</code> entries to land in one bucket. Further, since the buckets are not aligned, our ‘chunks’ may be misaligned with the start of the bucket. The implementation addresses this by attending to adjacent chunks as was described in the lecture:</p>
<img src="http://livingdatalab.com/posts/https:/github.com/pranath/blog/raw/master/images/C4W4_LN2_image13.png" height="400" width="750">
<center>
<b>Figure 12: Misaligned Access, looking before and after </b>
</center>
<p>Hopefully, having implemented parts of this, you will appreciate this diagram more fully.</p>
</section>
<section id="ourlshselfattention" class="level3" data-number="5.5">
<h3 data-number="5.5" class="anchored" data-anchor-id="ourlshselfattention"><span class="header-section-number">5.5</span> OurLSHSelfAttention</h3>
<p>We can examine the full implementations below. Area’s we did not ‘attend to’ in our implementations above include variable bucket sizes and masking. We will instantiate a layer of the full implementation below. We tried to use the same variable names above to make it easier to decipher the full version. Note that some of the functionality we implemented in our routines is split between <code>attend</code> and <code>forward_unbatched</code>. We’ve inserted our version of hash below, but use the original version of <code>attend</code>.</p>
<div class="cell" data-execution_count="26">
<div class="sourceCode cell-code" id="cb25" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><span class="co" style="color: #5E5E5E;"># original version from trax 1.3.4</span></span>
<span id="cb25-2"><span class="kw" style="color: #003B4F;">def</span> attend(</span>
<span id="cb25-3">    q,</span>
<span id="cb25-4">    k<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">None</span>,</span>
<span id="cb25-5">    v<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">None</span>,</span>
<span id="cb25-6">    q_chunk_len<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">None</span>,</span>
<span id="cb25-7">    kv_chunk_len<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">None</span>,</span>
<span id="cb25-8">    n_chunks_before<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">0</span>,</span>
<span id="cb25-9">    n_chunks_after<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">0</span>,</span>
<span id="cb25-10">    mask_fn<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">None</span>,</span>
<span id="cb25-11">    q_info<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">None</span>,</span>
<span id="cb25-12">    kv_info<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">None</span>,</span>
<span id="cb25-13">    dropout<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">0.0</span>,</span>
<span id="cb25-14">    rng<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">None</span>,</span>
<span id="cb25-15">):</span>
<span id="cb25-16">    <span class="co" style="color: #5E5E5E;">"""Dot-product attention, with optional chunking and/or masking.</span></span>
<span id="cb25-17"></span>
<span id="cb25-18"><span class="co" style="color: #5E5E5E;">  Args:</span></span>
<span id="cb25-19"><span class="co" style="color: #5E5E5E;">    q: Query vectors, shape [q_len, d_qk]</span></span>
<span id="cb25-20"><span class="co" style="color: #5E5E5E;">    k: Key vectors, shape [kv_len, d_qk]; or None</span></span>
<span id="cb25-21"><span class="co" style="color: #5E5E5E;">    v: Value vectors, shape [kv_len, d_v]</span></span>
<span id="cb25-22"><span class="co" style="color: #5E5E5E;">    q_chunk_len: Set to non-zero to enable chunking for query vectors</span></span>
<span id="cb25-23"><span class="co" style="color: #5E5E5E;">    kv_chunk_len: Set to non-zero to enable chunking for key/value vectors</span></span>
<span id="cb25-24"><span class="co" style="color: #5E5E5E;">    n_chunks_before: Number of adjacent previous chunks to attend to</span></span>
<span id="cb25-25"><span class="co" style="color: #5E5E5E;">    n_chunks_after: Number of adjacent subsequent chunks to attend to</span></span>
<span id="cb25-26"><span class="co" style="color: #5E5E5E;">    mask_fn: </span><span class="al" style="color: #AD0000;">TODO</span><span class="co" style="color: #5E5E5E;">(kitaev) doc</span></span>
<span id="cb25-27"><span class="co" style="color: #5E5E5E;">    q_info: Query-associated metadata for masking</span></span>
<span id="cb25-28"><span class="co" style="color: #5E5E5E;">    kv_info: Key-associated metadata for masking</span></span>
<span id="cb25-29"><span class="co" style="color: #5E5E5E;">    dropout: Dropout rate</span></span>
<span id="cb25-30"><span class="co" style="color: #5E5E5E;">    rng: RNG for dropout</span></span>
<span id="cb25-31"></span>
<span id="cb25-32"><span class="co" style="color: #5E5E5E;">  Returns:</span></span>
<span id="cb25-33"><span class="co" style="color: #5E5E5E;">    A tuple (output, dots_logsumexp). The output has shape [q_len, d_v], and</span></span>
<span id="cb25-34"><span class="co" style="color: #5E5E5E;">    dots_logsumexp has shape [q_len]. The logsumexp of the attention</span></span>
<span id="cb25-35"><span class="co" style="color: #5E5E5E;">    probabilities is useful for combining multiple rounds of attention (as in</span></span>
<span id="cb25-36"><span class="co" style="color: #5E5E5E;">    LSH attention).</span></span>
<span id="cb25-37"><span class="co" style="color: #5E5E5E;">  """</span></span>
<span id="cb25-38">    <span class="cf" style="color: #003B4F;">assert</span> v <span class="kw" style="color: #003B4F;">is</span> <span class="kw" style="color: #003B4F;">not</span> <span class="va" style="color: #111111;">None</span></span>
<span id="cb25-39">    share_qk <span class="op" style="color: #5E5E5E;">=</span> k <span class="kw" style="color: #003B4F;">is</span> <span class="va" style="color: #111111;">None</span></span>
<span id="cb25-40"></span>
<span id="cb25-41">    <span class="cf" style="color: #003B4F;">if</span> q_info <span class="kw" style="color: #003B4F;">is</span> <span class="va" style="color: #111111;">None</span>:</span>
<span id="cb25-42">        q_info <span class="op" style="color: #5E5E5E;">=</span> np.arange(q.shape[<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">2</span>], dtype<span class="op" style="color: #5E5E5E;">=</span>np.int32)</span>
<span id="cb25-43"></span>
<span id="cb25-44">    <span class="cf" style="color: #003B4F;">if</span> kv_info <span class="kw" style="color: #003B4F;">is</span> <span class="va" style="color: #111111;">None</span> <span class="kw" style="color: #003B4F;">and</span> <span class="kw" style="color: #003B4F;">not</span> share_qk:</span>
<span id="cb25-45">        kv_info <span class="op" style="color: #5E5E5E;">=</span> np.arange(v.shape[<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">2</span>], dtype<span class="op" style="color: #5E5E5E;">=</span>np.int32)</span>
<span id="cb25-46"></span>
<span id="cb25-47">    <span class="co" style="color: #5E5E5E;"># Split q/k/v into chunks along the time axis, if desired.</span></span>
<span id="cb25-48">    <span class="cf" style="color: #003B4F;">if</span> q_chunk_len <span class="kw" style="color: #003B4F;">is</span> <span class="kw" style="color: #003B4F;">not</span> <span class="va" style="color: #111111;">None</span>:</span>
<span id="cb25-49">        q <span class="op" style="color: #5E5E5E;">=</span> np.reshape(q, (<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>, q_chunk_len, q.shape[<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>]))</span>
<span id="cb25-50">        q_info <span class="op" style="color: #5E5E5E;">=</span> np.reshape(q_info, (<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>, q_chunk_len))</span>
<span id="cb25-51"></span>
<span id="cb25-52">    <span class="cf" style="color: #003B4F;">if</span> share_qk:</span>
<span id="cb25-53">        <span class="cf" style="color: #003B4F;">assert</span> kv_chunk_len <span class="kw" style="color: #003B4F;">is</span> <span class="va" style="color: #111111;">None</span> <span class="kw" style="color: #003B4F;">or</span> kv_chunk_len <span class="op" style="color: #5E5E5E;">==</span> q_chunk_len</span>
<span id="cb25-54">        k <span class="op" style="color: #5E5E5E;">=</span> q</span>
<span id="cb25-55">        kv_chunk_len <span class="op" style="color: #5E5E5E;">=</span> q_chunk_len</span>
<span id="cb25-56">        <span class="cf" style="color: #003B4F;">if</span> kv_info <span class="kw" style="color: #003B4F;">is</span> <span class="va" style="color: #111111;">None</span>:</span>
<span id="cb25-57">            kv_info <span class="op" style="color: #5E5E5E;">=</span> q_info</span>
<span id="cb25-58">        <span class="cf" style="color: #003B4F;">elif</span> kv_chunk_len <span class="kw" style="color: #003B4F;">is</span> <span class="kw" style="color: #003B4F;">not</span> <span class="va" style="color: #111111;">None</span>:</span>
<span id="cb25-59">            <span class="co" style="color: #5E5E5E;"># kv_info is not None, but reshape as required.</span></span>
<span id="cb25-60">            kv_info <span class="op" style="color: #5E5E5E;">=</span> np.reshape(kv_info, (<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>, kv_chunk_len))</span>
<span id="cb25-61">    <span class="cf" style="color: #003B4F;">elif</span> kv_chunk_len <span class="kw" style="color: #003B4F;">is</span> <span class="kw" style="color: #003B4F;">not</span> <span class="va" style="color: #111111;">None</span>:</span>
<span id="cb25-62">        k <span class="op" style="color: #5E5E5E;">=</span> np.reshape(k, (<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>, kv_chunk_len, k.shape[<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>]))</span>
<span id="cb25-63">        kv_info <span class="op" style="color: #5E5E5E;">=</span> np.reshape(kv_info, (<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>, kv_chunk_len))</span>
<span id="cb25-64"></span>
<span id="cb25-65">    <span class="cf" style="color: #003B4F;">if</span> kv_chunk_len <span class="kw" style="color: #003B4F;">is</span> <span class="kw" style="color: #003B4F;">not</span> <span class="va" style="color: #111111;">None</span>:</span>
<span id="cb25-66">        v <span class="op" style="color: #5E5E5E;">=</span> np.reshape(v, (<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>, kv_chunk_len, v.shape[<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>]))</span>
<span id="cb25-67"></span>
<span id="cb25-68">    <span class="cf" style="color: #003B4F;">if</span> share_qk:</span>
<span id="cb25-69">        k <span class="op" style="color: #5E5E5E;">=</span> length_normalized(k)</span>
<span id="cb25-70">    k <span class="op" style="color: #5E5E5E;">=</span> k <span class="op" style="color: #5E5E5E;">/</span> np.sqrt(k.shape[<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>])</span>
<span id="cb25-71"></span>
<span id="cb25-72">    <span class="co" style="color: #5E5E5E;"># Optionally include adjacent chunks.</span></span>
<span id="cb25-73">    <span class="cf" style="color: #003B4F;">if</span> q_chunk_len <span class="kw" style="color: #003B4F;">is</span> <span class="kw" style="color: #003B4F;">not</span> <span class="va" style="color: #111111;">None</span> <span class="kw" style="color: #003B4F;">or</span> kv_chunk_len <span class="kw" style="color: #003B4F;">is</span> <span class="kw" style="color: #003B4F;">not</span> <span class="va" style="color: #111111;">None</span>:</span>
<span id="cb25-74">        <span class="cf" style="color: #003B4F;">assert</span> q_chunk_len <span class="kw" style="color: #003B4F;">is</span> <span class="kw" style="color: #003B4F;">not</span> <span class="va" style="color: #111111;">None</span> <span class="kw" style="color: #003B4F;">and</span> kv_chunk_len <span class="kw" style="color: #003B4F;">is</span> <span class="kw" style="color: #003B4F;">not</span> <span class="va" style="color: #111111;">None</span></span>
<span id="cb25-75">    <span class="cf" style="color: #003B4F;">else</span>:</span>
<span id="cb25-76">        <span class="cf" style="color: #003B4F;">assert</span> n_chunks_before <span class="op" style="color: #5E5E5E;">==</span> <span class="dv" style="color: #AD0000;">0</span> <span class="kw" style="color: #003B4F;">and</span> n_chunks_after <span class="op" style="color: #5E5E5E;">==</span> <span class="dv" style="color: #AD0000;">0</span></span>
<span id="cb25-77"></span>
<span id="cb25-78">    k <span class="op" style="color: #5E5E5E;">=</span> look_adjacent(k, n_chunks_before, n_chunks_after)</span>
<span id="cb25-79">    v <span class="op" style="color: #5E5E5E;">=</span> look_adjacent(v, n_chunks_before, n_chunks_after)</span>
<span id="cb25-80">    kv_info <span class="op" style="color: #5E5E5E;">=</span> look_adjacent(kv_info, n_chunks_before, n_chunks_after)</span>
<span id="cb25-81"></span>
<span id="cb25-82">    <span class="co" style="color: #5E5E5E;"># Dot-product attention.</span></span>
<span id="cb25-83">    dots <span class="op" style="color: #5E5E5E;">=</span> np.matmul(q, np.swapaxes(k, <span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>, <span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">2</span>))</span>
<span id="cb25-84"></span>
<span id="cb25-85">    <span class="co" style="color: #5E5E5E;"># Masking</span></span>
<span id="cb25-86">    <span class="cf" style="color: #003B4F;">if</span> mask_fn <span class="kw" style="color: #003B4F;">is</span> <span class="kw" style="color: #003B4F;">not</span> <span class="va" style="color: #111111;">None</span>:</span>
<span id="cb25-87">        dots <span class="op" style="color: #5E5E5E;">=</span> mask_fn(dots, q_info[..., :, <span class="va" style="color: #111111;">None</span>], kv_info[..., <span class="va" style="color: #111111;">None</span>, :])</span>
<span id="cb25-88"></span>
<span id="cb25-89">    <span class="co" style="color: #5E5E5E;"># Softmax.</span></span>
<span id="cb25-90">    dots_logsumexp <span class="op" style="color: #5E5E5E;">=</span> fastmath.logsumexp(dots, axis<span class="op" style="color: #5E5E5E;">=-</span><span class="dv" style="color: #AD0000;">1</span>, keepdims<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>)</span>
<span id="cb25-91">    dots <span class="op" style="color: #5E5E5E;">=</span> np.exp(dots <span class="op" style="color: #5E5E5E;">-</span> dots_logsumexp)</span>
<span id="cb25-92"></span>
<span id="cb25-93">    <span class="cf" style="color: #003B4F;">if</span> dropout <span class="op" style="color: #5E5E5E;">&gt;</span> <span class="fl" style="color: #AD0000;">0.0</span>:</span>
<span id="cb25-94">        <span class="cf" style="color: #003B4F;">assert</span> rng <span class="kw" style="color: #003B4F;">is</span> <span class="kw" style="color: #003B4F;">not</span> <span class="va" style="color: #111111;">None</span></span>
<span id="cb25-95">        <span class="co" style="color: #5E5E5E;"># Dropout is broadcast across the bin dimension</span></span>
<span id="cb25-96">        dropout_shape <span class="op" style="color: #5E5E5E;">=</span> (dots.shape[<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">2</span>], dots.shape[<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>])</span>
<span id="cb25-97">        <span class="co" style="color: #5E5E5E;">#</span></span>
<span id="cb25-98">        keep_prob <span class="op" style="color: #5E5E5E;">=</span> tie_in(dots, <span class="fl" style="color: #AD0000;">1.0</span> <span class="op" style="color: #5E5E5E;">-</span> dropout)</span>
<span id="cb25-99">        keep <span class="op" style="color: #5E5E5E;">=</span> fastmath.random.bernoulli(rng, keep_prob, dropout_shape)</span>
<span id="cb25-100">        multiplier <span class="op" style="color: #5E5E5E;">=</span> keep.astype(dots.dtype) <span class="op" style="color: #5E5E5E;">/</span> tie_in(keep, keep_prob)</span>
<span id="cb25-101">        dots <span class="op" style="color: #5E5E5E;">=</span> dots <span class="op" style="color: #5E5E5E;">*</span> multiplier</span>
<span id="cb25-102"></span>
<span id="cb25-103">    <span class="co" style="color: #5E5E5E;"># The softmax normalizer (dots_logsumexp) is used by multi-round LSH attn.</span></span>
<span id="cb25-104">    out <span class="op" style="color: #5E5E5E;">=</span> np.matmul(dots, v)</span>
<span id="cb25-105">    out <span class="op" style="color: #5E5E5E;">=</span> np.reshape(out, (<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>, out.shape[<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>]))</span>
<span id="cb25-106">    dots_logsumexp <span class="op" style="color: #5E5E5E;">=</span> np.reshape(dots_logsumexp, (<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>,))</span>
<span id="cb25-107">    <span class="cf" style="color: #003B4F;">return</span> out, dots_logsumexp</span></code></pre></div>
</div>
<div class="cell" data-execution_count="27">
<div class="sourceCode cell-code" id="cb26" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><span class="kw" style="color: #003B4F;">class</span> OurLSHSelfAttention(tl.LSHSelfAttention):</span>
<span id="cb26-2">    <span class="co" style="color: #5E5E5E;">"""Our simplified LSH self-attention """</span></span>
<span id="cb26-3"></span>
<span id="cb26-4">    <span class="kw" style="color: #003B4F;">def</span> forward_unbatched(<span class="va" style="color: #111111;">self</span>, x, mask<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">None</span>, <span class="op" style="color: #5E5E5E;">*</span>, weights, state, rng, update_state):</span>
<span id="cb26-5">        attend_rng, output_rng <span class="op" style="color: #5E5E5E;">=</span> fastmath.random.split(rng)</span>
<span id="cb26-6">        w_q, w_v, w_o <span class="op" style="color: #5E5E5E;">=</span> weights</span>
<span id="cb26-7"></span>
<span id="cb26-8">        q <span class="op" style="color: #5E5E5E;">=</span> np.matmul(x, w_q)</span>
<span id="cb26-9">        v <span class="op" style="color: #5E5E5E;">=</span> np.matmul(x, w_v)</span>
<span id="cb26-10"></span>
<span id="cb26-11">        <span class="cf" style="color: #003B4F;">if</span> update_state:</span>
<span id="cb26-12">            _, old_hash_rng <span class="op" style="color: #5E5E5E;">=</span> state</span>
<span id="cb26-13">            hash_rng, hash_subrng <span class="op" style="color: #5E5E5E;">=</span> fastmath.random.split(old_hash_rng)</span>
<span id="cb26-14">            <span class="co" style="color: #5E5E5E;">#      buckets = self.hash_vectors(q, hash_subrng, mask)  #  original</span></span>
<span id="cb26-15">            <span class="co" style="color: #5E5E5E;">## use our version of hash</span></span>
<span id="cb26-16">            buckets <span class="op" style="color: #5E5E5E;">=</span> our_hash_vectors(</span>
<span id="cb26-17">                q, hash_subrng, <span class="va" style="color: #111111;">self</span>._n_buckets, <span class="va" style="color: #111111;">self</span>._n_hashes, mask<span class="op" style="color: #5E5E5E;">=</span>mask</span>
<span id="cb26-18">            )</span>
<span id="cb26-19">            s_buckets <span class="op" style="color: #5E5E5E;">=</span> buckets</span>
<span id="cb26-20">            <span class="cf" style="color: #003B4F;">if</span> <span class="va" style="color: #111111;">self</span>._max_length_for_buckets:</span>
<span id="cb26-21">                length <span class="op" style="color: #5E5E5E;">=</span> <span class="va" style="color: #111111;">self</span>._n_hashes <span class="op" style="color: #5E5E5E;">*</span> <span class="va" style="color: #111111;">self</span>._max_length_for_buckets</span>
<span id="cb26-22">                <span class="cf" style="color: #003B4F;">if</span> buckets.shape[<span class="dv" style="color: #AD0000;">0</span>] <span class="op" style="color: #5E5E5E;">&lt;</span> length:</span>
<span id="cb26-23">                    s_buckets <span class="op" style="color: #5E5E5E;">=</span> np.concatenate(</span>
<span id="cb26-24">                        [buckets, np.zeros(length <span class="op" style="color: #5E5E5E;">-</span> buckets.shape[<span class="dv" style="color: #AD0000;">0</span>], dtype<span class="op" style="color: #5E5E5E;">=</span>np.int32)],</span>
<span id="cb26-25">                        axis<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">0</span>,</span>
<span id="cb26-26">                    )</span>
<span id="cb26-27">            state <span class="op" style="color: #5E5E5E;">=</span> (s_buckets, hash_rng)</span>
<span id="cb26-28">        <span class="cf" style="color: #003B4F;">else</span>:</span>
<span id="cb26-29">            buckets, _ <span class="op" style="color: #5E5E5E;">=</span> state</span>
<span id="cb26-30">            <span class="cf" style="color: #003B4F;">if</span> <span class="va" style="color: #111111;">self</span>._max_length_for_buckets:</span>
<span id="cb26-31">                buckets <span class="op" style="color: #5E5E5E;">=</span> buckets[: <span class="va" style="color: #111111;">self</span>._n_hashes <span class="op" style="color: #5E5E5E;">*</span> x.shape[<span class="dv" style="color: #AD0000;">0</span>]]</span>
<span id="cb26-32"></span>
<span id="cb26-33">        seqlen <span class="op" style="color: #5E5E5E;">=</span> x.shape[<span class="dv" style="color: #AD0000;">0</span>]</span>
<span id="cb26-34">        <span class="cf" style="color: #003B4F;">assert</span> <span class="bu" style="color: null;">int</span>(buckets.shape[<span class="dv" style="color: #AD0000;">0</span>]) <span class="op" style="color: #5E5E5E;">==</span> <span class="va" style="color: #111111;">self</span>._n_hashes <span class="op" style="color: #5E5E5E;">*</span> seqlen</span>
<span id="cb26-35"></span>
<span id="cb26-36">        ticker <span class="op" style="color: #5E5E5E;">=</span> tie_in(x, np.arange(<span class="va" style="color: #111111;">self</span>._n_hashes <span class="op" style="color: #5E5E5E;">*</span> seqlen, dtype<span class="op" style="color: #5E5E5E;">=</span>np.int32))</span>
<span id="cb26-37">        buckets_and_t <span class="op" style="color: #5E5E5E;">=</span> seqlen <span class="op" style="color: #5E5E5E;">*</span> buckets <span class="op" style="color: #5E5E5E;">+</span> (ticker <span class="op" style="color: #5E5E5E;">%</span> seqlen)</span>
<span id="cb26-38">        buckets_and_t <span class="op" style="color: #5E5E5E;">=</span> fastmath.stop_gradient(buckets_and_t)</span>
<span id="cb26-39"></span>
<span id="cb26-40">        <span class="co" style="color: #5E5E5E;"># Hash-based sort ("s" at the start of variable names means "sorted")</span></span>
<span id="cb26-41">        sbuckets_and_t, sticker <span class="op" style="color: #5E5E5E;">=</span> fastmath.sort_key_val(</span>
<span id="cb26-42">            buckets_and_t, ticker, dimension<span class="op" style="color: #5E5E5E;">=-</span><span class="dv" style="color: #AD0000;">1</span></span>
<span id="cb26-43">        )</span>
<span id="cb26-44">        _, undo_sort <span class="op" style="color: #5E5E5E;">=</span> fastmath.sort_key_val(sticker, ticker, dimension<span class="op" style="color: #5E5E5E;">=-</span><span class="dv" style="color: #AD0000;">1</span>)</span>
<span id="cb26-45">        sbuckets_and_t <span class="op" style="color: #5E5E5E;">=</span> fastmath.stop_gradient(sbuckets_and_t)</span>
<span id="cb26-46">        sticker <span class="op" style="color: #5E5E5E;">=</span> fastmath.stop_gradient(sticker)</span>
<span id="cb26-47">        undo_sort <span class="op" style="color: #5E5E5E;">=</span> fastmath.stop_gradient(undo_sort)</span>
<span id="cb26-48"></span>
<span id="cb26-49">        st <span class="op" style="color: #5E5E5E;">=</span> sticker <span class="op" style="color: #5E5E5E;">%</span> seqlen</span>
<span id="cb26-50">        sq <span class="op" style="color: #5E5E5E;">=</span> np.take(q, st, axis<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">0</span>)</span>
<span id="cb26-51">        sv <span class="op" style="color: #5E5E5E;">=</span> np.take(v, st, axis<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">0</span>)</span>
<span id="cb26-52"></span>
<span id="cb26-53">        mask_fn <span class="op" style="color: #5E5E5E;">=</span> functools.partial(</span>
<span id="cb26-54">            mask_self_attention,</span>
<span id="cb26-55">            causal<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">self</span>._causal,</span>
<span id="cb26-56">            exclude_self<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>,</span>
<span id="cb26-57">            masked<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">self</span>._masked,</span>
<span id="cb26-58">        )</span>
<span id="cb26-59">        q_info <span class="op" style="color: #5E5E5E;">=</span> st</span>
<span id="cb26-60"></span>
<span id="cb26-61">        <span class="cf" style="color: #003B4F;">assert</span> (mask <span class="kw" style="color: #003B4F;">is</span> <span class="kw" style="color: #003B4F;">not</span> <span class="va" style="color: #111111;">None</span>) <span class="op" style="color: #5E5E5E;">==</span> <span class="va" style="color: #111111;">self</span>._masked</span>
<span id="cb26-62">        kv_info <span class="op" style="color: #5E5E5E;">=</span> <span class="va" style="color: #111111;">None</span></span>
<span id="cb26-63">        <span class="cf" style="color: #003B4F;">if</span> <span class="va" style="color: #111111;">self</span>._masked:</span>
<span id="cb26-64">            <span class="co" style="color: #5E5E5E;"># mask is a boolean array (True means "is valid token")</span></span>
<span id="cb26-65">            smask <span class="op" style="color: #5E5E5E;">=</span> np.take(mask, st, axis<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">0</span>)</span>
<span id="cb26-66">            ones_like_mask <span class="op" style="color: #5E5E5E;">=</span> tie_in(x, np.ones_like(smask, dtype<span class="op" style="color: #5E5E5E;">=</span>np.int32))</span>
<span id="cb26-67">            kv_info <span class="op" style="color: #5E5E5E;">=</span> q_info <span class="op" style="color: #5E5E5E;">*</span> np.where(smask, ones_like_mask, <span class="op" style="color: #5E5E5E;">-</span>ones_like_mask)</span>
<span id="cb26-68"></span>
<span id="cb26-69">        <span class="co" style="color: #5E5E5E;">## use original version of attend (could use ours but lacks masks and masking)</span></span>
<span id="cb26-70">        so, slogits <span class="op" style="color: #5E5E5E;">=</span> attend(</span>
<span id="cb26-71">            sq,</span>
<span id="cb26-72">            k<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">None</span>,</span>
<span id="cb26-73">            v<span class="op" style="color: #5E5E5E;">=</span>sv,</span>
<span id="cb26-74">            q_chunk_len<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">self</span>._chunk_len,</span>
<span id="cb26-75">            n_chunks_before<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">self</span>._n_chunks_before,</span>
<span id="cb26-76">            n_chunks_after<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">self</span>._n_chunks_after,</span>
<span id="cb26-77">            mask_fn<span class="op" style="color: #5E5E5E;">=</span>mask_fn,</span>
<span id="cb26-78">            q_info<span class="op" style="color: #5E5E5E;">=</span>q_info,</span>
<span id="cb26-79">            kv_info<span class="op" style="color: #5E5E5E;">=</span>kv_info,</span>
<span id="cb26-80">            dropout<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">self</span>._attention_dropout,</span>
<span id="cb26-81">            rng<span class="op" style="color: #5E5E5E;">=</span>attend_rng,</span>
<span id="cb26-82">        )</span>
<span id="cb26-83"></span>
<span id="cb26-84">        <span class="co" style="color: #5E5E5E;"># np.take(so, undo_sort, axis=0); np.take(slogits, undo_sort, axis=0) would</span></span>
<span id="cb26-85">        <span class="co" style="color: #5E5E5E;"># also work, but these helpers include performance optimizations for TPU.</span></span>
<span id="cb26-86">        o <span class="op" style="color: #5E5E5E;">=</span> permute_via_gather(so, undo_sort, sticker, axis<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">0</span>)</span>
<span id="cb26-87">        logits <span class="op" style="color: #5E5E5E;">=</span> permute_via_sort(slogits, sticker, buckets_and_t, axis<span class="op" style="color: #5E5E5E;">=-</span><span class="dv" style="color: #AD0000;">1</span>)</span>
<span id="cb26-88"></span>
<span id="cb26-89">        <span class="cf" style="color: #003B4F;">if</span> <span class="va" style="color: #111111;">self</span>._n_hashes <span class="op" style="color: #5E5E5E;">&gt;</span> <span class="dv" style="color: #AD0000;">1</span>:</span>
<span id="cb26-90">            o <span class="op" style="color: #5E5E5E;">=</span> np.reshape(o, (<span class="va" style="color: #111111;">self</span>._n_hashes, seqlen, o.shape[<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>]))</span>
<span id="cb26-91">            logits <span class="op" style="color: #5E5E5E;">=</span> np.reshape(logits, (<span class="va" style="color: #111111;">self</span>._n_hashes, seqlen, <span class="dv" style="color: #AD0000;">1</span>))</span>
<span id="cb26-92">            probs <span class="op" style="color: #5E5E5E;">=</span> np.exp(logits <span class="op" style="color: #5E5E5E;">-</span> fastmath.logsumexp(logits, axis<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">0</span>, keepdims<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>))</span>
<span id="cb26-93">            o <span class="op" style="color: #5E5E5E;">=</span> np.<span class="bu" style="color: null;">sum</span>(o <span class="op" style="color: #5E5E5E;">*</span> probs, axis<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">0</span>)</span>
<span id="cb26-94"></span>
<span id="cb26-95">        <span class="cf" style="color: #003B4F;">assert</span> o.shape <span class="op" style="color: #5E5E5E;">==</span> (seqlen, w_v.shape[<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>])</span>
<span id="cb26-96">        out <span class="op" style="color: #5E5E5E;">=</span> np.matmul(o, w_o)</span>
<span id="cb26-97">        out <span class="op" style="color: #5E5E5E;">=</span> apply_broadcasted_dropout(out, <span class="va" style="color: #111111;">self</span>._output_dropout, output_rng)</span>
<span id="cb26-98">        <span class="cf" style="color: #003B4F;">return</span> out, state</span></code></pre></div>
</div>
<div class="cell" data-execution_count="28">
<div class="sourceCode cell-code" id="cb27" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><span class="co" style="color: #5E5E5E;"># Here we're going to try out our LSHSelfAttention</span></span>
<span id="cb27-2">n_heads <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">3</span></span>
<span id="cb27-3">causal <span class="op" style="color: #5E5E5E;">=</span> <span class="va" style="color: #111111;">False</span></span>
<span id="cb27-4">masked <span class="op" style="color: #5E5E5E;">=</span> <span class="va" style="color: #111111;">False</span></span>
<span id="cb27-5">mask <span class="op" style="color: #5E5E5E;">=</span> <span class="va" style="color: #111111;">None</span></span>
<span id="cb27-6">chunk_len <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">8</span></span>
<span id="cb27-7">n_chunks_before <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">0</span></span>
<span id="cb27-8">n_chunks_after <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">0</span></span>
<span id="cb27-9">attention_dropout <span class="op" style="color: #5E5E5E;">=</span> <span class="fl" style="color: #AD0000;">0.0</span></span>
<span id="cb27-10">n_hashes <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">5</span></span>
<span id="cb27-11">n_buckets <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">4</span></span>
<span id="cb27-12">seq_len <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">8</span></span>
<span id="cb27-13">emb_len <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">5</span></span>
<span id="cb27-14">al <span class="op" style="color: #5E5E5E;">=</span> OurLSHSelfAttention(</span>
<span id="cb27-15">    n_heads<span class="op" style="color: #5E5E5E;">=</span>n_heads,</span>
<span id="cb27-16">    d_qk<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">3</span>,</span>
<span id="cb27-17">    d_v<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">4</span>,</span>
<span id="cb27-18">    causal<span class="op" style="color: #5E5E5E;">=</span>causal,</span>
<span id="cb27-19">    chunk_len<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">8</span>,</span>
<span id="cb27-20">    n_chunks_before<span class="op" style="color: #5E5E5E;">=</span>n_chunks_before,</span>
<span id="cb27-21">    n_chunks_after<span class="op" style="color: #5E5E5E;">=</span>n_chunks_after,</span>
<span id="cb27-22">    n_hashes<span class="op" style="color: #5E5E5E;">=</span>n_hashes,</span>
<span id="cb27-23">    n_buckets<span class="op" style="color: #5E5E5E;">=</span>n_buckets,</span>
<span id="cb27-24">    use_reference_code<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>,</span>
<span id="cb27-25">    attention_dropout<span class="op" style="color: #5E5E5E;">=</span>attention_dropout,</span>
<span id="cb27-26">    mode<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"train"</span>,</span>
<span id="cb27-27">)</span>
<span id="cb27-28"></span>
<span id="cb27-29">x <span class="op" style="color: #5E5E5E;">=</span> jax.random.uniform(jax.random.PRNGKey(<span class="dv" style="color: #AD0000;">0</span>), (<span class="dv" style="color: #AD0000;">1</span>, seq_len, emb_len), dtype<span class="op" style="color: #5E5E5E;">=</span>np.float32)</span>
<span id="cb27-30">al_osa <span class="op" style="color: #5E5E5E;">=</span> fastmath.random.get_prng(<span class="dv" style="color: #AD0000;">1</span>)</span>
<span id="cb27-31">_, _ <span class="op" style="color: #5E5E5E;">=</span> al.init(tl.shapes.signature(x), rng<span class="op" style="color: #5E5E5E;">=</span>al_osa)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="29">
<div class="sourceCode cell-code" id="cb28" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1">al(x)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="29">
<pre><code>DeviceArray([[[ 6.6842824e-01, -1.1364317e-01, -5.4430604e-01,
                2.1126242e-01, -1.0988623e-02],
              [ 7.0949769e-01, -1.5455186e-01, -5.9923327e-01,
                2.2719446e-01,  1.3833597e-02],
              [ 7.1442676e-01, -1.2046637e-01, -5.3956550e-01,
                1.7320302e-01, -1.6552359e-02],
              [ 6.7178923e-01, -7.6611102e-02, -5.9399861e-01,
                2.1236290e-01,  7.9482794e-04],
              [ 7.1518433e-01, -1.1359167e-01, -5.7821894e-01,
                2.1304408e-01,  3.0598283e-02],
              [ 6.8235350e-01, -9.3979925e-02, -5.5341840e-01,
                2.1608174e-01, -6.6673756e-04],
              [ 6.1286640e-01, -8.1027031e-02, -4.8148823e-01,
                1.9373316e-01,  3.1555220e-02],
              [ 7.2203499e-01, -1.0199663e-01, -5.5215168e-01,
                1.7872261e-01, -2.2289157e-02]]], dtype=float32)</code></pre>
</div>
</div>
</section>
</section>
<section id="acknowledgements" class="level2" data-number="6">
<h2 data-number="6" class="anchored" data-anchor-id="acknowledgements"><span class="header-section-number">6</span> Acknowledgements</h2>
<p>I’d like to express my thanks to the great <a href="https://www.coursera.org/learn/attention-models-in-nlp">Natural Language Processing with Attention Models Course</a> which i completed, and acknowledge the use of some images and other materials from the course in this article.</p>


</section>

 ]]></description>
  <category>natural-language-processing</category>
  <category>deep-learning</category>
  <guid>http://livingdatalab.com/posts/2023-03-26-making-more-efficient-transformers-with-reversable-layers-and-lsh.html</guid>
  <pubDate>Sun, 26 Mar 2023 00:00:00 GMT</pubDate>
  <media:content url="https://github.com/pranath/blog/raw/master/images/C4W4_LN2_image13.png" medium="image" type="image/png"/>
</item>
<item>
  <title>Customising a Chatbot with Fine Tuning and Hugging Face Pretrained Models</title>
  <dc:creator>Pranath Fernando</dc:creator>
  <link>http://livingdatalab.com/posts/2023-03-25-customising-a-chatbot-with-fine-tuning-and-huggingface-pre-trained-models.html</link>
  <description><![CDATA[ 




<section id="introduction" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="introduction"><span class="header-section-number">1</span> Introduction</h2>
<p>In a <a href="2023-03-24-creating-a-chatbot-with-huggingface-pre-trained-models.html">previous article</a> we saw how to use the pipeline objects to use pre-trained transformer models to create a chatbot. We saw there that the model didn’t always output the desired answers to a series of precise questions for a context related to the history of comic books.</p>
<p>In this article, we will fine-tune the model from that article to give better answers for that type of context. To do that, we’ll be using the <a href="https://ai.google.com/research/tydiqa">TyDi QA dataset</a> but on a filtered version with only English examples. Additionally, we will use a lot of the tools that Hugging Face has to offer.</p>
<p>We should note that, in general, you would fine-tune general-purpose transformer models to work for specific tasks. However, fine-tuning a general-purpose model can take a lot of time. That’s why we will be using a model from a hugging face question answering pipeline to speed things up.</p>
</section>
<section id="fine-tuning-a-bert-model" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="fine-tuning-a-bert-model"><span class="header-section-number">2</span> Fine-tuning a BERT model</h2>
<p>As we saw in the previous article, we can use hugging face pipelines as they are. But sometimes, you’ll need something more specific to your problem, or maybe you need it to perform better on your production data. In these cases, you’ll need to fine-tune a model.</p>
<p>Here, we’ll fine-tune a pre-trained DistilBERT model on the TyDi QA dataset.</p>
<p>To fine-tune your model, we will leverage three components provided by Hugging Face:</p>
<ul>
<li>Datasets: Library that contains some datasets and different metrics to evaluate the performance of our models.</li>
<li>Tokenizer: Object in charge of preprocessing your text to be given as input for the transformer models.</li>
<li>Transformers: Library with the pre-trained model checkpoints and the trainer object.</li>
</ul>
</section>
<section id="datasets" class="level2" data-number="3">
<h2 data-number="3" class="anchored" data-anchor-id="datasets"><span class="header-section-number">3</span> Datasets</h2>
<p>To get the dataset to fine-tune your model, we will use <a href="https://huggingface.co/docs/datasets/">🤗 Datasets</a>, a lightweight and extensible library to share and access datasets and evaluation metrics for NLP easily. We can download Hugging Face datasets directly using the <code>load_dataset</code> function from the <code>datasets</code> library. Although the most common approach is to use <code>load_dataset</code>, for this article we will use a filtered version containing only the English examples. We can read them from a public GCP bucket and use the <code>load_from_disk</code> function.</p>
<p>Hugging Face <code>datasets</code> allows to load data in several formats, such as CSV, JSON, text files and even parquet. We can see more about the supported formats in the <a href="https://huggingface.co/docs/datasets/loading.html">documentation</a></p>
<p>We already prepared the dataset, so we don’t need to uncomment the code from the cell below to load all the data and then filter the English examples. To download the dataset, we can uncomment the following cell and then jump to the cell in which you can see the type of object we get after loading the dataset.</p>
<div class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="co" style="color: #5E5E5E;"># We can download the dataset and process it to obtain the same dataset we are loading from disk</span></span>
<span id="cb1-2"><span class="co" style="color: #5E5E5E;">#&nbsp;Uncomment the following lines to download the dataset directly</span></span>
<span id="cb1-3"><span class="co" style="color: #5E5E5E;">#&nbsp;from datasets import load_dataset</span></span>
<span id="cb1-4"><span class="co" style="color: #5E5E5E;">#&nbsp;train_data = load_dataset('tydiqa', 'primary_task')</span></span>
<span id="cb1-5"><span class="co" style="color: #5E5E5E;"># tydiqa_data = &nbsp;train_data.filter(lambda example: example['language'] == 'english')</span></span></code></pre></div>
</div>
<p>To use the dataset loaded locally, we need to run the following cells. First, we will download the dataset from the GCP bucket.</p>
<div class="cell" data-outputid="e0a749a3-9fed-4145-ca95-9f5075be5e22" data-execution_count="4">
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="co" style="color: #5E5E5E;"># Download dataset from bucket.</span></span>
<span id="cb2-2"><span class="op" style="color: #5E5E5E;">!</span>wget https:<span class="op" style="color: #5E5E5E;">//</span>storage.googleapis.com<span class="op" style="color: #5E5E5E;">/</span>nlprefresh<span class="op" style="color: #5E5E5E;">-</span>public<span class="op" style="color: #5E5E5E;">/</span>tydiqa_data.<span class="bu" style="color: null;">zip</span></span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>--2023-03-22 19:23:05--  https://storage.googleapis.com/nlprefresh-public/tydiqa_data.zip
Resolving storage.googleapis.com (storage.googleapis.com)... 142.250.1.128, 108.177.121.128, 142.250.103.128, ...
Connecting to storage.googleapis.com (storage.googleapis.com)|142.250.1.128|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: 333821654 (318M) [application/zip]
Saving to: ‘tydiqa_data.zip’

tydiqa_data.zip     100%[===================&gt;] 318.36M   141MB/s    in 2.3s    

2023-03-22 19:23:08 (141 MB/s) - ‘tydiqa_data.zip’ saved [333821654/333821654]
</code></pre>
</div>
</div>
<div class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><span class="co" style="color: #5E5E5E;"># Uncomment if you want to check the size of the file. It should be around 319M.</span></span>
<span id="cb4-2"><span class="co" style="color: #5E5E5E;">#!ls -alh tydiqa_data.zip</span></span></code></pre></div>
</div>
<p>Now, let’s unzip the dataset</p>
<div class="cell" data-outputid="e0e17486-6e24-4c72-8a25-8e36c65134b4" data-execution_count="6">
<div class="sourceCode cell-code" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><span class="co" style="color: #5E5E5E;"># Unzip inside the dataset folder</span></span>
<span id="cb5-2"><span class="op" style="color: #5E5E5E;">!</span>unzip tydiqa_data</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Archive:  tydiqa_data.zip
  inflating: tydiqa_data/validation/dataset_info.json  
  inflating: tydiqa_data/dataset_dict.json  
  inflating: tydiqa_data/train/state.json  
  inflating: tydiqa_data/train/dataset_info.json  
  inflating: tydiqa_data/validation/dataset.arrow  
  inflating: tydiqa_data/validation/cache-32664b2bb6ecb93c.arrow  
  inflating: tydiqa_data/validation/cache-981c6a4602432980.arrow  
  inflating: tydiqa_data/validation/cache-0adce067eac1391a.arrow  
  inflating: tydiqa_data/validation/cache-22dd192df839003a.arrow  
  inflating: tydiqa_data/validation/cache-de50d25427e34427.arrow  
  inflating: tydiqa_data/train/cache-a7d4fcf0afedf699.arrow  
  inflating: tydiqa_data/train/cache-bec06ea6cf14cfc1.arrow  
  inflating: tydiqa_data/validation/state.json  
  inflating: tydiqa_data/train/dataset.arrow  
  inflating: tydiqa_data/train/cache-ce4e04eb371cb7de.arrow  </code></pre>
</div>
</div>
<p>Given that we used Apache Arrow format to save the dataset, we have to use the <code>load_from_disk</code> function from the <code>datasets</code> library to load it. To access the preprocessed dataset we created, we should execute the following commands.</p>
<div class="cell" data-outputid="dc3d32b3-053e-4673-e5a0-993f3fc26b52" data-execution_count="7">
<div class="sourceCode cell-code" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><span class="co" style="color: #5E5E5E;"># Execute this cell if to use the data pre-processed instead of downloading it.</span></span>
<span id="cb7-2"><span class="im" style="color: #00769E;">from</span> datasets <span class="im" style="color: #00769E;">import</span> load_from_disk</span>
<span id="cb7-3"></span>
<span id="cb7-4"><span class="co" style="color: #5E5E5E;">#The path where the dataset is stored</span></span>
<span id="cb7-5">path <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">'/content/tydiqa_data/'</span></span>
<span id="cb7-6"></span>
<span id="cb7-7"><span class="co" style="color: #5E5E5E;">#Load Dataset</span></span>
<span id="cb7-8">tydiqa_data <span class="op" style="color: #5E5E5E;">=</span> load_from_disk(path)</span>
<span id="cb7-9"></span>
<span id="cb7-10">tydiqa_data</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="7">
<pre><code>DatasetDict({
    train: Dataset({
        features: ['passage_answer_candidates', 'question_text', 'document_title', 'language', 'annotations', 'document_plaintext', 'document_url'],
        num_rows: 9211
    })
    validation: Dataset({
        features: ['passage_answer_candidates', 'question_text', 'document_title', 'language', 'annotations', 'document_plaintext', 'document_url'],
        num_rows: 1031
    })
})</code></pre>
</div>
</div>
<p>We can check below that the type of the loaded dataset is a <code>datasets.arrow_dataset.Dataset</code>. This object type corresponds to an Apache Arrow Table that allows creating a hash table that contains the position in memory where data is stored instead of loading the complete dataset into memory. But we don’t have to worry too much about that. It is just an efficient way to work with lots of data.</p>
<div class="cell" data-outputid="50d507ac-3b64-4201-844d-cb26ae368c9f" data-execution_count="8">
<div class="sourceCode cell-code" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><span class="co" style="color: #5E5E5E;"># Checking the object type for one of the elements in the dataset</span></span>
<span id="cb9-2"><span class="bu" style="color: null;">type</span>(tydiqa_data[<span class="st" style="color: #20794D;">'train'</span>])</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="8">
<pre><code>datasets.arrow_dataset.Dataset</code></pre>
</div>
</div>
<p>We can also check the structure of the dataset:</p>
<div class="cell" data-outputid="553c5126-c91f-494f-9b4d-43ba4c8d73f3" data-execution_count="9">
<div class="sourceCode cell-code" id="cb11" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1">tydiqa_data[<span class="st" style="color: #20794D;">'train'</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="9">
<pre><code>Dataset({
    features: ['passage_answer_candidates', 'question_text', 'document_title', 'language', 'annotations', 'document_plaintext', 'document_url'],
    num_rows: 9211
})</code></pre>
</div>
</div>
<p>We can see that each example is like a dictionary object. This dataset consists of questions, contexts, and indices that point to the start and end position of the answer inside the context. We can access the index using the <code>annotations</code> key, which is a kind of dictionary.</p>
<div class="cell" data-outputid="f2462c64-ba81-4038-d365-3edebc39fc16" data-execution_count="10">
<div class="sourceCode cell-code" id="cb13" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1">idx <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">600</span></span>
<span id="cb13-2"></span>
<span id="cb13-3"><span class="co" style="color: #5E5E5E;"># start index</span></span>
<span id="cb13-4">start_index <span class="op" style="color: #5E5E5E;">=</span> tydiqa_data[<span class="st" style="color: #20794D;">'train'</span>][idx][<span class="st" style="color: #20794D;">'annotations'</span>][<span class="st" style="color: #20794D;">'minimal_answers_start_byte'</span>][<span class="dv" style="color: #AD0000;">0</span>]</span>
<span id="cb13-5"></span>
<span id="cb13-6"><span class="co" style="color: #5E5E5E;"># end index</span></span>
<span id="cb13-7">end_index <span class="op" style="color: #5E5E5E;">=</span> tydiqa_data[<span class="st" style="color: #20794D;">'train'</span>][idx][<span class="st" style="color: #20794D;">'annotations'</span>][<span class="st" style="color: #20794D;">'minimal_answers_end_byte'</span>][<span class="dv" style="color: #AD0000;">0</span>]</span>
<span id="cb13-8"></span>
<span id="cb13-9"><span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">"Question: "</span> <span class="op" style="color: #5E5E5E;">+</span> tydiqa_data[<span class="st" style="color: #20794D;">'train'</span>][idx][<span class="st" style="color: #20794D;">'question_text'</span>])</span>
<span id="cb13-10"><span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">"</span><span class="ch" style="color: #20794D;">\n</span><span class="st" style="color: #20794D;">Context (truncated): "</span><span class="op" style="color: #5E5E5E;">+</span> tydiqa_data[<span class="st" style="color: #20794D;">'train'</span>][idx][<span class="st" style="color: #20794D;">'document_plaintext'</span>][<span class="dv" style="color: #AD0000;">0</span>:<span class="dv" style="color: #AD0000;">512</span>] <span class="op" style="color: #5E5E5E;">+</span> <span class="st" style="color: #20794D;">'...'</span>)</span>
<span id="cb13-11"><span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">"</span><span class="ch" style="color: #20794D;">\n</span><span class="st" style="color: #20794D;">Answer: "</span> <span class="op" style="color: #5E5E5E;">+</span> tydiqa_data[<span class="st" style="color: #20794D;">'train'</span>][idx][<span class="st" style="color: #20794D;">'document_plaintext'</span>][start_index:end_index])</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Question: What mental effects can a mother experience after childbirth?

Context (truncated): 

Postpartum depression (PPD), also called postnatal depression, is a type of mood disorder associated with childbirth, which can affect both sexes.[1][3] Symptoms may include extreme sadness, low energy, anxiety, crying episodes, irritability, and changes in sleeping or eating patterns.[1] Onset is typically between one week and one month following childbirth.[1] PPD can also negatively affect the newborn child.[2]

While the exact cause of PPD is unclear, the cause is believed to be a combination of physi...

Answer: Postpartum depression (PPD)</code></pre>
</div>
</div>
<p>The question answering model predicts a start and endpoint in the context to extract as the answer. That’s why this NLP task is known as extractive question answering.</p>
<p>To train our model, we need to pass start and endpoints as labels. So, we need to implement a function that extracts the start and end positions from the dataset.</p>
<p>The dataset contains unanswerable questions. For these, the start and end indices for the answer are equal to <code>-1</code>.</p>
<div class="cell" data-outputid="189ba3cd-b4d3-42f0-c524-138b686865f5" data-execution_count="11">
<div class="sourceCode cell-code" id="cb15" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1">tydiqa_data[<span class="st" style="color: #20794D;">'train'</span>][<span class="dv" style="color: #AD0000;">0</span>][<span class="st" style="color: #20794D;">'annotations'</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="11">
<pre><code>{'passage_answer_candidate_index': [-1],
 'minimal_answers_start_byte': [-1],
 'minimal_answers_end_byte': [-1],
 'yes_no_answer': ['NONE']}</code></pre>
</div>
</div>
<p>Now, we have to flatten the dataset to work with an object with a table structure instead of a dictionary structure. This step facilitates the pre-processing steps.</p>
<div class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb17" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><span class="co" style="color: #5E5E5E;">#&nbsp;Flattening the datasets</span></span>
<span id="cb17-2">flattened_train_data <span class="op" style="color: #5E5E5E;">=</span> tydiqa_data[<span class="st" style="color: #20794D;">'train'</span>].flatten()</span>
<span id="cb17-3">flattened_test_data <span class="op" style="color: #5E5E5E;">=</span>  tydiqa_data[<span class="st" style="color: #20794D;">'validation'</span>].flatten()</span></code></pre></div>
</div>
<p>Also, to make the training more straightforward and faster, we will extract a subset of the train and test datasets. For that purpose, we will use the Hugging Face Dataset object’s method called <code>select()</code>. This method allows you to take some data points by their index. Here, we will select the first 3000 rows; we can play with the number of data points but consider that this will increase the training time.</p>
<div class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb18" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><span class="co" style="color: #5E5E5E;"># Selecting a subset of the train dataset</span></span>
<span id="cb18-2">flattened_train_data <span class="op" style="color: #5E5E5E;">=</span> flattened_train_data.select(<span class="bu" style="color: null;">range</span>(<span class="dv" style="color: #AD0000;">3000</span>))</span>
<span id="cb18-3"></span>
<span id="cb18-4"><span class="co" style="color: #5E5E5E;"># Selecting a subset of the test dataset</span></span>
<span id="cb18-5">flattened_test_data <span class="op" style="color: #5E5E5E;">=</span> flattened_test_data.select(<span class="bu" style="color: null;">range</span>(<span class="dv" style="color: #AD0000;">1000</span>))</span></code></pre></div>
</div>
</section>
<section id="tokenizers" class="level2" data-number="4">
<h2 data-number="4" class="anchored" data-anchor-id="tokenizers"><span class="header-section-number">4</span> Tokenizers</h2>
<p>Now, we will use the <a href="https://huggingface.co/transformers/main_classes/tokenizer.html">tokenizer</a> object from Hugging Face. We can load a tokenizer using different methods. Here, we will retrieve it from the pipeline object we created in the previous article. With this tokenizer, we can ensure that the tokens we get for the dataset will match the tokens used in the original DistilBERT implementation.</p>
<p>When loading a tokenizer with any method, we must pass the model checkpoint that you want to fine-tune. Here, we are using the<code>'distilbert-base-cased-distilled-squad'</code> checkpoint.</p>
<div class="cell" data-outputid="4a496f21-babe-4014-e7d8-5d2404a1d729" data-execution_count="14">
<div class="sourceCode cell-code" id="cb19" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><span class="co" style="color: #5E5E5E;"># Import the AutoTokenizer from the transformers library</span></span>
<span id="cb19-2"><span class="im" style="color: #00769E;">from</span> transformers <span class="im" style="color: #00769E;">import</span> AutoTokenizer</span>
<span id="cb19-3">tokenizer <span class="op" style="color: #5E5E5E;">=</span> AutoTokenizer.from_pretrained(<span class="st" style="color: #20794D;">"distilbert-base-cased-distilled-squad"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"d80013709bd34f13b9c6a587c5f9c5f9","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"83643f4de74f4095bd51e595fb64f0c5","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"26e89703128d41e5afc14d3631b77e3e","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"468ff8e571274646b4300244c73b7f98","version_major":2,"version_minor":0}
</script>
</div>
</div>
<p>Given the characteristics of the dataset and the question-answering task, we will need to add some steps to pre-process the data after the tokenization:</p>
<ol type="1">
<li><p>When there is no answer to a question given a context, we will use the <code>CLS</code> token, a unique token used to represent the start of the sequence.</p></li>
<li><p>Tokenizers can split a given string into substrings, resulting in a subtoken for each substring, creating misalignment between the list of dataset tags and the labels generated by the tokenizer. Therefore, we will need to align the start and end indices with the tokens associated with the target answer word.</p></li>
<li><p>Finally, a tokenizer can truncate a very long sequence. So, if the start/end position of an answer is <code>None</code>, we will assume that it was truncated and assign the maximum length of the tokenizer to those positions.</p></li>
</ol>
<p>Those three steps are done within the <code>process_samples</code> function defined below.</p>
<div class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb20" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><span class="co" style="color: #5E5E5E;"># Processing samples using the 3 steps described.</span></span>
<span id="cb20-2"><span class="kw" style="color: #003B4F;">def</span> process_samples(sample):    </span>
<span id="cb20-3">    tokenized_data <span class="op" style="color: #5E5E5E;">=</span> tokenizer(sample[<span class="st" style="color: #20794D;">'document_plaintext'</span>], sample[<span class="st" style="color: #20794D;">'question_text'</span>], truncation<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"only_first"</span>, padding<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"max_length"</span>)</span>
<span id="cb20-4">    </span>
<span id="cb20-5">    input_ids <span class="op" style="color: #5E5E5E;">=</span> tokenized_data[<span class="st" style="color: #20794D;">"input_ids"</span>]</span>
<span id="cb20-6">        </span>
<span id="cb20-7">    <span class="co" style="color: #5E5E5E;"># We will label impossible answers with the index of the CLS token.</span></span>
<span id="cb20-8">    cls_index <span class="op" style="color: #5E5E5E;">=</span> input_ids.index(tokenizer.cls_token_id)</span>
<span id="cb20-9">        </span>
<span id="cb20-10">    <span class="co" style="color: #5E5E5E;"># If no answers are given, set the cls_index as answer.</span></span>
<span id="cb20-11">    <span class="cf" style="color: #003B4F;">if</span> sample[<span class="st" style="color: #20794D;">"annotations.minimal_answers_start_byte"</span>][<span class="dv" style="color: #AD0000;">0</span>] <span class="op" style="color: #5E5E5E;">==</span> <span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>:</span>
<span id="cb20-12">        start_position <span class="op" style="color: #5E5E5E;">=</span> cls_index</span>
<span id="cb20-13">        end_position <span class="op" style="color: #5E5E5E;">=</span> cls_index</span>
<span id="cb20-14">    <span class="cf" style="color: #003B4F;">else</span>:</span>
<span id="cb20-15">        <span class="co" style="color: #5E5E5E;"># Start/end character index of the answer in the text.</span></span>
<span id="cb20-16">        gold_text <span class="op" style="color: #5E5E5E;">=</span> sample[<span class="st" style="color: #20794D;">"document_plaintext"</span>][sample[<span class="st" style="color: #20794D;">'annotations.minimal_answers_start_byte'</span>][<span class="dv" style="color: #AD0000;">0</span>]:sample[<span class="st" style="color: #20794D;">'annotations.minimal_answers_end_byte'</span>][<span class="dv" style="color: #AD0000;">0</span>]]</span>
<span id="cb20-17">        start_char <span class="op" style="color: #5E5E5E;">=</span> sample[<span class="st" style="color: #20794D;">"annotations.minimal_answers_start_byte"</span>][<span class="dv" style="color: #AD0000;">0</span>]</span>
<span id="cb20-18">        end_char <span class="op" style="color: #5E5E5E;">=</span> sample[<span class="st" style="color: #20794D;">'annotations.minimal_answers_end_byte'</span>][<span class="dv" style="color: #AD0000;">0</span>] <span class="co" style="color: #5E5E5E;">#start_char + len(gold_text)</span></span>
<span id="cb20-19"></span>
<span id="cb20-20">        <span class="co" style="color: #5E5E5E;"># sometimes answers are off by a character or two – fix this</span></span>
<span id="cb20-21">        <span class="cf" style="color: #003B4F;">if</span> sample[<span class="st" style="color: #20794D;">'document_plaintext'</span>][start_char<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>:end_char<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>] <span class="op" style="color: #5E5E5E;">==</span> gold_text:</span>
<span id="cb20-22">            start_char <span class="op" style="color: #5E5E5E;">=</span> start_char <span class="op" style="color: #5E5E5E;">-</span> <span class="dv" style="color: #AD0000;">1</span></span>
<span id="cb20-23">            end_char <span class="op" style="color: #5E5E5E;">=</span> end_char <span class="op" style="color: #5E5E5E;">-</span> <span class="dv" style="color: #AD0000;">1</span>     <span class="co" style="color: #5E5E5E;"># When the gold label is off by one character</span></span>
<span id="cb20-24">        <span class="cf" style="color: #003B4F;">elif</span> sample[<span class="st" style="color: #20794D;">'document_plaintext'</span>][start_char<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">2</span>:end_char<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">2</span>] <span class="op" style="color: #5E5E5E;">==</span> gold_text:</span>
<span id="cb20-25">            start_char <span class="op" style="color: #5E5E5E;">=</span> start_char <span class="op" style="color: #5E5E5E;">-</span> <span class="dv" style="color: #AD0000;">2</span></span>
<span id="cb20-26">            end_char <span class="op" style="color: #5E5E5E;">=</span> end_char <span class="op" style="color: #5E5E5E;">-</span> <span class="dv" style="color: #AD0000;">2</span>     <span class="co" style="color: #5E5E5E;"># When the gold label is off by two characters</span></span>
<span id="cb20-27">                                  </span>
<span id="cb20-28">        start_token <span class="op" style="color: #5E5E5E;">=</span> tokenized_data.char_to_token(start_char)</span>
<span id="cb20-29">        end_token <span class="op" style="color: #5E5E5E;">=</span> tokenized_data.char_to_token(end_char <span class="op" style="color: #5E5E5E;">-</span> <span class="dv" style="color: #AD0000;">1</span>)</span>
<span id="cb20-30">        </span>
<span id="cb20-31">        <span class="co" style="color: #5E5E5E;"># if start position is None, the answer passage has been truncated</span></span>
<span id="cb20-32">        <span class="cf" style="color: #003B4F;">if</span> start_token <span class="kw" style="color: #003B4F;">is</span> <span class="va" style="color: #111111;">None</span>:</span>
<span id="cb20-33">            start_token <span class="op" style="color: #5E5E5E;">=</span> tokenizer.model_max_length</span>
<span id="cb20-34">        <span class="cf" style="color: #003B4F;">if</span> end_token <span class="kw" style="color: #003B4F;">is</span> <span class="va" style="color: #111111;">None</span>:</span>
<span id="cb20-35">            end_token <span class="op" style="color: #5E5E5E;">=</span> tokenizer.model_max_length</span>
<span id="cb20-36">            </span>
<span id="cb20-37">        start_position <span class="op" style="color: #5E5E5E;">=</span> start_token</span>
<span id="cb20-38">        end_position <span class="op" style="color: #5E5E5E;">=</span> end_token</span>
<span id="cb20-39"></span>
<span id="cb20-40">    <span class="cf" style="color: #003B4F;">return</span> {<span class="st" style="color: #20794D;">'input_ids'</span>: tokenized_data[<span class="st" style="color: #20794D;">'input_ids'</span>],</span>
<span id="cb20-41">          <span class="st" style="color: #20794D;">'attention_mask'</span>: tokenized_data[<span class="st" style="color: #20794D;">'attention_mask'</span>],</span>
<span id="cb20-42">          <span class="st" style="color: #20794D;">'start_positions'</span>: start_position,</span>
<span id="cb20-43">          <span class="st" style="color: #20794D;">'end_positions'</span>: end_position}</span></code></pre></div>
</div>
<p>To apply the <code>process_samples</code> function defined above to the whole dataset, we can use the <code>map</code> method as follows:</p>
<div class="cell" data-outputid="39f8a74e-b9bc-40a6-a4d3-df902d21a130" data-execution_count="16">
<div class="sourceCode cell-code" id="cb21" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><span class="co" style="color: #5E5E5E;"># Tokenizing and processing the flattened dataset</span></span>
<span id="cb21-2">processed_train_data <span class="op" style="color: #5E5E5E;">=</span> flattened_train_data.<span class="bu" style="color: null;">map</span>(process_samples)</span>
<span id="cb21-3">processed_test_data <span class="op" style="color: #5E5E5E;">=</span> flattened_test_data.<span class="bu" style="color: null;">map</span>(process_samples)</span></code></pre></div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"a0b21d0d779e426cb00485147f632159","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"891b80e755a641eeb98c75f4cf4d2934","version_major":2,"version_minor":0}
</script>
</div>
</div>
</section>
<section id="transformers" class="level2" data-number="5">
<h2 data-number="5" class="anchored" data-anchor-id="transformers"><span class="header-section-number">5</span> Transformers</h2>
<p>The last component of Hugging Face that is useful for fine-tuning a transformer corresponds to the pre-trained models we can access in multiple ways.</p>
<p>For this project, we will use the same model from the question-answering pipeline that we used in the previous article.</p>
<div class="cell" data-outputid="06e6b970-fbb7-4800-b32b-2e7bdfd29e3a" data-execution_count="17">
<div class="sourceCode cell-code" id="cb22" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><span class="co" style="color: #5E5E5E;"># Import the AutoModelForQuestionAnswering for the pre-trained model. We will only fine tune the head of the model</span></span>
<span id="cb22-2"><span class="im" style="color: #00769E;">from</span> transformers <span class="im" style="color: #00769E;">import</span> AutoModelForQuestionAnswering</span>
<span id="cb22-3">model <span class="op" style="color: #5E5E5E;">=</span> AutoModelForQuestionAnswering.from_pretrained(<span class="st" style="color: #20794D;">"distilbert-base-cased-distilled-squad"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"f0d30704f56143d4b1ab2b407ea84d7a","version_major":2,"version_minor":0}
</script>
</div>
</div>
<p>Now, we can take the necessary columns from the datasets to train/test and return them as Pytorch Tensors.</p>
<div class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb23" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1">columns_to_return <span class="op" style="color: #5E5E5E;">=</span> [<span class="st" style="color: #20794D;">'input_ids'</span>,<span class="st" style="color: #20794D;">'attention_mask'</span>, <span class="st" style="color: #20794D;">'start_positions'</span>, <span class="st" style="color: #20794D;">'end_positions'</span>]</span>
<span id="cb23-2">processed_train_data.set_format(<span class="bu" style="color: null;">type</span><span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'pt'</span>, columns<span class="op" style="color: #5E5E5E;">=</span>columns_to_return) </span>
<span id="cb23-3">processed_test_data.set_format(<span class="bu" style="color: null;">type</span><span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'pt'</span>, columns<span class="op" style="color: #5E5E5E;">=</span>columns_to_return) </span></code></pre></div>
</div>
<p>Here, we use the F1 score as a metric to evaluate our model’s performance. We will use this metric for simplicity, although it is based on the start and end values predicted by the model. If you want to dig deeper on other metrics that can be used for a question and answering task, you can also check <a href="https://colab.research.google.com/github/huggingface/notebooks/blob/master/examples/question_answering.ipynb">this colab notebook resource</a> from the Hugging Face team.</p>
<div class="cell" data-execution_count="19">
<div class="sourceCode cell-code" id="cb24" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><span class="im" style="color: #00769E;">from</span> sklearn.metrics <span class="im" style="color: #00769E;">import</span> f1_score</span>
<span id="cb24-2"></span>
<span id="cb24-3"><span class="kw" style="color: #003B4F;">def</span> compute_f1_metrics(pred):    </span>
<span id="cb24-4">    start_labels <span class="op" style="color: #5E5E5E;">=</span> pred.label_ids[<span class="dv" style="color: #AD0000;">0</span>]</span>
<span id="cb24-5">    start_preds <span class="op" style="color: #5E5E5E;">=</span> pred.predictions[<span class="dv" style="color: #AD0000;">0</span>].argmax(<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>)</span>
<span id="cb24-6">    end_labels <span class="op" style="color: #5E5E5E;">=</span> pred.label_ids[<span class="dv" style="color: #AD0000;">1</span>]</span>
<span id="cb24-7">    end_preds <span class="op" style="color: #5E5E5E;">=</span> pred.predictions[<span class="dv" style="color: #AD0000;">1</span>].argmax(<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>)</span>
<span id="cb24-8">    </span>
<span id="cb24-9">    f1_start <span class="op" style="color: #5E5E5E;">=</span> f1_score(start_labels, start_preds, average<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'macro'</span>)</span>
<span id="cb24-10">    f1_end <span class="op" style="color: #5E5E5E;">=</span> f1_score(end_labels, end_preds, average<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'macro'</span>)</span>
<span id="cb24-11">    </span>
<span id="cb24-12">    <span class="cf" style="color: #003B4F;">return</span> {</span>
<span id="cb24-13">        <span class="st" style="color: #20794D;">'f1_start'</span>: f1_start,</span>
<span id="cb24-14">        <span class="st" style="color: #20794D;">'f1_end'</span>: f1_end,</span>
<span id="cb24-15">    }</span></code></pre></div>
</div>
<p>Now, we will use the Hugging Face <a href="https://huggingface.co/transformers/main_classes/trainer.html">Trainer</a> to fine-tune our model.</p>
<div class="cell" data-outputid="40b7c894-5978-4b02-da2a-23d71377e6ce" data-execution_count="20">
<div class="sourceCode cell-code" id="cb25" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><span class="co" style="color: #5E5E5E;">#&nbsp;Training the model may take around 15 minutes.</span></span>
<span id="cb25-2"><span class="im" style="color: #00769E;">from</span> transformers <span class="im" style="color: #00769E;">import</span> Trainer, TrainingArguments</span>
<span id="cb25-3"></span>
<span id="cb25-4">training_args <span class="op" style="color: #5E5E5E;">=</span> TrainingArguments(</span>
<span id="cb25-5">    output_dir<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'model_results5'</span>,          <span class="co" style="color: #5E5E5E;"># output directory</span></span>
<span id="cb25-6">    overwrite_output_dir<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>,</span>
<span id="cb25-7">    num_train_epochs<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">3</span>,              <span class="co" style="color: #5E5E5E;"># total number of training epochs</span></span>
<span id="cb25-8">    per_device_train_batch_size<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">8</span>,  <span class="co" style="color: #5E5E5E;"># batch size per device during training</span></span>
<span id="cb25-9">    per_device_eval_batch_size<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">8</span>,   <span class="co" style="color: #5E5E5E;"># batch size for evaluation</span></span>
<span id="cb25-10">    warmup_steps<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">20</span>,                <span class="co" style="color: #5E5E5E;"># number of warmup steps for learning rate scheduler</span></span>
<span id="cb25-11">    weight_decay<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">0.01</span>,               <span class="co" style="color: #5E5E5E;"># strength of weight decay</span></span>
<span id="cb25-12">    logging_dir<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">None</span>,            <span class="co" style="color: #5E5E5E;"># directory for storing logs</span></span>
<span id="cb25-13">    logging_steps<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">50</span></span>
<span id="cb25-14">)</span>
<span id="cb25-15"></span>
<span id="cb25-16">trainer <span class="op" style="color: #5E5E5E;">=</span> Trainer(</span>
<span id="cb25-17">    model<span class="op" style="color: #5E5E5E;">=</span>model, <span class="co" style="color: #5E5E5E;"># the instantiated 🤗 Transformers model to be trained</span></span>
<span id="cb25-18">    args<span class="op" style="color: #5E5E5E;">=</span>training_args, <span class="co" style="color: #5E5E5E;"># training arguments, defined above</span></span>
<span id="cb25-19">    train_dataset<span class="op" style="color: #5E5E5E;">=</span>processed_train_data, <span class="co" style="color: #5E5E5E;"># training dataset</span></span>
<span id="cb25-20">    eval_dataset<span class="op" style="color: #5E5E5E;">=</span>processed_test_data, <span class="co" style="color: #5E5E5E;"># evaluation dataset</span></span>
<span id="cb25-21">    compute_metrics<span class="op" style="color: #5E5E5E;">=</span>compute_f1_metrics             </span>
<span id="cb25-22">)</span>
<span id="cb25-23"></span>
<span id="cb25-24">trainer.train()</span></code></pre></div>
<div class="cell-output cell-output-display">


    <div>
      
      <progress value="1125" max="1125" style="width:300px; height:20px; vertical-align: middle;"></progress>
      [1125/1125 08:25, Epoch 3/3]
    </div>
    <table class="dataframe table table-sm table-striped">
  <thead>
 <tr>
      <th>Step</th>
      <th>Training Loss</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>50</td>
      <td>2.121500</td>
    </tr>
    <tr>
      <td>100</td>
      <td>2.330300</td>
    </tr>
    <tr>
      <td>150</td>
      <td>2.058000</td>
    </tr>
    <tr>
      <td>200</td>
      <td>1.657700</td>
    </tr>
    <tr>
      <td>250</td>
      <td>1.829900</td>
    </tr>
    <tr>
      <td>300</td>
      <td>1.505300</td>
    </tr>
    <tr>
      <td>350</td>
      <td>1.741100</td>
    </tr>
    <tr>
      <td>400</td>
      <td>1.289300</td>
    </tr>
    <tr>
      <td>450</td>
      <td>1.208900</td>
    </tr>
    <tr>
      <td>500</td>
      <td>1.271700</td>
    </tr>
    <tr>
      <td>550</td>
      <td>1.275800</td>
    </tr>
    <tr>
      <td>600</td>
      <td>1.258400</td>
    </tr>
    <tr>
      <td>650</td>
      <td>1.184400</td>
    </tr>
    <tr>
      <td>700</td>
      <td>1.145600</td>
    </tr>
    <tr>
      <td>750</td>
      <td>1.063900</td>
    </tr>
    <tr>
      <td>800</td>
      <td>0.746800</td>
    </tr>
    <tr>
      <td>850</td>
      <td>0.670800</td>
    </tr>
    <tr>
      <td>900</td>
      <td>0.711500</td>
    </tr>
    <tr>
      <td>950</td>
      <td>0.784200</td>
    </tr>
    <tr>
      <td>1000</td>
      <td>0.721700</td>
    </tr>
    <tr>
      <td>1050</td>
      <td>0.553700</td>
    </tr>
    <tr>
      <td>1100</td>
      <td>0.616800</td>
    </tr>
  </tbody>
</table><p>
</p></div>
<div class="cell-output cell-output-display" data-execution_count="20">
<pre><code>TrainOutput(global_step=1125, training_loss=1.2449795515272353, metrics={'train_runtime': 509.2428, 'train_samples_per_second': 17.673, 'train_steps_per_second': 2.209, 'total_flos': 1175877900288000.0, 'train_loss': 1.2449795515272353, 'epoch': 3.0})</code></pre>
</div>
</div>
<p>And, in the next cell, we will evaluate the fine-tuned model’s performance on the test set.</p>
<div class="cell" data-outputid="3501a4db-704b-487a-c32b-455cda064e03" data-execution_count="21">
<div class="sourceCode cell-code" id="cb27" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><span class="co" style="color: #5E5E5E;"># The evaluation may take around 30 seconds</span></span>
<span id="cb27-2">trainer.evaluate(processed_test_data)</span></code></pre></div>
<div class="cell-output cell-output-display">

    <div>
      
      <progress value="125" max="125" style="width:300px; height:20px; vertical-align: middle;"></progress>
      [125/125 00:17]
    </div>
    
</div>
<div class="cell-output cell-output-display" data-execution_count="21">
<pre><code>{'eval_loss': 2.3243680000305176,
 'eval_f1_start': 0.09401088809221052,
 'eval_f1_end': 0.10903973263672619,
 'eval_runtime': 18.0907,
 'eval_samples_per_second': 55.277,
 'eval_steps_per_second': 6.91,
 'epoch': 3.0}</code></pre>
</div>
</div>
</section>
<section id="using-our-fine-tuned-model" class="level2" data-number="6">
<h2 data-number="6" class="anchored" data-anchor-id="using-our-fine-tuned-model"><span class="header-section-number">6</span> Using our Fine-Tuned Model</h2>
<p>After training and evaluating our fine-tuned model, we can check its results for the same questions from the previous article.</p>
<p>For that, we will tell Pytorch to use your GPU or your CPU to run the model. Additionally, we will need to tokenize your input context and questions. Finally, we need to post-process the output results to transform them from tokens to human-readable strings using the <code>tokenizer</code>.</p>
<div class="cell" data-outputid="4b01056f-99e9-44ad-84b0-ba6d51eeba40" data-execution_count="22">
<div class="sourceCode cell-code" id="cb29" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><span class="im" style="color: #00769E;">import</span> torch</span>
<span id="cb29-2"></span>
<span id="cb29-3">text <span class="op" style="color: #5E5E5E;">=</span> <span class="vs" style="color: #20794D;">r"""</span></span>
<span id="cb29-4"><span class="vs" style="color: #20794D;">The Golden Age of Comic Books describes an era of American comic books from the </span></span>
<span id="cb29-5"><span class="vs" style="color: #20794D;">late 1930s to circa 1950. During this time, modern comic books were first published </span></span>
<span id="cb29-6"><span class="vs" style="color: #20794D;">and rapidly increased in popularity. The superhero archetype was created and many </span></span>
<span id="cb29-7"><span class="vs" style="color: #20794D;">well-known characters were introduced, including Superman, Batman, Captain Marvel </span></span>
<span id="cb29-8"><span class="vs" style="color: #20794D;">(later known as SHAZAM!), Captain America, and Wonder Woman.</span></span>
<span id="cb29-9"><span class="vs" style="color: #20794D;">Between 1939 and 1941 Detective Comics and its sister company, All-American Publications, </span></span>
<span id="cb29-10"><span class="vs" style="color: #20794D;">introduced popular superheroes such as Batman and Robin, Wonder Woman, the Flash, </span></span>
<span id="cb29-11"><span class="vs" style="color: #20794D;">Green Lantern, Doctor Fate, the Atom, Hawkman, Green Arrow and Aquaman.[7] Timely Comics, </span></span>
<span id="cb29-12"><span class="vs" style="color: #20794D;">the 1940s predecessor of Marvel Comics, had million-selling titles featuring the Human Torch,</span></span>
<span id="cb29-13"><span class="vs" style="color: #20794D;">the Sub-Mariner, and Captain America.[8]</span></span>
<span id="cb29-14"><span class="vs" style="color: #20794D;">As comic books grew in popularity, publishers began launching titles that expanded </span></span>
<span id="cb29-15"><span class="vs" style="color: #20794D;">into a variety of genres. Dell Comics' non-superhero characters (particularly the </span></span>
<span id="cb29-16"><span class="vs" style="color: #20794D;">licensed Walt Disney animated-character comics) outsold the superhero comics of the day.[12] </span></span>
<span id="cb29-17"><span class="vs" style="color: #20794D;">The publisher featured licensed movie and literary characters such as Mickey Mouse, Donald Duck,</span></span>
<span id="cb29-18"><span class="vs" style="color: #20794D;">Roy Rogers and Tarzan.[13] It was during this era that noted Donald Duck writer-artist</span></span>
<span id="cb29-19"><span class="vs" style="color: #20794D;">Carl Barks rose to prominence.[14] Additionally, MLJ's introduction of Archie Andrews</span></span>
<span id="cb29-20"><span class="vs" style="color: #20794D;">in Pep Comics #22 (December 1941) gave rise to teen humor comics,[15] with the Archie </span></span>
<span id="cb29-21"><span class="vs" style="color: #20794D;">Andrews character remaining in print well into the 21st century.[16]</span></span>
<span id="cb29-22"><span class="vs" style="color: #20794D;">At the same time in Canada, American comic books were prohibited importation under </span></span>
<span id="cb29-23"><span class="vs" style="color: #20794D;">the War Exchange Conservation Act[17] which restricted the importation of non-essential </span></span>
<span id="cb29-24"><span class="vs" style="color: #20794D;">goods. As a result, a domestic publishing industry flourished during the duration </span></span>
<span id="cb29-25"><span class="vs" style="color: #20794D;">of the war which were collectively informally called the Canadian Whites.</span></span>
<span id="cb29-26"><span class="vs" style="color: #20794D;">The educational comic book Dagwood Splits the Atom used characters from the comic </span></span>
<span id="cb29-27"><span class="vs" style="color: #20794D;">strip Blondie.[18] According to historian Michael A. Amundson, appealing comic-book </span></span>
<span id="cb29-28"><span class="vs" style="color: #20794D;">characters helped ease young readers' fear of nuclear war and neutralize anxiety </span></span>
<span id="cb29-29"><span class="vs" style="color: #20794D;">about the questions posed by atomic power.[19] It was during this period that long-running </span></span>
<span id="cb29-30"><span class="vs" style="color: #20794D;">humor comics debuted, including EC's Mad and Carl Barks' Uncle Scrooge in Dell's Four </span></span>
<span id="cb29-31"><span class="vs" style="color: #20794D;">Color Comics (both in 1952).[20][21]</span></span>
<span id="cb29-32"><span class="vs" style="color: #20794D;">"""</span></span>
<span id="cb29-33"></span>
<span id="cb29-34">questions <span class="op" style="color: #5E5E5E;">=</span> [<span class="st" style="color: #20794D;">"What superheroes were introduced between 1939 and 1941 by Detective Comics and its sister company?"</span>,</span>
<span id="cb29-35">             <span class="st" style="color: #20794D;">"What comic book characters were created between 1939 and 1941?"</span>,</span>
<span id="cb29-36">             <span class="st" style="color: #20794D;">"What well-known characters were created between 1939 and 1941?"</span>,</span>
<span id="cb29-37">             <span class="st" style="color: #20794D;">"What well-known superheroes were introduced between 1939 and 1941 by Detective Comics?"</span>]</span>
<span id="cb29-38"></span>
<span id="cb29-39"><span class="cf" style="color: #003B4F;">for</span> question <span class="kw" style="color: #003B4F;">in</span> questions:</span>
<span id="cb29-40">    inputs <span class="op" style="color: #5E5E5E;">=</span> tokenizer.encode_plus(question, text, return_tensors<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"pt"</span>)</span>
<span id="cb29-41">    <span class="co" style="color: #5E5E5E;">#print("inputs", inputs)</span></span>
<span id="cb29-42">    <span class="co" style="color: #5E5E5E;">#print("inputs", type(inputs))</span></span>
<span id="cb29-43">    input_ids <span class="op" style="color: #5E5E5E;">=</span> inputs[<span class="st" style="color: #20794D;">"input_ids"</span>].tolist()[<span class="dv" style="color: #AD0000;">0</span>]</span>
<span id="cb29-44">    inputs.to(<span class="st" style="color: #20794D;">"cuda"</span>)</span>
<span id="cb29-45"></span>
<span id="cb29-46">    text_tokens <span class="op" style="color: #5E5E5E;">=</span> tokenizer.convert_ids_to_tokens(input_ids)</span>
<span id="cb29-47">    answer_model <span class="op" style="color: #5E5E5E;">=</span> model(<span class="op" style="color: #5E5E5E;">**</span>inputs)</span>
<span id="cb29-48"></span>
<span id="cb29-49">    answer_start <span class="op" style="color: #5E5E5E;">=</span> torch.argmax(</span>
<span id="cb29-50">        answer_model[<span class="st" style="color: #20794D;">'start_logits'</span>]</span>
<span id="cb29-51">    )  <span class="co" style="color: #5E5E5E;"># Get the most likely beginning of answer with the argmax of the score</span></span>
<span id="cb29-52">    answer_end <span class="op" style="color: #5E5E5E;">=</span> torch.argmax(answer_model[<span class="st" style="color: #20794D;">'end_logits'</span>]) <span class="op" style="color: #5E5E5E;">+</span> <span class="dv" style="color: #AD0000;">1</span>  <span class="co" style="color: #5E5E5E;"># Get the most likely end of answer with the argmax of the score</span></span>
<span id="cb29-53"></span>
<span id="cb29-54">    answer <span class="op" style="color: #5E5E5E;">=</span> tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(input_ids[answer_start:answer_end]))</span>
<span id="cb29-55"></span>
<span id="cb29-56">    <span class="bu" style="color: null;">print</span>(<span class="ss" style="color: #20794D;">f"Question: </span><span class="sc" style="color: #5E5E5E;">{</span>question<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">"</span>)</span>
<span id="cb29-57">    <span class="bu" style="color: null;">print</span>(<span class="ss" style="color: #20794D;">f"Answer: </span><span class="sc" style="color: #5E5E5E;">{</span>answer<span class="sc" style="color: #5E5E5E;">}</span><span class="ch" style="color: #20794D;">\n</span><span class="ss" style="color: #20794D;">"</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Question: What superheroes were introduced between 1939 and 1941 by Detective Comics and its sister company?
Answer: Superman, Batman, Captain Marvel ( later known as SHAZAM! ), Captain America, and Wonder Woman. Between 1939 and 1941 Detective Comics and its sister company, All - American Publications, introduced popular superheroes such as Batman and Robin, Wonder Woman, the Flash, Green Lantern, Doctor Fate, the Atom, Hawkman, Green Arrow and Aquaman

Question: What comic book characters were created between 1939 and 1941?
Answer: Superman, Batman, Captain Marvel ( later known as SHAZAM! ), Captain America, and Wonder Woman

Question: What well-known characters were created between 1939 and 1941?
Answer: Superman, Batman, Captain Marvel ( later known as SHAZAM! ), Captain America, and Wonder Woman

Question: What well-known superheroes were introduced between 1939 and 1941 by Detective Comics?
Answer: Superman, Batman, Captain Marvel ( later known as SHAZAM! ), Captain America, and Wonder Woman
</code></pre>
</div>
</div>
<p>We can compare those results with those obtained using the pipeline, as we did in the previous article. As a reminder, here are those results:</p>
<pre><code>What popular superheroes were introduced between 1939 and 1941? 
&gt;&gt; teen humor comics
What superheroes were introduced between 1939 and 1941 by Detective Comics and its sister company? 
&gt;&gt; Archie Andrews
What comic book characters were created between 1939 and 1941? 
&gt;&gt; Archie 
Andrews
What well-known characters were created between 1939 and 1941? 
&gt;&gt; Archie 
Andrews
What well-known superheroes were introduced between 1939 and 1941 by Detective Comics? 
&gt;&gt; Archie Andrews</code></pre>
</section>
<section id="acknowledgements" class="level2" data-number="7">
<h2 data-number="7" class="anchored" data-anchor-id="acknowledgements"><span class="header-section-number">7</span> Acknowledgements</h2>
<p>I’d like to express my thanks to the great <a href="https://www.coursera.org/learn/attention-models-in-nlp">Natural Language Processing with Attention Models Course</a> which i completed, and acknowledge the use of some images and other materials from the course in this article.</p>


</section>

 ]]></description>
  <category>natural-language-processing</category>
  <category>deep-learning</category>
  <category>hugging-face</category>
  <guid>http://livingdatalab.com/posts/2023-03-25-customising-a-chatbot-with-fine-tuning-and-huggingface-pre-trained-models.html</guid>
  <pubDate>Sat, 25 Mar 2023 00:00:00 GMT</pubDate>
  <media:content url="https://github.com/pranath/blog/raw/master/images/huggingface.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Creating a Chatbot with Hugging Face Pretrained Models</title>
  <dc:creator>Pranath Fernando</dc:creator>
  <link>http://livingdatalab.com/posts/2023-03-24-creating-a-chatbot-with-huggingface-pre-trained-models.html</link>
  <description><![CDATA[ 




<section id="introduction" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="introduction"><span class="header-section-number">1</span> Introduction</h2>
<p>In <a href="../#category=natural-language-processing">previous articles</a> we have seen how to use transformer models for a wide range of natural language tasks, including machine translation, summarization, and question answering. Transformers have become the standard model for NLP, similar to convolutional models in computer vision.</p>
<p>In practice, you’ll rarely train a transformer model from scratch. Transformers tend to be very large, so they take time, money, and lots of data to train fully. Instead, you’ll want to start with a pre-trained model and fine-tune it with a dataset if you need to for specific needs, which has become the norm in this new but thriving area of AI.</p>
<p><a href="https://huggingface.co/">Hugging Face</a> (🤗) is the best resource for pre-trained transformers. Their open-source libraries simplifies downloading and using transformer models like BERT, T5, and GPT-2. And you can use them alongside libraries such as FastAi, TensorFlow, PyTorch and Flax.</p>
<p>In this article, we will use Hugging Face 🤗 transformers to download and use the DistilBERT model to create a chat bot for question answering.</p>
</section>
<section id="pipelines" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="pipelines"><span class="header-section-number">2</span> Pipelines</h2>
<p>Before fine-tuning a model, we will look to the pipelines from Hugging Face to use pre-trained transformer models for specific tasks. The <code>transformers</code> library provides pipelines for popular tasks like sentiment analysis, summarization, and text generation. A pipeline consists of a tokenizer, a model, and the model configuration. All these are packaged together into an easy-to-use object.</p>
<p>Pipelines are intended to be used without fine-tuning and will often be immediately helpful in your projects. For example, <code>transformers</code> provides a pipeline for <a href="https://huggingface.co/transformers/main_classes/pipelines.html#the-pipeline-abstraction">question answering</a> that you can directly use to answer your questions if you give some context. Let’s see how to do just that.</p>
<p>We will import <code>pipeline</code> from <code>transformers</code> for creating pipelines.</p>
<div class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;">from</span> transformers <span class="im" style="color: #00769E;">import</span> pipeline</span></code></pre></div>
</div>
<p>Now, we will create the pipeline for question-answering, which uses the <a href="https://hf.co/distilbert-base-cased-distilled-squad">DistilBert</a> model for extractive question answering (i.e., answering questions with the exact wording provided in the context).</p>
<div class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="co" style="color: #5E5E5E;"># The task "question-answering" will return a QuestionAnsweringPipeline object</span></span>
<span id="cb2-2">question_answerer <span class="op" style="color: #5E5E5E;">=</span> pipeline(task<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"question-answering"</span>, model<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"distilbert-base-cased-distilled-squad"</span>)</span></code></pre></div>
</div>
<p>After running the last cell, we have a pipeline for performing question answering given a context string. The pipeline <code>question_answerer</code> we just created needs you to pass the question and context as strings. It returns an answer to the question from the context we provided. For example, here are the first few paragraphs from the <a href="https://en.wikipedia.org/wiki/Tea">Wikipedia entry for tea</a> that we will use as the context.</p>
<div class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1">context <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">"""</span></span>
<span id="cb3-2"><span class="st" style="color: #20794D;">Tea is an aromatic beverage prepared by pouring hot or boiling water over cured or fresh leaves of Camellia sinensis,</span></span>
<span id="cb3-3"><span class="st" style="color: #20794D;">an evergreen shrub native to China and East Asia. After water, it is the most widely consumed drink in the world. </span></span>
<span id="cb3-4"><span class="st" style="color: #20794D;">There are many different types of tea; some, like Chinese greens and Darjeeling, have a cooling, slightly bitter, </span></span>
<span id="cb3-5"><span class="st" style="color: #20794D;">and astringent flavour, while others have vastly different profiles that include sweet, nutty, floral, or grassy </span></span>
<span id="cb3-6"><span class="st" style="color: #20794D;">notes. Tea has a stimulating effect in humans primarily due to its caffeine content.</span></span>
<span id="cb3-7"></span>
<span id="cb3-8"><span class="st" style="color: #20794D;">The tea plant originated in the region encompassing today's Southwest China, Tibet, north Myanmar and Northeast India,</span></span>
<span id="cb3-9"><span class="st" style="color: #20794D;">where it was used as a medicinal drink by various ethnic groups. An early credible record of tea drinking dates to </span></span>
<span id="cb3-10"><span class="st" style="color: #20794D;">the 3rd century AD, in a medical text written by Hua Tuo. It was popularised as a recreational drink during the </span></span>
<span id="cb3-11"><span class="st" style="color: #20794D;">Chinese Tang dynasty, and tea drinking spread to other East Asian countries. Portuguese priests and merchants </span></span>
<span id="cb3-12"><span class="st" style="color: #20794D;">introduced it to Europe during the 16th century. During the 17th century, drinking tea became fashionable among the </span></span>
<span id="cb3-13"><span class="st" style="color: #20794D;">English, who started to plant tea on a large scale in India.</span></span>
<span id="cb3-14"></span>
<span id="cb3-15"><span class="st" style="color: #20794D;">The term herbal tea refers to drinks not made from Camellia sinensis: infusions of fruit, leaves, or other plant </span></span>
<span id="cb3-16"><span class="st" style="color: #20794D;">parts, such as steeps of rosehip, chamomile, or rooibos. These may be called tisanes or herbal infusions to prevent</span></span>
<span id="cb3-17"><span class="st" style="color: #20794D;">confusion with 'tea' made from the tea plant.</span></span>
<span id="cb3-18"><span class="st" style="color: #20794D;">"""</span></span></code></pre></div>
</div>
<p>Now, we can ask our model anything related to that passage. For instance, “Where is tea native to?”.</p>
<div class="cell" data-outputid="b097482b-578c-4430-f460-9da8d2324a44" data-scrolled="true" data-execution_count="15">
<div class="sourceCode cell-code" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1">result <span class="op" style="color: #5E5E5E;">=</span> question_answerer(question<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"Where is tea native to?"</span>, context<span class="op" style="color: #5E5E5E;">=</span>context)</span>
<span id="cb4-2"><span class="bu" style="color: null;">print</span>(result[<span class="st" style="color: #20794D;">'answer'</span>])</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>China and East Asia</code></pre>
</div>
</div>
<p>We can also pass multiple questions to our pipeline within a list so that you can ask:</p>
<ul>
<li>“Where is tea native to?”</li>
<li>“When was tea discovered?”</li>
<li>“What is the species name for tea?”</li>
</ul>
<p>at the same time, and our <code>question-answerer</code> will return all the answers.</p>
<div class="cell" data-outputid="48f91368-c988-46f6-b58a-9798a1047928" data-execution_count="16">
<div class="sourceCode cell-code" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1">questions <span class="op" style="color: #5E5E5E;">=</span> [<span class="st" style="color: #20794D;">"Where is tea native to?"</span>,</span>
<span id="cb6-2">             <span class="st" style="color: #20794D;">"When was tea discovered?"</span>,</span>
<span id="cb6-3">             <span class="st" style="color: #20794D;">"What is the species name for tea?"</span>]</span>
<span id="cb6-4"></span>
<span id="cb6-5">results <span class="op" style="color: #5E5E5E;">=</span> question_answerer(question<span class="op" style="color: #5E5E5E;">=</span>questions, context<span class="op" style="color: #5E5E5E;">=</span>context)</span>
<span id="cb6-6"></span>
<span id="cb6-7"><span class="cf" style="color: #003B4F;">for</span> q, r <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">zip</span>(questions, results):</span>
<span id="cb6-8">    <span class="bu" style="color: null;">print</span>(q, <span class="st" style="color: #20794D;">"</span><span class="ch" style="color: #20794D;">\n</span><span class="st" style="color: #20794D;">&gt;&gt; "</span> <span class="op" style="color: #5E5E5E;">+</span> r[<span class="st" style="color: #20794D;">'answer'</span>])</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Where is tea native to? 
&gt;&gt; China and East Asia
When was tea discovered? 
&gt;&gt; 3rd century AD
What is the species name for tea? 
&gt;&gt; Camellia sinensis</code></pre>
</div>
</div>
<p>Although the models used in the Hugging Face pipelines generally give outstanding results, sometimes you will have particular examples where they don’t perform so well. Let’s use the following example with a context string about the Golden Age of Comic Books:</p>
<div class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1">context <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">"""</span></span>
<span id="cb8-2"><span class="st" style="color: #20794D;">The Golden Age of Comic Books describes an era of American comic books from the </span></span>
<span id="cb8-3"><span class="st" style="color: #20794D;">late 1930s to circa 1950. During this time, modern comic books were first published </span></span>
<span id="cb8-4"><span class="st" style="color: #20794D;">and rapidly increased in popularity. The superhero archetype was created and many </span></span>
<span id="cb8-5"><span class="st" style="color: #20794D;">well-known characters were introduced, including Superman, Batman, Captain Marvel </span></span>
<span id="cb8-6"><span class="st" style="color: #20794D;">(later known as SHAZAM!), Captain America, and Wonder Woman.</span></span>
<span id="cb8-7"><span class="st" style="color: #20794D;">Between 1939 and 1941 Detective Comics and its sister company, All-American Publications, </span></span>
<span id="cb8-8"><span class="st" style="color: #20794D;">introduced popular superheroes such as Batman and Robin, Wonder Woman, the Flash, </span></span>
<span id="cb8-9"><span class="st" style="color: #20794D;">Green Lantern, Doctor Fate, the Atom, Hawkman, Green Arrow and Aquaman.[7] Timely Comics, </span></span>
<span id="cb8-10"><span class="st" style="color: #20794D;">the 1940s predecessor of Marvel Comics, had million-selling titles featuring the Human Torch,</span></span>
<span id="cb8-11"><span class="st" style="color: #20794D;">the Sub-Mariner, and Captain America.[8]</span></span>
<span id="cb8-12"><span class="st" style="color: #20794D;">As comic books grew in popularity, publishers began launching titles that expanded </span></span>
<span id="cb8-13"><span class="st" style="color: #20794D;">into a variety of genres. Dell Comics' non-superhero characters (particularly the </span></span>
<span id="cb8-14"><span class="st" style="color: #20794D;">licensed Walt Disney animated-character comics) outsold the superhero comics of the day.[12] </span></span>
<span id="cb8-15"><span class="st" style="color: #20794D;">The publisher featured licensed movie and literary characters such as Mickey Mouse, Donald Duck,</span></span>
<span id="cb8-16"><span class="st" style="color: #20794D;">Roy Rogers and Tarzan.[13] It was during this era that noted Donald Duck writer-artist</span></span>
<span id="cb8-17"><span class="st" style="color: #20794D;">Carl Barks rose to prominence.[14] Additionally, MLJ's introduction of Archie Andrews</span></span>
<span id="cb8-18"><span class="st" style="color: #20794D;">in Pep Comics #22 (December 1941) gave rise to teen humor comics,[15] with the Archie </span></span>
<span id="cb8-19"><span class="st" style="color: #20794D;">Andrews character remaining in print well into the 21st century.[16]</span></span>
<span id="cb8-20"><span class="st" style="color: #20794D;">At the same time in Canada, American comic books were prohibited importation under </span></span>
<span id="cb8-21"><span class="st" style="color: #20794D;">the War Exchange Conservation Act[17] which restricted the importation of non-essential </span></span>
<span id="cb8-22"><span class="st" style="color: #20794D;">goods. As a result, a domestic publishing industry flourished during the duration </span></span>
<span id="cb8-23"><span class="st" style="color: #20794D;">of the war which were collectively informally called the Canadian Whites.</span></span>
<span id="cb8-24"><span class="st" style="color: #20794D;">The educational comic book Dagwood Splits the Atom used characters from the comic </span></span>
<span id="cb8-25"><span class="st" style="color: #20794D;">strip Blondie.[18] According to historian Michael A. Amundson, appealing comic-book </span></span>
<span id="cb8-26"><span class="st" style="color: #20794D;">characters helped ease young readers' fear of nuclear war and neutralize anxiety </span></span>
<span id="cb8-27"><span class="st" style="color: #20794D;">about the questions posed by atomic power.[19] It was during this period that long-running </span></span>
<span id="cb8-28"><span class="st" style="color: #20794D;">humor comics debuted, including EC's Mad and Carl Barks' Uncle Scrooge in Dell's Four </span></span>
<span id="cb8-29"><span class="st" style="color: #20794D;">Color Comics (both in 1952).[20][21]</span></span>
<span id="cb8-30"><span class="st" style="color: #20794D;">"""</span></span></code></pre></div>
</div>
<p>Let’s ask the following question: “What popular superheroes were introduced between 1939 and 1941?” The answer is in the fourth paragraph of the context string.</p>
<div class="cell" data-outputid="4f34f120-772f-43aa-dcea-0c27402555cc" data-execution_count="18">
<div class="sourceCode cell-code" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1">question <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">"What popular superheroes were introduced between 1939 and 1941?"</span></span>
<span id="cb9-2"></span>
<span id="cb9-3">result <span class="op" style="color: #5E5E5E;">=</span> question_answerer(question<span class="op" style="color: #5E5E5E;">=</span>question, context<span class="op" style="color: #5E5E5E;">=</span>context)</span>
<span id="cb9-4"><span class="bu" style="color: null;">print</span>(result[<span class="st" style="color: #20794D;">'answer'</span>])</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>teen humor comics</code></pre>
</div>
</div>
<p>Here, the answer should be: “Batman and Robin, Wonder Woman, the Flash, Green Lantern, Doctor Fate, the Atom, Hawkman, Green Arrow, and Aquaman”, instead, the pipeline returned a different answer. You can even try different question wordings:</p>
<ul>
<li>“What superheroes were introduced between 1939 and 1941?”</li>
<li>“What comic book characters were created between 1939 and 1941?”</li>
<li>“What well-known characters were created between 1939 and 1941?”</li>
<li>“What well-known superheroes were introduced between 1939 and 1941 by Detective Comics?”</li>
</ul>
<p>and you will only get incorrect answers.</p>
<div class="cell" data-outputid="75bbacd1-6c7d-4d3c-e057-ca6e7a486675" data-execution_count="19">
<div class="sourceCode cell-code" id="cb11" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1">questions <span class="op" style="color: #5E5E5E;">=</span> [<span class="st" style="color: #20794D;">"What popular superheroes were introduced between 1939 and 1941?"</span>,</span>
<span id="cb11-2">             <span class="st" style="color: #20794D;">"What superheroes were introduced between 1939 and 1941 by Detective Comics and its sister company?"</span>,</span>
<span id="cb11-3">             <span class="st" style="color: #20794D;">"What comic book characters were created between 1939 and 1941?"</span>,</span>
<span id="cb11-4">             <span class="st" style="color: #20794D;">"What well-known characters were created between 1939 and 1941?"</span>,</span>
<span id="cb11-5">             <span class="st" style="color: #20794D;">"What well-known superheroes were introduced between 1939 and 1941 by Detective Comics?"</span>]</span>
<span id="cb11-6"></span>
<span id="cb11-7">results <span class="op" style="color: #5E5E5E;">=</span> question_answerer(question<span class="op" style="color: #5E5E5E;">=</span>questions, context<span class="op" style="color: #5E5E5E;">=</span>context)</span>
<span id="cb11-8"></span>
<span id="cb11-9"><span class="cf" style="color: #003B4F;">for</span> q, r <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">zip</span>(questions, results):</span>
<span id="cb11-10">    <span class="bu" style="color: null;">print</span>(q, <span class="st" style="color: #20794D;">"</span><span class="ch" style="color: #20794D;">\n</span><span class="st" style="color: #20794D;">&gt;&gt; "</span> <span class="op" style="color: #5E5E5E;">+</span> r[<span class="st" style="color: #20794D;">'answer'</span>])</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>What popular superheroes were introduced between 1939 and 1941? 
&gt;&gt; teen humor comics
What superheroes were introduced between 1939 and 1941 by Detective Comics and its sister company? 
&gt;&gt; Archie Andrews
What comic book characters were created between 1939 and 1941? 
&gt;&gt; Archie 
Andrews
What well-known characters were created between 1939 and 1941? 
&gt;&gt; Archie 
Andrews
What well-known superheroes were introduced between 1939 and 1941 by Detective Comics? 
&gt;&gt; Archie Andrews</code></pre>
</div>
</div>
<p>It seems like this model is a <strong>huge fan</strong> of Archie Andrews. It even considers him a superhero!</p>
<p>The example that fooled your <code>question_answerer</code> belongs to the <a href="https://ai.google.com/research/tydiqa">TyDi QA dataset</a>, a dataset from Google for question/answering in diverse languages. To achieve better results when you know that the pipeline isn’t working as it should, you need to consider fine-tuning your model.</p>
</section>
<section id="acknowledgements" class="level2" data-number="3">
<h2 data-number="3" class="anchored" data-anchor-id="acknowledgements"><span class="header-section-number">3</span> Acknowledgements</h2>
<p>I’d like to express my thanks to the great <a href="https://www.coursera.org/learn/attention-models-in-nlp">Natural Language Processing with Attention Models Course</a> which i completed, and acknowledge the use of some images and other materials from the course in this article.</p>


</section>

 ]]></description>
  <category>natural-language-processing</category>
  <category>deep-learning</category>
  <category>hugging-face</category>
  <guid>http://livingdatalab.com/posts/2023-03-24-creating-a-chatbot-with-huggingface-pre-trained-models.html</guid>
  <pubDate>Fri, 24 Mar 2023 00:00:00 GMT</pubDate>
  <media:content url="https://github.com/pranath/blog/raw/master/images/huggingface.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Implementing the T5 text transformer model</title>
  <dc:creator>Pranath Fernando</dc:creator>
  <link>http://livingdatalab.com/posts/2023-03-22-implementing-the-t5-text-transfomer-model.html</link>
  <description><![CDATA[ 




<section id="introduction" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="introduction"><span class="header-section-number">1</span> Introduction</h2>
<p>In this article we will explore question answering. We will implement the “Text to Text Transfer from Transformers” model (better known as T5) which can perform a wide variety of NLP tasks.</p>
<p><img src="http://livingdatalab.com/posts/https:/github.com/pranath/blog/raw/master/images/t5.png"></p>
<p>We will create the necessary building blocks for the transformer encoder model required and will use a pretrained version of the same model.</p>
<p>After completing these tasks we will:</p>
<ul>
<li>Understand how the C4 dataset is structured.</li>
<li>Use a pretrained model for inference.</li>
<li>Understand how the “Text to Text Transfer from Transformers” or T5 model works.</li>
</ul>
</section>
<section id="importing-the-packages" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="importing-the-packages"><span class="header-section-number">2</span> Importing the Packages</h2>
<div class="cell" data-outputid="64947d91-eef3-425b-9b4b-7ca7cefcc823" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;">import</span> ast</span>
<span id="cb1-2"><span class="im" style="color: #00769E;">import</span> pprint</span>
<span id="cb1-3"><span class="im" style="color: #00769E;">import</span> string</span>
<span id="cb1-4"><span class="im" style="color: #00769E;">import</span> textwrap</span>
<span id="cb1-5"><span class="im" style="color: #00769E;">import</span> itertools</span>
<span id="cb1-6"><span class="im" style="color: #00769E;">import</span> numpy <span class="im" style="color: #00769E;">as</span> np</span>
<span id="cb1-7"><span class="im" style="color: #00769E;">import</span> w3_tests</span>
<span id="cb1-8"></span>
<span id="cb1-9"><span class="im" style="color: #00769E;">import</span> trax </span>
<span id="cb1-10"><span class="im" style="color: #00769E;">from</span> trax <span class="im" style="color: #00769E;">import</span> layers <span class="im" style="color: #00769E;">as</span> tl</span>
<span id="cb1-11"><span class="im" style="color: #00769E;">from</span> trax.supervised <span class="im" style="color: #00769E;">import</span> decoding</span>
<span id="cb1-12"></span>
<span id="cb1-13"><span class="co" style="color: #5E5E5E;"># Will come handy later.</span></span>
<span id="cb1-14">wrapper <span class="op" style="color: #5E5E5E;">=</span> textwrap.TextWrapper(width<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">70</span>)</span>
<span id="cb1-15"></span>
<span id="cb1-16"><span class="co" style="color: #5E5E5E;"># Set random seed</span></span>
<span id="cb1-17">np.random.seed(<span class="dv" style="color: #AD0000;">42</span>)</span></code></pre></div>
</div>
</section>
<section id="c4-dataset" class="level2" data-number="3">
<h2 data-number="3" class="anchored" data-anchor-id="c4-dataset"><span class="header-section-number">3</span> C4 Dataset</h2>
<p>The <a href="https://www.tensorflow.org/datasets/catalog/c4">C4</a> is a huge data set. For the purpose of this project we will use a few examples out of it which are present in <code>data.txt</code>. C4 is based on the <a href="https://commoncrawl.org/">common crawl</a> project. Feel free to read more on their website.</p>
<div class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="co" style="color: #5E5E5E;"># load example jsons</span></span>
<span id="cb2-2">example_jsons <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">list</span>(<span class="bu" style="color: null;">map</span>(ast.literal_eval, <span class="bu" style="color: null;">open</span>(<span class="st" style="color: #20794D;">'data/data.txt'</span>)))</span></code></pre></div>
</div>
<div class="cell" data-outputid="338e9751-8fc1-4f64-817a-3406b67f5dd5" data-execution_count="3">
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><span class="co" style="color: #5E5E5E;"># Printing the examples to see how the data looks like</span></span>
<span id="cb3-2"><span class="cf" style="color: #003B4F;">for</span> i <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">range</span>(<span class="dv" style="color: #AD0000;">5</span>):</span>
<span id="cb3-3">    <span class="bu" style="color: null;">print</span>(<span class="ss" style="color: #20794D;">f'example number </span><span class="sc" style="color: #5E5E5E;">{</span>i<span class="op" style="color: #5E5E5E;">+</span><span class="dv" style="color: #AD0000;">1</span><span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">: </span><span class="ch" style="color: #20794D;">\n\n</span><span class="sc" style="color: #5E5E5E;">{</span>example_jsons[i]<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;"> </span><span class="ch" style="color: #20794D;">\n</span><span class="ss" style="color: #20794D;">'</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>example number 1: 

{'content-length': b'1970', 'content-type': b'text/plain', 'text': b'Beginners BBQ Class Taking Place in Missoula!\nDo you want to get better at making delicious BBQ? You will have the opportunity, put this on your calendar now. Thursday, September 22nd join World Class BBQ Champion, Tony Balay from Lonestar Smoke Rangers. He will be teaching a beginner level class for everyone who wants to get better with their culinary skills.\nHe will teach you everything you need to know to compete in a KCBS BBQ competition, including techniques, recipes, timelines, meat selection and trimming, plus smoker and fire information.\nThe cost to be in the class is $35 per person, and for spectators it is free. Included in the cost will be either a t-shirt or apron and you will be tasting samples of each meat that is prepared.', 'timestamp': b'2019-04-25T12:57:54Z', 'url': b'https://klyq.com/beginners-bbq-class-taking-place-in-missoula/'} 

example number 2: 

{'content-length': b'12064', 'content-type': b'text/plain', 'text': b'Discussion in \'Mac OS X Lion (10.7)\' started by axboi87, Jan 20, 2012.\nI\'ve got a 500gb internal drive and a 240gb SSD.\nWhen trying to restore using disk utility i\'m given the error "Not enough space on disk ____ to restore"\nBut I shouldn\'t have to do that!!!\nAny ideas or workarounds before resorting to the above?\nUse Carbon Copy Cloner to copy one drive to the other. I\'ve done this several times going from larger HDD to smaller SSD and I wound up with a bootable SSD drive. One step you have to remember not to skip is to use Disk Utility to partition the SSD as GUID partition scheme HFS+ before doing the clone. If it came Apple Partition Scheme, even if you let CCC do the clone, the resulting drive won\'t be bootable. CCC usually works in "file mode" and it can easily copy a larger drive (that\'s mostly empty) onto a smaller drive. If you tell CCC to clone a drive you did NOT boot from, it can work in block copy mode where the destination drive must be the same size or larger than the drive you are cloning from (if I recall).\nI\'ve actually done this somehow on Disk Utility several times (booting from a different drive (or even the dvd) so not running disk utility from the drive your cloning) and had it work just fine from larger to smaller bootable clone. Definitely format the drive cloning to first, as bootable Apple etc..\nThanks for pointing this out. My only experience using DU to go larger to smaller was when I was trying to make a Lion install stick and I was unable to restore InstallESD.dmg to a 4 GB USB stick but of course the reason that wouldn\'t fit is there was slightly more than 4 GB of data.', 'timestamp': b'2019-04-21T10:07:13Z', 'url': b'https://forums.macrumors.com/threads/restore-from-larger-disk-to-smaller-disk.1311329/'} 

example number 3: 

{'content-length': b'5235', 'content-type': b'text/plain', 'text': b'Foil plaid lycra and spandex shortall with metallic slinky insets. Attached metallic elastic belt with O-ring. Headband included. Great hip hop or jazz dance costume. Made in the USA.', 'timestamp': b'2019-04-25T10:40:23Z', 'url': b'https://awishcometrue.com/Catalogs/Clearance/Tweens/V1960-Find-A-Way'} 

example number 4: 

{'content-length': b'4967', 'content-type': b'text/plain', 'text': b"How many backlinks per day for new site?\nDiscussion in 'Black Hat SEO' started by Omoplata, Dec 3, 2010.\n1) for a newly created site, what's the max # backlinks per day I should do to be safe?\n2) how long do I have to let my site age before I can start making more blinks?\nI did about 6000 forum profiles every 24 hours for 10 days for one of my sites which had a brand new domain.\nThere is three backlinks for every of these forum profile so thats 18 000 backlinks every 24 hours and nothing happened in terms of being penalized or sandboxed. This is now maybe 3 months ago and the site is ranking on first page for a lot of my targeted keywords.\nbuild more you can in starting but do manual submission and not spammy type means manual + relevant to the post.. then after 1 month you can make a big blast..\nWow, dude, you built 18k backlinks a day on a brand new site? How quickly did you rank up? What kind of competition/searches did those keywords have?", 'timestamp': b'2019-04-21T12:46:19Z', 'url': b'https://www.blackhatworld.com/seo/how-many-backlinks-per-day-for-new-site.258615/'} 

example number 5: 

{'content-length': b'4499', 'content-type': b'text/plain', 'text': b'The Denver Board of Education opened the 2017-18 school year with an update on projects that include new construction, upgrades, heat mitigation and quality learning environments.\nWe are excited that Denver students will be the beneficiaries of a four year, $572 million General Obligation Bond. Since the passage of the bond, our construction team has worked to schedule the projects over the four-year term of the bond.\nDenver voters on Tuesday approved bond and mill funding measures for students in Denver Public Schools, agreeing to invest $572 million in bond funding to build and improve schools and $56.6 million in operating dollars to support proven initiatives, such as early literacy.\nDenver voters say yes to bond and mill levy funding support for DPS students and schools. Click to learn more about the details of the voter-approved bond measure.\nDenver voters on Nov. 8 approved bond and mill funding measures for DPS students and schools. Learn more about what\xe2\x80\x99s included in the mill levy measure.', 'timestamp': b'2019-04-20T14:33:21Z', 'url': b'http://bond.dpsk12.org/category/news/'} 
</code></pre>
</div>
</div>
<p>Notice the <code>b</code> before each string? This means that this data comes as bytes rather than strings. Strings are actually lists of bytes the name <code>strings</code> will be used to describe the data.</p>
<div class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><span class="bu" style="color: null;">type</span>(example_jsons[<span class="dv" style="color: #AD0000;">0</span>].get(<span class="st" style="color: #20794D;">'text'</span>))</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="4">
<pre><code>bytes</code></pre>
</div>
</div>
<section id="pre-training-objective" class="level3" data-number="3.1">
<h3 data-number="3.1" class="anchored" data-anchor-id="pre-training-objective"><span class="header-section-number">3.1</span> Pre-Training Objective</h3>
<p><strong>Note:</strong> The word “mask” will be used throughout this project in context of hiding/removing word(s)</p>
<p>We will be implementing the BERT loss as shown in the following image.</p>
<p><img src="http://livingdatalab.com/posts/https:/github.com/pranath/blog/raw/master/images/loss.png" width="600" height="400"></p>
<p>Say we have the following text: <span style="color:blue"> <strong>Thank you <span style="color:red">for inviting </span> me to your party <span style="color:red">last</span> week</strong> </span></p>
<p>Now as input we will mask the words in red in the text:</p>
<p><span style="color:blue"> <strong>Input:</strong></span> Thank you <strong>X</strong> me to your party <strong>Y</strong> week.</p>
<p><span style="color:blue"><strong>Output:</strong></span> The model should predict the words(s) for <strong>X</strong> and <strong>Y</strong>.</p>
<p><strong>Z</strong> is used to represent the end.</p>
</section>
<section id="process-c4" class="level3" data-number="3.2">
<h3 data-number="3.2" class="anchored" data-anchor-id="process-c4"><span class="header-section-number">3.2</span> Process C4</h3>
<p>C4 only has the plain string <code>text</code> field, so we will tokenize and have <code>inputs</code> and <code>targets</code> out of it for supervised learning. Given our inputs, the goal is to predict the targets during training.</p>
<p>We will now take the <code>text</code> and convert it to <code>inputs</code> and <code>targets</code>.</p>
<div class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><span class="co" style="color: #5E5E5E;"># Grab text field from dictionary</span></span>
<span id="cb7-2">natural_language_texts <span class="op" style="color: #5E5E5E;">=</span> [example_json[<span class="st" style="color: #20794D;">'text'</span>] <span class="cf" style="color: #003B4F;">for</span> example_json <span class="kw" style="color: #003B4F;">in</span> example_jsons]</span></code></pre></div>
</div>
<div class="cell" data-outputid="4f689b44-8ecb-45d6-d73f-22a0b2bf6d48" data-execution_count="6">
<div class="sourceCode cell-code" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><span class="co" style="color: #5E5E5E;"># First text example</span></span>
<span id="cb8-2">natural_language_texts[<span class="dv" style="color: #AD0000;">4</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="6">
<pre><code>b'The Denver Board of Education opened the 2017-18 school year with an update on projects that include new construction, upgrades, heat mitigation and quality learning environments.\nWe are excited that Denver students will be the beneficiaries of a four year, $572 million General Obligation Bond. Since the passage of the bond, our construction team has worked to schedule the projects over the four-year term of the bond.\nDenver voters on Tuesday approved bond and mill funding measures for students in Denver Public Schools, agreeing to invest $572 million in bond funding to build and improve schools and $56.6 million in operating dollars to support proven initiatives, such as early literacy.\nDenver voters say yes to bond and mill levy funding support for DPS students and schools. Click to learn more about the details of the voter-approved bond measure.\nDenver voters on Nov. 8 approved bond and mill funding measures for DPS students and schools. Learn more about what\xe2\x80\x99s included in the mill levy measure.'</code></pre>
</div>
</div>
<section id="decode-to-natural-language" class="level4">
<h4 class="anchored" data-anchor-id="decode-to-natural-language">Decode to Natural Language</h4>
<p>The following functions will help us <code>detokenize</code> and<code>tokenize</code> the text data.</p>
<p>The <code>sentencepiece</code> vocabulary was used to convert from text to ids. This vocabulary file is loaded and used in these helper functions.</p>
<p><code>natural_language_texts</code> has the text from the examples.</p>
<div class="cell" data-outputid="023a227c-d895-4fd9-ae83-9394fe48cebd" data-execution_count="7">
<div class="sourceCode cell-code" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><span class="co" style="color: #5E5E5E;"># Special tokens</span></span>
<span id="cb10-2">PAD, EOS, UNK <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">0</span>, <span class="dv" style="color: #AD0000;">1</span>, <span class="dv" style="color: #AD0000;">2</span></span>
<span id="cb10-3"></span>
<span id="cb10-4"><span class="kw" style="color: #003B4F;">def</span> detokenize(np_array):</span>
<span id="cb10-5">    <span class="cf" style="color: #003B4F;">return</span> trax.data.detokenize(</span>
<span id="cb10-6">        np_array,</span>
<span id="cb10-7">        vocab_type<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'sentencepiece'</span>,</span>
<span id="cb10-8">        vocab_file<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'sentencepiece.model'</span>,</span>
<span id="cb10-9">        vocab_dir<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'./models'</span>)</span>
<span id="cb10-10"></span>
<span id="cb10-11"><span class="kw" style="color: #003B4F;">def</span> tokenize(s):</span>
<span id="cb10-12">  <span class="co" style="color: #5E5E5E;"># The trax.data.tokenize function operates on streams,</span></span>
<span id="cb10-13">  <span class="co" style="color: #5E5E5E;"># that's why we have to create 1-element stream with iter</span></span>
<span id="cb10-14">  <span class="co" style="color: #5E5E5E;"># and later retrieve the result with next.</span></span>
<span id="cb10-15">    <span class="cf" style="color: #003B4F;">return</span> <span class="bu" style="color: null;">next</span>(trax.data.tokenize(</span>
<span id="cb10-16">        <span class="bu" style="color: null;">iter</span>([s]),</span>
<span id="cb10-17">        vocab_type<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'sentencepiece'</span>,</span>
<span id="cb10-18">        vocab_file<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'sentencepiece.model'</span>,</span>
<span id="cb10-19">        vocab_dir<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'./models'</span>))</span></code></pre></div>
</div>
<div class="cell" data-outputid="023a227c-d895-4fd9-ae83-9394fe48cebd" data-execution_count="8">
<div class="sourceCode cell-code" id="cb11" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><span class="co" style="color: #5E5E5E;"># printing the encoding of each word to see how subwords are tokenized</span></span>
<span id="cb11-2">tokenized_text <span class="op" style="color: #5E5E5E;">=</span> [(tokenize(word).tolist(), word) <span class="cf" style="color: #003B4F;">for</span> word <span class="kw" style="color: #003B4F;">in</span> natural_language_texts[<span class="dv" style="color: #AD0000;">0</span>].split()]</span>
<span id="cb11-3"><span class="bu" style="color: null;">print</span>(tokenized_text, <span class="st" style="color: #20794D;">'</span><span class="ch" style="color: #20794D;">\n</span><span class="st" style="color: #20794D;">'</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[([12847, 277], b'Beginners'), ([15068], b'BBQ'), ([4501], b'Class'), ([3, 12297], b'Taking'), ([3399], b'Place'), ([16], b'in'), ([5964, 7115, 9, 55], b'Missoula!'), ([531], b'Do'), ([25], b'you'), ([241], b'want'), ([12], b'to'), ([129], b'get'), ([394], b'better'), ([44], b'at'), ([492], b'making'), ([3326], b'delicious'), ([15068, 58], b'BBQ?'), ([148], b'You'), ([56], b'will'), ([43], b'have'), ([8], b'the'), ([1004, 6], b'opportunity,'), ([474], b'put'), ([48], b'this'), ([30], b'on'), ([39], b'your'), ([4793], b'calendar'), ([230, 5], b'now.'), ([2721, 6], b'Thursday,'), ([1600], b'September'), ([1630, 727], b'22nd'), ([1715], b'join'), ([1150], b'World'), ([4501], b'Class'), ([15068], b'BBQ'), ([16127, 6], b'Champion,'), ([9137], b'Tony'), ([2659, 5595], b'Balay'), ([45], b'from'), ([301, 782, 3624], b'Lonestar'), ([14627, 15], b'Smoke'), ([12612, 277, 5], b'Rangers.'), ([216], b'He'), ([56], b'will'), ([36], b'be'), ([2119], b'teaching'), ([3, 9], b'a'), ([19529], b'beginner'), ([593], b'level'), ([853], b'class'), ([21], b'for'), ([921], b'everyone'), ([113], b'who'), ([2746], b'wants'), ([12], b'to'), ([129], b'get'), ([394], b'better'), ([28], b'with'), ([70], b'their'), ([17712], b'culinary'), ([1098, 5], b'skills.'), ([216], b'He'), ([56], b'will'), ([3884], b'teach'), ([25], b'you'), ([762], b'everything'), ([25], b'you'), ([174], b'need'), ([12], b'to'), ([214], b'know'), ([12], b'to'), ([5978], b'compete'), ([16], b'in'), ([3, 9], b'a'), ([3, 23405, 4547], b'KCBS'), ([15068], b'BBQ'), ([2259, 6], b'competition,'), ([379], b'including'), ([2097, 6], b'techniques,'), ([5459, 6], b'recipes,'), ([13618, 7, 6], b'timelines,'), ([3604], b'meat'), ([1801], b'selection'), ([11], b'and'), ([27856, 6], b'trimming,'), ([303], b'plus'), ([24190], b'smoker'), ([11], b'and'), ([1472], b'fire'), ([251, 5], b'information.'), ([37], b'The'), ([583], b'cost'), ([12], b'to'), ([36], b'be'), ([16], b'in'), ([8], b'the'), ([853], b'class'), ([19], b'is'), ([25264], b'$35'), ([399], b'per'), ([568, 6], b'person,'), ([11], b'and'), ([21], b'for'), ([21380, 7], b'spectators'), ([34], b'it'), ([19], b'is'), ([339, 5], b'free.'), ([15746, 26], b'Included'), ([16], b'in'), ([8], b'the'), ([583], b'cost'), ([56], b'will'), ([36], b'be'), ([893], b'either'), ([3, 9], b'a'), ([3, 17, 18, 9486], b't-shirt'), ([42], b'or'), ([3, 9, 1409, 29], b'apron'), ([11], b'and'), ([25], b'you'), ([56], b'will'), ([36], b'be'), ([12246], b'tasting'), ([5977], b'samples'), ([13], b'of'), ([284], b'each'), ([3604], b'meat'), ([24], b'that'), ([19], b'is'), ([2657, 5], b'prepared.')] 
</code></pre>
</div>
</div>
<div class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb13" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><span class="co" style="color: #5E5E5E;"># We can see that detokenize successfully undoes the tokenization</span></span>
<span id="cb13-2"><span class="bu" style="color: null;">print</span>(<span class="ss" style="color: #20794D;">f"tokenized: </span><span class="sc" style="color: #5E5E5E;">{</span>tokenize(<span class="st" style="color: #20794D;">'Beginners'</span>)<span class="sc" style="color: #5E5E5E;">}</span><span class="ch" style="color: #20794D;">\n</span><span class="ss" style="color: #20794D;">detokenized: </span><span class="sc" style="color: #5E5E5E;">{</span>detokenize(tokenize(<span class="st" style="color: #20794D;">'Beginners'</span>))<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">"</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>tokenized: [12847   277]
detokenized: Beginners</code></pre>
</div>
</div>
<p>As we can see above, we were able to take a piece of string and tokenize it.</p>
<p>Now we will create <code>input</code> and <code>target</code> pairs that will allow us to train our model. T5 uses the ids at the end of the vocab file as sentinels. For example, it will replace: - <code>vocab_size - 1</code> by <code>&lt;Z&gt;</code> - <code>vocab_size - 2</code> by <code>&lt;Y&gt;</code> - and so forth.</p>
<p>It assigns every word a <code>chr</code>.</p>
<p>The <code>pretty_decode</code> function below, which we will use in a bit, helps in handling the type when decoding.</p>
<p>Notice that:</p>
<div class="sourceCode" id="cb15" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1">string.ascii_letters <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ'</span></span></code></pre></div>
<p><strong>NOTE:</strong> Targets may have more than the 52 sentinels we replace, but this is just to give us an idea of things.</p>
<div class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb16" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1">vocab_size <span class="op" style="color: #5E5E5E;">=</span> trax.data.vocab_size(</span>
<span id="cb16-2">    vocab_type<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'sentencepiece'</span>,</span>
<span id="cb16-3">    vocab_file<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'sentencepiece.model'</span>,</span>
<span id="cb16-4">    vocab_dir<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'./models'</span>)</span>
<span id="cb16-5"></span>
<span id="cb16-6"><span class="kw" style="color: #003B4F;">def</span> get_sentinels(vocab_size<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">32000</span>, display<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">False</span>):</span>
<span id="cb16-7">    sentinels <span class="op" style="color: #5E5E5E;">=</span> {}</span>
<span id="cb16-8">    <span class="cf" style="color: #003B4F;">for</span> i, char <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">enumerate</span>(<span class="bu" style="color: null;">reversed</span>(string.ascii_letters), <span class="dv" style="color: #AD0000;">1</span>):</span>
<span id="cb16-9">        decoded_text <span class="op" style="color: #5E5E5E;">=</span> detokenize([vocab_size <span class="op" style="color: #5E5E5E;">-</span> i]) </span>
<span id="cb16-10">        </span>
<span id="cb16-11">        <span class="co" style="color: #5E5E5E;"># Sentinels, ex: &lt;Z&gt; - &lt;a&gt;</span></span>
<span id="cb16-12">        sentinels[decoded_text] <span class="op" style="color: #5E5E5E;">=</span> <span class="ss" style="color: #20794D;">f'&lt;</span><span class="sc" style="color: #5E5E5E;">{</span>char<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">&gt;'</span>    </span>
<span id="cb16-13">    </span>
<span id="cb16-14">        <span class="cf" style="color: #003B4F;">if</span> display:</span>
<span id="cb16-15">            <span class="bu" style="color: null;">print</span>(<span class="ss" style="color: #20794D;">f'The sentinel is &lt;</span><span class="sc" style="color: #5E5E5E;">{</span>char<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">&gt; and the decoded token is:'</span>, decoded_text)</span>
<span id="cb16-16"></span>
<span id="cb16-17">    <span class="cf" style="color: #003B4F;">return</span> sentinels</span></code></pre></div>
</div>
<div class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb17" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1">sentinels <span class="op" style="color: #5E5E5E;">=</span> get_sentinels(vocab_size, display<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>The sentinel is &lt;Z&gt; and the decoded token is: Internațional
The sentinel is &lt;Y&gt; and the decoded token is: erwachsene
The sentinel is &lt;X&gt; and the decoded token is: Cushion
The sentinel is &lt;W&gt; and the decoded token is: imunitar
The sentinel is &lt;V&gt; and the decoded token is: Intellectual
The sentinel is &lt;U&gt; and the decoded token is: traditi
The sentinel is &lt;T&gt; and the decoded token is: disguise
The sentinel is &lt;S&gt; and the decoded token is: exerce
The sentinel is &lt;R&gt; and the decoded token is: nourishe
The sentinel is &lt;Q&gt; and the decoded token is: predominant
The sentinel is &lt;P&gt; and the decoded token is: amitié
The sentinel is &lt;O&gt; and the decoded token is: erkennt
The sentinel is &lt;N&gt; and the decoded token is: dimension
The sentinel is &lt;M&gt; and the decoded token is: inférieur
The sentinel is &lt;L&gt; and the decoded token is: refugi
The sentinel is &lt;K&gt; and the decoded token is: cheddar
The sentinel is &lt;J&gt; and the decoded token is: unterlieg
The sentinel is &lt;I&gt; and the decoded token is: garanteaz
The sentinel is &lt;H&gt; and the decoded token is: făcute
The sentinel is &lt;G&gt; and the decoded token is: réglage
The sentinel is &lt;F&gt; and the decoded token is: pedepse
The sentinel is &lt;E&gt; and the decoded token is: Germain
The sentinel is &lt;D&gt; and the decoded token is: distinctly
The sentinel is &lt;C&gt; and the decoded token is: Schraub
The sentinel is &lt;B&gt; and the decoded token is: emanat
The sentinel is &lt;A&gt; and the decoded token is: trimestre
The sentinel is &lt;z&gt; and the decoded token is: disrespect
The sentinel is &lt;y&gt; and the decoded token is: Erasmus
The sentinel is &lt;x&gt; and the decoded token is: Australia
The sentinel is &lt;w&gt; and the decoded token is: permeabil
The sentinel is &lt;v&gt; and the decoded token is: deseori
The sentinel is &lt;u&gt; and the decoded token is: manipulated
The sentinel is &lt;t&gt; and the decoded token is: suggér
The sentinel is &lt;s&gt; and the decoded token is: corespund
The sentinel is &lt;r&gt; and the decoded token is: nitro
The sentinel is &lt;q&gt; and the decoded token is: oyons
The sentinel is &lt;p&gt; and the decoded token is: Account
The sentinel is &lt;o&gt; and the decoded token is: échéan
The sentinel is &lt;n&gt; and the decoded token is: laundering
The sentinel is &lt;m&gt; and the decoded token is: genealogy
The sentinel is &lt;l&gt; and the decoded token is: QuickBooks
The sentinel is &lt;k&gt; and the decoded token is: constituted
The sentinel is &lt;j&gt; and the decoded token is: Fertigung
The sentinel is &lt;i&gt; and the decoded token is: goutte
The sentinel is &lt;h&gt; and the decoded token is: regulă
The sentinel is &lt;g&gt; and the decoded token is: overwhelmingly
The sentinel is &lt;f&gt; and the decoded token is: émerg
The sentinel is &lt;e&gt; and the decoded token is: broyeur
The sentinel is &lt;d&gt; and the decoded token is: povești
The sentinel is &lt;c&gt; and the decoded token is: emulator
The sentinel is &lt;b&gt; and the decoded token is: halloween
The sentinel is &lt;a&gt; and the decoded token is: combustibil</code></pre>
</div>
</div>
<div class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb19" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><span class="kw" style="color: #003B4F;">def</span> pretty_decode(encoded_str_list, sentinels):</span>
<span id="cb19-2">    <span class="co" style="color: #5E5E5E;"># If already a string, just do the replacements.</span></span>
<span id="cb19-3">    <span class="cf" style="color: #003B4F;">if</span> <span class="bu" style="color: null;">isinstance</span>(encoded_str_list, (<span class="bu" style="color: null;">str</span>, <span class="bu" style="color: null;">bytes</span>)):</span>
<span id="cb19-4">        <span class="cf" style="color: #003B4F;">for</span> token, char <span class="kw" style="color: #003B4F;">in</span> sentinels.items():</span>
<span id="cb19-5">            encoded_str_list <span class="op" style="color: #5E5E5E;">=</span> encoded_str_list.replace(token, char)</span>
<span id="cb19-6">        <span class="cf" style="color: #003B4F;">return</span> encoded_str_list</span>
<span id="cb19-7">  </span>
<span id="cb19-8">    <span class="co" style="color: #5E5E5E;"># We need to decode and then prettyfy it.</span></span>
<span id="cb19-9">    <span class="cf" style="color: #003B4F;">return</span> pretty_decode(detokenize(encoded_str_list), sentinels)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb20" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1">pretty_decode(<span class="st" style="color: #20794D;">"I want to dress up as an Intellectual this halloween."</span>, sentinels)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="13">
<pre><code>'I want to dress up as an &lt;V&gt; this &lt;b&gt;.'</code></pre>
</div>
</div>
<p>The functions above make our <code>inputs</code> and <code>targets</code> more readable. For example, we might see something like this once we implement the masking function below.</p>
<ul>
<li><span style="color:red"> Input sentence: </span> Younes and Lukasz were working together in the lab yesterday after lunch.</li>
<li><span style="color:red">Input: </span> Younes and Lukasz <strong>Z</strong> together in the <strong>Y</strong> yesterday after lunch.</li>
<li><span style="color:red">Target: </span> <strong>Z</strong> were working <strong>Y</strong> lab.</li>
</ul>
</section>
</section>
<section id="tokenizing-and-masking" class="level3" data-number="3.3">
<h3 data-number="3.3" class="anchored" data-anchor-id="tokenizing-and-masking"><span class="header-section-number">3.3</span> Tokenizing and Masking</h3>
<p>We will now implement the <code>tokenize_and_mask</code> function. This function will allow us to tokenize and mask input words with a noise probability. We usually mask 15% of the words.</p>
<div class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb22" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><span class="kw" style="color: #003B4F;">def</span> tokenize_and_mask(text, vocab_size<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">32000</span>, noise<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">0.15</span>, </span>
<span id="cb22-2">                      randomizer<span class="op" style="color: #5E5E5E;">=</span>np.random.uniform, tokenize<span class="op" style="color: #5E5E5E;">=</span>tokenize):</span>
<span id="cb22-3">    <span class="co" style="color: #5E5E5E;">"""Tokenizes and masks a given input.</span></span>
<span id="cb22-4"></span>
<span id="cb22-5"><span class="co" style="color: #5E5E5E;">    Args:</span></span>
<span id="cb22-6"><span class="co" style="color: #5E5E5E;">        text (str or bytes): Text input.</span></span>
<span id="cb22-7"><span class="co" style="color: #5E5E5E;">        vocab_size (int, optional): Size of the vocabulary. Defaults to vocab_size.</span></span>
<span id="cb22-8"><span class="co" style="color: #5E5E5E;">        noise (float, optional): Probability of masking a token. Defaults to 0.15.</span></span>
<span id="cb22-9"><span class="co" style="color: #5E5E5E;">        randomizer (function, optional): Function that generates random values. Defaults to np.random.uniform.</span></span>
<span id="cb22-10"><span class="co" style="color: #5E5E5E;">        tokenize (function, optional): Tokenizer function. Defaults to tokenize.</span></span>
<span id="cb22-11"></span>
<span id="cb22-12"><span class="co" style="color: #5E5E5E;">    Returns:</span></span>
<span id="cb22-13"><span class="co" style="color: #5E5E5E;">        tuple: Tuple of lists of integers associated to inputs and targets.</span></span>
<span id="cb22-14"><span class="co" style="color: #5E5E5E;">    """</span></span>
<span id="cb22-15">    </span>
<span id="cb22-16">    <span class="co" style="color: #5E5E5E;"># current sentinel number (starts at 0)</span></span>
<span id="cb22-17">    cur_sentinel_num <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">0</span></span>
<span id="cb22-18">    <span class="co" style="color: #5E5E5E;"># inputs</span></span>
<span id="cb22-19">    inps <span class="op" style="color: #5E5E5E;">=</span> []</span>
<span id="cb22-20">    <span class="co" style="color: #5E5E5E;"># targets</span></span>
<span id="cb22-21">    targs <span class="op" style="color: #5E5E5E;">=</span> []</span>
<span id="cb22-22">        </span>
<span id="cb22-23">    <span class="co" style="color: #5E5E5E;"># prev_no_mask is True if the previous token was NOT masked, False otherwise</span></span>
<span id="cb22-24">    <span class="co" style="color: #5E5E5E;"># set prev_no_mask to True</span></span>
<span id="cb22-25">    prev_no_mask <span class="op" style="color: #5E5E5E;">=</span> <span class="va" style="color: #111111;">True</span></span>
<span id="cb22-26">    </span>
<span id="cb22-27">    <span class="co" style="color: #5E5E5E;"># loop through tokenized `text`</span></span>
<span id="cb22-28">    <span class="cf" style="color: #003B4F;">for</span> token <span class="kw" style="color: #003B4F;">in</span> tokenize(text):</span>
<span id="cb22-29">        <span class="co" style="color: #5E5E5E;"># check if the `noise` is greater than a random value (weighted coin flip)</span></span>
<span id="cb22-30">        <span class="cf" style="color: #003B4F;">if</span> randomizer() <span class="op" style="color: #5E5E5E;">&lt;</span> noise:</span>
<span id="cb22-31">            <span class="co" style="color: #5E5E5E;"># check to see if the previous token was not masked</span></span>
<span id="cb22-32">            <span class="cf" style="color: #003B4F;">if</span> prev_no_mask<span class="op" style="color: #5E5E5E;">==</span><span class="va" style="color: #111111;">True</span>: <span class="co" style="color: #5E5E5E;"># add new masked token at end_id</span></span>
<span id="cb22-33">                <span class="co" style="color: #5E5E5E;"># number of masked tokens increases by 1</span></span>
<span id="cb22-34">                cur_sentinel_num <span class="op" style="color: #5E5E5E;">+=</span> <span class="dv" style="color: #AD0000;">1</span></span>
<span id="cb22-35">                <span class="co" style="color: #5E5E5E;"># compute `end_id` by subtracting current sentinel value out of the total vocabulary size</span></span>
<span id="cb22-36">                end_id <span class="op" style="color: #5E5E5E;">=</span> vocab_size <span class="op" style="color: #5E5E5E;">-</span> cur_sentinel_num</span>
<span id="cb22-37">                <span class="co" style="color: #5E5E5E;"># append `end_id` at the end of the targets</span></span>
<span id="cb22-38">                targs.append(end_id)</span>
<span id="cb22-39">                <span class="co" style="color: #5E5E5E;"># append `end_id` at the end of the inputs</span></span>
<span id="cb22-40">                inps.append(end_id)</span>
<span id="cb22-41">            <span class="co" style="color: #5E5E5E;"># append `token` at the end of the targets</span></span>
<span id="cb22-42">            targs.append(token)</span>
<span id="cb22-43">            <span class="co" style="color: #5E5E5E;"># set prev_no_mask accordingly</span></span>
<span id="cb22-44">            prev_no_mask <span class="op" style="color: #5E5E5E;">=</span> <span class="va" style="color: #111111;">False</span></span>
<span id="cb22-45">        </span>
<span id="cb22-46">        <span class="cf" style="color: #003B4F;">else</span>: <span class="co" style="color: #5E5E5E;"># don't have two masked tokens in a row</span></span>
<span id="cb22-47">            <span class="co" style="color: #5E5E5E;"># append `token ` at the end of the inputs</span></span>
<span id="cb22-48">            inps.append(token)</span>
<span id="cb22-49">            <span class="co" style="color: #5E5E5E;"># set prev_no_mask accordingly</span></span>
<span id="cb22-50">            prev_no_mask <span class="op" style="color: #5E5E5E;">=</span> <span class="va" style="color: #111111;">True</span></span>
<span id="cb22-51">                </span>
<span id="cb22-52">    <span class="cf" style="color: #003B4F;">return</span> inps, targs</span></code></pre></div>
</div>
<div class="cell" data-outputid="2b0dc5e4-8d58-4eb0-a146-0c9f158264ac" data-execution_count="15">
<div class="sourceCode cell-code" id="cb23" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><span class="co" style="color: #5E5E5E;"># Some logic to mock a np.random value generator</span></span>
<span id="cb23-2"><span class="co" style="color: #5E5E5E;"># Needs to be in the same cell for it to always generate same output</span></span>
<span id="cb23-3"><span class="kw" style="color: #003B4F;">def</span> testing_rnd():</span>
<span id="cb23-4">    <span class="kw" style="color: #003B4F;">def</span> dummy_generator():</span>
<span id="cb23-5">        vals <span class="op" style="color: #5E5E5E;">=</span> np.linspace(<span class="dv" style="color: #AD0000;">0</span>, <span class="dv" style="color: #AD0000;">1</span>, <span class="dv" style="color: #AD0000;">10</span>)</span>
<span id="cb23-6">        cyclic_vals <span class="op" style="color: #5E5E5E;">=</span> itertools.cycle(vals)</span>
<span id="cb23-7">        <span class="cf" style="color: #003B4F;">for</span> _ <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">range</span>(<span class="dv" style="color: #AD0000;">100</span>):</span>
<span id="cb23-8">            <span class="cf" style="color: #003B4F;">yield</span> <span class="bu" style="color: null;">next</span>(cyclic_vals)</span>
<span id="cb23-9"></span>
<span id="cb23-10">    dumr <span class="op" style="color: #5E5E5E;">=</span> itertools.cycle(dummy_generator())</span>
<span id="cb23-11"></span>
<span id="cb23-12">    <span class="kw" style="color: #003B4F;">def</span> dummy_randomizer():</span>
<span id="cb23-13">        <span class="cf" style="color: #003B4F;">return</span> <span class="bu" style="color: null;">next</span>(dumr)</span>
<span id="cb23-14">    </span>
<span id="cb23-15">    <span class="cf" style="color: #003B4F;">return</span> dummy_randomizer</span>
<span id="cb23-16"></span>
<span id="cb23-17">input_str <span class="op" style="color: #5E5E5E;">=</span> natural_language_texts[<span class="dv" style="color: #AD0000;">0</span>]</span>
<span id="cb23-18"><span class="bu" style="color: null;">print</span>(<span class="ss" style="color: #20794D;">f"input string:</span><span class="ch" style="color: #20794D;">\n\n</span><span class="sc" style="color: #5E5E5E;">{</span>input_str<span class="sc" style="color: #5E5E5E;">}</span><span class="ch" style="color: #20794D;">\n</span><span class="ss" style="color: #20794D;">"</span>)</span>
<span id="cb23-19">inps, targs <span class="op" style="color: #5E5E5E;">=</span> tokenize_and_mask(input_str, randomizer<span class="op" style="color: #5E5E5E;">=</span>testing_rnd())</span>
<span id="cb23-20"><span class="bu" style="color: null;">print</span>(<span class="ss" style="color: #20794D;">f"tokenized inputs:</span><span class="ch" style="color: #20794D;">\n\n</span><span class="sc" style="color: #5E5E5E;">{</span>inps<span class="sc" style="color: #5E5E5E;">}</span><span class="ch" style="color: #20794D;">\n</span><span class="ss" style="color: #20794D;">"</span>)</span>
<span id="cb23-21"><span class="bu" style="color: null;">print</span>(<span class="ss" style="color: #20794D;">f"targets:</span><span class="ch" style="color: #20794D;">\n\n</span><span class="sc" style="color: #5E5E5E;">{</span>targs<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">"</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>input string:

b'Beginners BBQ Class Taking Place in Missoula!\nDo you want to get better at making delicious BBQ? You will have the opportunity, put this on your calendar now. Thursday, September 22nd join World Class BBQ Champion, Tony Balay from Lonestar Smoke Rangers. He will be teaching a beginner level class for everyone who wants to get better with their culinary skills.\nHe will teach you everything you need to know to compete in a KCBS BBQ competition, including techniques, recipes, timelines, meat selection and trimming, plus smoker and fire information.\nThe cost to be in the class is $35 per person, and for spectators it is free. Included in the cost will be either a t-shirt or apron and you will be tasting samples of each meat that is prepared.'

tokenized inputs:

[31999, 15068, 4501, 3, 12297, 3399, 16, 5964, 7115, 31998, 531, 25, 241, 12, 129, 394, 44, 492, 31997, 58, 148, 56, 43, 8, 1004, 6, 474, 31996, 39, 4793, 230, 5, 2721, 6, 1600, 1630, 31995, 1150, 4501, 15068, 16127, 6, 9137, 2659, 5595, 31994, 782, 3624, 14627, 15, 12612, 277, 5, 216, 31993, 2119, 3, 9, 19529, 593, 853, 21, 921, 31992, 12, 129, 394, 28, 70, 17712, 1098, 5, 31991, 3884, 25, 762, 25, 174, 12, 214, 12, 31990, 3, 9, 3, 23405, 4547, 15068, 2259, 6, 31989, 6, 5459, 6, 13618, 7, 6, 3604, 1801, 31988, 6, 303, 24190, 11, 1472, 251, 5, 37, 31987, 36, 16, 8, 853, 19, 25264, 399, 568, 31986, 21, 21380, 7, 34, 19, 339, 5, 15746, 31985, 8, 583, 56, 36, 893, 3, 9, 3, 31984, 9486, 42, 3, 9, 1409, 29, 11, 25, 31983, 12246, 5977, 13, 284, 3604, 24, 19, 2657, 31982]

targets:

[31999, 12847, 277, 31998, 9, 55, 31997, 3326, 15068, 31996, 48, 30, 31995, 727, 1715, 31994, 45, 301, 31993, 56, 36, 31992, 113, 2746, 31991, 216, 56, 31990, 5978, 16, 31989, 379, 2097, 31988, 11, 27856, 31987, 583, 12, 31986, 6, 11, 31985, 26, 16, 31984, 17, 18, 31983, 56, 36, 31982, 5]</code></pre>
</div>
</div>
<div class="cell" data-outputid="4330ae1e-1805-40c9-daf3-c6bbe92d957b" data-execution_count="16">
<div class="sourceCode cell-code" id="cb25" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">'Inputs: </span><span class="ch" style="color: #20794D;">\n\n</span><span class="st" style="color: #20794D;">'</span>, pretty_decode(inps, sentinels))</span>
<span id="cb25-2"><span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">'</span><span class="ch" style="color: #20794D;">\n</span><span class="st" style="color: #20794D;">Targets: </span><span class="ch" style="color: #20794D;">\n\n</span><span class="st" style="color: #20794D;">'</span>, pretty_decode(targs, sentinels))</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Inputs: 

 &lt;Z&gt; BBQ Class Taking Place in Missoul &lt;Y&gt; Do you want to get better at making &lt;X&gt;? You will have the opportunity, put &lt;W&gt; your calendar now. Thursday, September 22 &lt;V&gt; World Class BBQ Champion, Tony Balay &lt;U&gt;onestar Smoke Rangers. He &lt;T&gt; teaching a beginner level class for everyone&lt;S&gt; to get better with their culinary skills.&lt;R&gt; teach you everything you need to know to &lt;Q&gt; a KCBS BBQ competition,&lt;P&gt;, recipes, timelines, meat selection &lt;O&gt;, plus smoker and fire information. The&lt;N&gt; be in the class is $35 per person &lt;M&gt; for spectators it is free. Include &lt;L&gt; the cost will be either a  &lt;K&gt;shirt or apron and you &lt;J&gt; tasting samples of each meat that is prepared &lt;I&gt;

Targets: 

 &lt;Z&gt; Beginners &lt;Y&gt;a! &lt;X&gt; delicious BBQ &lt;W&gt; this on &lt;V&gt;nd join &lt;U&gt; from L &lt;T&gt; will be&lt;S&gt; who wants&lt;R&gt; He will &lt;Q&gt; compete in&lt;P&gt; including techniques &lt;O&gt; and trimming&lt;N&gt; cost to &lt;M&gt;, and &lt;L&gt;d in &lt;K&gt;t- &lt;J&gt; will be &lt;I&gt;.</code></pre>
</div>
</div>
<p>We will now use the inputs and the targets from the <code>tokenize_and_mask</code> function we implemented above.</p>
</section>
<section id="creating-the-pairs" class="level3" data-number="3.4">
<h3 data-number="3.4" class="anchored" data-anchor-id="creating-the-pairs"><span class="header-section-number">3.4</span> Creating the Pairs</h3>
<p>We will now create pairs using our dataset. We will iterate over our data and create (inp, targ) pairs using the functions already defined.</p>
<div class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb27" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><span class="co" style="color: #5E5E5E;"># Apply tokenize_and_mask</span></span>
<span id="cb27-2">inputs_targets_pairs <span class="op" style="color: #5E5E5E;">=</span> [tokenize_and_mask(text) <span class="cf" style="color: #003B4F;">for</span> text <span class="kw" style="color: #003B4F;">in</span> natural_language_texts]</span></code></pre></div>
</div>
<div class="cell" data-outputid="fc194524-41de-4d3b-87d9-ae35c29c9f79" data-execution_count="19">
<div class="sourceCode cell-code" id="cb28" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><span class="kw" style="color: #003B4F;">def</span> display_input_target_pairs(inputs_targets_pairs, sentinels, wrapper<span class="op" style="color: #5E5E5E;">=</span>textwrap.TextWrapper(width<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">70</span>)):</span>
<span id="cb28-2">    <span class="cf" style="color: #003B4F;">for</span> i, inp_tgt_pair <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">enumerate</span>(inputs_targets_pairs, <span class="dv" style="color: #AD0000;">1</span>):</span>
<span id="cb28-3">        inps, tgts <span class="op" style="color: #5E5E5E;">=</span> inp_tgt_pair</span>
<span id="cb28-4">        inps, tgts <span class="op" style="color: #5E5E5E;">=</span> pretty_decode(inps, sentinels), pretty_decode(tgts, sentinels)</span>
<span id="cb28-5">        <span class="bu" style="color: null;">print</span>(<span class="ss" style="color: #20794D;">f'[</span><span class="sc" style="color: #5E5E5E;">{</span>i<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">]</span><span class="ch" style="color: #20794D;">\n\n</span><span class="ss" style="color: #20794D;">'</span></span>
<span id="cb28-6">              <span class="ss" style="color: #20794D;">f'inputs:</span><span class="ch" style="color: #20794D;">\n</span><span class="sc" style="color: #5E5E5E;">{</span>wrapper<span class="sc" style="color: #5E5E5E;">.</span>fill(text<span class="op" style="color: #5E5E5E;">=</span>inps)<span class="sc" style="color: #5E5E5E;">}</span><span class="ch" style="color: #20794D;">\n\n</span><span class="ss" style="color: #20794D;">'</span></span>
<span id="cb28-7">              <span class="ss" style="color: #20794D;">f'targets:</span><span class="ch" style="color: #20794D;">\n</span><span class="sc" style="color: #5E5E5E;">{</span>wrapper<span class="sc" style="color: #5E5E5E;">.</span>fill(text<span class="op" style="color: #5E5E5E;">=</span>tgts)<span class="sc" style="color: #5E5E5E;">}</span><span class="ch" style="color: #20794D;">\n\n\n\n</span><span class="ss" style="color: #20794D;">'</span>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="20">
<div class="sourceCode cell-code" id="cb29" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1">display_input_target_pairs(inputs_targets_pairs, sentinels, wrapper)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1]

inputs:
Beginners BBQ Class Taking Place in Missoula! Do you &lt;Z&gt; to get better
at making delicious BBQ? You will have the opportunity, put this on
your calendar now. Thursday, September 22nd join World Class &lt;Y&gt;
Champion, Tony Ba &lt;X&gt; from Lone &lt;W&gt;e Rangers. He will be teaching  &lt;V&gt;
beginner level class for everyone who wants &lt;U&gt; get better with their
culinary &lt;T&gt;. He&lt;S&gt; teach you everything you&lt;R&gt; to know to compete in
a KCBS BBQ competition, including techniques, &lt;Q&gt;, timelines,&lt;P&gt;
selection and &lt;O&gt;, plus smoker and fire information. The cost to be in
the class is $35 per&lt;N&gt; and for &lt;M&gt;s it &lt;L&gt; free. &lt;K&gt;d in &lt;J&gt; will be
either a t-shirt or  &lt;I&gt;pron and you will be tasting samples of each
meat that is prepared.

targets:
&lt;Z&gt; want &lt;Y&gt; BBQ &lt;X&gt;lay &lt;W&gt;star Smok &lt;V&gt;a &lt;U&gt; to &lt;T&gt; skills&lt;S&gt; will&lt;R&gt;
need &lt;Q&gt; recipes&lt;P&gt; meat &lt;O&gt; trimming&lt;N&gt; person, &lt;M&gt; spectator &lt;L&gt; is
&lt;K&gt; Include &lt;J&gt; the cost &lt;I&gt;a




[2]

inputs:
Discussion in ' &lt;Z&gt; OS X Lion (10.7) &lt;Y&gt; axboi87, Jan 20, 2012. I've
&lt;X&gt; a 500gb internal drive and &lt;W&gt;a 240gb SSD. When trying to restore
using &lt;V&gt; utility i'm given &lt;U&gt; error "Not enough space &lt;T&gt; disk
&lt;S&gt;___ to restore"&lt;R&gt; I shouldn't have to do that!!! Any ideas or
workarounds before resort &lt;Q&gt; the above&lt;P&gt; Use Carbon &lt;O&gt; Cloner to
copy one drive to the other. I've done this several times&lt;N&gt; from
larger HD &lt;M&gt; to &lt;L&gt; I &lt;K&gt; up with a bootable SSD drive &lt;J&gt; One &lt;I&gt;
you have&lt;H&gt; remember not to skip is to use Disk Utility to partition
the SSD as GUID partition scheme HFS+ before&lt;G&gt; the clone. If it came
Apple &lt;F&gt;ition Scheme,&lt;E&gt;if you let CCC do the clone, the resulting
drive won't be bootable.&lt;D&gt;CC&lt;C&gt; works in "file mode" &lt;B&gt; can &lt;A&gt; copy
a larger drive (that &lt;z&gt; mostly empty) onto a smaller drive. If &lt;y&gt;
tell C&lt;x&gt; to&lt;w&gt;clone a drive you did NOT&lt;v&gt; from, it can work in block
copy mode&lt;u&gt; the destination drive must be the same size or larger
than the drive you &lt;t&gt; cloning from (if I recall). I've actually done
this somehow on Disk Utility several times (booting from a different
drive ( &lt;s&gt; even the dvd) so&lt;r&gt; disk utility from&lt;q&gt; your cloning)
and&lt;p&gt; work just fine from larger &lt;o&gt; smaller bootable clone &lt;n&gt;
Definitely &lt;m&gt; the drive clo &lt;l&gt;ing to&lt;k&gt;, &lt;j&gt; boot&lt;i&gt; Apple etc..
Thanks for pointing this&lt;h&gt; My only&lt;g&gt; using DU to go larger to &lt;f&gt;
was when I was trying&lt;e&gt; make a Lion install &lt;d&gt; and &lt;c&gt; was unable to
restore InstallESD.dmg to a 4 GB USB stick but of &lt;b&gt; the reason that
wouldn't fit is there was &lt;a&gt; more than Théâtre GB of data.

targets:
&lt;Z&gt;Mac &lt;Y&gt;' started by &lt;X&gt; got &lt;W&gt;  &lt;V&gt; disk &lt;U&gt; the &lt;T&gt; on&lt;S&gt;_&lt;R&gt; But
&lt;Q&gt;ing to&lt;P&gt;? &lt;O&gt; Copy&lt;N&gt; going &lt;M&gt;D &lt;L&gt; smaller SSD and &lt;K&gt; wound
&lt;J&gt;. &lt;I&gt; step&lt;H&gt; to&lt;G&gt; doing &lt;F&gt; Part&lt;E&gt; even &lt;D&gt; C&lt;C&gt; usually &lt;B&gt; and
it &lt;A&gt; easily &lt;z&gt;'s &lt;y&gt; you&lt;x&gt;CC&lt;w&gt; &lt;v&gt; boot&lt;u&gt; where &lt;t&gt; are &lt;s&gt;or&lt;r&gt;
not running&lt;q&gt; the drive&lt;p&gt; had it &lt;o&gt; to &lt;n&gt;. &lt;m&gt; format &lt;l&gt;n&lt;k&gt;
first &lt;j&gt; as&lt;i&gt;able&lt;h&gt; out.&lt;g&gt; experience &lt;f&gt; smaller&lt;e&gt; to &lt;d&gt; stick
&lt;c&gt; I &lt;b&gt; course &lt;a&gt; slightly Théâtre 4




[3]

inputs:
&lt;Z&gt;il plaid lycra and span &lt;Y&gt;ex shortall with metallic slink &lt;X&gt;
inset &lt;W&gt;. Attached metallic elastic belt with O &lt;V&gt;ring. Headband
included. &lt;U&gt; hip &lt;T&gt; jazz dance costume.&lt;S&gt; in the USA.

targets:
&lt;Z&gt; Fo &lt;Y&gt;d &lt;X&gt;y &lt;W&gt;s &lt;V&gt;- &lt;U&gt; Great &lt;T&gt; hop or&lt;S&gt; Made




[4]

inputs:
&lt;Z&gt; many backlinks per day for new site &lt;Y&gt; Discussion in &lt;X&gt;'Black
Hat SEO' started by Omopla &lt;W&gt;a, Dec 3, 2010. 1) for &lt;V&gt;a newly
created site, what's the max # backlinks per &lt;U&gt; I should do to be
safe? 2) how &lt;T&gt; do I have to let my site age before I can start
making&lt;S&gt;s? I did about 6000 forum profiles every 24 hours for 10 days
for one of my sites&lt;R&gt; had a brand new &lt;Q&gt; There is three back&lt;P&gt;s for
every of these forum profile so thats 18 000 &lt;O&gt;links every&lt;N&gt; hours
and nothing happened in terms &lt;M&gt; being &lt;L&gt;ized or  &lt;K&gt;andbox &lt;J&gt;d &lt;I&gt;
This is now&lt;H&gt; 3 months ago and the&lt;G&gt; is ranking on first page &lt;F&gt; a
lot of my targeted keywords. build more you can in starting but do
manual submission and not spammy type means manual +&lt;E&gt; to the
post.&lt;D&gt; then after 1 month&lt;C&gt; can make  &lt;B&gt; big blast.. Wow, dude,
you &lt;A&gt; 18k backlinks a day on  &lt;z&gt; brand new site? How quickly did
you rank up? What kind of competition/search &lt;y&gt;s did those keywords
have?

targets:
&lt;Z&gt; How &lt;Y&gt;? &lt;X&gt;  &lt;W&gt;t &lt;V&gt;  &lt;U&gt; day &lt;T&gt; long&lt;S&gt; more blink&lt;R&gt; which
&lt;Q&gt; domain.&lt;P&gt;link &lt;O&gt; back&lt;N&gt; 24 &lt;M&gt; of &lt;L&gt; penal &lt;K&gt;s &lt;J&gt;e &lt;I&gt;.&lt;H&gt;
maybe&lt;G&gt; site &lt;F&gt; for&lt;E&gt; relevant&lt;D&gt;.&lt;C&gt; you &lt;B&gt;a &lt;A&gt; built &lt;z&gt;a &lt;y&gt;e




[5]

inputs:
The Denver Board of Education opened the &lt;Z&gt;-18 school year with an
&lt;Y&gt; on projects &lt;X&gt; include new &lt;W&gt;, upgrades, &lt;V&gt; mitigation and
quality learning environments. We &lt;U&gt; that &lt;T&gt; students will be the
beneficiaries&lt;S&gt; a four year, $572 million General Obligation Bond.
Since the passage of the&lt;R&gt;, our construction team has worked to &lt;Q&gt;
the projects over the four-year term of the&lt;P&gt;. Denver voters on
Tuesday approved bond and mill &lt;O&gt; measures for students in Denver
Public Schools, agreeing to invest $5&lt;N&gt; million in &lt;M&gt; funding to
build and improve schools and $56.6 million in operating dollars to
&lt;L&gt; proven initiatives, such as early literacy. Denver voters say &lt;K&gt;
to bond and mill levy &lt;J&gt; support for D &lt;I&gt; students and schools.
Click to learn more about&lt;H&gt; details of the voter-approved bond
measure. Denver voters on&lt;G&gt;. 8 approved bond and mill funding
measures for DPS students and schools. Learn more about &lt;F&gt;’s included
in the mill &lt;E&gt;.

targets:
&lt;Z&gt; 2017 &lt;Y&gt; update &lt;X&gt; that &lt;W&gt; construction &lt;V&gt; heat &lt;U&gt; are excited
&lt;T&gt; Denver&lt;S&gt; of&lt;R&gt; bond &lt;Q&gt; schedule&lt;P&gt; bond &lt;O&gt; funding&lt;N&gt;72 &lt;M&gt;
bond &lt;L&gt; support &lt;K&gt; yes &lt;J&gt; funding &lt;I&gt;PS&lt;H&gt; the&lt;G&gt; Nov &lt;F&gt;
what&lt;E&gt;levy measure



</code></pre>
</div>
</div>
</section>
</section>
<section id="transformer" class="level2" data-number="4">
<h2 data-number="4" class="anchored" data-anchor-id="transformer"><span class="header-section-number">4</span> Transformer</h2>
<p>We now load a Transformer model checkpoint that has been pre-trained using the above C4 dataset and decode from it. This will save us a lot of time rather than have to train our model from scratch. Later we will see how to fine-tune our model.</p>
<p><img src="http://livingdatalab.com/posts/https:/github.com/pranath/blog/raw/master/images/fulltransformer.png" width="300" height="600"></p>
<p>We will start by loading in the model. We copy the checkpoint to local dir for speed, otherwise initialization takes a very long time. Now you will implement the encoder part of the transformer architecture for this. Concretely we will implement the following.</p>
<p><img src="http://livingdatalab.com/posts/https:/github.com/pranath/blog/raw/master/images/encoder.png" width="300" height="600"></p>
</section>
<section id="transformer-encoder" class="level2" data-number="5">
<h2 data-number="5" class="anchored" data-anchor-id="transformer-encoder"><span class="header-section-number">5</span> Transformer Encoder</h2>
<p>We will now implement the transformer encoder. Concretely we will implement two functions. The first function is <code>FeedForwardBlock</code>.</p>
<section id="the-feedforward-block" class="level3" data-number="5.1">
<h3 data-number="5.1" class="anchored" data-anchor-id="the-feedforward-block"><span class="header-section-number">5.1</span> The Feedforward Block</h3>
<p>The <code>FeedForwardBlock</code> function is an important one so we will start by implementing it. To do so, we need to return a list of the following:</p>
<ul>
<li><a href="https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.normalization.LayerNorm"><code>tl.LayerNorm()</code></a> = layer normalization.</li>
<li><a href="https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.core.Dense"><code>tl.Dense(d_ff)</code></a> = fully connected layer.</li>
<li><a href="https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.activation_fns.Relu"><code>activation</code></a> = activation relu, tanh, sigmoid etc.</li>
<li><code>dropout_middle</code> = we gave you this function (don’t worry about its implementation).</li>
<li><a href="https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.core.Dense"><code>tl.Dense(d_model)</code></a> = fully connected layer with same dimension as the model.</li>
<li><code>dropout_final</code> = we gave you this function (don’t worry about its implementation).</li>
</ul>
<p>We can always take a look at <a href="https://trax-ml.readthedocs.io/en/latest/">trax documentation</a> if needed.</p>
<div class="cell" data-execution_count="21">
<div class="sourceCode cell-code" id="cb31" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><span class="kw" style="color: #003B4F;">def</span> FeedForwardBlock(d_model, d_ff, dropout, dropout_shared_axes, mode, activation):</span>
<span id="cb31-2">    <span class="co" style="color: #5E5E5E;">"""Returns a list of layers implementing a feed-forward block.</span></span>
<span id="cb31-3"><span class="co" style="color: #5E5E5E;">    Args:</span></span>
<span id="cb31-4"><span class="co" style="color: #5E5E5E;">        d_model: int:  depth of embedding</span></span>
<span id="cb31-5"><span class="co" style="color: #5E5E5E;">        d_ff: int: depth of feed-forward layer</span></span>
<span id="cb31-6"><span class="co" style="color: #5E5E5E;">        dropout: float: dropout rate (how much to drop out)</span></span>
<span id="cb31-7"><span class="co" style="color: #5E5E5E;">        dropout_shared_axes: list of integers, axes to share dropout mask</span></span>
<span id="cb31-8"><span class="co" style="color: #5E5E5E;">        mode: str: 'train' or 'eval'</span></span>
<span id="cb31-9"><span class="co" style="color: #5E5E5E;">        activation: the non-linearity in feed-forward layer</span></span>
<span id="cb31-10"><span class="co" style="color: #5E5E5E;">    Returns:</span></span>
<span id="cb31-11"><span class="co" style="color: #5E5E5E;">        A list of layers which maps vectors to vectors.</span></span>
<span id="cb31-12"><span class="co" style="color: #5E5E5E;">    """</span></span>
<span id="cb31-13">    </span>
<span id="cb31-14">    dropout_middle <span class="op" style="color: #5E5E5E;">=</span> tl.Dropout(rate<span class="op" style="color: #5E5E5E;">=</span>dropout,</span>
<span id="cb31-15">                                shared_axes<span class="op" style="color: #5E5E5E;">=</span>dropout_shared_axes, </span>
<span id="cb31-16">                                mode<span class="op" style="color: #5E5E5E;">=</span>mode)</span>
<span id="cb31-17">  </span>
<span id="cb31-18">    dropout_final <span class="op" style="color: #5E5E5E;">=</span> tl.Dropout(rate<span class="op" style="color: #5E5E5E;">=</span>dropout, </span>
<span id="cb31-19">                               shared_axes<span class="op" style="color: #5E5E5E;">=</span>dropout_shared_axes, </span>
<span id="cb31-20">                               mode<span class="op" style="color: #5E5E5E;">=</span>mode)</span>
<span id="cb31-21">    </span>
<span id="cb31-22">    ff_block <span class="op" style="color: #5E5E5E;">=</span> [ </span>
<span id="cb31-23">        <span class="co" style="color: #5E5E5E;"># trax Layer normalization </span></span>
<span id="cb31-24">        tl.LayerNorm(),</span>
<span id="cb31-25">        <span class="co" style="color: #5E5E5E;"># trax Dense layer using `d_ff`</span></span>
<span id="cb31-26">        tl.Dense(d_ff),</span>
<span id="cb31-27">        <span class="co" style="color: #5E5E5E;"># activation() layer - you need to call (use parentheses) this func!</span></span>
<span id="cb31-28">        activation(),</span>
<span id="cb31-29">        <span class="co" style="color: #5E5E5E;"># dropout middle layer</span></span>
<span id="cb31-30">        dropout_middle,</span>
<span id="cb31-31">        <span class="co" style="color: #5E5E5E;"># trax Dense layer using `d_model`</span></span>
<span id="cb31-32">        tl.Dense(d_model),</span>
<span id="cb31-33">        <span class="co" style="color: #5E5E5E;"># dropout final layer</span></span>
<span id="cb31-34">        dropout_final,</span>
<span id="cb31-35">    ]</span>
<span id="cb31-36">        </span>
<span id="cb31-37">    <span class="cf" style="color: #003B4F;">return</span> ff_block</span></code></pre></div>
</div>
<div class="cell" data-outputid="0ea9ddf6-f2e0-4b96-edb7-3b04d869295a" data-execution_count="22">
<div class="sourceCode cell-code" id="cb32" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><span class="co" style="color: #5E5E5E;"># Print the block layout</span></span>
<span id="cb32-2">feed_forward_example <span class="op" style="color: #5E5E5E;">=</span> FeedForwardBlock(d_model<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">512</span>, d_ff<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">2048</span>, dropout<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">0.8</span>, dropout_shared_axes<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">0</span>, mode <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">'train'</span>, activation <span class="op" style="color: #5E5E5E;">=</span> tl.Relu)</span>
<span id="cb32-3"><span class="bu" style="color: null;">print</span>(feed_forward_example)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[LayerNorm, Dense_2048, Serial[
  Relu
], Dropout, Dense_512, Dropout]</code></pre>
</div>
</div>
<div class="cell" data-execution_count="23">
<div class="sourceCode cell-code" id="cb34" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1">FeedForwardBlock(d_model<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">16</span>, d_ff<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">64</span>, dropout<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">0.1</span>, dropout_shared_axes<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">0</span>, mode <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">'train'</span>, activation <span class="op" style="color: #5E5E5E;">=</span> tl.Relu)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="23">
<pre><code>[LayerNorm,
 Dense_64,
 Serial[
   Relu
 ],
 Dropout,
 Dense_16,
 Dropout]</code></pre>
</div>
</div>
<div class="cell" data-execution_count="24">
<div class="sourceCode cell-code" id="cb36" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb36-1">test_func <span class="op" style="color: #5E5E5E;">=</span> <span class="kw" style="color: #003B4F;">lambda</span> x: <span class="bu" style="color: null;">list</span>((<span class="bu" style="color: null;">map</span>(<span class="bu" style="color: null;">type</span>, x)))</span>
<span id="cb36-2">test_func(FeedForwardBlock(d_model<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">16</span>, d_ff<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">64</span>, dropout<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">0.1</span>, dropout_shared_axes<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">0</span>, mode <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">'train'</span>, activation <span class="op" style="color: #5E5E5E;">=</span> tl.Relu))</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="24">
<pre><code>[trax.layers.normalization.LayerNorm,
 trax.layers.core.Dense,
 trax.layers.combinators.Serial,
 trax.layers.core.Dropout,
 trax.layers.core.Dense,
 trax.layers.core.Dropout]</code></pre>
</div>
</div>
</section>
<section id="the-encoder-block" class="level3" data-number="5.2">
<h3 data-number="5.2" class="anchored" data-anchor-id="the-encoder-block"><span class="header-section-number">5.2</span> The Encoder Block</h3>
<p>The encoder block will use the <code>FeedForwardBlock</code>.</p>
<p>We will have to build two residual connections. Inside the first residual connection we will have the <code>tl.LayerNorm()</code>, <code>attention</code>, and <code>dropout_</code> layers. The second residual connection will have the <code>feed_forward</code>.</p>
<p>We will also need to implement <code>feed_forward</code>, <code>attention</code> and <code>dropout_</code> blocks.</p>
<p>So far we haven’t seen the <a href="https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.attention.Attention"><code>tl.Attention()</code></a> and <a href="https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.combinators.Residual"><code>tl.Residual()</code></a> layers so we can check the docs by clicking on them.</p>
<div class="cell" data-execution_count="26">
<div class="sourceCode cell-code" id="cb38" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb38-1"><span class="kw" style="color: #003B4F;">def</span> EncoderBlock(d_model, d_ff, n_heads, dropout, dropout_shared_axes,</span>
<span id="cb38-2">                  mode, ff_activation, FeedForwardBlock<span class="op" style="color: #5E5E5E;">=</span>FeedForwardBlock):</span>
<span id="cb38-3">    <span class="co" style="color: #5E5E5E;">"""</span></span>
<span id="cb38-4"><span class="co" style="color: #5E5E5E;">    Returns a list of layers that implements a Transformer encoder block.</span></span>
<span id="cb38-5"><span class="co" style="color: #5E5E5E;">    The input to the layer is a pair, (activations, mask), where the mask was</span></span>
<span id="cb38-6"><span class="co" style="color: #5E5E5E;">    created from the original source tokens to prevent attending to the padding</span></span>
<span id="cb38-7"><span class="co" style="color: #5E5E5E;">    part of the input.</span></span>
<span id="cb38-8"><span class="co" style="color: #5E5E5E;">    </span></span>
<span id="cb38-9"><span class="co" style="color: #5E5E5E;">    Args:</span></span>
<span id="cb38-10"><span class="co" style="color: #5E5E5E;">        d_model (int): depth of embedding.</span></span>
<span id="cb38-11"><span class="co" style="color: #5E5E5E;">        d_ff (int): depth of feed-forward layer.</span></span>
<span id="cb38-12"><span class="co" style="color: #5E5E5E;">        n_heads (int): number of attention heads.</span></span>
<span id="cb38-13"><span class="co" style="color: #5E5E5E;">        dropout (float): dropout rate (how much to drop out).</span></span>
<span id="cb38-14"><span class="co" style="color: #5E5E5E;">        dropout_shared_axes (int): axes on which to share dropout mask.</span></span>
<span id="cb38-15"><span class="co" style="color: #5E5E5E;">        mode (str): 'train' or 'eval'.</span></span>
<span id="cb38-16"><span class="co" style="color: #5E5E5E;">        ff_activation (function): the non-linearity in feed-forward layer.</span></span>
<span id="cb38-17"><span class="co" style="color: #5E5E5E;">        FeedForwardBlock (function): A function that returns the feed forward block.</span></span>
<span id="cb38-18"><span class="co" style="color: #5E5E5E;">    Returns:</span></span>
<span id="cb38-19"><span class="co" style="color: #5E5E5E;">        list: A list of layers that maps (activations, mask) to (activations, mask).</span></span>
<span id="cb38-20"><span class="co" style="color: #5E5E5E;">        </span></span>
<span id="cb38-21"><span class="co" style="color: #5E5E5E;">    """</span></span>
<span id="cb38-22">        </span>
<span id="cb38-23">    <span class="co" style="color: #5E5E5E;"># Attention block</span></span>
<span id="cb38-24">    attention <span class="op" style="color: #5E5E5E;">=</span> tl.Attention( </span>
<span id="cb38-25">        <span class="co" style="color: #5E5E5E;"># Use dimension of the model</span></span>
<span id="cb38-26">        d_feature<span class="op" style="color: #5E5E5E;">=</span>d_model,</span>
<span id="cb38-27">        <span class="co" style="color: #5E5E5E;"># Set it equal to number of attention heads</span></span>
<span id="cb38-28">        n_heads<span class="op" style="color: #5E5E5E;">=</span>n_heads,</span>
<span id="cb38-29">        <span class="co" style="color: #5E5E5E;"># Set it equal `dropout`</span></span>
<span id="cb38-30">        dropout<span class="op" style="color: #5E5E5E;">=</span>dropout,</span>
<span id="cb38-31">        <span class="co" style="color: #5E5E5E;"># Set it equal `mode`</span></span>
<span id="cb38-32">        mode<span class="op" style="color: #5E5E5E;">=</span>mode</span>
<span id="cb38-33">    )</span>
<span id="cb38-34">    </span>
<span id="cb38-35">    <span class="co" style="color: #5E5E5E;"># Call the function `FeedForwardBlock` (implemented before) and pass in the parameters</span></span>
<span id="cb38-36">    feed_forward <span class="op" style="color: #5E5E5E;">=</span> FeedForwardBlock( </span>
<span id="cb38-37">        d_model,</span>
<span id="cb38-38">        d_ff,</span>
<span id="cb38-39">        dropout,</span>
<span id="cb38-40">        dropout_shared_axes,</span>
<span id="cb38-41">        mode,</span>
<span id="cb38-42">        ff_activation</span>
<span id="cb38-43">    )</span>
<span id="cb38-44">    </span>
<span id="cb38-45">    <span class="co" style="color: #5E5E5E;"># Dropout block</span></span>
<span id="cb38-46">    dropout_ <span class="op" style="color: #5E5E5E;">=</span> tl.Dropout( </span>
<span id="cb38-47">        <span class="co" style="color: #5E5E5E;"># set it equal to `dropout`</span></span>
<span id="cb38-48">        rate<span class="op" style="color: #5E5E5E;">=</span>dropout,</span>
<span id="cb38-49">        <span class="co" style="color: #5E5E5E;"># set it equal to the axes on which to share dropout mask</span></span>
<span id="cb38-50">        shared_axes<span class="op" style="color: #5E5E5E;">=</span>dropout_shared_axes,</span>
<span id="cb38-51">        <span class="co" style="color: #5E5E5E;"># set it equal to `mode`</span></span>
<span id="cb38-52">        mode<span class="op" style="color: #5E5E5E;">=</span>mode</span>
<span id="cb38-53">    )</span>
<span id="cb38-54">    </span>
<span id="cb38-55">    encoder_block <span class="op" style="color: #5E5E5E;">=</span> [ </span>
<span id="cb38-56">        <span class="co" style="color: #5E5E5E;"># add `Residual` layer</span></span>
<span id="cb38-57">        tl.Residual(</span>
<span id="cb38-58">            <span class="co" style="color: #5E5E5E;"># add norm layer</span></span>
<span id="cb38-59">            tl.LayerNorm(),</span>
<span id="cb38-60">            <span class="co" style="color: #5E5E5E;"># add attention</span></span>
<span id="cb38-61">            attention,</span>
<span id="cb38-62">            <span class="co" style="color: #5E5E5E;"># add dropout</span></span>
<span id="cb38-63">            dropout_,</span>
<span id="cb38-64">        ),</span>
<span id="cb38-65">        <span class="co" style="color: #5E5E5E;"># add another `Residual` layer</span></span>
<span id="cb38-66">        tl.Residual(</span>
<span id="cb38-67">            <span class="co" style="color: #5E5E5E;"># add feed forward</span></span>
<span id="cb38-68">            feed_forward,</span>
<span id="cb38-69">        ),</span>
<span id="cb38-70">    ]</span>
<span id="cb38-71">        </span>
<span id="cb38-72">    <span class="cf" style="color: #003B4F;">return</span> encoder_block</span></code></pre></div>
</div>
<div class="cell" data-execution_count="27">
<div class="sourceCode cell-code" id="cb39" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1"><span class="co" style="color: #5E5E5E;"># Print the block layout</span></span>
<span id="cb39-2">encoder_example <span class="op" style="color: #5E5E5E;">=</span> EncoderBlock(d_model<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">512</span>, d_ff<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">2048</span>, n_heads<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">6</span>, dropout<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">0.8</span>, dropout_shared_axes<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">0</span>, mode <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">'train'</span>, ff_activation<span class="op" style="color: #5E5E5E;">=</span>tl.Relu)</span>
<span id="cb39-3"><span class="bu" style="color: null;">print</span>(encoder_example)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[Serial_in2_out2[
  Branch_in2_out3[
    None
    Serial_in2_out2[
      LayerNorm
      Serial_in2_out2[
        _in2_out2
        Serial_in2_out2[
          Select[0,0,0]_out3
          Serial_in4_out2[
            _in4_out4
            Serial_in4_out2[
              Parallel_in3_out3[
                Dense_512
                Dense_512
                Dense_512
              ]
              PureAttention_in4_out2
              Dense_512
            ]
            _in2_out2
          ]
        ]
        _in2_out2
      ]
      Dropout
    ]
  ]
  Add_in2
], Serial[
  Branch_out2[
    None
    Serial[
      LayerNorm
      Dense_2048
      Serial[
        Relu
      ]
      Dropout
      Dense_512
      Dropout
    ]
  ]
  Add_in2
]]</code></pre>
</div>
</div>
</section>
<section id="the-transformer-encoder" class="level3" data-number="5.3">
<h3 data-number="5.3" class="anchored" data-anchor-id="the-transformer-encoder"><span class="header-section-number">5.3</span> The Transformer Encoder</h3>
<p>Now that we have implemented the <code>EncoderBlock</code>, it is time to build the full encoder. BERT, or Bidirectional Encoder Representations from Transformers is one such encoder.</p>
<p>We will implement its core code in the function below by using the functions we have coded so far.</p>
<p>The model takes in many hyperparameters, such as the <code>vocab_size</code>, the number of classes, the dimension of your model, etc. We want to build a generic function that will take in many parameters, so we can use it later. At the end of the day, anyone can just load in an API and call transformer, but it is helpful to understand how it is built. Let’s get started.</p>
<p>For this encoder we will need a <code>positional_encoder</code> first (which is already provided) followed by <code>n_layers</code> encoder blocks, which are the same encoder blocks we previously built. Once we store the <code>n_layers</code> <code>EncoderBlock</code> in a list, we are going to encode a <code>Serial</code> layer with the following sublayers:</p>
<ul>
<li><a href="https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.combinators.Branch"><code>tl.Branch</code></a>: helps with the branching and has the following sublayers:
<ul>
<li><code>positional_encoder</code>.</li>
<li><a href="https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.attention.PaddingMask"><code>tl.PaddingMask()</code></a>: layer that maps integer sequences to padding masks.</li>
</ul></li>
<li>Your list of <code>EncoderBlock</code>s</li>
<li><a href="https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.combinators.Select"><code>tl.Select([0], n_in=2)</code></a>: Copies, reorders, or deletes stack elements according to indices.</li>
<li><a href="https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.normalization.LayerNorm"><code>tl.LayerNorm()</code></a>.</li>
<li><a href="https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.core.Mean"><code>tl.Mean()</code></a>: Mean along the first axis.</li>
<li><code>tl.Dense()</code> with n_units set to n_classes.</li>
<li><code>tl.LogSoftmax()</code></li>
</ul>
<p>Please refer to the <a href="https://trax-ml.readthedocs.io/en/latest/">trax documentation</a> for further information.</p>
<div class="cell" data-execution_count="29">
<div class="sourceCode cell-code" id="cb41" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1"><span class="kw" style="color: #003B4F;">def</span> TransformerEncoder(vocab_size<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">32000</span>,</span>
<span id="cb41-2">                       n_classes<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">10</span>,</span>
<span id="cb41-3">                       d_model<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">512</span>,</span>
<span id="cb41-4">                       d_ff<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">2048</span>,</span>
<span id="cb41-5">                       n_layers<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">6</span>,</span>
<span id="cb41-6">                       n_heads<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">8</span>,</span>
<span id="cb41-7">                       dropout<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">0.1</span>,</span>
<span id="cb41-8">                       dropout_shared_axes<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">None</span>,</span>
<span id="cb41-9">                       max_len<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">2048</span>,</span>
<span id="cb41-10">                       mode<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'train'</span>,</span>
<span id="cb41-11">                       ff_activation<span class="op" style="color: #5E5E5E;">=</span>tl.Relu,</span>
<span id="cb41-12">                      EncoderBlock<span class="op" style="color: #5E5E5E;">=</span>EncoderBlock):</span>
<span id="cb41-13">    </span>
<span id="cb41-14">    <span class="co" style="color: #5E5E5E;">"""</span></span>
<span id="cb41-15"><span class="co" style="color: #5E5E5E;">    Returns a Transformer encoder model.</span></span>
<span id="cb41-16"><span class="co" style="color: #5E5E5E;">    The input to the model is a tensor of tokens.</span></span>
<span id="cb41-17"><span class="co" style="color: #5E5E5E;">  </span></span>
<span id="cb41-18"><span class="co" style="color: #5E5E5E;">    Args:</span></span>
<span id="cb41-19"><span class="co" style="color: #5E5E5E;">        vocab_size (int): vocab size. Defaults to vocab_size.</span></span>
<span id="cb41-20"><span class="co" style="color: #5E5E5E;">        n_classes (int): how many classes on output. Defaults to 10.</span></span>
<span id="cb41-21"><span class="co" style="color: #5E5E5E;">        d_model (int): depth of embedding. Defaults to 512.</span></span>
<span id="cb41-22"><span class="co" style="color: #5E5E5E;">        d_ff (int): depth of feed-forward layer. Defaults to 2048.</span></span>
<span id="cb41-23"><span class="co" style="color: #5E5E5E;">        n_layers (int): number of encoder/decoder layers. Defaults to 6.</span></span>
<span id="cb41-24"><span class="co" style="color: #5E5E5E;">        n_heads (int): number of attention heads. Defaults to 8.</span></span>
<span id="cb41-25"><span class="co" style="color: #5E5E5E;">        dropout (float): dropout rate (how much to drop out). Defaults to 0.1.</span></span>
<span id="cb41-26"><span class="co" style="color: #5E5E5E;">        dropout_shared_axes (int): axes on which to share dropout mask. Defaults to None.</span></span>
<span id="cb41-27"><span class="co" style="color: #5E5E5E;">        max_len (int): maximum symbol length for positional encoding. Defaults to 2048.</span></span>
<span id="cb41-28"><span class="co" style="color: #5E5E5E;">        mode (str): 'train' or 'eval'. Defaults to 'train'.</span></span>
<span id="cb41-29"><span class="co" style="color: #5E5E5E;">        ff_activation (function): the non-linearity in feed-forward layer. Defaults to tl.Relu.</span></span>
<span id="cb41-30"><span class="co" style="color: #5E5E5E;">        EncoderBlock (function): Returns the encoder block. Defaults to EncoderBlock.</span></span>
<span id="cb41-31"><span class="co" style="color: #5E5E5E;">  </span></span>
<span id="cb41-32"><span class="co" style="color: #5E5E5E;">    Returns:</span></span>
<span id="cb41-33"><span class="co" style="color: #5E5E5E;">        trax.layers.combinators.Serial: A Transformer model as a layer that maps</span></span>
<span id="cb41-34"><span class="co" style="color: #5E5E5E;">        from a tensor of tokens to activations over a set of output classes.</span></span>
<span id="cb41-35"><span class="co" style="color: #5E5E5E;">    """</span></span>
<span id="cb41-36">    </span>
<span id="cb41-37">    positional_encoder <span class="op" style="color: #5E5E5E;">=</span> [</span>
<span id="cb41-38">        tl.Embedding(vocab_size, d_model),</span>
<span id="cb41-39">        tl.Dropout(rate<span class="op" style="color: #5E5E5E;">=</span>dropout, shared_axes<span class="op" style="color: #5E5E5E;">=</span>dropout_shared_axes, mode<span class="op" style="color: #5E5E5E;">=</span>mode),</span>
<span id="cb41-40">        tl.PositionalEncoding(max_len<span class="op" style="color: #5E5E5E;">=</span>max_len)</span>
<span id="cb41-41">    ]</span>
<span id="cb41-42">        </span>
<span id="cb41-43">    <span class="co" style="color: #5E5E5E;"># We use the function `EncoderBlock` (implemented above) and pass in the parameters over `n_layers`</span></span>
<span id="cb41-44">    encoder_blocks <span class="op" style="color: #5E5E5E;">=</span> [EncoderBlock(d_model, d_ff, n_heads, dropout, dropout_shared_axes,</span>
<span id="cb41-45">                  mode, ff_activation, FeedForwardBlock<span class="op" style="color: #5E5E5E;">=</span>FeedForwardBlock) <span class="cf" style="color: #003B4F;">for</span> _ <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">range</span>(n_layers)]</span>
<span id="cb41-46"></span>
<span id="cb41-47">    <span class="co" style="color: #5E5E5E;"># Assemble and return the model.</span></span>
<span id="cb41-48">    <span class="cf" style="color: #003B4F;">return</span> tl.Serial(</span>
<span id="cb41-49">        <span class="co" style="color: #5E5E5E;"># Encode</span></span>
<span id="cb41-50">        tl.Branch(</span>
<span id="cb41-51">            <span class="co" style="color: #5E5E5E;"># Use `positional_encoder`</span></span>
<span id="cb41-52">            positional_encoder,</span>
<span id="cb41-53">            <span class="co" style="color: #5E5E5E;"># Use trax padding mask</span></span>
<span id="cb41-54">            tl.PaddingMask(),</span>
<span id="cb41-55">        ),</span>
<span id="cb41-56">        <span class="co" style="color: #5E5E5E;"># Use `encoder_blocks`</span></span>
<span id="cb41-57">        encoder_blocks,</span>
<span id="cb41-58">        <span class="co" style="color: #5E5E5E;"># Use select layer</span></span>
<span id="cb41-59">        tl.Select([<span class="dv" style="color: #AD0000;">0</span>], n_in<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">2</span>),</span>
<span id="cb41-60">        <span class="co" style="color: #5E5E5E;"># Use trax layer normalization</span></span>
<span id="cb41-61">        tl.LayerNorm(),</span>
<span id="cb41-62">        <span class="co" style="color: #5E5E5E;"># Map to output categories.</span></span>
<span id="cb41-63">        <span class="co" style="color: #5E5E5E;"># Use trax mean. set axis to 1</span></span>
<span id="cb41-64">        tl.Mean(axis<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">1</span>),</span>
<span id="cb41-65">        <span class="co" style="color: #5E5E5E;"># Use trax Dense using `n_classes`</span></span>
<span id="cb41-66">        tl.Dense(n_classes),</span>
<span id="cb41-67">        <span class="co" style="color: #5E5E5E;"># Use trax log softmax</span></span>
<span id="cb41-68">        tl.LogSoftmax(),</span>
<span id="cb41-69">    )</span>
<span id="cb41-70"></span>
<span id="cb41-71">    <span class="co" style="color: #5E5E5E;">### </span><span class="re">END</span><span class="co" style="color: #5E5E5E;"> CODE HERE </span><span class="al" style="color: #AD0000;">###</span></span></code></pre></div>
</div>
<div class="cell" data-outputid="65d3d76a-96fd-44ea-9353-c89e6d8c0e1e" data-execution_count="30">
<div class="sourceCode cell-code" id="cb42" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb42-1"><span class="co" style="color: #5E5E5E;"># See the structure of our model</span></span>
<span id="cb42-2"><span class="co" style="color: #5E5E5E;"># Only 1 layer is used to keep the output readable</span></span>
<span id="cb42-3">TransformerEncoder(n_layers<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">1</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="30">
<pre><code>Serial[
  Branch_out2[
    [Embedding_32000_512, Dropout, PositionalEncoding]
    Serial[
      PaddingMask(0)
    ]
  ]
  Serial_in2_out2[
    Branch_in2_out3[
      None
      Serial_in2_out2[
        LayerNorm
        Serial_in2_out2[
          _in2_out2
          Serial_in2_out2[
            Select[0,0,0]_out3
            Serial_in4_out2[
              _in4_out4
              Serial_in4_out2[
                Parallel_in3_out3[
                  Dense_512
                  Dense_512
                  Dense_512
                ]
                PureAttention_in4_out2
                Dense_512
              ]
              _in2_out2
            ]
          ]
          _in2_out2
        ]
        Dropout
      ]
    ]
    Add_in2
  ]
  Serial[
    Branch_out2[
      None
      Serial[
        LayerNorm
        Dense_2048
        Serial[
          Relu
        ]
        Dropout
        Dense_512
        Dropout
      ]
    ]
    Add_in2
  ]
  Select[0]_in2
  LayerNorm
  Mean
  Dense_10
  LogSoftmax
]</code></pre>
</div>
</div>
</section>
</section>
<section id="acknowledgements" class="level2" data-number="6">
<h2 data-number="6" class="anchored" data-anchor-id="acknowledgements"><span class="header-section-number">6</span> Acknowledgements</h2>
<p>I’d like to express my thanks to the great <a href="https://www.coursera.org/learn/attention-models-in-nlp">Natural Language Processing with Attention Models Course</a> which i completed, and acknowledge the use of some images and other materials from the course in this article.</p>


</section>

 ]]></description>
  <category>natural-language-processing</category>
  <category>deep-learning</category>
  <guid>http://livingdatalab.com/posts/2023-03-22-implementing-the-t5-text-transfomer-model.html</guid>
  <pubDate>Wed, 22 Mar 2023 00:00:00 GMT</pubDate>
  <media:content url="https://github.com/pranath/blog/raw/master/images/t5.png" medium="image" type="image/png"/>
</item>
<item>
  <title>Creating a Transformer Model for Text Summarisation</title>
  <dc:creator>Pranath Fernando</dc:creator>
  <link>http://livingdatalab.com/posts/2023-03-18-creating-transformer-model-for-text-summarisation.html</link>
  <description><![CDATA[ 




<section id="introduction" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="introduction"><span class="header-section-number">1</span> Introduction</h2>
<p>In an <a href="2023-03-11-implementing-gpt2-a-transformer-decoder-nlp-model.html">earlier article</a> we created a transformer decoder model the same kind used to create the famous GPT-2. In this article we will explore summarization using a transfomer decoder model.</p>
<p><img src="http://livingdatalab.com/posts/https:/github.com/pranath/blog/raw/master/images/transformerNews.png" width="700"></p>
<p>Summarization is an important task in natural language processing and could be useful for a number of businesses and use cases. For example, bots can be used to scrape articles, summarize them, and then you can use sentiment analysis to identify the sentiment about certain stocks. Why always read an article or a long email today, when you can build a transformer to summarize text for you.</p>
<p>In this project we will:</p>
<ul>
<li>Use built-in functions to preprocess data</li>
<li>Implement DotProductAttention</li>
<li>Implement Causal Attention</li>
<li>Understand how attention works</li>
<li>Build the transformer model</li>
<li>Evaluate your model</li>
<li>Summarize an article</li>
</ul>
<p>This model is slightly different than the ones we have looked at previously. This is heavily based on attention and does not rely on sequences, which allows for parallel computing.</p>
</section>
<section id="import-libraries" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="import-libraries"><span class="header-section-number">2</span> Import Libraries</h2>
<div class="cell" data-outputid="a0b3e98b-7fc6-492d-c8ad-3a263b54f670" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;">import</span> sys</span>
<span id="cb1-2"><span class="im" style="color: #00769E;">import</span> os</span>
<span id="cb1-3"><span class="im" style="color: #00769E;">import</span> w2_tests</span>
<span id="cb1-4"><span class="im" style="color: #00769E;">import</span> numpy <span class="im" style="color: #00769E;">as</span> np</span>
<span id="cb1-5"></span>
<span id="cb1-6"><span class="im" style="color: #00769E;">import</span> textwrap</span>
<span id="cb1-7">wrapper <span class="op" style="color: #5E5E5E;">=</span> textwrap.TextWrapper(width<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">70</span>)</span>
<span id="cb1-8"></span>
<span id="cb1-9"><span class="im" style="color: #00769E;">import</span> trax</span>
<span id="cb1-10"><span class="im" style="color: #00769E;">from</span> trax <span class="im" style="color: #00769E;">import</span> layers <span class="im" style="color: #00769E;">as</span> tl</span>
<span id="cb1-11"><span class="im" style="color: #00769E;">from</span> trax.fastmath <span class="im" style="color: #00769E;">import</span> numpy <span class="im" style="color: #00769E;">as</span> jnp</span>
<span id="cb1-12"></span>
<span id="cb1-13"><span class="co" style="color: #5E5E5E;"># to print the entire np array</span></span>
<span id="cb1-14">np.set_printoptions(threshold<span class="op" style="color: #5E5E5E;">=</span>sys.maxsize)</span></code></pre></div>
</div>
</section>
<section id="importing-the-dataset" class="level2" data-number="3">
<h2 data-number="3" class="anchored" data-anchor-id="importing-the-dataset"><span class="header-section-number">3</span> Importing the dataset</h2>
<p>The Trax library makes it easy to work with Tensorflow’s datasets:</p>
<div class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="co" style="color: #5E5E5E;"># This will download the dataset if no data_dir is specified.</span></span>
<span id="cb2-2"><span class="co" style="color: #5E5E5E;"># Downloading and processing can take bit of time,</span></span>
<span id="cb2-3"><span class="co" style="color: #5E5E5E;"># So I have the data already in 'data/' </span></span>
<span id="cb2-4"></span>
<span id="cb2-5"><span class="co" style="color: #5E5E5E;"># Importing CNN/DailyMail articles dataset</span></span>
<span id="cb2-6">train_stream_fn <span class="op" style="color: #5E5E5E;">=</span> trax.data.TFDS(<span class="st" style="color: #20794D;">'cnn_dailymail'</span>,</span>
<span id="cb2-7">                                 data_dir<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'data/'</span>,</span>
<span id="cb2-8">                                 keys<span class="op" style="color: #5E5E5E;">=</span>(<span class="st" style="color: #20794D;">'article'</span>, <span class="st" style="color: #20794D;">'highlights'</span>),</span>
<span id="cb2-9">                                 train<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>)</span>
<span id="cb2-10"></span>
<span id="cb2-11"><span class="co" style="color: #5E5E5E;"># This should be much faster as the data is downloaded already.</span></span>
<span id="cb2-12">eval_stream_fn <span class="op" style="color: #5E5E5E;">=</span> trax.data.TFDS(<span class="st" style="color: #20794D;">'cnn_dailymail'</span>,</span>
<span id="cb2-13">                                data_dir<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'data/'</span>,</span>
<span id="cb2-14">                                keys<span class="op" style="color: #5E5E5E;">=</span>(<span class="st" style="color: #20794D;">'article'</span>, <span class="st" style="color: #20794D;">'highlights'</span>),</span>
<span id="cb2-15">                                train<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">False</span>)</span></code></pre></div>
</div>
<section id="tokenize-detokenize-helper-functions" class="level3" data-number="3.1">
<h3 data-number="3.1" class="anchored" data-anchor-id="tokenize-detokenize-helper-functions"><span class="header-section-number">3.1</span> Tokenize &amp; Detokenize helper functions</h3>
<p>The cell above loads in the encoder for us. Given any data set, we have to be able to map words to their indices, and indices to their words. The inputs and outputs to your <a href="https://github.com/google/trax">Trax</a> models are usually tensors of numbers where each number corresponds to a word. If we were to process your data manually, we would have to make use of the following:</p>
<ul>
<li><span style="color:blue"> word2Ind: </span> a dictionary mapping the word to its index.</li>
<li><span style="color:blue"> ind2Word:</span> a dictionary mapping the index to its word.</li>
<li><span style="color:blue"> word2Count:</span> a dictionary mapping the word to the number of times it appears.</li>
<li><span style="color:blue"> num_words:</span> total number of words that have appeared.</li>
</ul>
<p>We have created helper functions to simplify this process.</p>
<ul>
<li><span style="color:blue"> tokenize: </span> converts a text sentence to its corresponding token list (i.e.&nbsp;list of indices). Also converts words to subwords.</li>
<li><span style="color:blue"> detokenize: </span> converts a token list to its corresponding sentence (i.e.&nbsp;string).</li>
</ul>
<div class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><span class="kw" style="color: #003B4F;">def</span> tokenize(input_str, EOS<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">1</span>):</span>
<span id="cb3-2">    <span class="co" style="color: #5E5E5E;">"""Input str to features dict, ready for inference"""</span></span>
<span id="cb3-3">  </span>
<span id="cb3-4">    <span class="co" style="color: #5E5E5E;"># Use the trax.data.tokenize method. It takes streams and returns streams,</span></span>
<span id="cb3-5">    <span class="co" style="color: #5E5E5E;"># we get around it by making a 1-element stream with `iter`.</span></span>
<span id="cb3-6">    inputs <span class="op" style="color: #5E5E5E;">=</span>  <span class="bu" style="color: null;">next</span>(trax.data.tokenize(<span class="bu" style="color: null;">iter</span>([input_str]),</span>
<span id="cb3-7">                                      vocab_dir<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'vocab_dir/'</span>,</span>
<span id="cb3-8">                                      vocab_file<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'summarize32k.subword.subwords'</span>))</span>
<span id="cb3-9">    </span>
<span id="cb3-10">    <span class="co" style="color: #5E5E5E;"># Mark the end of the sentence with EOS</span></span>
<span id="cb3-11">    <span class="cf" style="color: #003B4F;">return</span> <span class="bu" style="color: null;">list</span>(inputs) <span class="op" style="color: #5E5E5E;">+</span> [EOS]</span>
<span id="cb3-12"></span>
<span id="cb3-13"><span class="kw" style="color: #003B4F;">def</span> detokenize(integers):</span>
<span id="cb3-14">    <span class="co" style="color: #5E5E5E;">"""List of ints to str"""</span></span>
<span id="cb3-15">  </span>
<span id="cb3-16">    s <span class="op" style="color: #5E5E5E;">=</span> trax.data.detokenize(integers,</span>
<span id="cb3-17">                             vocab_dir<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'vocab_dir/'</span>,</span>
<span id="cb3-18">                             vocab_file<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'summarize32k.subword.subwords'</span>)</span>
<span id="cb3-19">    </span>
<span id="cb3-20">    <span class="cf" style="color: #003B4F;">return</span> wrapper.fill(s)</span></code></pre></div>
</div>
</section>
<section id="preprocessing-for-language-models-concatenate-it" class="level3" data-number="3.2">
<h3 data-number="3.2" class="anchored" data-anchor-id="preprocessing-for-language-models-concatenate-it"><span class="header-section-number">3.2</span> Preprocessing for Language Models: Concatenate It!</h3>
<p>So we will use a language model – Transformer Decoder – to solve an input-output problem. Language models only predict the next word, they have no notion of inputs. To create a single input suitable for a language model, we concatenate inputs with targets putting a separator in between.</p>
<p>We also need to create a mask – with 0s at inputs and 1s at targets – so that the model is not penalized for mis-predicting the article and only focuses on the summary.</p>
<div class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><span class="co" style="color: #5E5E5E;"># Special tokens</span></span>
<span id="cb4-2">SEP <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">0</span> <span class="co" style="color: #5E5E5E;"># Padding or separator token</span></span>
<span id="cb4-3">EOS <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">1</span> <span class="co" style="color: #5E5E5E;"># End of sentence token</span></span>
<span id="cb4-4"></span>
<span id="cb4-5"><span class="co" style="color: #5E5E5E;"># Concatenate tokenized inputs and targets using 0 as separator.</span></span>
<span id="cb4-6"><span class="kw" style="color: #003B4F;">def</span> preprocess(stream):</span>
<span id="cb4-7">    <span class="cf" style="color: #003B4F;">for</span> (article, summary) <span class="kw" style="color: #003B4F;">in</span> stream:</span>
<span id="cb4-8">        joint <span class="op" style="color: #5E5E5E;">=</span> np.array(<span class="bu" style="color: null;">list</span>(article) <span class="op" style="color: #5E5E5E;">+</span> [EOS, SEP] <span class="op" style="color: #5E5E5E;">+</span> <span class="bu" style="color: null;">list</span>(summary) <span class="op" style="color: #5E5E5E;">+</span> [EOS])</span>
<span id="cb4-9">        mask <span class="op" style="color: #5E5E5E;">=</span> [<span class="dv" style="color: #AD0000;">0</span>] <span class="op" style="color: #5E5E5E;">*</span> (<span class="bu" style="color: null;">len</span>(<span class="bu" style="color: null;">list</span>(article)) <span class="op" style="color: #5E5E5E;">+</span> <span class="dv" style="color: #AD0000;">2</span>) <span class="op" style="color: #5E5E5E;">+</span> [<span class="dv" style="color: #AD0000;">1</span>] <span class="op" style="color: #5E5E5E;">*</span> (<span class="bu" style="color: null;">len</span>(<span class="bu" style="color: null;">list</span>(summary)) <span class="op" style="color: #5E5E5E;">+</span> <span class="dv" style="color: #AD0000;">1</span>) <span class="co" style="color: #5E5E5E;"># Accounting for EOS and SEP</span></span>
<span id="cb4-10">        <span class="cf" style="color: #003B4F;">yield</span> joint, joint, np.array(mask)</span>
<span id="cb4-11"></span>
<span id="cb4-12"><span class="co" style="color: #5E5E5E;"># We can combine a few data preprocessing steps into a pipeline like this.</span></span>
<span id="cb4-13">input_pipeline <span class="op" style="color: #5E5E5E;">=</span> trax.data.Serial(</span>
<span id="cb4-14">    <span class="co" style="color: #5E5E5E;"># Tokenizes</span></span>
<span id="cb4-15">    trax.data.Tokenize(vocab_dir<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'vocab_dir/'</span>,</span>
<span id="cb4-16">                       vocab_file<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'summarize32k.subword.subwords'</span>),</span>
<span id="cb4-17">    <span class="co" style="color: #5E5E5E;"># Uses function defined above</span></span>
<span id="cb4-18">    preprocess,</span>
<span id="cb4-19">    <span class="co" style="color: #5E5E5E;"># Filters out examples longer than 2048</span></span>
<span id="cb4-20">    trax.data.FilterByLength(<span class="dv" style="color: #AD0000;">2048</span>)</span>
<span id="cb4-21">)</span>
<span id="cb4-22"></span>
<span id="cb4-23"><span class="co" style="color: #5E5E5E;"># Apply preprocessing to data streams.</span></span>
<span id="cb4-24">train_stream <span class="op" style="color: #5E5E5E;">=</span> input_pipeline(train_stream_fn())</span>
<span id="cb4-25">eval_stream <span class="op" style="color: #5E5E5E;">=</span> input_pipeline(eval_stream_fn())</span>
<span id="cb4-26"></span>
<span id="cb4-27">train_input, train_target, train_mask <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">next</span>(train_stream)</span>
<span id="cb4-28"></span>
<span id="cb4-29"><span class="cf" style="color: #003B4F;">assert</span> <span class="bu" style="color: null;">sum</span>((train_input <span class="op" style="color: #5E5E5E;">-</span> train_target)<span class="op" style="color: #5E5E5E;">**</span><span class="dv" style="color: #AD0000;">2</span>) <span class="op" style="color: #5E5E5E;">==</span> <span class="dv" style="color: #AD0000;">0</span>  <span class="co" style="color: #5E5E5E;"># They are the same in Language Model (LM).</span></span></code></pre></div>
</div>
<div class="cell" data-outputid="bc4d6634-d716-4311-d49c-1956bca2bc2d" data-execution_count="6">
<div class="sourceCode cell-code" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><span class="co" style="color: #5E5E5E;"># prints mask, 0s on article, 1s on summary</span></span>
<span id="cb5-2"><span class="bu" style="color: null;">print</span>(<span class="ss" style="color: #20794D;">f'Single example mask:</span><span class="ch" style="color: #20794D;">\n\n</span><span class="ss" style="color: #20794D;"> </span><span class="sc" style="color: #5E5E5E;">{</span>train_mask<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">'</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Single example mask:

 [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]</code></pre>
</div>
</div>
<div class="cell" data-outputid="52845be8-f2fc-4803-bf7a-ed9725fe2bac" data-execution_count="7">
<div class="sourceCode cell-code" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><span class="co" style="color: #5E5E5E;"># prints: [Example][&lt;EOS&gt;][&lt;pad&gt;][Example Summary][&lt;EOS&gt;]</span></span>
<span id="cb7-2"><span class="bu" style="color: null;">print</span>(<span class="ss" style="color: #20794D;">f'Single example:</span><span class="ch" style="color: #20794D;">\n\n</span><span class="ss" style="color: #20794D;"> </span><span class="sc" style="color: #5E5E5E;">{</span>detokenize(train_input)<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">'</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Single example:

 By . Associated Press . PUBLISHED: . 14:11 EST, 25 October 2013 . | .
UPDATED: . 15:36 EST, 25 October 2013 . The bishop of the Fargo
Catholic Diocese in North Dakota has exposed potentially hundreds of
church members in Fargo, Grand Forks and Jamestown to the hepatitis A
virus in late September and early October. The state Health Department
has issued an advisory of exposure for anyone who attended five
churches and took communion. Bishop John Folda (pictured) of the Fargo
Catholic Diocese in North Dakota has exposed potentially hundreds of
church members in Fargo, Grand Forks and Jamestown to the hepatitis A
. State Immunization Program Manager Molly Howell says the risk is
low, but officials feel it's important to alert people to the possible
exposure. The diocese announced on Monday that Bishop John Folda is
taking time off after being diagnosed with hepatitis A. The diocese
says he contracted the infection through contaminated food while
attending a conference for newly ordained bishops in Italy last month.
Symptoms of hepatitis A include fever, tiredness, loss of appetite,
nausea and abdominal discomfort. Fargo Catholic Diocese in North
Dakota (pictured) is where the bishop is located .&lt;EOS&gt;&lt;pad&gt;BishopJohn
Folda, of North Dakota, is taking time off after being diagnosed . He
contracted the infection through contaminated food in Italy . Church
members in Fargo, Grand Forks and Jamestown could have been exposed
.&lt;EOS&gt;</code></pre>
</div>
</div>
</section>
<section id="batching-with-bucketing" class="level3" data-number="3.3">
<h3 data-number="3.3" class="anchored" data-anchor-id="batching-with-bucketing"><span class="header-section-number">3.3</span> Batching with bucketing</h3>
<p>We use bucketing to create batches of data.</p>
<div class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><span class="co" style="color: #5E5E5E;"># Bucketing to create batched generators.</span></span>
<span id="cb9-2"></span>
<span id="cb9-3"><span class="co" style="color: #5E5E5E;"># Buckets are defined in terms of boundaries and batch sizes.</span></span>
<span id="cb9-4"><span class="co" style="color: #5E5E5E;"># Batch_sizes[i] determines the batch size for items with length &lt; boundaries[i]</span></span>
<span id="cb9-5"><span class="co" style="color: #5E5E5E;"># So below, we'll take a batch of 16 sentences of length &lt; 128 , 8 of length &lt; 256,</span></span>
<span id="cb9-6"><span class="co" style="color: #5E5E5E;"># 4 of length &lt; 512. And so on. </span></span>
<span id="cb9-7">boundaries <span class="op" style="color: #5E5E5E;">=</span>  [<span class="dv" style="color: #AD0000;">128</span>, <span class="dv" style="color: #AD0000;">256</span>,  <span class="dv" style="color: #AD0000;">512</span>, <span class="dv" style="color: #AD0000;">1024</span>]</span>
<span id="cb9-8">batch_sizes <span class="op" style="color: #5E5E5E;">=</span> [<span class="dv" style="color: #AD0000;">16</span>,    <span class="dv" style="color: #AD0000;">8</span>,    <span class="dv" style="color: #AD0000;">4</span>,    <span class="dv" style="color: #AD0000;">2</span>, <span class="dv" style="color: #AD0000;">1</span>]</span>
<span id="cb9-9"></span>
<span id="cb9-10"><span class="co" style="color: #5E5E5E;"># Create the streams.</span></span>
<span id="cb9-11">train_batch_stream <span class="op" style="color: #5E5E5E;">=</span> trax.data.BucketByLength(</span>
<span id="cb9-12">    boundaries, batch_sizes)(train_stream)</span>
<span id="cb9-13"></span>
<span id="cb9-14">eval_batch_stream <span class="op" style="color: #5E5E5E;">=</span> trax.data.BucketByLength(</span>
<span id="cb9-15">    boundaries, batch_sizes)(eval_stream)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><span class="co" style="color: #5E5E5E;"># Every execution will result in generation of a different article</span></span>
<span id="cb10-2"><span class="co" style="color: #5E5E5E;"># We can try running this cell multiple times to see how the length of the examples affects the batch size</span></span>
<span id="cb10-3">input_batch, _, mask_batch <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">next</span>(train_batch_stream)</span>
<span id="cb10-4"></span>
<span id="cb10-5"><span class="co" style="color: #5E5E5E;"># Shape of the input_batch</span></span>
<span id="cb10-6">input_batch.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="9">
<pre><code>(1, 1201)</code></pre>
</div>
</div>
<div class="cell" data-outputid="9227c68c-6369-4ce8-8137-506c594f6ad2" data-execution_count="10">
<div class="sourceCode cell-code" id="cb12" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><span class="co" style="color: #5E5E5E;"># print corresponding integer values</span></span>
<span id="cb12-2"><span class="bu" style="color: null;">print</span>(input_batch[<span class="dv" style="color: #AD0000;">0</span>])</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[   27 23176  4694  1779  1343    28   506  1091   132    28   570     6
    78  7124   192 14454    15  3570  2067    23    46 26133    17  1019
   635    91     3  5349 23421   494     6 10487     2   728     2  1353
  3156   278  1838    28   736   809    28 13481  7511    22   625    28
  1311  2396     3   187    22  1353  1510   181 16146  1049   320   103
     2    22 26563   651   467   213   826   192  3156  1262    28 13131
     4   186 16949    17    71 12319  6604   828 29725     4     5  1081
  1083   213    54   138     3  5349 23421   494     6 10487     2   728
     8   346    12  1353   354    15  3570  2067  7511    22 24497   570
     6    78    71   213  1081   144  3360   691 12319  6604   828     2
   705     8   231    24   305   710   272  1838    68  6341   379     9
   570     6    78  7124   436   219   132   560   429     3   368 23421
   494     6 10487     7     5  1081  1353 10874 20919   217     8 12370
    21    12  2713   127 23421   494     6 10487    40 23176   809   518
   150   181   290  3892   275   527  8947   171  1269   936   213  9025
     3    69  1353   233  8272   527  6056   583   691  4398  3156   809
 14507  5429   812  7356     3  3622  6604   828     2    28   705     6
   104     6   292 15004   181 29725     4     5 21961  1838 10687    45
     2 11985   527 11907  5364     2    40    43  1383   213  2801  1248
  1078   809    28 13481    35    40    19 23176   116  4016     2   864
   127     3   305  1353  3156 17775 12979  3095   186    77  1353   669
 27439  6050 13459  1628  1290   131   143    18   757   320  2501   213
 25725 29725     2    41   969     3 16978  1822  9855  1962     2 17347
    16     2   127  4601 27439  6050 13459  1628  5349 23421   494     6
 10487 29725     4     5  3156  2868   132   213 15191   583   527    28
   506  1091     2 12319  6604   828     2    28   583   285   143    18
    46 13488 23707  6050 13459  1628   368 23421   494     6 10487   436
   213   884   320  3429    61    15  3570  2067  6715  3156   186     2
   673  1510   181 16146  1049   320   824  1311  2396     2  1353    90
 15438    17   285    22  2214   320 17950    28   346     6   650 13131
     4     2  7228   213  1052   763   314    71   213  2358   527  3622
  6604   828 29725     4     5 18352  2398  1081     3  3622  6604   828
  1353  7214   213 19839   277   527    68 27439  9275  1628 12320  5403
  9242  5590  2385    35   710   272  1838    68  6341   132  2642 11969
 27439  6050 13459  1628  3622  6604   828   669 27884     4    40 27872
   391    28  5302   531  2504   527    68     3   305  1353    43  4925
   278   523  1383   163 20812  2801  1248  1078   186  1353  3156 17775
 12979  3095 23707  6050 13459  1628   305    40  5945   320  1242    68
  1078  7511   131   540   278   320  8916   285   131    40  2362 15627
     3  1561  1078  8075   114   369  1613  1838    68   102    41  7584
    17   458 23707  6050 13459  1628  3622  6604   828 29725     4     5
   583   132    97  2861  6107 17946     5   213  6349   527   354    28
   650     6   475  3570  2067  6715  3156  4172 29725   391  2713    25
  3630   320   245 17388   181  1884  4140  1838 23421   494     6 10487
  1820     2    35   132  4140   329   926   102   213  5556    22  1353
    86 25070   918   155   213  6700     6  2057  3602     3     9  4038
  2256  1248   864   285    22    62    18    46    95   213  3602   809
   213    55    15   651  6866  4604   279  1205  3622  6604   828 29725
     4     5  2498 12320  5403  9242  5590  2385    78    28   826   542
 15902  3569     2 11985   527 11907  5364     2    78   560   253     2
   429     3   405  2067   992  1606    22  1353    43 17997   595   239
   213    55   527   213  7124     3  6753  1565  8120   479     2  1838
 12887 26509 21380   328 29725     4     5  1839 25725  2694  1676     2
   127  3611   871  5784  1435  1248 12319     7     5   228   809   824
    55     3   305    40    46    64  1248  1078   809    28 13481   132
 15010  7301   285  2801     2    35    40    19    40   116  4016  1782
   871  2694  1606   285    77  1353  1290   131   143    18   757   320
  2501   213 25725   186  8075   114   103   919    68    68   177  1782
   368 23421   494     6 10487    40   346   126   132 15902  3569   186
  1326  1248  1078   809    28 13481  4872    22  6005  6929   809   518
   150   320   290  3892   275   527  7468    81     3    69 12402     7
    26   209   346   213 13481   320   955   278  7511   213 25725  1841
   809   239   128    10  3229  2535  1782   129  8198     7    26   217
   320   245 17388   181  1884  4140  1838   134  1820   186   849  1884
   576   329   926   102   213 25725  1606    22  1353 25070   918   155
   213  3602     2    51  2253    22    62    18    46    95   213  3602
   809   213    55   527   213 25725   186   132 13040  2398    61   592
     2   213  4038  2256  1782     9   641   527    15  2067   992  1606
   285    22  1353 17997   595    78    15  2067   239   213    55   527
   213 25725    90   103     7     5  1232   761   824    62    43    18
  3625   320    15  4398  3156   186  1201   527   490  2002 23421   494
     6 10487  1353   233  8272   527  6056   583   691  4398  3156   355
    28  2145   809 14507  5429   812     8 12370    21    12    69   969
  3611   368 23421   494     6 10487    39   169  3263   635    91   936
  5892     2    35 12319     7     5   228    18   913    68  8232  1782
    13  1525   824    39   191   101   362  3060   171  6642   116  4016
   186  1269   936   213  9025     2   181   354    28  2067   640    41
     7   165    78   213   826  1782     9 26024   527  6700  3156   186
  3156  6715   354    28  3570  2067  1435  3787     3  2994  1779   952
   320   124    90   993  3736    28  3537    55   132  2173     3    56
   347  6335   141  7270 15191   213  4472   527 16972   595    97 23891
  6412    49  1151 20327 27439  6050 13459  1628   368 23421   494     6
 10487    39   169  3263   635    91   936  5892     2    35 12319 29725
     4     5   228    18   913    68  1019   545     3    13  1525   824
    39   191   101   362  3060   171  6642   116  4016   186  1269   936
   213  9025     2   181   354    28  2067   640    41 29725     4   165
    78   213   826     3    56   347  6335   141  7270 15191   213  4472
   527 16972   595    97 23891  6412    49  1151  4172 29725   391 23421
   494     6 10487     2   527 14735     2 11985   527 11907  5364     2
  1353    43 24306  5831  4461  1838  3156  1019  1223    91 27439  9275
  1628   102  1480    22    39    18   320   976   163  2008   165     6
  1166    10     1     0  5349 23421   494     6 10487     2   728     2
    40 23176   809   518   150  3892   275   171  3156  1081 16346 27439
  6774  1628  5670   354  2067  7511    22 26563   651   467   826   132
 15902  3569     2 11985   527 11907  5364 16346 27439  6774  1628  3481
  3094   570     6    78    71   705     6   104     6   292 12319  6604
   828     7     5  1081     2  1779   710   132  2642 16346 27439  6774
  1628  2713   476    22    62    18    46    95   904  6700     6  2057
  3602   809    55   527  7124 16346 27439  6774  1628    69  1353   233
  8272   809 14507  5429   812   527  6056   583   691  4398  3156  2104
     1]</code></pre>
</div>
</div>
<p>Things to notice: - First we see the corresponding values of the words. - The first 1, which represents the <code>&lt;EOS&gt;</code> tag of the article. - Followed by a 0, which represents a <code>&lt;pad&gt;</code> tag. - After the first 0 (<code>&lt;pad&gt;</code> tag) the corresponding values are of the words that are used for the summary of the article. - The second 1 represents the <code>&lt;EOS&gt;</code> tag for the summary. - All the trailing 0s represent <code>&lt;pad&gt;</code> tags which are appended to maintain consistent length (If you don’t see them then it would mean it is already of max length)</p>
<div class="cell" data-outputid="3d455bd7-e343-4c25-a467-572d2abd837f" data-execution_count="11">
<div class="sourceCode cell-code" id="cb14" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><span class="co" style="color: #5E5E5E;"># print the article and its summary</span></span>
<span id="cb14-2"><span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">'Article:</span><span class="ch" style="color: #20794D;">\n\n</span><span class="st" style="color: #20794D;">'</span>, detokenize(input_batch[<span class="dv" style="color: #AD0000;">0</span>]))</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Article:

 A drunk driver who killed a young woman in a head-on crash while
checking his mobile phone has been jailed for six years. Craig
Eccleston-Todd, 27, was driving home from a night at a pub when he
received a text message. As he was reading or replying to it, he
veered across the road while driving round a bend and smashed into
Rachel Titley’s car coming the other way. Craig Eccleston-Todd, 27
(left) was using his mobile phone when he crashed head-on into the car
being driven by Rachel Titley, 28 (right). She died later from her
injuries . The head-on crash took place in October 2013. Mr Eccleston-
Todd's car was barely recognisable (pictured) Police said Eccleston-
Todd had drunk at least three or four pints of beer before getting
behind the wheel. He was found guilty of causing death by dangerous
driving at Portsmouth Crown Court yesterday. Miss Titley, a 28-year-
old solicitor’s clerk from Cowes, Isle of Wight, had also spent the
evening with friends at a pub but had not drunk any alcohol, police
said. She was driving responsibly and there was ‘nothing she could
have done to avoid the collision’, they added. Lindsay Pennell,
prosecuting, said: ‘Craig Eccleston-Todd’s driving resulted in the
tragic death of a young woman, Rachel Titley, a death that could have
been avoided. ‘Mr Eccleston-Todd took the decision to pick up his
mobile phone whilst driving and, either reading or replying to this
text message, was so distracted that he failed to negotiate a left-
hand bend, crossing the central white line into the path of Miss
Titley’s oncoming car. Miss Titley was pulled the wreckage of
her&nbsp;Daihatsu Cuore but died later from her injuries in hospital .
‘Miss Titley [had] a bright future ahead of her. She was also
returning home having spent an enjoyable evening with friends and was
driving responsibly. ‘She had arranged to contact her friends when she
got home to confirm that she had arrived safely. Her friends sadly
never heard from her after they parted company. ‘Miss Titley’s death
in these circumstances reiterates the danger of using a hand-held
mobile phone whilst driving.’ Police were unable to take breath or
blood tests from Eccleston-Todd immediately, but in tests several
hours after the accident he was only marginally under the drink-drive
limit. The judge agreed with police that he would have been over the
limit at the time his red Citroen hit Miss Titley’s blue Daihatsu
Cuore on a road near Yarmouth, Isle of Wight, on October 11, 2013. His
phone records showed he was also texting around the time of the crash.
PC Mark Furse, from Hampshire constabulary’s serious collision
investigation unit, said: 'Our thoughts are with Rachel's family at
this time. She had been out with friends at a pub in Shalfleet that
evening, but had not had any alcohol. 'Our investigation showed that
there was nothing she could have done to avoid the collision and sadly
it cost her her life. 'Mr Eccleston-Todd had left work in Yarmouth and
met with friends at a pub where he drank at least three to four pints
of lager. He hadn't long left the pub to return home when the
collision occurred at around 9.30pm. 'We weren't able to take breath
or blood tests from him immediately and although blood taken several
hours after the collision showed he was marginally under the limit, we
maintain he would have been over the limit at the time of the
collision and in summing up today, the judge agreed. 'The analysis of
his phone records showed that he was texting on his phone around the
time of the collision so it's highly likely this would also have
contributed to his dangerous driving and loss of control.' Eccleston-
Todd was found guilty of causing death by dangerous driving following
a trial at Portsmouth Crown Court (pictured) He added: 'Mr Eccleston-
Todd will now spend six years behind bars, but Rachel's family have
lost her forever. 'I hope this will make people think twice before
drinking any alcohol and getting behind the wheel, or using a phone
once they're on the road. 'The dangers of drink driving and driving
whilst using a mobile phone are obvious. Those who continue to do so
risk spending a substantial time in prison. This case highlights just
how tragic the consequences of committing these offences can be.' ‘Mr
Eccleston-Todd will now spend six years behind bars, but Rachel’s
family have lost her for ever. I hope this will make people think
twice before drinking any alcohol and getting behind the wheel, or
using a phone once they’re on the road. This case highlights just how
tragic the consequences of committing these offences can be.’
Eccleston-Todd, of Newport, Isle of Wight, was also disqualified from
driving for eight years&nbsp;after which he will have to complete an
extended re-test.&lt;EOS&gt;&lt;pad&gt;CraigEccleston-Todd, 27, had drunk at least
three pints before driving car . Was using phone when he veered across
road in Yarmouth, Isle of Wight . Crashed head-on into 28-year-old
Rachel Titley's car, who died in hospital . Police say he would have
been over legal drink-drive limit at time of crash . He was found
guilty at Portsmouth Crown Court of causing death by dangerous driving
.&lt;EOS&gt;</code></pre>
</div>
</div>
<p>We can see that the data has the following structure: - <span style="color:blue"> [Article] </span> -&gt; <code>&lt;EOS&gt;</code> -&gt; <code>&lt;pad&gt;</code> -&gt; <span style="color:blue"> [Article Summary] </span> -&gt; <code>&lt;EOS&gt;</code> -&gt; (possibly) multiple <code>&lt;pad&gt;</code></p>
<p>The loss is taken only on the summary using cross_entropy as loss function.</p>
</section>
</section>
<section id="summarization-with-transformer" class="level2" data-number="4">
<h2 data-number="4" class="anchored" data-anchor-id="summarization-with-transformer"><span class="header-section-number">4</span> Summarization with transformer</h2>
<p>Now that we have the data generator and have handled the preprocessing, it is time to build our model.</p>
<p>We will be implementing the attention from scratch and then using it in our transformer model. Concretely, we will understand how attention works, and how we use it to connect the encoder and the decoder.</p>
<p><img src="http://livingdatalab.com/posts/https:/github.com/pranath/blog/raw/master/images/transformer_decoder_zoomin.png" width="800"></p>
<section id="dot-product-attention" class="level3" data-number="4.1">
<h3 data-number="4.1" class="anchored" data-anchor-id="dot-product-attention"><span class="header-section-number">4.1</span> Dot product attention</h3>
<p>Now we will implement dot product attention which takes in a query, key, value, and a mask. It returns the output.</p>
<p><img src="http://livingdatalab.com/posts/https:/github.com/pranath/blog/raw/master/images/dotproduct.png" width="800"></p>
<p>These are some helper functions that will help create tensors and display useful information: - <code>create_tensor</code> creates a <code>jax numpy array</code> from a list of lists. - <code>display_tensor</code> prints out the shape and the actual tensor.</p>
<div class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb16" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><span class="kw" style="color: #003B4F;">def</span> create_tensor(t):</span>
<span id="cb16-2">    <span class="co" style="color: #5E5E5E;">"""Create tensor from list of lists"""</span></span>
<span id="cb16-3">    <span class="cf" style="color: #003B4F;">return</span> jnp.array(t)</span>
<span id="cb16-4"></span>
<span id="cb16-5"></span>
<span id="cb16-6"><span class="kw" style="color: #003B4F;">def</span> display_tensor(t, name):</span>
<span id="cb16-7">    <span class="co" style="color: #5E5E5E;">"""Display shape and tensor"""</span></span>
<span id="cb16-8">    <span class="bu" style="color: null;">print</span>(<span class="ss" style="color: #20794D;">f'</span><span class="sc" style="color: #5E5E5E;">{</span>name<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;"> shape: </span><span class="sc" style="color: #5E5E5E;">{</span>t<span class="sc" style="color: #5E5E5E;">.</span>shape<span class="sc" style="color: #5E5E5E;">}</span><span class="ch" style="color: #20794D;">\n</span><span class="ss" style="color: #20794D;">'</span>)</span>
<span id="cb16-9">    <span class="bu" style="color: null;">print</span>(<span class="ss" style="color: #20794D;">f'</span><span class="sc" style="color: #5E5E5E;">{</span>t<span class="sc" style="color: #5E5E5E;">}</span><span class="ch" style="color: #20794D;">\n</span><span class="ss" style="color: #20794D;">'</span>)</span></code></pre></div>
</div>
<p>Before implementing, we can play around with a toy example of <code>dot product attention</code> without the softmax operation. Technically it would not be <code>dot product attention</code> without the softmax but this is done to avoid giving away too much of the answer and the idea is to display these tensors to give you a sense of how they look like.</p>
<p>The formula for attention is this one:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Ctext%20%7B%20Attention%20%7D(Q,%20K,%20V)=%5Coperatorname%7Bsoftmax%7D%5Cleft(%5Cfrac%7BQ%20K%5E%7BT%7D%7D%7B%5Csqrt%7Bd_%7Bk%7D%7D%7D+%7BM%7D%5Cright)%20V%5Ctag%7B1%7D%5C%0A"></p>
<p><img src="https://latex.codecogs.com/png.latex?d_%7Bk%7D"> stands for the dimension of queries and keys.</p>
<p>The <code>query</code>, <code>key</code>, <code>value</code> and <code>mask</code> vectors are provided for this example.</p>
<p>Notice that the masking is done using very negative values that will yield a similar effect to using $-$.</p>
<div class="cell" data-outputid="d6d78a8e-e3cc-47af-9584-2bdcdfcca0cd" data-execution_count="13">
<div class="sourceCode cell-code" id="cb17" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1">q <span class="op" style="color: #5E5E5E;">=</span> create_tensor([[<span class="dv" style="color: #AD0000;">1</span>, <span class="dv" style="color: #AD0000;">0</span>, <span class="dv" style="color: #AD0000;">0</span>], [<span class="dv" style="color: #AD0000;">0</span>, <span class="dv" style="color: #AD0000;">1</span>, <span class="dv" style="color: #AD0000;">0</span>]])</span>
<span id="cb17-2">display_tensor(q, <span class="st" style="color: #20794D;">'query'</span>)</span>
<span id="cb17-3">k <span class="op" style="color: #5E5E5E;">=</span> create_tensor([[<span class="dv" style="color: #AD0000;">1</span>, <span class="dv" style="color: #AD0000;">2</span>, <span class="dv" style="color: #AD0000;">3</span>], [<span class="dv" style="color: #AD0000;">4</span>, <span class="dv" style="color: #AD0000;">5</span>, <span class="dv" style="color: #AD0000;">6</span>]])</span>
<span id="cb17-4">display_tensor(k, <span class="st" style="color: #20794D;">'key'</span>)</span>
<span id="cb17-5">v <span class="op" style="color: #5E5E5E;">=</span> create_tensor([[<span class="dv" style="color: #AD0000;">0</span>, <span class="dv" style="color: #AD0000;">1</span>, <span class="dv" style="color: #AD0000;">0</span>], [<span class="dv" style="color: #AD0000;">1</span>, <span class="dv" style="color: #AD0000;">0</span>, <span class="dv" style="color: #AD0000;">1</span>]])</span>
<span id="cb17-6">display_tensor(v, <span class="st" style="color: #20794D;">'value'</span>)</span>
<span id="cb17-7">m <span class="op" style="color: #5E5E5E;">=</span> create_tensor([[<span class="dv" style="color: #AD0000;">0</span>, <span class="dv" style="color: #AD0000;">0</span>], [<span class="op" style="color: #5E5E5E;">-</span><span class="fl" style="color: #AD0000;">1e9</span>, <span class="dv" style="color: #AD0000;">0</span>]])</span>
<span id="cb17-8">display_tensor(m, <span class="st" style="color: #20794D;">'mask'</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>query shape: (2, 3)

[[1 0 0]
 [0 1 0]]

key shape: (2, 3)

[[1 2 3]
 [4 5 6]]

value shape: (2, 3)

[[0 1 0]
 [1 0 1]]

mask shape: (2, 2)

[[ 0.e+00  0.e+00]
 [-1.e+09  0.e+00]]
</code></pre>
</div>
</div>
<div class="cell" data-outputid="f01ea4ca-4152-4b54-b76a-e4b5917ae2b7" data-execution_count="14">
<div class="sourceCode cell-code" id="cb19" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1">q_dot_k <span class="op" style="color: #5E5E5E;">=</span> q <span class="op" style="color: #5E5E5E;">@</span> k.T <span class="op" style="color: #5E5E5E;">/</span> jnp.sqrt(<span class="dv" style="color: #AD0000;">3</span>)</span>
<span id="cb19-2">display_tensor(q_dot_k, <span class="st" style="color: #20794D;">'query dot key'</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>query dot key shape: (2, 2)

[[0.57735026 2.309401  ]
 [1.1547005  2.8867514 ]]
</code></pre>
</div>
</div>
<div class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb21" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1">masked <span class="op" style="color: #5E5E5E;">=</span> q_dot_k <span class="op" style="color: #5E5E5E;">+</span> m</span>
<span id="cb21-2">display_tensor(masked, <span class="st" style="color: #20794D;">'masked query dot key'</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>masked query dot key shape: (2, 2)

[[ 5.7735026e-01  2.3094010e+00]
 [-1.0000000e+09  2.8867514e+00]]
</code></pre>
</div>
</div>
<div class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb23" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1">display_tensor(masked <span class="op" style="color: #5E5E5E;">@</span> v, <span class="st" style="color: #20794D;">'masked query dot key dot value'</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>masked query dot key dot value shape: (2, 3)

[[ 2.3094010e+00  5.7735026e-01  2.3094010e+00]
 [ 2.8867514e+00 -1.0000000e+09  2.8867514e+00]]
</code></pre>
</div>
</div>
<p>In order to use the previous dummy tensors to test some of the graded functions, a batch dimension should be added to them so they mimic the shape of real-life examples. The mask is also replaced by a version of it that resembles the one that is used by trax:</p>
<div class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb25" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1">q_with_batch <span class="op" style="color: #5E5E5E;">=</span> q[<span class="va" style="color: #111111;">None</span>,:]</span>
<span id="cb25-2">display_tensor(q_with_batch, <span class="st" style="color: #20794D;">'query with batch dim'</span>)</span>
<span id="cb25-3">k_with_batch <span class="op" style="color: #5E5E5E;">=</span> k[<span class="va" style="color: #111111;">None</span>,:]</span>
<span id="cb25-4">display_tensor(k_with_batch, <span class="st" style="color: #20794D;">'key with batch dim'</span>)</span>
<span id="cb25-5">v_with_batch <span class="op" style="color: #5E5E5E;">=</span> v[<span class="va" style="color: #111111;">None</span>,:]</span>
<span id="cb25-6">display_tensor(v_with_batch, <span class="st" style="color: #20794D;">'value with batch dim'</span>)</span>
<span id="cb25-7">m_bool <span class="op" style="color: #5E5E5E;">=</span> create_tensor([[<span class="va" style="color: #111111;">True</span>, <span class="va" style="color: #111111;">True</span>], [<span class="va" style="color: #111111;">False</span>, <span class="va" style="color: #111111;">True</span>]])</span>
<span id="cb25-8">display_tensor(m_bool, <span class="st" style="color: #20794D;">'boolean mask'</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>query with batch dim shape: (1, 2, 3)

[[[1 0 0]
  [0 1 0]]]

key with batch dim shape: (1, 2, 3)

[[[1 2 3]
  [4 5 6]]]

value with batch dim shape: (1, 2, 3)

[[[0 1 0]
  [1 0 1]]]

boolean mask shape: (2, 2)

[[ True  True]
 [False  True]]
</code></pre>
</div>
</div>
<p>Let’s now implement the dot product attention. Concretely, we will implement the following equation</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Ctext%20%7B%20Attention%20%7D(Q,%20K,%20V)=%5Coperatorname%7Bsoftmax%7D%5Cleft(%5Cfrac%7BQ%20K%5E%7BT%7D%7D%7B%5Csqrt%7Bd_%7Bk%7D%7D%7D+%7BM%7D%5Cright)%20V%5Ctag%7B1%7D%5C%0A"></p>
<p><img src="https://latex.codecogs.com/png.latex?Q"> - query, <img src="https://latex.codecogs.com/png.latex?K"> - key, <img src="https://latex.codecogs.com/png.latex?V"> - values, <img src="https://latex.codecogs.com/png.latex?M"> - mask, <img src="https://latex.codecogs.com/png.latex?%7Bd_k%7D"> - depth/dimension of the queries and keys (used for scaling down)</p>
<div class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb27" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><span class="kw" style="color: #003B4F;">def</span> DotProductAttention(query, key, value, mask):</span>
<span id="cb27-2">    <span class="co" style="color: #5E5E5E;">"""Dot product self-attention.</span></span>
<span id="cb27-3"><span class="co" style="color: #5E5E5E;">    Args:</span></span>
<span id="cb27-4"><span class="co" style="color: #5E5E5E;">        query (jax.interpreters.xla.DeviceArray): array of query representations with shape (L_q by d)</span></span>
<span id="cb27-5"><span class="co" style="color: #5E5E5E;">        key (jax.interpreters.xla.DeviceArray): array of key representations with shape (L_k by d)</span></span>
<span id="cb27-6"><span class="co" style="color: #5E5E5E;">        value (jax.interpreters.xla.DeviceArray): array of value representations with shape (L_k by d) where L_v = L_k</span></span>
<span id="cb27-7"><span class="co" style="color: #5E5E5E;">        mask (jax.interpreters.xla.DeviceArray): attention-mask, gates attention with shape (L_q by L_k)</span></span>
<span id="cb27-8"></span>
<span id="cb27-9"><span class="co" style="color: #5E5E5E;">    Returns:</span></span>
<span id="cb27-10"><span class="co" style="color: #5E5E5E;">        jax.interpreters.xla.DeviceArray: Self-attention array for q, k, v arrays. (L_q by d)</span></span>
<span id="cb27-11"><span class="co" style="color: #5E5E5E;">    """</span></span>
<span id="cb27-12"></span>
<span id="cb27-13">    <span class="cf" style="color: #003B4F;">assert</span> query.shape[<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>] <span class="op" style="color: #5E5E5E;">==</span> key.shape[<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>] <span class="op" style="color: #5E5E5E;">==</span> value.shape[<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>], <span class="st" style="color: #20794D;">"Embedding dimensions of q, k, v aren't all the same"</span></span>
<span id="cb27-14"></span>
<span id="cb27-15">    <span class="co" style="color: #5E5E5E;"># Save depth/dimension of the query embedding for scaling down the dot product</span></span>
<span id="cb27-16">    depth <span class="op" style="color: #5E5E5E;">=</span> query.shape[<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>]</span>
<span id="cb27-17"></span>
<span id="cb27-18">    <span class="co" style="color: #5E5E5E;"># Calculate scaled query key dot product according to formula above</span></span>
<span id="cb27-19">    dots <span class="op" style="color: #5E5E5E;">=</span> jnp.matmul(query, jnp.swapaxes(key, <span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>, <span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">2</span>)) <span class="op" style="color: #5E5E5E;">/</span> jnp.sqrt(depth)</span>
<span id="cb27-20">    </span>
<span id="cb27-21">    <span class="co" style="color: #5E5E5E;"># Apply the mask</span></span>
<span id="cb27-22">    <span class="cf" style="color: #003B4F;">if</span> mask <span class="kw" style="color: #003B4F;">is</span> <span class="kw" style="color: #003B4F;">not</span> <span class="va" style="color: #111111;">None</span>: <span class="co" style="color: #5E5E5E;"># You do not need to replace the 'None' on this line</span></span>
<span id="cb27-23">        dots <span class="op" style="color: #5E5E5E;">=</span> jnp.where(mask, dots, jnp.full_like(dots, <span class="op" style="color: #5E5E5E;">-</span><span class="fl" style="color: #AD0000;">1e9</span>))</span>
<span id="cb27-24">    </span>
<span id="cb27-25">    <span class="co" style="color: #5E5E5E;"># Softmax formula implementation</span></span>
<span id="cb27-26">    <span class="co" style="color: #5E5E5E;"># We use trax.fastmath.logsumexp of masked_qkT to avoid underflow by division by large numbers</span></span>
<span id="cb27-27">    logsumexp <span class="op" style="color: #5E5E5E;">=</span> trax.fastmath.logsumexp(dots, axis<span class="op" style="color: #5E5E5E;">=-</span><span class="dv" style="color: #AD0000;">1</span>, keepdims<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>)</span>
<span id="cb27-28"></span>
<span id="cb27-29">    <span class="co" style="color: #5E5E5E;"># Take exponential of dots minus logsumexp to get softmax</span></span>
<span id="cb27-30">    dots <span class="op" style="color: #5E5E5E;">=</span> jnp.exp(dots <span class="op" style="color: #5E5E5E;">-</span> logsumexp)</span>
<span id="cb27-31"></span>
<span id="cb27-32">    <span class="co" style="color: #5E5E5E;"># Multiply dots by value to get self-attention</span></span>
<span id="cb27-33">    attention <span class="op" style="color: #5E5E5E;">=</span> jnp.matmul(dots, value)</span>
<span id="cb27-34">    </span>
<span id="cb27-35">    <span class="cf" style="color: #003B4F;">return</span> attention</span></code></pre></div>
</div>
<div class="cell" data-outputid="1c51af3a-5f11-480f-b33b-419072d8298c" data-execution_count="19">
<div class="sourceCode cell-code" id="cb28" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1">DotProductAttention(q_with_batch, k_with_batch, v_with_batch, m_bool)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="19">
<pre><code>DeviceArray([[[0.8496746 , 0.15032545, 0.8496746 ],
              [1.        , 0.        , 1.        ]]], dtype=float32)</code></pre>
</div>
</div>
</section>
<section id="causal-attention" class="level3" data-number="4.2">
<h3 data-number="4.2" class="anchored" data-anchor-id="causal-attention"><span class="header-section-number">4.2</span> Causal Attention</h3>
<p>Now we are going to implement causal attention: multi-headed attention with a mask to attend only to words that occurred before.</p>
<p><img src="http://livingdatalab.com/posts/https:/github.com/pranath/blog/raw/master/images/causal.png" width="800"></p>
<p>In the image above, a word can see everything that is before it, but not what is after it. To implement causal attention, we will have to transform vectors and do many reshapes.</p>
<p>We will implement the following functions that will be needed for Causal Attention:</p>
<ul>
<li><span style="color:blue"> compute_attention_heads </span>: Gets an input <img src="https://latex.codecogs.com/png.latex?x"> of dimension (n_batch, seqlen, n_heads <img src="https://latex.codecogs.com/png.latex?%5Ctimes"> d_head) and splits the last (depth) dimension and stacks it to the zeroth dimension to allow matrix multiplication (n_batch <img src="https://latex.codecogs.com/png.latex?%5Ctimes"> n_heads, seqlen, d_head).</li>
<li><span style="color:blue"> dot_product_self_attention </span>: Creates a mask matrix with <code>False</code> values above the diagonal and <code>True</code> values below and calls DotProductAttention which implements dot product self attention.</li>
<li><span style="color:blue"> compute_attention_output </span>: Undoes compute_attention_heads by splitting first (vertical) dimension and stacking in the last (depth) dimension (n_batch, seqlen, n_heads <img src="https://latex.codecogs.com/png.latex?%5Ctimes"> d_head). These operations concatenate (stack/merge) the heads.</li>
</ul>
<p>We use some toy tensors which gives us an idea of the data shapes and opperations involved in Causal Attention. They are also useful to test out our functions!</p>
<div class="cell" data-outputid="847a9416-877a-4246-c738-0eacdf46de59" data-execution_count="21">
<div class="sourceCode cell-code" id="cb30" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1">tensor2d <span class="op" style="color: #5E5E5E;">=</span> create_tensor(q)</span>
<span id="cb30-2">display_tensor(tensor2d, <span class="st" style="color: #20794D;">'query matrix (2D tensor)'</span>)</span>
<span id="cb30-3"></span>
<span id="cb30-4">tensor4d2b <span class="op" style="color: #5E5E5E;">=</span> create_tensor([[q, q], [q, q]])</span>
<span id="cb30-5">display_tensor(tensor4d2b, <span class="st" style="color: #20794D;">'batch of two (multi-head) collections of query matrices (4D tensor)'</span>)</span>
<span id="cb30-6"></span>
<span id="cb30-7">tensor3dc <span class="op" style="color: #5E5E5E;">=</span> create_tensor([jnp.concatenate([q, q], axis <span class="op" style="color: #5E5E5E;">=</span> <span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>)])</span>
<span id="cb30-8">display_tensor(tensor3dc, <span class="st" style="color: #20794D;">'one batch of concatenated heads of query matrices (3d tensor)'</span>)</span>
<span id="cb30-9"></span>
<span id="cb30-10">tensor3dc3b <span class="op" style="color: #5E5E5E;">=</span> create_tensor([jnp.concatenate([q, q], axis <span class="op" style="color: #5E5E5E;">=</span> <span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>), jnp.concatenate([q, q], axis <span class="op" style="color: #5E5E5E;">=</span> <span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>), jnp.concatenate([q, q], axis <span class="op" style="color: #5E5E5E;">=</span> <span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>)])</span>
<span id="cb30-11">display_tensor(tensor3dc3b, <span class="st" style="color: #20794D;">'three batches of concatenated heads of query matrices (3d tensor)'</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>query matrix (2D tensor) shape: (2, 3)

[[1 0 0]
 [0 1 0]]

batch of two (multi-head) collections of query matrices (4D tensor) shape: (2, 2, 2, 3)

[[[[1 0 0]
   [0 1 0]]

  [[1 0 0]
   [0 1 0]]]


 [[[1 0 0]
   [0 1 0]]

  [[1 0 0]
   [0 1 0]]]]

one batch of concatenated heads of query matrices (3d tensor) shape: (1, 2, 6)

[[[1 0 0 1 0 0]
  [0 1 0 0 1 0]]]

three batches of concatenated heads of query matrices (3d tensor) shape: (3, 2, 6)

[[[1 0 0 1 0 0]
  [0 1 0 0 1 0]]

 [[1 0 0 1 0 0]
  [0 1 0 0 1 0]]

 [[1 0 0 1 0 0]
  [0 1 0 0 1 0]]]
</code></pre>
</div>
</div>
<p>It is important to know that the following 3 functions would normally be defined within the <code>CausalAttention</code> function further below.</p>
<p>However this makes these functions harder to test. Because of this, these functions are shown individually using a <code>closure</code> (when necessary) that simulates them being inside of the <code>CausalAttention</code> function. This is done because they rely on some variables that can be accessed from within <code>CausalAttention</code>.</p>
</section>
<section id="support-functions" class="level3" data-number="4.3">
<h3 data-number="4.3" class="anchored" data-anchor-id="support-functions"><span class="header-section-number">4.3</span> Support Functions</h3>
<p><span style="color:blue"> compute_attention_heads </span>: Gets an input <img src="https://latex.codecogs.com/png.latex?x"> of dimension (n_batch, seqlen, n_heads <img src="https://latex.codecogs.com/png.latex?%5Ctimes"> d_head) and splits the last (depth) dimension and stacks it to the zeroth dimension to allow matrix multiplication (n_batch <img src="https://latex.codecogs.com/png.latex?%5Ctimes"> n_heads, seqlen, d_head).</p>
<div class="cell" data-execution_count="22">
<div class="sourceCode cell-code" id="cb32" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><span class="kw" style="color: #003B4F;">def</span> compute_attention_heads_closure(n_heads, d_head):</span>
<span id="cb32-2">    <span class="co" style="color: #5E5E5E;">""" Function that simulates environment inside CausalAttention function.</span></span>
<span id="cb32-3"><span class="co" style="color: #5E5E5E;">    Args:</span></span>
<span id="cb32-4"><span class="co" style="color: #5E5E5E;">        d_head (int):  dimensionality of heads</span></span>
<span id="cb32-5"><span class="co" style="color: #5E5E5E;">        n_heads (int): number of attention heads</span></span>
<span id="cb32-6"><span class="co" style="color: #5E5E5E;">    Returns:</span></span>
<span id="cb32-7"><span class="co" style="color: #5E5E5E;">        function: compute_attention_heads function</span></span>
<span id="cb32-8"><span class="co" style="color: #5E5E5E;">    """</span></span>
<span id="cb32-9"></span>
<span id="cb32-10">    <span class="kw" style="color: #003B4F;">def</span> compute_attention_heads(x):</span>
<span id="cb32-11">        <span class="co" style="color: #5E5E5E;">""" Compute the attention heads.</span></span>
<span id="cb32-12"><span class="co" style="color: #5E5E5E;">        Args:</span></span>
<span id="cb32-13"><span class="co" style="color: #5E5E5E;">            x (jax.interpreters.xla.DeviceArray): tensor with shape (n_batch, seqlen, n_heads X d_head).</span></span>
<span id="cb32-14"><span class="co" style="color: #5E5E5E;">        Returns:</span></span>
<span id="cb32-15"><span class="co" style="color: #5E5E5E;">            jax.interpreters.xla.DeviceArray: reshaped tensor with shape (n_batch X n_heads, seqlen, d_head).</span></span>
<span id="cb32-16"><span class="co" style="color: #5E5E5E;">        """</span></span>
<span id="cb32-17">        </span>
<span id="cb32-18">        <span class="co" style="color: #5E5E5E;"># Size of the x's batch dimension</span></span>
<span id="cb32-19">        batch_size <span class="op" style="color: #5E5E5E;">=</span> x.shape[<span class="dv" style="color: #AD0000;">0</span>]</span>
<span id="cb32-20">        <span class="co" style="color: #5E5E5E;"># Length of the sequence</span></span>
<span id="cb32-21">        <span class="co" style="color: #5E5E5E;"># Should be size of x's first dimension without counting the batch dim</span></span>
<span id="cb32-22">        seqlen <span class="op" style="color: #5E5E5E;">=</span> x.shape[<span class="dv" style="color: #AD0000;">1</span>]</span>
<span id="cb32-23">        <span class="co" style="color: #5E5E5E;"># Reshape x using jnp.reshape()</span></span>
<span id="cb32-24">        <span class="co" style="color: #5E5E5E;"># n_batch, seqlen, n_heads*d_head -&gt; n_batch, seqlen, n_heads, d_head</span></span>
<span id="cb32-25">        x <span class="op" style="color: #5E5E5E;">=</span> jnp.reshape(x, (batch_size, seqlen, n_heads, d_head))</span>
<span id="cb32-26">        <span class="co" style="color: #5E5E5E;"># Transpose x using jnp.transpose()</span></span>
<span id="cb32-27">        <span class="co" style="color: #5E5E5E;"># n_batch, seqlen, n_heads, d_head -&gt; n_batch, n_heads, seqlen, d_head</span></span>
<span id="cb32-28">        <span class="co" style="color: #5E5E5E;"># Note that the values within the tuple are the indexes of the dimensions of x and we must rearrange them</span></span>
<span id="cb32-29">        x <span class="op" style="color: #5E5E5E;">=</span> jnp.transpose(x, (<span class="dv" style="color: #AD0000;">0</span>, <span class="dv" style="color: #AD0000;">2</span>, <span class="dv" style="color: #AD0000;">1</span>, <span class="dv" style="color: #AD0000;">3</span>))</span>
<span id="cb32-30">        <span class="co" style="color: #5E5E5E;"># Reshape x using jnp.reshape()</span></span>
<span id="cb32-31">        <span class="co" style="color: #5E5E5E;"># n_batch, n_heads, seqlen, d_head -&gt; n_batch*n_heads, seqlen, d_head</span></span>
<span id="cb32-32">        x <span class="op" style="color: #5E5E5E;">=</span> jnp.reshape(x, (batch_size<span class="op" style="color: #5E5E5E;">*</span>n_heads, seqlen, d_head))</span>
<span id="cb32-33"></span>
<span id="cb32-34">        <span class="cf" style="color: #003B4F;">return</span> x</span>
<span id="cb32-35">    <span class="cf" style="color: #003B4F;">return</span> compute_attention_heads</span></code></pre></div>
</div>
<div class="cell" data-execution_count="23">
<div class="sourceCode cell-code" id="cb33" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1">display_tensor(tensor3dc3b, <span class="st" style="color: #20794D;">"input tensor"</span>)</span>
<span id="cb33-2">result_cah <span class="op" style="color: #5E5E5E;">=</span> compute_attention_heads_closure(<span class="dv" style="color: #AD0000;">2</span>,<span class="dv" style="color: #AD0000;">3</span>)(tensor3dc3b)</span>
<span id="cb33-3">display_tensor(result_cah, <span class="st" style="color: #20794D;">"output tensor"</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>input tensor shape: (3, 2, 6)

[[[1 0 0 1 0 0]
  [0 1 0 0 1 0]]

 [[1 0 0 1 0 0]
  [0 1 0 0 1 0]]

 [[1 0 0 1 0 0]
  [0 1 0 0 1 0]]]

output tensor shape: (6, 2, 3)

[[[1 0 0]
  [0 1 0]]

 [[1 0 0]
  [0 1 0]]

 [[1 0 0]
  [0 1 0]]

 [[1 0 0]
  [0 1 0]]

 [[1 0 0]
  [0 1 0]]

 [[1 0 0]
  [0 1 0]]]
</code></pre>
</div>
</div>
<p><span style="color:blue"> dot_product_self_attention </span>: Creates a mask matrix with <code>False</code> values above the diagonal and <code>True</code> values below and calls DotProductAttention which implements dot product self attention.</p>
<div class="cell" data-execution_count="25">
<div class="sourceCode cell-code" id="cb35" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><span class="kw" style="color: #003B4F;">def</span> dot_product_self_attention(q, k, v):</span>
<span id="cb35-2">    <span class="co" style="color: #5E5E5E;">""" Masked dot product self attention.</span></span>
<span id="cb35-3"><span class="co" style="color: #5E5E5E;">    Args:</span></span>
<span id="cb35-4"><span class="co" style="color: #5E5E5E;">        q (jax.interpreters.xla.DeviceArray): queries.</span></span>
<span id="cb35-5"><span class="co" style="color: #5E5E5E;">        k (jax.interpreters.xla.DeviceArray): keys.</span></span>
<span id="cb35-6"><span class="co" style="color: #5E5E5E;">        v (jax.interpreters.xla.DeviceArray): values.</span></span>
<span id="cb35-7"><span class="co" style="color: #5E5E5E;">    Returns:</span></span>
<span id="cb35-8"><span class="co" style="color: #5E5E5E;">        jax.interpreters.xla.DeviceArray: masked dot product self attention tensor.</span></span>
<span id="cb35-9"><span class="co" style="color: #5E5E5E;">    """</span>    </span>
<span id="cb35-10">    <span class="co" style="color: #5E5E5E;"># Mask size should be equal to L_q. Q has shape (batch_size, L_q, d)</span></span>
<span id="cb35-11">    mask_size <span class="op" style="color: #5E5E5E;">=</span> q.shape[<span class="dv" style="color: #AD0000;">1</span>]</span>
<span id="cb35-12"></span>
<span id="cb35-13"></span>
<span id="cb35-14">    <span class="co" style="color: #5E5E5E;"># Creates a matrix with ones below the diagonal and 0s above. It should have shape (1, mask_size, mask_size)</span></span>
<span id="cb35-15">    <span class="co" style="color: #5E5E5E;"># Notice that 1's and 0's get casted to True/False by setting dtype to jnp.bool_</span></span>
<span id="cb35-16">    mask <span class="op" style="color: #5E5E5E;">=</span> jnp.tril(jnp.ones((<span class="dv" style="color: #AD0000;">1</span>, mask_size, mask_size), dtype<span class="op" style="color: #5E5E5E;">=</span>jnp.bool_), k<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">0</span>)</span>
<span id="cb35-17">    </span>
<span id="cb35-18">    <span class="cf" style="color: #003B4F;">return</span> DotProductAttention(q, k, v, mask)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="26">
<div class="sourceCode cell-code" id="cb36" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb36-1">dot_product_self_attention(q_with_batch, k_with_batch, v_with_batch)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="26">
<pre><code>DeviceArray([[[0.        , 1.        , 0.        ],
              [0.8496746 , 0.15032543, 0.8496746 ]]], dtype=float32)</code></pre>
</div>
</div>
<p><span style="color:blue"> compute_attention_output </span>: Undoes compute_attention_heads by splitting first (vertical) dimension and stacking in the last (depth) dimension (n_batch, seqlen, n_heads <img src="https://latex.codecogs.com/png.latex?%5Ctimes"> d_head). These operations concatenate (stack/merge) the heads.</p>
<div class="cell" data-execution_count="28">
<div class="sourceCode cell-code" id="cb38" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb38-1"><span class="kw" style="color: #003B4F;">def</span> compute_attention_output_closure(n_heads, d_head):</span>
<span id="cb38-2">    <span class="co" style="color: #5E5E5E;">""" Function that simulates environment inside CausalAttention function.</span></span>
<span id="cb38-3"><span class="co" style="color: #5E5E5E;">    Args:</span></span>
<span id="cb38-4"><span class="co" style="color: #5E5E5E;">        d_head (int):  dimensionality of heads</span></span>
<span id="cb38-5"><span class="co" style="color: #5E5E5E;">        n_heads (int): number of attention heads</span></span>
<span id="cb38-6"><span class="co" style="color: #5E5E5E;">    Returns:</span></span>
<span id="cb38-7"><span class="co" style="color: #5E5E5E;">        function: compute_attention_output function</span></span>
<span id="cb38-8"><span class="co" style="color: #5E5E5E;">    """</span></span>
<span id="cb38-9">    </span>
<span id="cb38-10">    <span class="kw" style="color: #003B4F;">def</span> compute_attention_output(x):</span>
<span id="cb38-11">        <span class="co" style="color: #5E5E5E;">""" Compute the attention output.</span></span>
<span id="cb38-12"><span class="co" style="color: #5E5E5E;">        Args:</span></span>
<span id="cb38-13"><span class="co" style="color: #5E5E5E;">            x (jax.interpreters.xla.DeviceArray): tensor with shape (n_batch X n_heads, seqlen, d_head).</span></span>
<span id="cb38-14"><span class="co" style="color: #5E5E5E;">        Returns:</span></span>
<span id="cb38-15"><span class="co" style="color: #5E5E5E;">            jax.interpreters.xla.DeviceArray: reshaped tensor with shape (n_batch, seqlen, n_heads X d_head).</span></span>
<span id="cb38-16"><span class="co" style="color: #5E5E5E;">        """</span>        </span>
<span id="cb38-17">        <span class="co" style="color: #5E5E5E;"># Length of the sequence</span></span>
<span id="cb38-18">        <span class="co" style="color: #5E5E5E;"># Should be size of x's first dimension without counting the batch dim</span></span>
<span id="cb38-19">        seqlen <span class="op" style="color: #5E5E5E;">=</span> x.shape[<span class="dv" style="color: #AD0000;">1</span>]</span>
<span id="cb38-20">        <span class="co" style="color: #5E5E5E;"># Reshape x using jnp.reshape() to shape (n_batch, n_heads, seqlen, d_head)</span></span>
<span id="cb38-21">        x <span class="op" style="color: #5E5E5E;">=</span> jnp.reshape(x, (<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>, n_heads, seqlen, d_head))</span>
<span id="cb38-22">        <span class="co" style="color: #5E5E5E;"># Transpose x using jnp.transpose() to shape (n_batch, seqlen, n_heads, d_head)</span></span>
<span id="cb38-23">        x <span class="op" style="color: #5E5E5E;">=</span> jnp.transpose(x, (<span class="dv" style="color: #AD0000;">0</span>,<span class="dv" style="color: #AD0000;">2</span>,<span class="dv" style="color: #AD0000;">1</span>,<span class="dv" style="color: #AD0000;">3</span>))</span>
<span id="cb38-24">        </span>
<span id="cb38-25">        <span class="co" style="color: #5E5E5E;"># Reshape to allow to concatenate the heads</span></span>
<span id="cb38-26">        <span class="cf" style="color: #003B4F;">return</span> jnp.reshape(x, (<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>, seqlen, n_heads <span class="op" style="color: #5E5E5E;">*</span> d_head))</span>
<span id="cb38-27">    <span class="cf" style="color: #003B4F;">return</span> compute_attention_output</span></code></pre></div>
</div>
<div class="cell" data-execution_count="29">
<div class="sourceCode cell-code" id="cb39" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1">display_tensor(result_cah, <span class="st" style="color: #20794D;">"input tensor"</span>)</span>
<span id="cb39-2">result_cao <span class="op" style="color: #5E5E5E;">=</span> compute_attention_output_closure(<span class="dv" style="color: #AD0000;">2</span>,<span class="dv" style="color: #AD0000;">3</span>)(result_cah)</span>
<span id="cb39-3">display_tensor(result_cao, <span class="st" style="color: #20794D;">"output tensor"</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>input tensor shape: (6, 2, 3)

[[[1 0 0]
  [0 1 0]]

 [[1 0 0]
  [0 1 0]]

 [[1 0 0]
  [0 1 0]]

 [[1 0 0]
  [0 1 0]]

 [[1 0 0]
  [0 1 0]]

 [[1 0 0]
  [0 1 0]]]

output tensor shape: (3, 2, 6)

[[[1 0 0 1 0 0]
  [0 1 0 0 1 0]]

 [[1 0 0 1 0 0]
  [0 1 0 0 1 0]]

 [[1 0 0 1 0 0]
  [0 1 0 0 1 0]]]
</code></pre>
</div>
</div>
</section>
<section id="causal-attention-function" class="level3" data-number="4.4">
<h3 data-number="4.4" class="anchored" data-anchor-id="causal-attention-function"><span class="header-section-number">4.4</span> Causal Attention Function</h3>
<p>Now it is time for us to put everything together within the <code>CausalAttention</code> or Masked multi-head attention function:</p>
<p><img src="http://livingdatalab.com/posts/https:/github.com/pranath/blog/raw/master/images/masked-attention.png"></p>
<p>We will implement causal attention. Our model returns the causal attention through a <img src="https://latex.codecogs.com/png.latex?tl.Serial"> with the following:</p>
<ul>
<li><span style="color:blue"> <a href="https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.combinators.Branch">tl.Branch</a> </span>: consisting of 3 [tl.Dense(d_feature), ComputeAttentionHeads] to account for the queries, keys, and values.</li>
<li><span style="color:blue"> <a href="https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.base.Fn">tl.Fn</a></span>: Takes in dot_product_self_attention function and uses it to compute the dot product using <img src="https://latex.codecogs.com/png.latex?Q">, <img src="https://latex.codecogs.com/png.latex?K">, <img src="https://latex.codecogs.com/png.latex?V">.</li>
<li><span style="color:blue"> <a href="https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.base.Fn">tl.Fn</a></span>: Takes in compute_attention_output_closure to allow for parallel computing.</li>
<li><span style="color:blue"> <a href="https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.core.Dense">tl.Dense</a></span>: Final Dense layer, with dimension <code>d_feature</code>.</li>
</ul>
<p>In order for trax to properly handle the functions we just defined, they need to be added as layers using the <a href="https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.base.Fn"><code>tl.Fn()</code></a> function.</p>
<div class="cell" data-execution_count="31">
<div class="sourceCode cell-code" id="cb41" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1"><span class="kw" style="color: #003B4F;">def</span> CausalAttention(d_feature, </span>
<span id="cb41-2">                    n_heads, </span>
<span id="cb41-3">                    compute_attention_heads_closure<span class="op" style="color: #5E5E5E;">=</span>compute_attention_heads_closure,</span>
<span id="cb41-4">                    dot_product_self_attention<span class="op" style="color: #5E5E5E;">=</span>dot_product_self_attention,</span>
<span id="cb41-5">                    compute_attention_output_closure<span class="op" style="color: #5E5E5E;">=</span>compute_attention_output_closure,</span>
<span id="cb41-6">                    mode<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'train'</span>):</span>
<span id="cb41-7">    <span class="co" style="color: #5E5E5E;">"""Transformer-style multi-headed causal attention.</span></span>
<span id="cb41-8"></span>
<span id="cb41-9"><span class="co" style="color: #5E5E5E;">    Args:</span></span>
<span id="cb41-10"><span class="co" style="color: #5E5E5E;">        d_feature (int):  dimensionality of feature embedding.</span></span>
<span id="cb41-11"><span class="co" style="color: #5E5E5E;">        n_heads (int): number of attention heads.</span></span>
<span id="cb41-12"><span class="co" style="color: #5E5E5E;">        compute_attention_heads_closure (function): Closure around compute_attention heads.</span></span>
<span id="cb41-13"><span class="co" style="color: #5E5E5E;">        dot_product_self_attention (function): dot_product_self_attention function. </span></span>
<span id="cb41-14"><span class="co" style="color: #5E5E5E;">        compute_attention_output_closure (function): Closure around compute_attention_output. </span></span>
<span id="cb41-15"><span class="co" style="color: #5E5E5E;">        mode (str): 'train' or 'eval'.</span></span>
<span id="cb41-16"></span>
<span id="cb41-17"><span class="co" style="color: #5E5E5E;">    Returns:</span></span>
<span id="cb41-18"><span class="co" style="color: #5E5E5E;">        trax.layers.combinators.Serial: Multi-headed self-attention model.</span></span>
<span id="cb41-19"><span class="co" style="color: #5E5E5E;">    """</span></span>
<span id="cb41-20">    </span>
<span id="cb41-21">    <span class="cf" style="color: #003B4F;">assert</span> d_feature <span class="op" style="color: #5E5E5E;">%</span> n_heads <span class="op" style="color: #5E5E5E;">==</span> <span class="dv" style="color: #AD0000;">0</span></span>
<span id="cb41-22">    d_head <span class="op" style="color: #5E5E5E;">=</span> d_feature <span class="op" style="color: #5E5E5E;">//</span> n_heads</span>
<span id="cb41-23">    </span>
<span id="cb41-24">    <span class="co" style="color: #5E5E5E;"># The second argument to tl.Fn() is an uncalled function (without the parentheses)</span></span>
<span id="cb41-25">    <span class="co" style="color: #5E5E5E;"># Since we are dealing with closures we might need to call the outer </span></span>
<span id="cb41-26">    <span class="co" style="color: #5E5E5E;"># function with the correct parameters to get the actual uncalled function.</span></span>
<span id="cb41-27">    ComputeAttentionHeads <span class="op" style="color: #5E5E5E;">=</span> tl.Fn(<span class="st" style="color: #20794D;">'AttnHeads'</span>, compute_attention_heads_closure(n_heads, d_head), n_out<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">1</span>)</span>
<span id="cb41-28">        </span>
<span id="cb41-29"></span>
<span id="cb41-30">    <span class="cf" style="color: #003B4F;">return</span> tl.Serial(</span>
<span id="cb41-31">        tl.Branch( <span class="co" style="color: #5E5E5E;"># creates three towers for one input, takes activations and creates queries keys and values</span></span>
<span id="cb41-32">            [tl.Dense(d_feature), ComputeAttentionHeads], <span class="co" style="color: #5E5E5E;"># queries</span></span>
<span id="cb41-33">            [tl.Dense(d_feature), ComputeAttentionHeads], <span class="co" style="color: #5E5E5E;"># keys</span></span>
<span id="cb41-34">            [tl.Dense(d_feature), ComputeAttentionHeads], <span class="co" style="color: #5E5E5E;"># values</span></span>
<span id="cb41-35">        ),</span>
<span id="cb41-36">        </span>
<span id="cb41-37">        tl.Fn(<span class="st" style="color: #20794D;">'DotProductAttn'</span>, dot_product_self_attention, n_out<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">1</span>), <span class="co" style="color: #5E5E5E;"># takes QKV</span></span>
<span id="cb41-38">        <span class="co" style="color: #5E5E5E;"># The second argument to tl.Fn() is an uncalled function</span></span>
<span id="cb41-39">        <span class="co" style="color: #5E5E5E;"># Since we are dealing with closures we might need to call the outer </span></span>
<span id="cb41-40">        <span class="co" style="color: #5E5E5E;"># function with the correct parameters to get the actual uncalled function.</span></span>
<span id="cb41-41">        tl.Fn(<span class="st" style="color: #20794D;">'AttnOutput'</span>, compute_attention_output_closure(n_heads, d_head), n_out<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">1</span>), <span class="co" style="color: #5E5E5E;"># to allow for parallel</span></span>
<span id="cb41-42">        tl.Dense(d_feature) <span class="co" style="color: #5E5E5E;"># Final dense layer</span></span>
<span id="cb41-43">    )</span></code></pre></div>
</div>
<div class="cell" data-execution_count="32">
<div class="sourceCode cell-code" id="cb42" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb42-1"><span class="co" style="color: #5E5E5E;"># Take a look at the causal attention model</span></span>
<span id="cb42-2"><span class="bu" style="color: null;">print</span>(CausalAttention(d_feature<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">512</span>, n_heads<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">8</span>))</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Serial[
  Branch_out3[
    [Dense_512, AttnHeads]
    [Dense_512, AttnHeads]
    [Dense_512, AttnHeads]
  ]
  DotProductAttn_in3
  AttnOutput
  Dense_512
]</code></pre>
</div>
</div>
</section>
<section id="transformer-decoder-block" class="level3" data-number="4.5">
<h3 data-number="4.5" class="anchored" data-anchor-id="transformer-decoder-block"><span class="header-section-number">4.5</span> Transformer decoder block</h3>
<p>Now that we have implemented the causal part of the transformer, we will implement the transformer decoder block. Concretely we will be implementing this image now.</p>
<p><img src="http://livingdatalab.com/posts/https:/github.com/pranath/blog/raw/master/images/transformer_decoder_1.png" style="height:300px"></p>
<p>To implement this function, we will have to call the <code>CausalAttention</code> or Masked multi-head attention function we implemented above. We will have to add a feedforward which consists of:</p>
<ul>
<li><span style="color:blue"> <a href="https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.normalization.LayerNorm">tl.LayerNorm</a> </span>: used to layer normalize</li>
<li><span style="color:blue"> <a href="https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.core.Dense">tl.Dense</a> </span>: the dense layer</li>
<li><span style="color:blue"> <a href="https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.activation_fns.Relu">ff_activation</a> </span>: feed forward activation (we use ReLu) here.</li>
<li><span style="color:blue"> <a href="https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.core.Dropout">tl.Dropout</a> </span>: dropout layer</li>
<li><span style="color:blue"> <a href="https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.core.Dense">tl.Dense</a> </span>: dense layer</li>
<li><span style="color:blue"> <a href="https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.core.Dropout">tl.Dropout</a> </span>: dropout layer</li>
</ul>
<p>Finally once we implement the feedforward, we can go ahead and implement the entire block using:</p>
<ul>
<li><p><span style="color:blue"> <a href="https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.combinators.Residual">tl.Residual</a> </span>: takes in the tl.LayerNorm(), causal attention block, tl.dropout.</p></li>
<li><p><span style="color:blue"> <a href="https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.combinators.Residual">tl.Residual</a> </span>: takes in the feedforward block you will implement.</p></li>
</ul>
<div class="cell" data-execution_count="34">
<div class="sourceCode cell-code" id="cb44" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb44-1"><span class="kw" style="color: #003B4F;">def</span> DecoderBlock(d_model, d_ff, n_heads,</span>
<span id="cb44-2">                 dropout, mode, ff_activation):</span>
<span id="cb44-3">    <span class="co" style="color: #5E5E5E;">"""Returns a list of layers that implements a Transformer decoder block.</span></span>
<span id="cb44-4"></span>
<span id="cb44-5"><span class="co" style="color: #5E5E5E;">    The input is an activation tensor.</span></span>
<span id="cb44-6"></span>
<span id="cb44-7"><span class="co" style="color: #5E5E5E;">    Args:</span></span>
<span id="cb44-8"><span class="co" style="color: #5E5E5E;">        d_model (int):  depth of embedding.</span></span>
<span id="cb44-9"><span class="co" style="color: #5E5E5E;">        d_ff (int): depth of feed-forward layer.</span></span>
<span id="cb44-10"><span class="co" style="color: #5E5E5E;">        n_heads (int): number of attention heads.</span></span>
<span id="cb44-11"><span class="co" style="color: #5E5E5E;">        dropout (float): dropout rate (how much to drop out).</span></span>
<span id="cb44-12"><span class="co" style="color: #5E5E5E;">        mode (str): 'train' or 'eval'.</span></span>
<span id="cb44-13"><span class="co" style="color: #5E5E5E;">        ff_activation (function): the non-linearity in feed-forward layer.</span></span>
<span id="cb44-14"></span>
<span id="cb44-15"><span class="co" style="color: #5E5E5E;">    Returns:</span></span>
<span id="cb44-16"><span class="co" style="color: #5E5E5E;">        list: list of trax.layers.combinators.Serial that maps an activation tensor to an activation tensor.</span></span>
<span id="cb44-17"><span class="co" style="color: #5E5E5E;">    """</span></span>
<span id="cb44-18">        </span>
<span id="cb44-19">    <span class="co" style="color: #5E5E5E;"># Create masked multi-head attention block using CausalAttention function</span></span>
<span id="cb44-20">    causal_attention <span class="op" style="color: #5E5E5E;">=</span> CausalAttention( </span>
<span id="cb44-21">                        d_feature<span class="op" style="color: #5E5E5E;">=</span>d_model,</span>
<span id="cb44-22">                        n_heads<span class="op" style="color: #5E5E5E;">=</span>n_heads,</span>
<span id="cb44-23">                        mode<span class="op" style="color: #5E5E5E;">=</span>mode</span>
<span id="cb44-24">                        )</span>
<span id="cb44-25"></span>
<span id="cb44-26">    <span class="co" style="color: #5E5E5E;"># Create feed-forward block (list) with two dense layers with dropout and input normalized</span></span>
<span id="cb44-27">    feed_forward <span class="op" style="color: #5E5E5E;">=</span> [ </span>
<span id="cb44-28">        <span class="co" style="color: #5E5E5E;"># Normalize layer inputs</span></span>
<span id="cb44-29">        tl.LayerNorm(),</span>
<span id="cb44-30">        <span class="co" style="color: #5E5E5E;"># Add first feed forward (dense) layer (don't forget to set the correct value for n_units)</span></span>
<span id="cb44-31">        tl.Dense(d_ff),</span>
<span id="cb44-32">        <span class="co" style="color: #5E5E5E;"># Add activation function passed in as a parameter (you need to call it!)</span></span>
<span id="cb44-33">        ff_activation(), <span class="co" style="color: #5E5E5E;"># Generally ReLU</span></span>
<span id="cb44-34">        <span class="co" style="color: #5E5E5E;"># Add dropout with rate and mode specified (i.e., don't use dropout during evaluation)</span></span>
<span id="cb44-35">        tl.Dropout(rate<span class="op" style="color: #5E5E5E;">=</span>dropout, mode<span class="op" style="color: #5E5E5E;">=</span>mode),</span>
<span id="cb44-36">        <span class="co" style="color: #5E5E5E;"># Add second feed forward layer (don't forget to set the correct value for n_units)</span></span>
<span id="cb44-37">        tl.Dense(d_model),</span>
<span id="cb44-38">        <span class="co" style="color: #5E5E5E;"># Add dropout with rate and mode specified (i.e., don't use dropout during evaluation)</span></span>
<span id="cb44-39">        tl.Dropout(rate<span class="op" style="color: #5E5E5E;">=</span>dropout, mode<span class="op" style="color: #5E5E5E;">=</span>mode)</span>
<span id="cb44-40">    ]</span>
<span id="cb44-41"></span>
<span id="cb44-42">    <span class="co" style="color: #5E5E5E;"># Add list of two Residual blocks: the attention with normalization and dropout and feed-forward blocks</span></span>
<span id="cb44-43">    <span class="cf" style="color: #003B4F;">return</span> [</span>
<span id="cb44-44">      tl.Residual(</span>
<span id="cb44-45">          <span class="co" style="color: #5E5E5E;"># Normalize layer input</span></span>
<span id="cb44-46">          tl.LayerNorm(),</span>
<span id="cb44-47">          <span class="co" style="color: #5E5E5E;"># Add causal attention block previously defined (without parentheses)</span></span>
<span id="cb44-48">          causal_attention,</span>
<span id="cb44-49">          <span class="co" style="color: #5E5E5E;"># Add dropout with rate and mode specified</span></span>
<span id="cb44-50">          tl.Dropout(rate<span class="op" style="color: #5E5E5E;">=</span>dropout, mode<span class="op" style="color: #5E5E5E;">=</span>mode)</span>
<span id="cb44-51">        ),</span>
<span id="cb44-52">      tl.Residual(</span>
<span id="cb44-53">          <span class="co" style="color: #5E5E5E;"># Add feed forward block (without parentheses)</span></span>
<span id="cb44-54">          feed_forward</span>
<span id="cb44-55">        ),</span>
<span id="cb44-56">      ]</span></code></pre></div>
</div>
<div class="cell" data-execution_count="35">
<div class="sourceCode cell-code" id="cb45" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb45-1"><span class="co" style="color: #5E5E5E;"># Take a look at the decoder block</span></span>
<span id="cb45-2"><span class="bu" style="color: null;">print</span>(DecoderBlock(d_model<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">512</span>, d_ff<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">2048</span>, n_heads<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">8</span>, dropout<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">0.1</span>, mode<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'train'</span>, ff_activation<span class="op" style="color: #5E5E5E;">=</span>tl.Relu))</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[Serial[
  Branch_out2[
    None
    Serial[
      LayerNorm
      Serial[
        Branch_out3[
          [Dense_512, AttnHeads]
          [Dense_512, AttnHeads]
          [Dense_512, AttnHeads]
        ]
        DotProductAttn_in3
        AttnOutput
        Dense_512
      ]
      Dropout
    ]
  ]
  Add_in2
], Serial[
  Branch_out2[
    None
    Serial[
      LayerNorm
      Dense_2048
      Serial[
        Relu
      ]
      Dropout
      Dense_512
      Dropout
    ]
  ]
  Add_in2
]]</code></pre>
</div>
</div>
</section>
<section id="transformer-language-model" class="level3" data-number="4.6">
<h3 data-number="4.6" class="anchored" data-anchor-id="transformer-language-model"><span class="header-section-number">4.6</span> Transformer Language Model</h3>
<p>We will now bring it all together. In this part we will use all the subcomponents you previously built to make the final model. Concretely, here is the image we will be implementing. <img src="http://livingdatalab.com/posts/images/transformer_decoder.png" style="height:400px"></p>
<p>Previously we coded the decoder block. Now we will code the transformer language model. Here is what we will need.</p>
<ul>
<li><span style="color:blue"> positional_enconder </span>- a list containing the following layers:
<ul>
<li><span style="color:blue"> <a href="https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.core.Embedding">tl.Embedding</a></span></li>
<li><span style="color:blue"> <a href="https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.core.Dropout">tl.Dropout</a></span></li>
<li><span style="color:blue"> <a href="https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.attention.PositionalEncoding">tl.PositionalEncoding</a></span></li>
</ul></li>
<li>A list of <code>n_layers</code> <span style="color:blue"> decoder blocks</span>.</li>
<li><span style="color:blue"> <a href="https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.combinators.Serial">tl.Serial</a>: </span> takes in the following layers or lists of layers:
<ul>
<li><span style="color:blue"> <a href="https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.attention.ShiftRight">tl.ShiftRight</a>: </span>: shift the tensor to the right by padding on axis 1.</li>
<li><span style="color:blue"> positional_encoder </span>: encodes the text positions.</li>
<li><span style="color:blue"> decoder_blocks </span>: the ones you created.</li>
<li><span style="color:blue"> <a href="https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.normalization.LayerNorm">tl.LayerNorm</a> </span>: a layer norm.</li>
<li><span style="color:blue"> <a href="https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.core.Dense">tl.Dense</a> </span>: takes in the vocab_size.</li>
<li><span style="color:blue"> <a href="https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.core.LogSoftmax">tl.LogSoftmax</a> </span>: to predict.</li>
</ul></li>
</ul>
<div class="cell" data-execution_count="37">
<div class="sourceCode cell-code" id="cb47" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb47-1"><span class="kw" style="color: #003B4F;">def</span> TransformerLM(vocab_size<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">33300</span>,</span>
<span id="cb47-2">                  d_model<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">512</span>,</span>
<span id="cb47-3">                  d_ff<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">2048</span>,</span>
<span id="cb47-4">                  n_layers<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">6</span>,</span>
<span id="cb47-5">                  n_heads<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">8</span>,</span>
<span id="cb47-6">                  dropout<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">0.1</span>,</span>
<span id="cb47-7">                  max_len<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">4096</span>,</span>
<span id="cb47-8">                  mode<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'train'</span>,</span>
<span id="cb47-9">                  ff_activation<span class="op" style="color: #5E5E5E;">=</span>tl.Relu):</span>
<span id="cb47-10">    <span class="co" style="color: #5E5E5E;">"""Returns a Transformer language model.</span></span>
<span id="cb47-11"></span>
<span id="cb47-12"><span class="co" style="color: #5E5E5E;">    The input to the model is a tensor of tokens. (This model uses only the</span></span>
<span id="cb47-13"><span class="co" style="color: #5E5E5E;">    decoder part of the overall Transformer.)</span></span>
<span id="cb47-14"></span>
<span id="cb47-15"><span class="co" style="color: #5E5E5E;">    Args:</span></span>
<span id="cb47-16"><span class="co" style="color: #5E5E5E;">        vocab_size (int): vocab size.</span></span>
<span id="cb47-17"><span class="co" style="color: #5E5E5E;">        d_model (int):  depth of embedding.</span></span>
<span id="cb47-18"><span class="co" style="color: #5E5E5E;">        d_ff (int): depth of feed-forward layer.</span></span>
<span id="cb47-19"><span class="co" style="color: #5E5E5E;">        n_layers (int): number of decoder layers.</span></span>
<span id="cb47-20"><span class="co" style="color: #5E5E5E;">        n_heads (int): number of attention heads.</span></span>
<span id="cb47-21"><span class="co" style="color: #5E5E5E;">        dropout (float): dropout rate (how much to drop out).</span></span>
<span id="cb47-22"><span class="co" style="color: #5E5E5E;">        max_len (int): maximum symbol length for positional encoding.</span></span>
<span id="cb47-23"><span class="co" style="color: #5E5E5E;">        mode (str): 'train', 'eval' or 'predict', predict mode is for fast inference.</span></span>
<span id="cb47-24"><span class="co" style="color: #5E5E5E;">        ff_activation (function): the non-linearity in feed-forward layer.</span></span>
<span id="cb47-25"></span>
<span id="cb47-26"><span class="co" style="color: #5E5E5E;">    Returns:</span></span>
<span id="cb47-27"><span class="co" style="color: #5E5E5E;">        trax.layers.combinators.Serial: A Transformer language model as a layer that maps from a tensor of tokens</span></span>
<span id="cb47-28"><span class="co" style="color: #5E5E5E;">        to activations over a vocab set.</span></span>
<span id="cb47-29"><span class="co" style="color: #5E5E5E;">    """</span></span>
<span id="cb47-30">        </span>
<span id="cb47-31">    <span class="co" style="color: #5E5E5E;"># Embedding inputs and positional encoder</span></span>
<span id="cb47-32">    positional_encoder <span class="op" style="color: #5E5E5E;">=</span> [ </span>
<span id="cb47-33">        <span class="co" style="color: #5E5E5E;"># Add embedding layer of dimension (vocab_size, d_model)</span></span>
<span id="cb47-34">        tl.Embedding(vocab_size<span class="op" style="color: #5E5E5E;">=</span>vocab_size, d_feature<span class="op" style="color: #5E5E5E;">=</span>d_model),</span>
<span id="cb47-35">        <span class="co" style="color: #5E5E5E;"># Use dropout with rate and mode specified</span></span>
<span id="cb47-36">        tl.Dropout(rate<span class="op" style="color: #5E5E5E;">=</span>dropout, mode<span class="op" style="color: #5E5E5E;">=</span>mode),</span>
<span id="cb47-37">        <span class="co" style="color: #5E5E5E;"># Add positional encoding layer with maximum input length and mode specified</span></span>
<span id="cb47-38">        tl.PositionalEncoding(max_len<span class="op" style="color: #5E5E5E;">=</span>max_len, mode<span class="op" style="color: #5E5E5E;">=</span>mode)]</span>
<span id="cb47-39"></span>
<span id="cb47-40">    <span class="co" style="color: #5E5E5E;"># Create stack (list) of decoder blocks with n_layers with necessary parameters</span></span>
<span id="cb47-41">    decoder_blocks <span class="op" style="color: #5E5E5E;">=</span> [ </span>
<span id="cb47-42">        DecoderBlock(d_model, d_ff, n_heads, dropout, mode, ff_activation) <span class="cf" style="color: #003B4F;">for</span> _ <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">range</span>(n_layers)]</span>
<span id="cb47-43"></span>
<span id="cb47-44">    <span class="co" style="color: #5E5E5E;"># Create the complete model as written in the figure</span></span>
<span id="cb47-45">    <span class="cf" style="color: #003B4F;">return</span> tl.Serial(</span>
<span id="cb47-46">        <span class="co" style="color: #5E5E5E;"># Use teacher forcing (feed output of previous step to current step)</span></span>
<span id="cb47-47">        tl.ShiftRight(mode<span class="op" style="color: #5E5E5E;">=</span>mode), <span class="co" style="color: #5E5E5E;"># Specify the mode!</span></span>
<span id="cb47-48">        <span class="co" style="color: #5E5E5E;"># Add positional encoder</span></span>
<span id="cb47-49">        positional_encoder,</span>
<span id="cb47-50">        <span class="co" style="color: #5E5E5E;"># Add decoder blocks</span></span>
<span id="cb47-51">        decoder_blocks,</span>
<span id="cb47-52">        <span class="co" style="color: #5E5E5E;"># Normalize layer</span></span>
<span id="cb47-53">        tl.LayerNorm(),</span>
<span id="cb47-54"></span>
<span id="cb47-55">        <span class="co" style="color: #5E5E5E;"># Add dense layer of vocab_size (since need to select a word to translate to)</span></span>
<span id="cb47-56">        <span class="co" style="color: #5E5E5E;"># (a.k.a., logits layer. Note: activation already set by ff_activation)</span></span>
<span id="cb47-57">        tl.Dense(vocab_size),</span>
<span id="cb47-58">        <span class="co" style="color: #5E5E5E;"># Get probabilities with Logsoftmax</span></span>
<span id="cb47-59">        tl.LogSoftmax()</span>
<span id="cb47-60">    )</span></code></pre></div>
</div>
<div class="cell" data-execution_count="38">
<div class="sourceCode cell-code" id="cb48" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb48-1"><span class="co" style="color: #5E5E5E;"># Take a look at the Transformer</span></span>
<span id="cb48-2"><span class="bu" style="color: null;">print</span>(TransformerLM(n_layers<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">1</span>))</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Serial[
  Serial[
    ShiftRight(1)
  ]
  Embedding_33300_512
  Dropout
  PositionalEncoding
  Serial[
    Branch_out2[
      None
      Serial[
        LayerNorm
        Serial[
          Branch_out3[
            [Dense_512, AttnHeads]
            [Dense_512, AttnHeads]
            [Dense_512, AttnHeads]
          ]
          DotProductAttn_in3
          AttnOutput
          Dense_512
        ]
        Dropout
      ]
    ]
    Add_in2
  ]
  Serial[
    Branch_out2[
      None
      Serial[
        LayerNorm
        Dense_2048
        Serial[
          Relu
        ]
        Dropout
        Dense_512
        Dropout
      ]
    ]
    Add_in2
  ]
  LayerNorm
  Dense_33300
  LogSoftmax
]</code></pre>
</div>
</div>
</section>
</section>
<section id="training" class="level2" data-number="5">
<h2 data-number="5" class="anchored" data-anchor-id="training"><span class="header-section-number">5</span> Training</h2>
<p>Now we are going to train our model. As usual, we have to define the cost function, the optimizer, and decide whether we will be training it on a <code>gpu</code> or <code>cpu</code>. In this case, we will train your model on a cpu for a few steps and we will load in a pre-trained model that we can use to predict with our own words.</p>
<section id="training-the-model" class="level3" data-number="5.1">
<h3 data-number="5.1" class="anchored" data-anchor-id="training-the-model"><span class="header-section-number">5.1</span> Training the model</h3>
<p>We will now write a function that takes in our model and trains it. To train our model we have to decide how many times we want to iterate over the entire data set. Each iteration is defined as an <code>epoch</code>. For each epoch, we have to go over all the data, using our training iterator.</p>
<p>Lets implement the <code>train_model</code> program below to train the neural network above. Here is a list of things we should do:</p>
<ul>
<li>Create the train task by calling <a href="https://trax-ml.readthedocs.io/en/latest/trax.supervised.html#trax.supervised.training.TrainTask"><code>trax.supervised.training.TrainTask</code></a> and pass in the following:
<ul>
<li><span style="color:blue"> labeled_data </span> = train_gen</li>
<li><span style="color:blue"> loss_layer </span> = <a href="https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.metrics.CrossEntropyLoss">tl.CrossEntropyLoss()</a></li>
<li><span style="color:blue"> optimizer </span> = <a href="https://trax-ml.readthedocs.io/en/latest/trax.optimizers.html#trax.optimizers.adam.Adam">trax.optimizers.Adam(0.01)</a></li>
<li><span style="color:blue"> lr_schedule </span> = <a href="https://trax-ml.readthedocs.io/en/latest/trax.supervised.html#trax.supervised.lr_schedules.warmup_and_rsqrt_decay">lr_schedule</a></li>
</ul></li>
<li>Create the eval task by calling <a href="https://trax-ml.readthedocs.io/en/latest/trax.supervised.html#trax.supervised.training.EvalTask"><code>trax.supervised.training.EvalTask</code></a> and pass in the following:
<ul>
<li><span style="color:blue"> labeled_data </span> = eval_gen</li>
<li><span style="color:blue"> metrics </span> = tl.CrossEntropyLoss() and <a href="https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.metrics.Accuracy">tl.Accuracy()</a></li>
</ul></li>
<li>Create the training loop by calling <a href="https://trax-ml.readthedocs.io/en/latest/trax.supervised.html#trax.supervised.training.Loop"><code>trax.supervised.Training.Loop</code></a> and pass in the following:
<ul>
<li><span style="color:blue"> TransformerLM </span></li>
<li><span style="color:blue"> train_task </span></li>
<li><span style="color:blue"> eval_task </span> = [eval_task]</li>
<li><span style="color:blue"> output_dir</span> = output_dir</li>
</ul></li>
</ul>
<p>We will be using a cross entropy loss, with Adam optimizer. Read the <a href="https://trax-ml.readthedocs.io/en/latest/index.html">Trax</a> documentation to get a full understanding.</p>
<p>The training loop that this function returns can be runned using the <code>run()</code> method by passing in the desired number of steps.</p>
<div class="cell" data-execution_count="40">
<div class="sourceCode cell-code" id="cb50" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb50-1"><span class="im" style="color: #00769E;">from</span> trax.supervised <span class="im" style="color: #00769E;">import</span> training</span>
<span id="cb50-2"></span>
<span id="cb50-3"><span class="kw" style="color: #003B4F;">def</span> training_loop(TransformerLM, train_gen, eval_gen, output_dir <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">"~/model"</span>):</span>
<span id="cb50-4">    <span class="co" style="color: #5E5E5E;">'''</span></span>
<span id="cb50-5"><span class="co" style="color: #5E5E5E;">    Input:</span></span>
<span id="cb50-6"><span class="co" style="color: #5E5E5E;">        TransformerLM (trax.layers.combinators.Serial): The model you are building.</span></span>
<span id="cb50-7"><span class="co" style="color: #5E5E5E;">        train_gen (generator): Training stream of data.</span></span>
<span id="cb50-8"><span class="co" style="color: #5E5E5E;">        eval_gen (generator): Evaluation stream of data.</span></span>
<span id="cb50-9"><span class="co" style="color: #5E5E5E;">        output_dir (str): folder to save your file.</span></span>
<span id="cb50-10"><span class="co" style="color: #5E5E5E;">        </span></span>
<span id="cb50-11"><span class="co" style="color: #5E5E5E;">    Returns:</span></span>
<span id="cb50-12"><span class="co" style="color: #5E5E5E;">        trax.supervised.training.Loop: Training loop.</span></span>
<span id="cb50-13"><span class="co" style="color: #5E5E5E;">    '''</span></span>
<span id="cb50-14">    output_dir <span class="op" style="color: #5E5E5E;">=</span> os.path.expanduser(output_dir)  <span class="co" style="color: #5E5E5E;"># trainer is an object</span></span>
<span id="cb50-15">    lr_schedule <span class="op" style="color: #5E5E5E;">=</span> trax.lr.warmup_and_rsqrt_decay(n_warmup_steps<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">1000</span>, max_value<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">0.01</span>)</span>
<span id="cb50-16"></span>
<span id="cb50-17">    train_task <span class="op" style="color: #5E5E5E;">=</span> training.TrainTask( </span>
<span id="cb50-18">      labeled_data<span class="op" style="color: #5E5E5E;">=</span>train_gen, <span class="co" style="color: #5E5E5E;"># The training generator</span></span>
<span id="cb50-19">      loss_layer<span class="op" style="color: #5E5E5E;">=</span>tl.CrossEntropyLoss(), <span class="co" style="color: #5E5E5E;"># Loss function </span></span>
<span id="cb50-20">      optimizer<span class="op" style="color: #5E5E5E;">=</span>trax.optimizers.Adam(<span class="fl" style="color: #AD0000;">0.01</span>), <span class="co" style="color: #5E5E5E;"># Optimizer (Don't forget to set LR to 0.01)</span></span>
<span id="cb50-21">      lr_schedule<span class="op" style="color: #5E5E5E;">=</span>lr_schedule,</span>
<span id="cb50-22">      n_steps_per_checkpoint<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">10</span></span>
<span id="cb50-23">    )</span>
<span id="cb50-24"></span>
<span id="cb50-25">    eval_task <span class="op" style="color: #5E5E5E;">=</span> training.EvalTask( </span>
<span id="cb50-26">      labeled_data<span class="op" style="color: #5E5E5E;">=</span>eval_gen, <span class="co" style="color: #5E5E5E;"># The evaluation generator</span></span>
<span id="cb50-27">      metrics<span class="op" style="color: #5E5E5E;">=</span>[tl.CrossEntropyLoss(), tl.Accuracy()] <span class="co" style="color: #5E5E5E;"># CrossEntropyLoss and Accuracy</span></span>
<span id="cb50-28">    )</span>
<span id="cb50-29"></span>
<span id="cb50-30">    loop <span class="op" style="color: #5E5E5E;">=</span> training.Loop(TransformerLM(d_model<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">4</span>,</span>
<span id="cb50-31">                                       d_ff<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">16</span>,</span>
<span id="cb50-32">                                       n_layers<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">1</span>,</span>
<span id="cb50-33">                                       n_heads<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">2</span>,</span>
<span id="cb50-34">                                       mode<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'train'</span>),</span>
<span id="cb50-35">                         train_task,</span>
<span id="cb50-36">                         eval_tasks<span class="op" style="color: #5E5E5E;">=</span>[eval_task],</span>
<span id="cb50-37">                         output_dir<span class="op" style="color: #5E5E5E;">=</span>output_dir)</span>
<span id="cb50-38">    </span>
<span id="cb50-39">    <span class="cf" style="color: #003B4F;">return</span> loop</span></code></pre></div>
</div>
<p>Notice that the model will be trained for only 10 steps.</p>
<p>Even with this constraint the model with the original default arguments took a very long time to finish. Because of this some parameters are changed when defining the model that is fed into the training loop in the function above.</p>
<div class="cell" data-outputid="aff859e5-8f4a-4d3b-f1d3-98e137581a77" data-execution_count="42">
<div class="sourceCode cell-code" id="cb51" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb51-1"><span class="co" style="color: #5E5E5E;"># Should take around 1.5 minutes</span></span>
<span id="cb51-2"><span class="op" style="color: #5E5E5E;">!</span>rm <span class="op" style="color: #5E5E5E;">-</span>f <span class="op" style="color: #5E5E5E;">~/</span>model<span class="op" style="color: #5E5E5E;">/</span>model.pkl.gz</span>
<span id="cb51-3">loop <span class="op" style="color: #5E5E5E;">=</span> training_loop(TransformerLM, train_batch_stream, eval_batch_stream)</span>
<span id="cb51-4">loop.run(<span class="dv" style="color: #AD0000;">10</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Step      1: Total number of trainable weights: 316336
Step      1: Ran 1 train steps in 8.90 secs
Step      1: train CrossEntropyLoss |  10.41016102
Step      1: eval  CrossEntropyLoss |  10.41146946
Step      1: eval          Accuracy |  0.00000000

Step     10: Ran 9 train steps in 52.26 secs
Step     10: train CrossEntropyLoss |  10.41224766
Step     10: eval  CrossEntropyLoss |  10.40876579
Step     10: eval          Accuracy |  0.00000000</code></pre>
</div>
</div>
</section>
</section>
<section id="loading-in-a-pre-trained-model" class="level2" data-number="6">
<h2 data-number="6" class="anchored" data-anchor-id="loading-in-a-pre-trained-model"><span class="header-section-number">6</span> Loading in a Pre-trained model</h2>
<p>In this part we will evaluate by loading in an almost exact version of the model we coded, but this has been trained previously to save time.</p>
<div class="cell" data-execution_count="43">
<div class="sourceCode cell-code" id="cb53" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb53-1"><span class="co" style="color: #5E5E5E;"># THIS STEP COULD TAKE BETWEEN 15 SECONDS TO 15 MINUTES</span></span>
<span id="cb53-2"><span class="co" style="color: #5E5E5E;"># Get the model architecture</span></span>
<span id="cb53-3">model <span class="op" style="color: #5E5E5E;">=</span> TransformerLM(mode<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'eval'</span>)</span>
<span id="cb53-4"></span>
<span id="cb53-5"><span class="co" style="color: #5E5E5E;"># Load the pre-trained weights</span></span>
<span id="cb53-6">model.init_from_file(<span class="st" style="color: #20794D;">'model.pkl.gz'</span>, weights_only<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>)</span></code></pre></div>
</div>
</section>
<section id="testing-with-our-own-input" class="level2" data-number="7">
<h2 data-number="7" class="anchored" data-anchor-id="testing-with-our-own-input"><span class="header-section-number">7</span> Testing with our own input</h2>
<p>We will now test our input. We are going to implement greedy decoding. This consists of two functions. The first one allows us to identify the next symbol. It gets the argmax of the output of our model and then returns that index.</p>
<p>We will now implement the next symbol function that takes in the cur_output_tokens and the trained model to return the the index of the next word.</p>
<div class="cell" data-execution_count="44">
<div class="sourceCode cell-code" id="cb54" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb54-1"><span class="kw" style="color: #003B4F;">def</span> next_symbol(cur_output_tokens, model):</span>
<span id="cb54-2">    <span class="co" style="color: #5E5E5E;">"""Returns the next symbol for a given sentence.</span></span>
<span id="cb54-3"></span>
<span id="cb54-4"><span class="co" style="color: #5E5E5E;">    Args:</span></span>
<span id="cb54-5"><span class="co" style="color: #5E5E5E;">        cur_output_tokens (list): tokenized sentence with EOS and PAD tokens at the end.</span></span>
<span id="cb54-6"><span class="co" style="color: #5E5E5E;">        model (trax.layers.combinators.Serial): The transformer model.</span></span>
<span id="cb54-7"></span>
<span id="cb54-8"><span class="co" style="color: #5E5E5E;">    Returns:</span></span>
<span id="cb54-9"><span class="co" style="color: #5E5E5E;">        int: tokenized symbol.</span></span>
<span id="cb54-10"><span class="co" style="color: #5E5E5E;">    """</span></span>
<span id="cb54-11">    </span>
<span id="cb54-12">    <span class="co" style="color: #5E5E5E;"># current output tokens length</span></span>
<span id="cb54-13">    token_length <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">len</span>(cur_output_tokens)</span>
<span id="cb54-14">    <span class="co" style="color: #5E5E5E;"># calculate the minimum power of 2 big enough to store token_length</span></span>
<span id="cb54-15">    <span class="co" style="color: #5E5E5E;"># add 1 to token_length so np.log2() doesn't receive 0 when token_length is 0</span></span>
<span id="cb54-16">    padded_length <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">2</span><span class="op" style="color: #5E5E5E;">**</span><span class="bu" style="color: null;">int</span>(np.ceil(np.log2(token_length <span class="op" style="color: #5E5E5E;">+</span> <span class="dv" style="color: #AD0000;">1</span>)))</span>
<span id="cb54-17"></span>
<span id="cb54-18">    <span class="co" style="color: #5E5E5E;"># Fill cur_output_tokens with 0's until it reaches padded_length</span></span>
<span id="cb54-19">    padded <span class="op" style="color: #5E5E5E;">=</span> cur_output_tokens <span class="op" style="color: #5E5E5E;">+</span> [<span class="dv" style="color: #AD0000;">0</span>] <span class="op" style="color: #5E5E5E;">*</span> (padded_length <span class="op" style="color: #5E5E5E;">-</span> token_length)</span>
<span id="cb54-20">    padded_with_batch <span class="op" style="color: #5E5E5E;">=</span> np.array(padded)[<span class="va" style="color: #111111;">None</span>, :] <span class="co" style="color: #5E5E5E;"># Don't replace this 'None'! This is a way of setting the batch dim</span></span>
<span id="cb54-21"></span>
<span id="cb54-22">    <span class="co" style="color: #5E5E5E;"># model expects a tuple containing two padded tensors (with batch)</span></span>
<span id="cb54-23">    output, _ <span class="op" style="color: #5E5E5E;">=</span> model((padded_with_batch, padded_with_batch)) </span>
<span id="cb54-24">    <span class="co" style="color: #5E5E5E;"># To get log_probs you need to index output with 0 in the first dim</span></span>
<span id="cb54-25">    <span class="co" style="color: #5E5E5E;"># token_length in the second dim and all of the entries for the last dim.</span></span>
<span id="cb54-26">    log_probs <span class="op" style="color: #5E5E5E;">=</span> output[<span class="dv" style="color: #AD0000;">0</span>, token_length, :]</span>
<span id="cb54-27">    </span>
<span id="cb54-28">    <span class="cf" style="color: #003B4F;">return</span> <span class="bu" style="color: null;">int</span>(np.argmax(log_probs))</span></code></pre></div>
</div>
<div class="cell" data-execution_count="52">
<div class="sourceCode cell-code" id="cb55" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb55-1"><span class="co" style="color: #5E5E5E;"># Test it out!</span></span>
<span id="cb55-2">sentence_test_nxt_symbl <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">"I want to fly in the sky."</span></span>
<span id="cb55-3">detokenize([next_symbol(tokenize(sentence_test_nxt_symbl)<span class="op" style="color: #5E5E5E;">+</span>[<span class="dv" style="color: #AD0000;">0</span>], model)])</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="52">
<pre><code>'The'</code></pre>
</div>
</div>
<section id="greedy-decoding" class="level3" data-number="7.1">
<h3 data-number="7.1" class="anchored" data-anchor-id="greedy-decoding"><span class="header-section-number">7.1</span> Greedy decoding</h3>
<p>Now we will implement the greedy_decode algorithm that will call the <code>next_symbol</code> function. It takes in the input_sentence, the trained model and returns the the decoded sentence.</p>
<div class="cell" data-execution_count="54">
<div class="sourceCode cell-code" id="cb57" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb57-1"><span class="co" style="color: #5E5E5E;"># Decoding functions.</span></span>
<span id="cb57-2"><span class="kw" style="color: #003B4F;">def</span> greedy_decode(input_sentence, model, next_symbol<span class="op" style="color: #5E5E5E;">=</span>next_symbol, tokenize<span class="op" style="color: #5E5E5E;">=</span>tokenize, detokenize<span class="op" style="color: #5E5E5E;">=</span>detokenize):</span>
<span id="cb57-3">    <span class="co" style="color: #5E5E5E;">"""Greedy decode function.</span></span>
<span id="cb57-4"></span>
<span id="cb57-5"><span class="co" style="color: #5E5E5E;">    Args:</span></span>
<span id="cb57-6"><span class="co" style="color: #5E5E5E;">        input_sentence (string): a sentence or article.</span></span>
<span id="cb57-7"><span class="co" style="color: #5E5E5E;">        model (trax.layers.combinators.Serial): Transformer model.</span></span>
<span id="cb57-8"></span>
<span id="cb57-9"><span class="co" style="color: #5E5E5E;">    Returns:</span></span>
<span id="cb57-10"><span class="co" style="color: #5E5E5E;">        string: summary of the input.</span></span>
<span id="cb57-11"><span class="co" style="color: #5E5E5E;">    """</span></span>
<span id="cb57-12">    </span>
<span id="cb57-13">    <span class="co" style="color: #5E5E5E;"># Use tokenize()</span></span>
<span id="cb57-14">    cur_output_tokens <span class="op" style="color: #5E5E5E;">=</span> tokenize(input_sentence) <span class="op" style="color: #5E5E5E;">+</span> [<span class="dv" style="color: #AD0000;">0</span>]</span>
<span id="cb57-15">    generated_output <span class="op" style="color: #5E5E5E;">=</span> [] </span>
<span id="cb57-16">    cur_output <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">0</span> </span>
<span id="cb57-17">    EOS <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">1</span> </span>
<span id="cb57-18">    </span>
<span id="cb57-19">    <span class="cf" style="color: #003B4F;">while</span> cur_output <span class="op" style="color: #5E5E5E;">!=</span> EOS:</span>
<span id="cb57-20">        <span class="co" style="color: #5E5E5E;"># Get next symbol</span></span>
<span id="cb57-21">        cur_output <span class="op" style="color: #5E5E5E;">=</span> next_symbol(cur_output_tokens, model)</span>
<span id="cb57-22">        <span class="co" style="color: #5E5E5E;"># Append next symbol to original sentence</span></span>
<span id="cb57-23">        cur_output_tokens.append(cur_output)</span>
<span id="cb57-24">        <span class="co" style="color: #5E5E5E;"># Append next symbol to generated sentence</span></span>
<span id="cb57-25">        generated_output.append(cur_output)</span>
<span id="cb57-26">        <span class="bu" style="color: null;">print</span>(detokenize(generated_output))</span>
<span id="cb57-27">        </span>
<span id="cb57-28">    <span class="cf" style="color: #003B4F;">return</span> detokenize(generated_output)</span></code></pre></div>
</div>
<div class="cell" data-outputid="2525ca2c-4625-47c0-8456-f75598581993" data-execution_count="55">
<div class="sourceCode cell-code" id="cb58" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb58-1"><span class="co" style="color: #5E5E5E;"># Test it out on a sentence!</span></span>
<span id="cb58-2">test_sentence <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">"It was a sunny day when I went to the market to buy some flowers. But I only found roses, not tulips."</span></span>
<span id="cb58-3"><span class="bu" style="color: null;">print</span>(wrapper.fill(test_sentence), <span class="st" style="color: #20794D;">'</span><span class="ch" style="color: #20794D;">\n</span><span class="st" style="color: #20794D;">'</span>)</span>
<span id="cb58-4"><span class="bu" style="color: null;">print</span>(greedy_decode(test_sentence, model))</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>It was a sunny day when I went to the market to buy some flowers. But
I only found roses, not tulips. 

:
: I
: I just
: I just found
: I just found ros
: I just found roses
: I just found roses,
: I just found roses, not
: I just found roses, not tu
: I just found roses, not tulips
: I just found roses, not tulips
: I just found roses, not tulips.
: I just found roses, not tulips.&lt;EOS&gt;
: I just found roses, not tulips.&lt;EOS&gt;</code></pre>
</div>
</div>
<div class="cell" data-outputid="b901e164-48b3-4124-d21a-fe7443d15b79" data-execution_count="56">
<div class="sourceCode cell-code" id="cb60" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb60-1"><span class="co" style="color: #5E5E5E;"># Test it out with a whole article!</span></span>
<span id="cb60-2">article <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">"It’s the posing craze sweeping the U.S. after being brought to fame by skier Lindsey Vonn, soccer star Omar Cummings, baseball player Albert Pujols - and even Republican politician Rick Perry. But now four students at Riverhead High School on Long Island, New York, have been suspended for dropping to a knee and taking up a prayer pose to mimic Denver Broncos quarterback Tim Tebow. Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were all suspended for one day because the ‘Tebowing’ craze was blocking the hallway and presenting a safety hazard to students. Scroll down for video. Banned: Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll (all pictured left) were all suspended for one day by Riverhead High School on Long Island, New York, for their tribute to Broncos quarterback Tim Tebow. Issue: Four of the pupils were suspended for one day because they allegedly did not heed to warnings that the 'Tebowing' craze at the school was blocking the hallway and presenting a safety hazard to students."</span></span>
<span id="cb60-3"><span class="bu" style="color: null;">print</span>(wrapper.fill(article), <span class="st" style="color: #20794D;">'</span><span class="ch" style="color: #20794D;">\n</span><span class="st" style="color: #20794D;">'</span>)</span>
<span id="cb60-4"><span class="bu" style="color: null;">print</span>(greedy_decode(article, model))</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>It’s the posing craze sweeping the U.S. after being brought to fame by
skier Lindsey Vonn, soccer star Omar Cummings, baseball player Albert
Pujols - and even Republican politician Rick Perry. But now four
students at Riverhead High School on Long Island, New York, have been
suspended for dropping to a knee and taking up a prayer pose to mimic
Denver Broncos quarterback Tim Tebow. Jordan Fulcoly, Wayne Drexel,
Tyler Carroll and Connor Carroll were all suspended for one day
because the ‘Tebowing’ craze was blocking the hallway and presenting a
safety hazard to students. Scroll down for video. Banned: Jordan
Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll (all pictured
left) were all suspended for one day by Riverhead High School on Long
Island, New York, for their tribute to Broncos quarterback Tim Tebow.
Issue: Four of the pupils were suspended for one day because they
allegedly did not heed to warnings that the 'Tebowing' craze at the
school was blocking the hallway and presenting a safety hazard to
students. 

Jordan
Jordan Ful
Jordan Fulcol
Jordan Fulcoly
Jordan Fulcoly,
Jordan Fulcoly, Wayne
Jordan Fulcoly, Wayne Dre
Jordan Fulcoly, Wayne Drexe
Jordan Fulcoly, Wayne Drexel
Jordan Fulcoly, Wayne Drexel,
Jordan Fulcoly, Wayne Drexel, Tyler
Jordan Fulcoly, Wayne Drexel, Tyler Carroll
Jordan Fulcoly, Wayne Drexel, Tyler Carroll and
Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor
Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll
Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were
Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were
suspended
Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were
suspended for
Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were
suspended for one
Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were
suspended for one day
Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were
suspended for one day.
Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were
suspended for one day. Four
Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were
suspended for one day. Four students
Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were
suspended for one day. Four students were
Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were
suspended for one day. Four students were suspended
Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were
suspended for one day. Four students were suspended for
Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were
suspended for one day. Four students were suspended for one
Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were
suspended for one day. Four students were suspended for one day
Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were
suspended for one day. Four students were suspended for one day
because
Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were
suspended for one day. Four students were suspended for one day
because they
Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were
suspended for one day. Four students were suspended for one day
because they allegedly
Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were
suspended for one day. Four students were suspended for one day
because they allegedly did
Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were
suspended for one day. Four students were suspended for one day
because they allegedly did not
Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were
suspended for one day. Four students were suspended for one day
because they allegedly did not hee
Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were
suspended for one day. Four students were suspended for one day
because they allegedly did not heed
Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were
suspended for one day. Four students were suspended for one day
because they allegedly did not heed to
Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were
suspended for one day. Four students were suspended for one day
because they allegedly did not heed to warn
Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were
suspended for one day. Four students were suspended for one day
because they allegedly did not heed to warnings
Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were
suspended for one day. Four students were suspended for one day
because they allegedly did not heed to warnings that
Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were
suspended for one day. Four students were suspended for one day
because they allegedly did not heed to warnings that the
Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were
suspended for one day. Four students were suspended for one day
because they allegedly did not heed to warnings that the '
Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were
suspended for one day. Four students were suspended for one day
because they allegedly did not heed to warnings that the 'Te
Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were
suspended for one day. Four students were suspended for one day
because they allegedly did not heed to warnings that the 'Tebow
Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were
suspended for one day. Four students were suspended for one day
because they allegedly did not heed to warnings that the 'Tebowing
Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were
suspended for one day. Four students were suspended for one day
because they allegedly did not heed to warnings that the 'Tebowing'
Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were
suspended for one day. Four students were suspended for one day
because they allegedly did not heed to warnings that the 'Tebowing'
cra
Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were
suspended for one day. Four students were suspended for one day
because they allegedly did not heed to warnings that the 'Tebowing'
craze
Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were
suspended for one day. Four students were suspended for one day
because they allegedly did not heed to warnings that the 'Tebowing'
craze was
Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were
suspended for one day. Four students were suspended for one day
because they allegedly did not heed to warnings that the 'Tebowing'
craze was blocki
Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were
suspended for one day. Four students were suspended for one day
because they allegedly did not heed to warnings that the 'Tebowing'
craze was blocking
Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were
suspended for one day. Four students were suspended for one day
because they allegedly did not heed to warnings that the 'Tebowing'
craze was blocking the
Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were
suspended for one day. Four students were suspended for one day
because they allegedly did not heed to warnings that the 'Tebowing'
craze was blocking the hall
Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were
suspended for one day. Four students were suspended for one day
because they allegedly did not heed to warnings that the 'Tebowing'
craze was blocking the hallway
Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were
suspended for one day. Four students were suspended for one day
because they allegedly did not heed to warnings that the 'Tebowing'
craze was blocking the hallway and
Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were
suspended for one day. Four students were suspended for one day
because they allegedly did not heed to warnings that the 'Tebowing'
craze was blocking the hallway and presenting
Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were
suspended for one day. Four students were suspended for one day
because they allegedly did not heed to warnings that the 'Tebowing'
craze was blocking the hallway and presenting a
Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were
suspended for one day. Four students were suspended for one day
because they allegedly did not heed to warnings that the 'Tebowing'
craze was blocking the hallway and presenting a safety
Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were
suspended for one day. Four students were suspended for one day
because they allegedly did not heed to warnings that the 'Tebowing'
craze was blocking the hallway and presenting a safety hazard
Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were
suspended for one day. Four students were suspended for one day
because they allegedly did not heed to warnings that the 'Tebowing'
craze was blocking the hallway and presenting a safety hazard to
Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were
suspended for one day. Four students were suspended for one day
because they allegedly did not heed to warnings that the 'Tebowing'
craze was blocking the hallway and presenting a safety hazard to
students
Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were
suspended for one day. Four students were suspended for one day
because they allegedly did not heed to warnings that the 'Tebowing'
craze was blocking the hallway and presenting a safety hazard to
students.
Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were
suspended for one day. Four students were suspended for one day
because they allegedly did not heed to warnings that the 'Tebowing'
craze was blocking the hallway and presenting a safety hazard to
students.&lt;EOS&gt;
Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were
suspended for one day. Four students were suspended for one day
because they allegedly did not heed to warnings that the 'Tebowing'
craze was blocking the hallway and presenting a safety hazard to
students.&lt;EOS&gt;</code></pre>
</div>
</div>
</section>
</section>
<section id="acknowledgements" class="level2" data-number="8">
<h2 data-number="8" class="anchored" data-anchor-id="acknowledgements"><span class="header-section-number">8</span> Acknowledgements</h2>
<p>I’d like to express my thanks to the great <a href="https://www.coursera.org/learn/attention-models-in-nlp">Natural Language Processing with Attention Models Course</a> which i completed, and acknowledge the use of some images and other materials from the course in this article.</p>


</section>

 ]]></description>
  <category>natural-language-processing</category>
  <category>deep-learning</category>
  <guid>http://livingdatalab.com/posts/2023-03-18-creating-transformer-model-for-text-summarisation.html</guid>
  <pubDate>Sat, 18 Mar 2023 00:00:00 GMT</pubDate>
  <media:content url="https://github.com/pranath/blog/raw/master/images/summarization-img.png" medium="image" type="image/png"/>
</item>
<item>
  <title>Implementing GPT-2 A Transfomer Decoder NLP Model</title>
  <dc:creator>Pranath Fernando</dc:creator>
  <link>http://livingdatalab.com/posts/2023-03-11-implementing-gpt2-a-transformer-decoder-nlp-model.html</link>
  <description><![CDATA[ 




<section id="introduction" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="introduction"><span class="header-section-number">1</span> Introduction</h2>
<p>In an <a href="2023-03-04-three-types-of-attention-for-transformer-nlp-models.html">earlier article</a> we looked at 3 types of attention used for transformer based NLP models which was used in the 2017 paper <a href="https://arxiv.org/abs/1706.03762">Attention Is All You Need</a> which introduced the Transformer model. Since then, Transformers have come to dominate large-scale natural language applications.</p>
<p>In this article we’ll explore the transformer decoder and how to implement it with trax.</p>
<p>Previously we saw how to translate the mathematics of attention into NumPy code. Here, we’ll see how multi-head causal attention fits into GPT-2 which is essentially just a transformer decoder, and see how to build one with trax layers. We’ll implement causal attention from scratch, and exploit the handy-dandy <code>tl.CausalAttention()</code> layer.</p>
<p>The schematic depiction below illustrates the components and flow of a transformer decoder. Note that while the algorithm diagram flows from the bottom to the top, the overview and subsequent Trax layer codes are top-down.</p>
<p><img src="http://livingdatalab.com/posts/https:/github.com/pranath/blog/raw/master/images/C4_W2_L6_transformer-decoder_S01_transformer-decoder.png" width="1000"></p>
</section>
<section id="import-libraries-setup" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="import-libraries-setup"><span class="header-section-number">2</span> Import Libraries &amp; Setup</h2>
<div class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;">import</span> sys</span>
<span id="cb1-2"><span class="im" style="color: #00769E;">import</span> os</span>
<span id="cb1-3"></span>
<span id="cb1-4"><span class="im" style="color: #00769E;">import</span> time</span>
<span id="cb1-5"><span class="im" style="color: #00769E;">import</span> numpy <span class="im" style="color: #00769E;">as</span> np</span>
<span id="cb1-6"><span class="im" style="color: #00769E;">import</span> gin</span>
<span id="cb1-7"></span>
<span id="cb1-8"><span class="im" style="color: #00769E;">import</span> textwrap</span>
<span id="cb1-9">wrapper <span class="op" style="color: #5E5E5E;">=</span> textwrap.TextWrapper(width<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">70</span>)</span>
<span id="cb1-10"></span>
<span id="cb1-11"><span class="im" style="color: #00769E;">import</span> trax</span>
<span id="cb1-12"><span class="im" style="color: #00769E;">from</span> trax <span class="im" style="color: #00769E;">import</span> layers <span class="im" style="color: #00769E;">as</span> tl</span>
<span id="cb1-13"><span class="im" style="color: #00769E;">from</span> trax.fastmath <span class="im" style="color: #00769E;">import</span> numpy <span class="im" style="color: #00769E;">as</span> jnp</span>
<span id="cb1-14"></span>
<span id="cb1-15"><span class="co" style="color: #5E5E5E;"># to print the entire np array</span></span>
<span id="cb1-16">np.set_printoptions(threshold<span class="op" style="color: #5E5E5E;">=</span>sys.maxsize)</span></code></pre></div>
</div>
</section>
<section id="sentence-gets-embedded-then-add-positional-encoding" class="level2" data-number="3">
<h2 data-number="3" class="anchored" data-anchor-id="sentence-gets-embedded-then-add-positional-encoding"><span class="header-section-number">3</span> Sentence gets embedded, then add positional encoding</h2>
<p>We will embed the words, then create vectors representing each word’s position in each sentence <img src="https://latex.codecogs.com/png.latex?%5Cin%20%5C%7B%200,%201,%202,%20%5Cldots%20,%20K%5C%7D"> = <code>range(max_len)</code>, where <code>max_len</code> = <img src="https://latex.codecogs.com/png.latex?K+1">)</p>
<div class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="kw" style="color: #003B4F;">def</span> PositionalEncoder(vocab_size, d_model, dropout, max_len, mode):</span>
<span id="cb2-2">    <span class="co" style="color: #5E5E5E;">"""Returns a list of layers that: </span></span>
<span id="cb2-3"><span class="co" style="color: #5E5E5E;">    1. takes a block of text as input, </span></span>
<span id="cb2-4"><span class="co" style="color: #5E5E5E;">    2. embeds the words in that text, and </span></span>
<span id="cb2-5"><span class="co" style="color: #5E5E5E;">    3. adds positional encoding, </span></span>
<span id="cb2-6"><span class="co" style="color: #5E5E5E;">       i.e. associates a number in range(max_len) with </span></span>
<span id="cb2-7"><span class="co" style="color: #5E5E5E;">       each word in each sentence of embedded input text </span></span>
<span id="cb2-8"><span class="co" style="color: #5E5E5E;">    </span></span>
<span id="cb2-9"><span class="co" style="color: #5E5E5E;">    The input is a list of tokenized blocks of text</span></span>
<span id="cb2-10"><span class="co" style="color: #5E5E5E;">    </span></span>
<span id="cb2-11"><span class="co" style="color: #5E5E5E;">    Args:</span></span>
<span id="cb2-12"><span class="co" style="color: #5E5E5E;">        vocab_size (int): vocab size.</span></span>
<span id="cb2-13"><span class="co" style="color: #5E5E5E;">        d_model (int):  depth of embedding.</span></span>
<span id="cb2-14"><span class="co" style="color: #5E5E5E;">        dropout (float): dropout rate (how much to drop out).</span></span>
<span id="cb2-15"><span class="co" style="color: #5E5E5E;">        max_len (int): maximum symbol length for positional encoding.</span></span>
<span id="cb2-16"><span class="co" style="color: #5E5E5E;">        mode (str): 'train' or 'eval'.</span></span>
<span id="cb2-17"><span class="co" style="color: #5E5E5E;">    """</span></span>
<span id="cb2-18">    <span class="co" style="color: #5E5E5E;"># Embedding inputs and positional encoder</span></span>
<span id="cb2-19">    <span class="cf" style="color: #003B4F;">return</span> [ </span>
<span id="cb2-20">        <span class="co" style="color: #5E5E5E;"># Add embedding layer of dimension (vocab_size, d_model)</span></span>
<span id="cb2-21">        tl.Embedding(vocab_size, d_model),  </span>
<span id="cb2-22">        <span class="co" style="color: #5E5E5E;"># Use dropout with rate and mode specified</span></span>
<span id="cb2-23">        tl.Dropout(rate<span class="op" style="color: #5E5E5E;">=</span>dropout, mode<span class="op" style="color: #5E5E5E;">=</span>mode), </span>
<span id="cb2-24">        <span class="co" style="color: #5E5E5E;"># Add positional encoding layer with maximum input length and mode specified</span></span>
<span id="cb2-25">        tl.PositionalEncoding(max_len<span class="op" style="color: #5E5E5E;">=</span>max_len, mode<span class="op" style="color: #5E5E5E;">=</span>mode)] </span></code></pre></div>
</div>
</section>
<section id="multi-head-causal-attention" class="level2" data-number="4">
<h2 data-number="4" class="anchored" data-anchor-id="multi-head-causal-attention"><span class="header-section-number">4</span> Multi-head causal attention</h2>
<p>The layers and array dimensions involved in multi-head causal attention (which looks at previous words in the input text) are summarized in the figure below:</p>
<p><img src="http://livingdatalab.com/posts/https:/github.com/pranath/blog/raw/master/images/C4_W2_L5_multi-head-attention_S05_multi-head-attention-concatenation_stripped.png" width="1000"></p>
<p><code>tl.CausalAttention()</code> does all of this for us! You might be wondering, though, whether we need to pass in our input text 3 times, since for causal attention, the queries Q, keys K, and values V all come from the same source. Fortunately, <code>tl.CausalAttention()</code> handles this as well by making use of the <a href="https://trax-ml.readthedocs.io/en/latest/trax.layers.html#module-trax.layers.combinators"><code>tl.Branch()</code></a> combinator layer. In general, each branch within a <code>tl.Branch()</code> layer performs parallel operations on copies of the layer’s inputs. For causal attention, each branch (representing Q, K, and V) applies a linear transformation (i.e.&nbsp;a dense layer without a subsequent activation) to its copy of the input, then splits that result into heads. You can see the syntax for this in the screenshot from the <code>trax.layers.attention.py</code> <a href="https://github.com/google/trax/blob/master/trax/layers/attention.py">source code</a> below:</p>
<p><img src="http://livingdatalab.com/posts/https:/github.com/pranath/blog/raw/master/images/use-of-tl-Branch-in-tl-CausalAttention.png" width="500"></p>
</section>
<section id="feed-forward-layer" class="level2" data-number="5">
<h2 data-number="5" class="anchored" data-anchor-id="feed-forward-layer"><span class="header-section-number">5</span> Feed-forward layer</h2>
<ul>
<li>Typically ends with a ReLU activation, but we’ll leave open the possibility of a different activation</li>
<li>Most of the parameters are here</li>
</ul>
<div class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><span class="kw" style="color: #003B4F;">def</span> FeedForward(d_model, d_ff, dropout, mode, ff_activation):</span>
<span id="cb3-2">    <span class="co" style="color: #5E5E5E;">"""Returns a list of layers that implements a feed-forward block.</span></span>
<span id="cb3-3"></span>
<span id="cb3-4"><span class="co" style="color: #5E5E5E;">    The input is an activation tensor.</span></span>
<span id="cb3-5"></span>
<span id="cb3-6"><span class="co" style="color: #5E5E5E;">    Args:</span></span>
<span id="cb3-7"><span class="co" style="color: #5E5E5E;">        d_model (int):  depth of embedding.</span></span>
<span id="cb3-8"><span class="co" style="color: #5E5E5E;">        d_ff (int): depth of feed-forward layer.</span></span>
<span id="cb3-9"><span class="co" style="color: #5E5E5E;">        dropout (float): dropout rate (how much to drop out).</span></span>
<span id="cb3-10"><span class="co" style="color: #5E5E5E;">        mode (str): 'train' or 'eval'.</span></span>
<span id="cb3-11"><span class="co" style="color: #5E5E5E;">        ff_activation (function): the non-linearity in feed-forward layer.</span></span>
<span id="cb3-12"></span>
<span id="cb3-13"><span class="co" style="color: #5E5E5E;">    Returns:</span></span>
<span id="cb3-14"><span class="co" style="color: #5E5E5E;">        list: list of trax.layers.combinators.Serial that maps an activation tensor to an activation tensor.</span></span>
<span id="cb3-15"><span class="co" style="color: #5E5E5E;">    """</span></span>
<span id="cb3-16">    </span>
<span id="cb3-17">    <span class="co" style="color: #5E5E5E;"># Create feed-forward block (list) with two dense layers with dropout and input normalized</span></span>
<span id="cb3-18">    <span class="cf" style="color: #003B4F;">return</span> [ </span>
<span id="cb3-19">        <span class="co" style="color: #5E5E5E;"># Normalize layer inputs</span></span>
<span id="cb3-20">        tl.LayerNorm(), </span>
<span id="cb3-21">        <span class="co" style="color: #5E5E5E;"># Add first feed forward (dense) layer (don't forget to set the correct value for n_units)</span></span>
<span id="cb3-22">        tl.Dense(d_ff), </span>
<span id="cb3-23">        <span class="co" style="color: #5E5E5E;"># Add activation function passed in as a parameter (you need to call it!)</span></span>
<span id="cb3-24">        ff_activation(),  <span class="co" style="color: #5E5E5E;"># Generally ReLU</span></span>
<span id="cb3-25">        <span class="co" style="color: #5E5E5E;"># Add dropout with rate and mode specified (i.e., don't use dropout during evaluation)</span></span>
<span id="cb3-26">        tl.Dropout(rate<span class="op" style="color: #5E5E5E;">=</span>dropout, mode<span class="op" style="color: #5E5E5E;">=</span>mode), </span>
<span id="cb3-27">        <span class="co" style="color: #5E5E5E;"># Add second feed forward layer (don't forget to set the correct value for n_units)</span></span>
<span id="cb3-28">        tl.Dense(d_model), </span>
<span id="cb3-29">        <span class="co" style="color: #5E5E5E;"># Add dropout with rate and mode specified (i.e., don't use dropout during evaluation)</span></span>
<span id="cb3-30">        tl.Dropout(rate<span class="op" style="color: #5E5E5E;">=</span>dropout, mode<span class="op" style="color: #5E5E5E;">=</span>mode) </span>
<span id="cb3-31">    ]</span></code></pre></div>
</div>
</section>
<section id="decoder-block" class="level2" data-number="6">
<h2 data-number="6" class="anchored" data-anchor-id="decoder-block"><span class="header-section-number">6</span> Decoder block</h2>
<p>Here, we return a list containing two residual blocks. The first wraps around the causal attention layer, whose inputs are normalized and to which we apply dropout regulation. The second wraps around the feed-forward layer. You may notice that the second call to <code>tl.Residual()</code> doesn’t call a normalization layer before calling the feed-forward layer. This is because the normalization layer is included in the feed-forward layer.</p>
<div class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><span class="kw" style="color: #003B4F;">def</span> DecoderBlock(d_model, d_ff, n_heads,</span>
<span id="cb4-2">                 dropout, mode, ff_activation):</span>
<span id="cb4-3">    <span class="co" style="color: #5E5E5E;">"""Returns a list of layers that implements a Transformer decoder block.</span></span>
<span id="cb4-4"></span>
<span id="cb4-5"><span class="co" style="color: #5E5E5E;">    The input is an activation tensor.</span></span>
<span id="cb4-6"></span>
<span id="cb4-7"><span class="co" style="color: #5E5E5E;">    Args:</span></span>
<span id="cb4-8"><span class="co" style="color: #5E5E5E;">        d_model (int):  depth of embedding.</span></span>
<span id="cb4-9"><span class="co" style="color: #5E5E5E;">        d_ff (int): depth of feed-forward layer.</span></span>
<span id="cb4-10"><span class="co" style="color: #5E5E5E;">        n_heads (int): number of attention heads.</span></span>
<span id="cb4-11"><span class="co" style="color: #5E5E5E;">        dropout (float): dropout rate (how much to drop out).</span></span>
<span id="cb4-12"><span class="co" style="color: #5E5E5E;">        mode (str): 'train' or 'eval'.</span></span>
<span id="cb4-13"><span class="co" style="color: #5E5E5E;">        ff_activation (function): the non-linearity in feed-forward layer.</span></span>
<span id="cb4-14"></span>
<span id="cb4-15"><span class="co" style="color: #5E5E5E;">    Returns:</span></span>
<span id="cb4-16"><span class="co" style="color: #5E5E5E;">        list: list of trax.layers.combinators.Serial that maps an activation tensor to an activation tensor.</span></span>
<span id="cb4-17"><span class="co" style="color: #5E5E5E;">    """</span></span>
<span id="cb4-18">        </span>
<span id="cb4-19">    <span class="co" style="color: #5E5E5E;"># Add list of two Residual blocks: the attention with normalization and dropout and feed-forward blocks</span></span>
<span id="cb4-20">    <span class="cf" style="color: #003B4F;">return</span> [</span>
<span id="cb4-21">      tl.Residual(</span>
<span id="cb4-22">          <span class="co" style="color: #5E5E5E;"># Normalize layer input</span></span>
<span id="cb4-23">          tl.LayerNorm(), </span>
<span id="cb4-24">          <span class="co" style="color: #5E5E5E;"># Add causal attention </span></span>
<span id="cb4-25">          tl.CausalAttention(d_model, n_heads<span class="op" style="color: #5E5E5E;">=</span>n_heads, dropout<span class="op" style="color: #5E5E5E;">=</span>dropout, mode<span class="op" style="color: #5E5E5E;">=</span>mode) </span>
<span id="cb4-26">        ),</span>
<span id="cb4-27">      tl.Residual(</span>
<span id="cb4-28">          <span class="co" style="color: #5E5E5E;"># Add feed-forward block</span></span>
<span id="cb4-29">          <span class="co" style="color: #5E5E5E;"># We don't need to normalize the layer inputs here. The feed-forward block takes care of that for us.</span></span>
<span id="cb4-30">          FeedForward(d_model, d_ff, dropout, mode, ff_activation)</span>
<span id="cb4-31">        ),</span>
<span id="cb4-32">      ]</span></code></pre></div>
</div>
</section>
<section id="the-transformer-decoder-putting-it-all-together" class="level2" data-number="7">
<h2 data-number="7" class="anchored" data-anchor-id="the-transformer-decoder-putting-it-all-together"><span class="header-section-number">7</span> The Transformer Decoder: Putting it all together</h2>
<p>So we repeat N times, dense layer and softmax for output</p>
<div class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><span class="kw" style="color: #003B4F;">def</span> TransformerLM(vocab_size<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">33300</span>,</span>
<span id="cb5-2">                  d_model<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">512</span>,</span>
<span id="cb5-3">                  d_ff<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">2048</span>,</span>
<span id="cb5-4">                  n_layers<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">6</span>,</span>
<span id="cb5-5">                  n_heads<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">8</span>,</span>
<span id="cb5-6">                  dropout<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">0.1</span>,</span>
<span id="cb5-7">                  max_len<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">4096</span>,</span>
<span id="cb5-8">                  mode<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'train'</span>,</span>
<span id="cb5-9">                  ff_activation<span class="op" style="color: #5E5E5E;">=</span>tl.Relu):</span>
<span id="cb5-10">    <span class="co" style="color: #5E5E5E;">"""Returns a Transformer language model.</span></span>
<span id="cb5-11"></span>
<span id="cb5-12"><span class="co" style="color: #5E5E5E;">    The input to the model is a tensor of tokens. (This model uses only the</span></span>
<span id="cb5-13"><span class="co" style="color: #5E5E5E;">    decoder part of the overall Transformer.)</span></span>
<span id="cb5-14"></span>
<span id="cb5-15"><span class="co" style="color: #5E5E5E;">    Args:</span></span>
<span id="cb5-16"><span class="co" style="color: #5E5E5E;">        vocab_size (int): vocab size.</span></span>
<span id="cb5-17"><span class="co" style="color: #5E5E5E;">        d_model (int):  depth of embedding.</span></span>
<span id="cb5-18"><span class="co" style="color: #5E5E5E;">        d_ff (int): depth of feed-forward layer.</span></span>
<span id="cb5-19"><span class="co" style="color: #5E5E5E;">        n_layers (int): number of decoder layers.</span></span>
<span id="cb5-20"><span class="co" style="color: #5E5E5E;">        n_heads (int): number of attention heads.</span></span>
<span id="cb5-21"><span class="co" style="color: #5E5E5E;">        dropout (float): dropout rate (how much to drop out).</span></span>
<span id="cb5-22"><span class="co" style="color: #5E5E5E;">        max_len (int): maximum symbol length for positional encoding.</span></span>
<span id="cb5-23"><span class="co" style="color: #5E5E5E;">        mode (str): 'train', 'eval' or 'predict', predict mode is for fast inference.</span></span>
<span id="cb5-24"><span class="co" style="color: #5E5E5E;">        ff_activation (function): the non-linearity in feed-forward layer.</span></span>
<span id="cb5-25"></span>
<span id="cb5-26"><span class="co" style="color: #5E5E5E;">    Returns:</span></span>
<span id="cb5-27"><span class="co" style="color: #5E5E5E;">        trax.layers.combinators.Serial: A Transformer language model as a layer that maps from a tensor of tokens</span></span>
<span id="cb5-28"><span class="co" style="color: #5E5E5E;">        to activations over a vocab set.</span></span>
<span id="cb5-29"><span class="co" style="color: #5E5E5E;">    """</span></span>
<span id="cb5-30">    </span>
<span id="cb5-31">    <span class="co" style="color: #5E5E5E;"># Create stack (list) of decoder blocks with n_layers with necessary parameters</span></span>
<span id="cb5-32">    decoder_blocks <span class="op" style="color: #5E5E5E;">=</span> [ </span>
<span id="cb5-33">        DecoderBlock(d_model, d_ff, n_heads, dropout, mode, ff_activation) <span class="cf" style="color: #003B4F;">for</span> _ <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">range</span>(n_layers)] </span>
<span id="cb5-34"></span>
<span id="cb5-35">    <span class="co" style="color: #5E5E5E;"># Create the complete model as written in the figure</span></span>
<span id="cb5-36">    <span class="cf" style="color: #003B4F;">return</span> tl.Serial(</span>
<span id="cb5-37">        <span class="co" style="color: #5E5E5E;"># Use teacher forcing (feed output of previous step to current step)</span></span>
<span id="cb5-38">        tl.ShiftRight(mode<span class="op" style="color: #5E5E5E;">=</span>mode), </span>
<span id="cb5-39">        <span class="co" style="color: #5E5E5E;"># Add embedding inputs and positional encoder</span></span>
<span id="cb5-40">        PositionalEncoder(vocab_size, d_model, dropout, max_len, mode),</span>
<span id="cb5-41">        <span class="co" style="color: #5E5E5E;"># Add decoder blocks</span></span>
<span id="cb5-42">        decoder_blocks, </span>
<span id="cb5-43">        <span class="co" style="color: #5E5E5E;"># Normalize layer</span></span>
<span id="cb5-44">        tl.LayerNorm(), </span>
<span id="cb5-45"></span>
<span id="cb5-46">        <span class="co" style="color: #5E5E5E;"># Add dense layer of vocab_size (since need to select a word to translate to)</span></span>
<span id="cb5-47">        <span class="co" style="color: #5E5E5E;"># (a.k.a., logits layer. Note: activation already set by ff_activation)</span></span>
<span id="cb5-48">        tl.Dense(vocab_size), </span>
<span id="cb5-49">        <span class="co" style="color: #5E5E5E;"># Get probabilities with Logsoftmax</span></span>
<span id="cb5-50">        tl.LogSoftmax() </span>
<span id="cb5-51">    )</span></code></pre></div>
</div>
</section>
<section id="acknowledgements" class="level2" data-number="8">
<h2 data-number="8" class="anchored" data-anchor-id="acknowledgements"><span class="header-section-number">8</span> Acknowledgements</h2>
<p>I’d like to express my thanks to the great <a href="https://www.coursera.org/learn/attention-models-in-nlp">Natural Language Processing with Attention Models Course</a> which i completed, and acknowledge the use of some images and other materials from the course in this article.</p>


</section>

 ]]></description>
  <category>natural-language-processing</category>
  <category>deep-learning</category>
  <category>mathematics</category>
  <guid>http://livingdatalab.com/posts/2023-03-11-implementing-gpt2-a-transformer-decoder-nlp-model.html</guid>
  <pubDate>Sat, 11 Mar 2023 00:00:00 GMT</pubDate>
  <media:content url="https://github.com/pranath/blog/raw/master/images/openai.png" medium="image" type="image/png"/>
</item>
<item>
  <title>3 Types of Attention for Transfomer based NLP Models</title>
  <dc:creator>Pranath Fernando</dc:creator>
  <link>http://livingdatalab.com/posts/2023-03-04-three-types-of-attention-for-transformer-nlp-models.html</link>
  <description><![CDATA[ 




<section id="introduction" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="introduction"><span class="header-section-number">1</span> Introduction</h2>
<p>In an <a href="2023-03-02-improving-seq2seq-language-models-using-dot-product-attention.html">earlier article</a> we looked at scaled dot product attention which was used in the 2017 paper <a href="https://arxiv.org/abs/1706.03762">Attention Is All You Need</a> which introduced the Transformer model, sometimes also called QKV (<strong>Q</strong>ueries, <strong>K</strong>eys, <strong>V</strong>alues) attention. Since then, Transformers have come to dominate large-scale natural language applications.</p>
<p>In this article we’ll explore the three ways of attention (encoder-decoder attention, causal attention, and bi-directional self attention) and how to implement the latter two with dot product attention.</p>
<p><strong>Attention models</strong> constitute powerful tools in the NLP practitioner’s toolkit. Like LSTMs, they learn which words are most important to phrases, sentences, paragraphs, and so on. Moreover, they mitigate the vanishing gradient problem even better than LSTMs.</p>
<p><img src="http://livingdatalab.com/posts/https:/github.com/pranath/blog/raw/master/images/C4_W2_L3_dot-product-attention_S01_introducing-attention_stripped.png" width="500"></p>
<p>Now we will exlore how to integrate attention into <strong>transformers</strong>. Because transformers are not sequence models, they are much easier to parallelize and accelerate. Beyond machine translation, applications of transformers include:</p>
<ul>
<li>Auto-completion</li>
<li>Named Entity Recognition</li>
<li>Chatbots</li>
<li>Question-Answering</li>
<li>And more!</li>
</ul>
<p>Along with embedding, positional encoding, dense layers, and residual connections, attention is a crucial component of transformers. At the heart of any attention scheme used in a transformer is <strong>dot product attention</strong>, of which the figures below display a simplified picture:</p>
<p><img src="http://livingdatalab.com/posts/https:/github.com/pranath/blog/raw/master/images/C4_W2_L3_dot-product-attention_S03_concept-of-attention_stripped.png" width="500"></p>
<p><img src="http://livingdatalab.com/posts/https:/github.com/pranath/blog/raw/master/images/C4_W2_L3_dot-product-attention_S04_attention-math_stripped.png" width="500"></p>
<p>With basic dot product attention, you capture the interactions between every word (embedding) in your query and every word in your key. If the queries and keys belong to the same sentences, this constitutes <strong>bi-directional self-attention</strong>. In some situations, however, it’s more appropriate to consider only words which have come before the current one. Such cases, particularly when the queries and keys come from the same sentences, fall into the category of <strong>causal attention</strong>.</p>
<p><img src="http://livingdatalab.com/posts/https:/github.com/pranath/blog/raw/master/images/C4_W2_L4_causal-attention_S02_causal-attention_stripped.png" width="500"></p>
<p>For causal attention, we add a <strong>mask</strong> to the argument of our softmax function, as illustrated below:</p>
<p><img src="http://livingdatalab.com/posts/https:/github.com/pranath/blog/raw/master/images/C4_W2_L4_causal-attention_S03_causal-attention-math_stripped.png" width="500"></p>
<p><img src="http://livingdatalab.com/posts/https:/github.com/pranath/blog/raw/master/images/C4_W2_L4_causal-attention_S04_causal-attention-math-2_stripped.png" width="500"></p>
<p>Now let’s see how to implement attention with NumPy. When we integrate attention into a transformer network defined with the trax library, we’ll have to use <code>trax.fastmath.numpy</code> instead, since trax’s arrays are based on JAX DeviceArrays. Fortunately, the function interfaces are often identical.</p>
</section>
<section id="import-libraries-setup" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="import-libraries-setup"><span class="header-section-number">2</span> Import Libraries &amp; Setup</h2>
<div class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;">import</span> sys</span>
<span id="cb1-2"></span>
<span id="cb1-3"><span class="im" style="color: #00769E;">import</span> numpy <span class="im" style="color: #00769E;">as</span> np</span>
<span id="cb1-4"><span class="im" style="color: #00769E;">import</span> scipy.special</span>
<span id="cb1-5"></span>
<span id="cb1-6"><span class="im" style="color: #00769E;">import</span> textwrap</span>
<span id="cb1-7">wrapper <span class="op" style="color: #5E5E5E;">=</span> textwrap.TextWrapper(width<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">70</span>)</span>
<span id="cb1-8"></span>
<span id="cb1-9"><span class="co" style="color: #5E5E5E;"># to print the entire np array</span></span>
<span id="cb1-10">np.set_printoptions(threshold<span class="op" style="color: #5E5E5E;">=</span>sys.maxsize)</span></code></pre></div>
</div>
<p>We will now create some helper functions that will help us create tensors and display useful information:</p>
<ul>
<li><code>create_tensor()</code> creates a numpy array from a list of lists.</li>
<li><code>display_tensor()</code> prints out the shape and the actual tensor.</li>
</ul>
<div class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="kw" style="color: #003B4F;">def</span> create_tensor(t):</span>
<span id="cb2-2">    <span class="co" style="color: #5E5E5E;">"""Create tensor from list of lists"""</span></span>
<span id="cb2-3">    <span class="cf" style="color: #003B4F;">return</span> np.array(t)</span>
<span id="cb2-4"></span>
<span id="cb2-5"></span>
<span id="cb2-6"><span class="kw" style="color: #003B4F;">def</span> display_tensor(t, name):</span>
<span id="cb2-7">    <span class="co" style="color: #5E5E5E;">"""Display shape and tensor"""</span></span>
<span id="cb2-8">    <span class="bu" style="color: null;">print</span>(<span class="ss" style="color: #20794D;">f'</span><span class="sc" style="color: #5E5E5E;">{</span>name<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;"> shape: </span><span class="sc" style="color: #5E5E5E;">{</span>t<span class="sc" style="color: #5E5E5E;">.</span>shape<span class="sc" style="color: #5E5E5E;">}</span><span class="ch" style="color: #20794D;">\n</span><span class="ss" style="color: #20794D;">'</span>)</span>
<span id="cb2-9">    <span class="bu" style="color: null;">print</span>(<span class="ss" style="color: #20794D;">f'</span><span class="sc" style="color: #5E5E5E;">{</span>t<span class="sc" style="color: #5E5E5E;">}</span><span class="ch" style="color: #20794D;">\n</span><span class="ss" style="color: #20794D;">'</span>)</span></code></pre></div>
</div>
<p>Let’s create some tensors and display their shapes. Note though, that the query, key, and value arrays must all have the same embedding dimensions (number of columns), and the mask array must have the same shape as <code>np.dot(query, key.T)</code>.</p>
<div class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1">q <span class="op" style="color: #5E5E5E;">=</span> create_tensor([[<span class="dv" style="color: #AD0000;">1</span>, <span class="dv" style="color: #AD0000;">0</span>, <span class="dv" style="color: #AD0000;">0</span>], [<span class="dv" style="color: #AD0000;">0</span>, <span class="dv" style="color: #AD0000;">1</span>, <span class="dv" style="color: #AD0000;">0</span>]])</span>
<span id="cb3-2">display_tensor(q, <span class="st" style="color: #20794D;">'query'</span>)</span>
<span id="cb3-3">k <span class="op" style="color: #5E5E5E;">=</span> create_tensor([[<span class="dv" style="color: #AD0000;">1</span>, <span class="dv" style="color: #AD0000;">2</span>, <span class="dv" style="color: #AD0000;">3</span>], [<span class="dv" style="color: #AD0000;">4</span>, <span class="dv" style="color: #AD0000;">5</span>, <span class="dv" style="color: #AD0000;">6</span>]])</span>
<span id="cb3-4">display_tensor(k, <span class="st" style="color: #20794D;">'key'</span>)</span>
<span id="cb3-5">v <span class="op" style="color: #5E5E5E;">=</span> create_tensor([[<span class="dv" style="color: #AD0000;">0</span>, <span class="dv" style="color: #AD0000;">1</span>, <span class="dv" style="color: #AD0000;">0</span>], [<span class="dv" style="color: #AD0000;">1</span>, <span class="dv" style="color: #AD0000;">0</span>, <span class="dv" style="color: #AD0000;">1</span>]])</span>
<span id="cb3-6">display_tensor(v, <span class="st" style="color: #20794D;">'value'</span>)</span>
<span id="cb3-7">m <span class="op" style="color: #5E5E5E;">=</span> create_tensor([[<span class="dv" style="color: #AD0000;">0</span>, <span class="dv" style="color: #AD0000;">0</span>], [<span class="op" style="color: #5E5E5E;">-</span><span class="fl" style="color: #AD0000;">1e9</span>, <span class="dv" style="color: #AD0000;">0</span>]])</span>
<span id="cb3-8">display_tensor(m, <span class="st" style="color: #20794D;">'mask'</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>query shape: (2, 3)

[[1 0 0]
 [0 1 0]]

key shape: (2, 3)

[[1 2 3]
 [4 5 6]]

value shape: (2, 3)

[[0 1 0]
 [1 0 1]]

mask shape: (2, 2)

[[ 0.e+00  0.e+00]
 [-1.e+09  0.e+00]]
</code></pre>
</div>
</div>
</section>
<section id="dot-product-attention" class="level2" data-number="3">
<h2 data-number="3" class="anchored" data-anchor-id="dot-product-attention"><span class="header-section-number">3</span> Dot product attention</h2>
<p>Here we come to the crux of this article, in which we compute <img src="https://latex.codecogs.com/png.latex?%5Ctextrm%7Bsoftmax%7D%20%5Cleft(%5Cfrac%7BQ%20K%5ET%7D%7B%5Csqrt%7Bd%7D%7D%20+%20M%20%5Cright)%20V">, where the (optional, but default) scaling factor <img src="https://latex.codecogs.com/png.latex?%5Csqrt%7Bd%7D"> is the square root of the embedding dimension.</p>
<div class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><span class="kw" style="color: #003B4F;">def</span> DotProductAttention(query, key, value, mask, scale<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>):</span>
<span id="cb5-2">    <span class="co" style="color: #5E5E5E;">"""Dot product self-attention.</span></span>
<span id="cb5-3"><span class="co" style="color: #5E5E5E;">    Args:</span></span>
<span id="cb5-4"><span class="co" style="color: #5E5E5E;">        query (numpy.ndarray): array of query representations with shape (L_q by d)</span></span>
<span id="cb5-5"><span class="co" style="color: #5E5E5E;">        key (numpy.ndarray): array of key representations with shape (L_k by d)</span></span>
<span id="cb5-6"><span class="co" style="color: #5E5E5E;">        value (numpy.ndarray): array of value representations with shape (L_k by d) where L_v = L_k</span></span>
<span id="cb5-7"><span class="co" style="color: #5E5E5E;">        mask (numpy.ndarray): attention-mask, gates attention with shape (L_q by L_k)</span></span>
<span id="cb5-8"><span class="co" style="color: #5E5E5E;">        scale (bool): whether to scale the dot product of the query and transposed key</span></span>
<span id="cb5-9"></span>
<span id="cb5-10"><span class="co" style="color: #5E5E5E;">    Returns:</span></span>
<span id="cb5-11"><span class="co" style="color: #5E5E5E;">        numpy.ndarray: Self-attention array for q, k, v arrays. (L_q by d)</span></span>
<span id="cb5-12"><span class="co" style="color: #5E5E5E;">    """</span></span>
<span id="cb5-13"></span>
<span id="cb5-14">    <span class="cf" style="color: #003B4F;">assert</span> query.shape[<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>] <span class="op" style="color: #5E5E5E;">==</span> key.shape[<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>] <span class="op" style="color: #5E5E5E;">==</span> value.shape[<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>], <span class="st" style="color: #20794D;">"Embedding dimensions of q, k, v aren't all the same"</span></span>
<span id="cb5-15"></span>
<span id="cb5-16">    <span class="co" style="color: #5E5E5E;"># Save depth/dimension of the query embedding for scaling down the dot product</span></span>
<span id="cb5-17">    <span class="cf" style="color: #003B4F;">if</span> scale: </span>
<span id="cb5-18">        depth <span class="op" style="color: #5E5E5E;">=</span> query.shape[<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>]</span>
<span id="cb5-19">    <span class="cf" style="color: #003B4F;">else</span>:</span>
<span id="cb5-20">        depth <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">1</span></span>
<span id="cb5-21"></span>
<span id="cb5-22">    <span class="co" style="color: #5E5E5E;"># Calculate scaled query key dot product according to formula above</span></span>
<span id="cb5-23">    dots <span class="op" style="color: #5E5E5E;">=</span> np.matmul(query, np.swapaxes(key, <span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>, <span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">2</span>)) <span class="op" style="color: #5E5E5E;">/</span> np.sqrt(depth) </span>
<span id="cb5-24">    </span>
<span id="cb5-25">    <span class="co" style="color: #5E5E5E;"># Apply the mask</span></span>
<span id="cb5-26">    <span class="cf" style="color: #003B4F;">if</span> mask <span class="kw" style="color: #003B4F;">is</span> <span class="kw" style="color: #003B4F;">not</span> <span class="va" style="color: #111111;">None</span>:</span>
<span id="cb5-27">        dots <span class="op" style="color: #5E5E5E;">=</span> np.where(mask, dots, np.full_like(dots, <span class="op" style="color: #5E5E5E;">-</span><span class="fl" style="color: #AD0000;">1e9</span>)) </span>
<span id="cb5-28">    </span>
<span id="cb5-29">    <span class="co" style="color: #5E5E5E;"># Softmax formula implementation</span></span>
<span id="cb5-30">    <span class="co" style="color: #5E5E5E;"># We use scipy.special.logsumexp of masked_qkT to avoid underflow by division by large numbers</span></span>
<span id="cb5-31">    <span class="co" style="color: #5E5E5E;"># Note: softmax = e^(dots - logaddexp(dots)) = E^dots / sumexp(dots)</span></span>
<span id="cb5-32">    logsumexp <span class="op" style="color: #5E5E5E;">=</span> scipy.special.logsumexp(dots, axis<span class="op" style="color: #5E5E5E;">=-</span><span class="dv" style="color: #AD0000;">1</span>, keepdims<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>)</span>
<span id="cb5-33"></span>
<span id="cb5-34">    <span class="co" style="color: #5E5E5E;"># Take exponential of dots minus logsumexp to get softmax</span></span>
<span id="cb5-35">    <span class="co" style="color: #5E5E5E;"># We use np.exp()</span></span>
<span id="cb5-36">    dots <span class="op" style="color: #5E5E5E;">=</span> np.exp(dots <span class="op" style="color: #5E5E5E;">-</span> logsumexp)</span>
<span id="cb5-37"></span>
<span id="cb5-38">    <span class="co" style="color: #5E5E5E;"># Multiply dots by value to get self-attention</span></span>
<span id="cb5-39">    <span class="co" style="color: #5E5E5E;"># We use np.matmul()</span></span>
<span id="cb5-40">    attention <span class="op" style="color: #5E5E5E;">=</span> np.matmul(dots, value)</span>
<span id="cb5-41">    </span>
<span id="cb5-42">    <span class="cf" style="color: #003B4F;">return</span> attention</span></code></pre></div>
</div>
<p>Now let’s implement the <em>masked</em> dot product self-attention (at the heart of causal attention) as a special case of dot product attention</p>
<div class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><span class="kw" style="color: #003B4F;">def</span> dot_product_self_attention(q, k, v, scale<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>):</span>
<span id="cb6-2">    <span class="co" style="color: #5E5E5E;">""" Masked dot product self attention.</span></span>
<span id="cb6-3"><span class="co" style="color: #5E5E5E;">    Args:</span></span>
<span id="cb6-4"><span class="co" style="color: #5E5E5E;">        q (numpy.ndarray): queries.</span></span>
<span id="cb6-5"><span class="co" style="color: #5E5E5E;">        k (numpy.ndarray): keys.</span></span>
<span id="cb6-6"><span class="co" style="color: #5E5E5E;">        v (numpy.ndarray): values.</span></span>
<span id="cb6-7"><span class="co" style="color: #5E5E5E;">    Returns:</span></span>
<span id="cb6-8"><span class="co" style="color: #5E5E5E;">        numpy.ndarray: masked dot product self attention tensor.</span></span>
<span id="cb6-9"><span class="co" style="color: #5E5E5E;">    """</span></span>
<span id="cb6-10">    </span>
<span id="cb6-11">    <span class="co" style="color: #5E5E5E;"># Size of the penultimate dimension of the query</span></span>
<span id="cb6-12">    mask_size <span class="op" style="color: #5E5E5E;">=</span> q.shape[<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">2</span>]</span>
<span id="cb6-13"></span>
<span id="cb6-14">    <span class="co" style="color: #5E5E5E;"># Creates a matrix with ones below the diagonal and 0s above. It should have shape (1, mask_size, mask_size)</span></span>
<span id="cb6-15">    <span class="co" style="color: #5E5E5E;"># Use np.tril() - Lower triangle of an array and np.ones()</span></span>
<span id="cb6-16">    mask <span class="op" style="color: #5E5E5E;">=</span> np.tril(np.ones((<span class="dv" style="color: #AD0000;">1</span>, mask_size, mask_size), dtype<span class="op" style="color: #5E5E5E;">=</span>np.bool_), k<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">0</span>)  </span>
<span id="cb6-17">        </span>
<span id="cb6-18">    <span class="cf" style="color: #003B4F;">return</span> DotProductAttention(q, k, v, mask, scale<span class="op" style="color: #5E5E5E;">=</span>scale)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1">dot_product_self_attention(q, k, v)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="6">
<pre><code>array([[[0.        , 1.        , 0.        ],
        [0.84967455, 0.15032545, 0.84967455]]])</code></pre>
</div>
</div>
</section>
<section id="acknowledgements" class="level2" data-number="4">
<h2 data-number="4" class="anchored" data-anchor-id="acknowledgements"><span class="header-section-number">4</span> Acknowledgements</h2>
<p>I’d like to express my thanks to the great <a href="https://www.coursera.org/learn/attention-models-in-nlp">Natural Language Processing with Attention Models Course</a> which i completed, and acknowledge the use of some images and other materials from the course in this article.</p>


</section>

 ]]></description>
  <category>natural-language-processing</category>
  <category>deep-learning</category>
  <category>research-paper-review</category>
  <category>mathematics</category>
  <guid>http://livingdatalab.com/posts/2023-03-04-three-types-of-attention-for-transformer-nlp-models.html</guid>
  <pubDate>Sat, 04 Mar 2023 00:00:00 GMT</pubDate>
  <media:content url="https://github.com/pranath/blog/raw/master/images/arxiv.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Improving seq2seq Language Models using Scaled Dot-Product Attention</title>
  <dc:creator>Pranath Fernando</dc:creator>
  <link>http://livingdatalab.com/posts/2023-03-02-improving-seq2seq-language-models-using-dot-product-attention.html</link>
  <description><![CDATA[ 




<section id="introduction" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="introduction"><span class="header-section-number">1</span> Introduction</h2>
<p>In an <a href="2023-03-01-improving-seq2seq-language-models-using-basic-attention.html">earlier article</a> we looked at the simple attention model used for language translation introduced in the Bhadanau, et al.&nbsp;(2014) paper.</p>
<p>The 2017 paper <a href="https://arxiv.org/abs/1706.03762">Attention Is All You Need</a> introduced the Transformer model and scaled dot-product attention, sometimes also called QKV (<strong>Q</strong>ueries, <strong>K</strong>eys, <strong>V</strong>alues) attention. Since then, Transformers have come to dominate large-scale natural language applications. Scaled dot-product attention can be used to improve seq2seq models as well. In this article, we’ll implement a simplified version of scaled dot-product attention and replicate word alignment between English and French, as shown in <a href="https://arxiv.org/abs/1409.0473">Bhadanau, et al.&nbsp;(2014)</a>.</p>
</section>
<section id="import-libraries-setup" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="import-libraries-setup"><span class="header-section-number">2</span> Import Libraries &amp; Setup</h2>
<p>A Transformer model can learn how to align words in different languages. We won’t be training any weights here, so we’ve prepared some <a href="https://fasttext.cc/docs/en/aligned-vectors.html">pre-trained aligned word embeddings from here</a>.</p>
<div class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;">import</span> pickle</span>
<span id="cb1-2"><span class="im" style="color: #00769E;">import</span> matplotlib.pyplot <span class="im" style="color: #00769E;">as</span> plt</span>
<span id="cb1-3"><span class="im" style="color: #00769E;">import</span> numpy <span class="im" style="color: #00769E;">as</span> np</span>
<span id="cb1-4"></span>
<span id="cb1-5"><span class="co" style="color: #5E5E5E;"># Load the word2int dictionaries</span></span>
<span id="cb1-6"><span class="cf" style="color: #003B4F;">with</span> <span class="bu" style="color: null;">open</span>(<span class="st" style="color: #20794D;">"./data/word2int_en.pkl"</span>, <span class="st" style="color: #20794D;">"rb"</span>) <span class="im" style="color: #00769E;">as</span> f:</span>
<span id="cb1-7">    en_words <span class="op" style="color: #5E5E5E;">=</span> pickle.load(f)</span>
<span id="cb1-8">    </span>
<span id="cb1-9"><span class="cf" style="color: #003B4F;">with</span> <span class="bu" style="color: null;">open</span>(<span class="st" style="color: #20794D;">"./data/word2int_fr.pkl"</span>, <span class="st" style="color: #20794D;">"rb"</span>) <span class="im" style="color: #00769E;">as</span> f:</span>
<span id="cb1-10">    fr_words <span class="op" style="color: #5E5E5E;">=</span> pickle.load(f)</span>
<span id="cb1-11"></span>
<span id="cb1-12"><span class="co" style="color: #5E5E5E;"># Load the word embeddings</span></span>
<span id="cb1-13">en_embeddings <span class="op" style="color: #5E5E5E;">=</span> np.load(<span class="st" style="color: #20794D;">"./data/embeddings_en.npz"</span>)[<span class="st" style="color: #20794D;">"embeddings"</span>]</span>
<span id="cb1-14">fr_embeddings <span class="op" style="color: #5E5E5E;">=</span> np.load(<span class="st" style="color: #20794D;">"./data/embeddings_fr.npz"</span>)[<span class="st" style="color: #20794D;">"embeddings"</span>]</span>
<span id="cb1-15"></span>
<span id="cb1-16"><span class="kw" style="color: #003B4F;">def</span> tokenize(sentence, token_mapping):</span>
<span id="cb1-17">    tokenized <span class="op" style="color: #5E5E5E;">=</span> []</span>
<span id="cb1-18">    </span>
<span id="cb1-19">    <span class="cf" style="color: #003B4F;">for</span> word <span class="kw" style="color: #003B4F;">in</span> sentence.lower().split(<span class="st" style="color: #20794D;">" "</span>):</span>
<span id="cb1-20">        <span class="cf" style="color: #003B4F;">try</span>:</span>
<span id="cb1-21">            tokenized.append(token_mapping[word])</span>
<span id="cb1-22">        <span class="cf" style="color: #003B4F;">except</span> <span class="pp" style="color: #AD0000;">KeyError</span>:</span>
<span id="cb1-23">            <span class="co" style="color: #5E5E5E;"># Using -1 to indicate an unknown word</span></span>
<span id="cb1-24">            tokenized.append(<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>)</span>
<span id="cb1-25">        </span>
<span id="cb1-26">    <span class="cf" style="color: #003B4F;">return</span> tokenized</span>
<span id="cb1-27"></span>
<span id="cb1-28"><span class="kw" style="color: #003B4F;">def</span> embed(tokens, embeddings):</span>
<span id="cb1-29">    embed_size <span class="op" style="color: #5E5E5E;">=</span> embeddings.shape[<span class="dv" style="color: #AD0000;">1</span>]</span>
<span id="cb1-30">    </span>
<span id="cb1-31">    output <span class="op" style="color: #5E5E5E;">=</span> np.zeros((<span class="bu" style="color: null;">len</span>(tokens), embed_size))</span>
<span id="cb1-32">    <span class="cf" style="color: #003B4F;">for</span> i, token <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">enumerate</span>(tokens):</span>
<span id="cb1-33">        <span class="cf" style="color: #003B4F;">if</span> token <span class="op" style="color: #5E5E5E;">==</span> <span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>:</span>
<span id="cb1-34">            output[i] <span class="op" style="color: #5E5E5E;">=</span> np.zeros((<span class="dv" style="color: #AD0000;">1</span>, embed_size))</span>
<span id="cb1-35">        <span class="cf" style="color: #003B4F;">else</span>:</span>
<span id="cb1-36">            output[i] <span class="op" style="color: #5E5E5E;">=</span> embeddings[token]</span>
<span id="cb1-37">            </span>
<span id="cb1-38">    <span class="cf" style="color: #003B4F;">return</span> output</span></code></pre></div>
</div>
</section>
<section id="scaled-dot-product-attention" class="level2" data-number="3">
<h2 data-number="3" class="anchored" data-anchor-id="scaled-dot-product-attention"><span class="header-section-number">3</span> Scaled Dot-Product Attention</h2>
<p>The scaled-dot product attention consists of two matrix multiplications and a softmax scaling as shown in the diagram below from <a href="https://arxiv.org/abs/1706.03762">Vaswani, et al.&nbsp;(2017)</a>. It takes three input matrices, the queries, keys, and values.</p>
<p><img src="http://livingdatalab.com/posts/https:/github.com/pranath/blog/raw/master/images/attention.png" title="Scaled-dot product attention" class="img-fluid"></p>
<p>Mathematically, this is expressed as</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Clarge%20%5Cmathrm%7BAttention%7D%5Cleft(Q,%20K,%20V%5Cright)%20=%20%5Cmathrm%7Bsoftmax%7D%5Cleft(%5Cfrac%7BQK%5E%7B%5Ctop%7D%7D%7B%5Csqrt%7Bd_k%7D%7D%5Cright)V%0A"></p>
<p>where <img src="https://latex.codecogs.com/png.latex?Q">, <img src="https://latex.codecogs.com/png.latex?K">, and <img src="https://latex.codecogs.com/png.latex?V"> are the queries, keys, and values matrices respectively, and <img src="https://latex.codecogs.com/png.latex?d_k"> is the dimension of the keys. In practice, Q, K, and V all have the same dimensions. This form of attention is faster and more space-efficient than what <a href="2023-03-01-improving-seq2seq-language-models-using-basic-attention.html">we implemented before with the simple attention of Bhadanau, et al.&nbsp;(2014)</a> since it consists of only matrix multiplications instead of a learned feed-forward layer.</p>
<p>Conceptually, the first matrix multiplication is a measure of the similarity between the queries and the keys. This is transformed into weights using the softmax function. These weights are then applied to the values with the second matrix multiplication resulting in output attention vectors. Typically, decoder states are used as the queries while encoder states are the keys and values.</p>
<p>We will implement the softmax function with Numpy and use it to calculate the weights from the queries and keys. Let’s assume the queries and keys are 2D arrays (matrices). Note that since the dot-product of Q and K will be a matrix, we’ll need to take care to calculate softmax over a specific axis.</p>
<div class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="kw" style="color: #003B4F;">def</span> softmax(x, axis<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">0</span>):    </span>
<span id="cb2-2">    <span class="co" style="color: #5E5E5E;">""" Calculate softmax function for an array x</span></span>
<span id="cb2-3"></span>
<span id="cb2-4"><span class="co" style="color: #5E5E5E;">        axis=0 calculates softmax across rows which means each column sums to 1 </span></span>
<span id="cb2-5"><span class="co" style="color: #5E5E5E;">        axis=1 calculates softmax across columns which means each row sums to 1</span></span>
<span id="cb2-6"><span class="co" style="color: #5E5E5E;">    """</span></span>
<span id="cb2-7">    y <span class="op" style="color: #5E5E5E;">=</span> np.exp(x) </span>
<span id="cb2-8">    <span class="cf" style="color: #003B4F;">return</span> y <span class="op" style="color: #5E5E5E;">/</span> np.expand_dims(np.<span class="bu" style="color: null;">sum</span>(y, axis<span class="op" style="color: #5E5E5E;">=</span>axis), axis)</span>
<span id="cb2-9"></span>
<span id="cb2-10"><span class="kw" style="color: #003B4F;">def</span> calculate_weights(queries, keys):</span>
<span id="cb2-11">    <span class="co" style="color: #5E5E5E;">""" Calculate the weights for scaled dot-product attention"""</span></span>
<span id="cb2-12">    dot <span class="op" style="color: #5E5E5E;">=</span> np.matmul(queries, keys.T)<span class="op" style="color: #5E5E5E;">/</span>np.sqrt(keys.shape[<span class="dv" style="color: #AD0000;">1</span>])</span>
<span id="cb2-13">    weights <span class="op" style="color: #5E5E5E;">=</span> softmax(dot, axis<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">1</span>)</span>
<span id="cb2-14">    </span>
<span id="cb2-15">    <span class="cf" style="color: #003B4F;">assert</span> weights.<span class="bu" style="color: null;">sum</span>(axis<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">1</span>)[<span class="dv" style="color: #AD0000;">0</span>] <span class="op" style="color: #5E5E5E;">==</span> <span class="dv" style="color: #AD0000;">1</span>, <span class="st" style="color: #20794D;">"Each row in weights must sum to 1"</span></span>
<span id="cb2-16">    </span>
<span id="cb2-17">    <span class="cf" style="color: #003B4F;">return</span> weights</span></code></pre></div>
</div>
<div class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><span class="co" style="color: #5E5E5E;"># Tokenize example sentences in English and French, then get their embeddings</span></span>
<span id="cb3-2">sentence_en <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">"The agreement on the European Economic Area was signed in August 1992 ."</span></span>
<span id="cb3-3">tokenized_en <span class="op" style="color: #5E5E5E;">=</span> tokenize(sentence_en, en_words)</span>
<span id="cb3-4">embedded_en <span class="op" style="color: #5E5E5E;">=</span> embed(tokenized_en, en_embeddings)</span>
<span id="cb3-5"></span>
<span id="cb3-6">sentence_fr <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">"L accord sur la zone économique européenne a été signé en août 1992 ."</span></span>
<span id="cb3-7">tokenized_fr <span class="op" style="color: #5E5E5E;">=</span> tokenize(sentence_fr, fr_words)</span>
<span id="cb3-8">embedded_fr <span class="op" style="color: #5E5E5E;">=</span> embed(tokenized_fr, fr_embeddings)</span>
<span id="cb3-9"></span>
<span id="cb3-10"><span class="co" style="color: #5E5E5E;"># These weights indicate alignment between words in English and French</span></span>
<span id="cb3-11">alignment <span class="op" style="color: #5E5E5E;">=</span> calculate_weights(embedded_fr, embedded_en)</span>
<span id="cb3-12"></span>
<span id="cb3-13"><span class="co" style="color: #5E5E5E;"># Visualize weights to check for alignment</span></span>
<span id="cb3-14">fig, ax <span class="op" style="color: #5E5E5E;">=</span> plt.subplots(figsize<span class="op" style="color: #5E5E5E;">=</span>(<span class="dv" style="color: #AD0000;">7</span>,<span class="dv" style="color: #AD0000;">7</span>))</span>
<span id="cb3-15">ax.imshow(alignment, cmap<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'gray'</span>)</span>
<span id="cb3-16">ax.xaxis.tick_top()</span>
<span id="cb3-17">ax.set_xticks(np.arange(alignment.shape[<span class="dv" style="color: #AD0000;">1</span>]))</span>
<span id="cb3-18">ax.set_xticklabels(sentence_en.split(<span class="st" style="color: #20794D;">" "</span>), rotation<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">90</span>, size<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">16</span>)<span class="op" style="color: #5E5E5E;">;</span></span>
<span id="cb3-19">ax.set_yticks(np.arange(alignment.shape[<span class="dv" style="color: #AD0000;">0</span>]))<span class="op" style="color: #5E5E5E;">;</span></span>
<span id="cb3-20">ax.set_yticklabels(sentence_fr.split(<span class="st" style="color: #20794D;">" "</span>), size<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">16</span>)<span class="op" style="color: #5E5E5E;">;</span></span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="http://livingdatalab.com/posts/2023-03-02-improving-seq2seq-language-models-using-dot-product-attention_files/figure-html/cell-4-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>This is a demonstration of alignment where the model has learned which words in English correspond to words in French. For example, the words <em>signed</em> and <em>signé</em> have a large weight because they have the same meaning. Typically, these alignments are learned using linear layers in the model, but we’ve used pre-trained embeddings here.</p>
<p>Let’s now complete the implementation of scaled dot-product attention using our <code>calculate_weights</code> function.</p>
<div class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><span class="kw" style="color: #003B4F;">def</span> attention_qkv(queries, keys, values):</span>
<span id="cb4-2">    <span class="co" style="color: #5E5E5E;">""" Calculate scaled dot-product attention from queries, keys, and values matrices """</span></span>
<span id="cb4-3">    </span>
<span id="cb4-4">    weights <span class="op" style="color: #5E5E5E;">=</span> calculate_weights(queries, keys)</span>
<span id="cb4-5">    <span class="cf" style="color: #003B4F;">return</span> np.matmul(weights, values)</span>
<span id="cb4-6"></span>
<span id="cb4-7"></span>
<span id="cb4-8">attention_qkv_result <span class="op" style="color: #5E5E5E;">=</span> attention_qkv(embedded_fr, embedded_en, embedded_en)</span>
<span id="cb4-9"></span>
<span id="cb4-10"><span class="bu" style="color: null;">print</span>(<span class="ss" style="color: #20794D;">f"The shape of the attention_qkv function is&nbsp;</span><span class="sc" style="color: #5E5E5E;">{</span>attention_qkv_result<span class="sc" style="color: #5E5E5E;">.</span>shape<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">"</span>)</span>
<span id="cb4-11"><span class="bu" style="color: null;">print</span>(<span class="ss" style="color: #20794D;">f"Some elements of the attention_qkv function are&nbsp;</span><span class="ch" style="color: #20794D;">\n</span><span class="sc" style="color: #5E5E5E;">{</span>attention_qkv_result[<span class="dv" style="color: #AD0000;">0</span>:<span class="dv" style="color: #AD0000;">2</span>,:<span class="dv" style="color: #AD0000;">10</span>]<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">"</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>The shape of the attention_qkv function is&nbsp;(14, 300)
Some elements of the attention_qkv function are&nbsp;
[[-0.04039161 -0.00275749  0.00389873  0.04842744 -0.02472726  0.01435613
  -0.00370253 -0.0619686  -0.00206159  0.01615228]
 [-0.04083253 -0.00245985  0.00409068  0.04830341 -0.02479128  0.01447497
  -0.00355203 -0.06196036 -0.00241327  0.01582606]]</code></pre>
</div>
</div>
</section>
<section id="acknowledgements" class="level2" data-number="4">
<h2 data-number="4" class="anchored" data-anchor-id="acknowledgements"><span class="header-section-number">4</span> Acknowledgements</h2>
<p>I’d like to express my thanks to the great <a href="https://www.coursera.org/learn/attention-models-in-nlp">Natural Language Processing with Attention Models Course</a> which i completed, and acknowledge the use of some images and other materials from the course in this article.</p>


</section>

 ]]></description>
  <category>natural-language-processing</category>
  <category>deep-learning</category>
  <category>research-paper-review</category>
  <category>mathematics</category>
  <guid>http://livingdatalab.com/posts/2023-03-02-improving-seq2seq-language-models-using-dot-product-attention.html</guid>
  <pubDate>Thu, 02 Mar 2023 00:00:00 GMT</pubDate>
  <media:content url="https://github.com/pranath/blog/raw/master/images/arxiv.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Improving seq2seq Language Models using Basic Attention</title>
  <dc:creator>Pranath Fernando</dc:creator>
  <link>http://livingdatalab.com/posts/2023-03-01-improving-seq2seq-language-models-using-basic-attention.html</link>
  <description><![CDATA[ 




<section id="introduction" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="introduction"><span class="header-section-number">1</span> Introduction</h2>
<p>As of 2023, in deep learning the Transformer model architecture has been behind many recent advances in deep learning model performance in many areas including Natural Language Processing and Computer Vision. An <strong>Attention</strong> mechanism is a key part of Transformer architecture. Attention was first introduced by <a href="https://arxiv.org/abs/1409.0473">Bhadanau, et al (2014)</a> as a method for improving seq2seq language models.</p>
<p>In this article we will look at this first use of an attention mechanism as proposed by <a href="https://arxiv.org/abs/1409.0473">Bhadanau, et al (2014)</a> and implement it in NumPy.</p>
<p>Attention allows a seq2seq decoder to use information from each encoder step instead of just the final encoder hidden state. In the attention operation, the encoder outputs are weighted based on the decoder hidden state, then combined into one context vector. This vector is then used as input to the decoder to predict the next output step.</p>
</section>
<section id="machine-translation-and-the-information-bottleneck" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="machine-translation-and-the-information-bottleneck"><span class="header-section-number">2</span> Machine translation and the ‘Information Bottleneck’</h2>
<p>The traditional seq2seq model was introduced by Google in 2014 and it was a revolution at the time for helping with Machine Translation from text in one language to another. Basically, it works by taking one sequence of items such as words and its output, is another sequence. The way this is done is by mapping variable length sequences to a fixed length memory, which in machine translation, encodes the overall meaning of sentences. For example, you can have a text of length that varies and you can encode it into a vector or fixed dimension like 300, for example. This feature is what’s made this model a powerhouse for machine translation. Additionally, the inputs and outputs don’t need to have matching lengths, which is a desirable feature when translating texts.</p>
<p><img src="http://livingdatalab.com/posts/https:/github.com/pranath/blog/raw/master/images/seq2seq-6.png" title="Seq2Seq Models" class="img-fluid"></p>
<p>In a seq2seq model, you have an encoder and a decoder. The encoder takes word tokens as input, and it returns its final hidden states as outputs.</p>
<p><img src="http://livingdatalab.com/posts/https:/github.com/pranath/blog/raw/master/images/seq2seq-5.png" title="Seq2Seq Models" class="img-fluid"></p>
<p>This hidden state is used by the decoder to generate the translated sentence in the target language.</p>
<p><img src="http://livingdatalab.com/posts/https:/github.com/pranath/blog/raw/master/images/seq2seq-4.png" title="Seq2Seq Models" class="img-fluid"></p>
<p>One major limitation of the traditional seq2seq model is what’s referred to as the <strong>information bottleneck</strong>. Since seq2seq uses a fixed length memory for the hidden states, long sequences become problematic. This is due to the fact that in traditional seq2seq models, only a fixed amount of information can be passed from the encoder to the decoder no matter how much information is contained in the input sequence.</p>
<p><img src="http://livingdatalab.com/posts/https:/github.com/pranath/blog/raw/master/images/seq2seq-3.png" title="Seq2Seq Models" class="img-fluid"></p>
<p>The power of seq2seq, which allows for inputs and outputs to be different sizes, becomes not effective when the input sequence is long. The result is lower model performance, a sequence size increases and that’s no good. The issue with having one fixed size encoder hidden states is that it struggles to compress longer sequences and it ends up throttling itself and punishing the decoder who only wants to make a good prediction. One workaround is to use the encoder hidden states for each word instead of trying to smash it all into one big vector. But this model would have flaws with memory and contexts.</p>
<p><img src="http://livingdatalab.com/posts/https:/github.com/pranath/blog/raw/master/images/seq2seq-2.png" title="Seq2Seq Models" class="img-fluid"></p>
<p>How could you build a time and memory efficient model that predicts accurately from a long sequence? This becomes possible if the model has a way to select and focus on the most important words at each time step. We can think of this as giving the model a new layer to process this information, which we call <strong>Attention</strong>. If we provide the information specific to each input word, you can give the model a way to focus it’s attention in the right place at each step of the decoding process.</p>
<p>Seq2seq models perform well for sentences with about 10-20 words, but they fall off beyond that. This is what you should expect. These are the results from the <a href="https://arxiv.org/abs/1409.0473">Bhadanau, et al (2014)</a> paper comparing models with and without attention.</p>
<p><img src="http://livingdatalab.com/posts/https:/github.com/pranath/blog/raw/master/images/seq2seq-1.png" title="Seq2Seq Models" class="img-fluid"></p>
<p>The models with attention perform better than the traditional Seq2Seq models across all sentence lengths.</p>
</section>
<section id="import-libraries-setup" class="level2" data-number="3">
<h2 data-number="3" class="anchored" data-anchor-id="import-libraries-setup"><span class="header-section-number">3</span> Import Libraries &amp; Setup</h2>
<p>Let’s import NumPy and define a softmax function we will use later.</p>
<div class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="co" style="color: #5E5E5E;"># Run this first, a bit of setup for the rest of the lab</span></span>
<span id="cb1-2"><span class="im" style="color: #00769E;">import</span> numpy <span class="im" style="color: #00769E;">as</span> np</span>
<span id="cb1-3"></span>
<span id="cb1-4"><span class="kw" style="color: #003B4F;">def</span> softmax(x, axis<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">0</span>):</span>
<span id="cb1-5">    <span class="co" style="color: #5E5E5E;">""" Calculate softmax function for an array x along specified axis</span></span>
<span id="cb1-6"><span class="co" style="color: #5E5E5E;">    </span></span>
<span id="cb1-7"><span class="co" style="color: #5E5E5E;">        axis=0 calculates softmax across rows which means each column sums to 1 </span></span>
<span id="cb1-8"><span class="co" style="color: #5E5E5E;">        axis=1 calculates softmax across columns which means each row sums to 1</span></span>
<span id="cb1-9"><span class="co" style="color: #5E5E5E;">    """</span></span>
<span id="cb1-10">    <span class="cf" style="color: #003B4F;">return</span> np.exp(x) <span class="op" style="color: #5E5E5E;">/</span> np.expand_dims(np.<span class="bu" style="color: null;">sum</span>(np.exp(x), axis<span class="op" style="color: #5E5E5E;">=</span>axis), axis)</span></code></pre></div>
</div>
</section>
<section id="calculating-alignment-scores" class="level2" data-number="4">
<h2 data-number="4" class="anchored" data-anchor-id="calculating-alignment-scores"><span class="header-section-number">4</span> Calculating alignment scores</h2>
<p>The first step is to calculate the alignment scores. This is a measure of similarity between the decoder hidden state and each encoder hidden state. From the paper Appendix Section A.1.2, this operation looks like</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Clarge%20e_%7Bij%7D%20=%20v_a%5E%5Ctop%20%5Ctanh%7B%5Cleft(W_a%20s_%7Bi-1%7D%20+%20U_a%20h_j%5Cright)%7D%0A"></p>
<p>where <img src="https://latex.codecogs.com/png.latex?W_a%20%5Cin%20%5Cmathbb%7BR%7D%5E%7Bn%5Ctimes%20m%7D">, <img src="https://latex.codecogs.com/png.latex?U_a%20%5Cin%20%5Cmathbb%7BR%7D%5E%7Bn%20%5Ctimes%20m%7D">, and <img src="https://latex.codecogs.com/png.latex?v_a%20%5Cin%20%5Cmathbb%7BR%7D%5Em"> are the weight matrices and <img src="https://latex.codecogs.com/png.latex?n"> is the hidden state size. In practice, this is implemented as a feedforward neural network with two layers, where <img src="https://latex.codecogs.com/png.latex?m"> is the size of the layers in the alignment network. It looks something like:</p>
<p><img src="http://livingdatalab.com/posts/https:/github.com/pranath/blog/raw/master/images/alignment_model_3.png" title="alignment model" class="img-fluid"></p>
<p>Here <img src="https://latex.codecogs.com/png.latex?h_j"> are the encoder hidden states for each input step <img src="https://latex.codecogs.com/png.latex?j"> and <img src="https://latex.codecogs.com/png.latex?s_%7Bi%20-%201%7D"> is the decoder hidden state of the previous step. The first layer corresponds to <img src="https://latex.codecogs.com/png.latex?W_a"> and <img src="https://latex.codecogs.com/png.latex?U_a">, while the second layer corresponds to <img src="https://latex.codecogs.com/png.latex?v_a">.</p>
<p>To implement this, lets first concatenate the encoder and decoder hidden states to produce an array with size <img src="https://latex.codecogs.com/png.latex?K%20%5Ctimes%202n"> where <img src="https://latex.codecogs.com/png.latex?K"> is the number of encoder states/steps. For this, we use <code>np.concatenate</code> (<a href="https://numpy.org/doc/stable/reference/generated/numpy.concatenate.html">docs</a>). Note that there is only one decoder state so we’ll need to reshape it to successfully concatenate the arrays. The easiest way is to use <code>decoder_state.repeat</code> (<a href="https://numpy.org/doc/stable/reference/generated/numpy.repeat.html#numpy.repeat">docs</a>) to match the hidden state array size.</p>
<p>Then, we apply the first layer as a matrix multiplication between the weights and the concatenated input. We will use the tanh function to get the activations. Finally, we compute the matrix multiplication of the second layer weights and the activations. This returns the alignment scores.</p>
<div class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1">hidden_size <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">16</span></span>
<span id="cb2-2">attention_size <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">10</span></span>
<span id="cb2-3">input_length <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">5</span></span>
<span id="cb2-4"></span>
<span id="cb2-5">np.random.seed(<span class="dv" style="color: #AD0000;">42</span>)</span>
<span id="cb2-6"></span>
<span id="cb2-7"><span class="co" style="color: #5E5E5E;"># Synthetic vectors used to test</span></span>
<span id="cb2-8">encoder_states <span class="op" style="color: #5E5E5E;">=</span> np.random.randn(input_length, hidden_size)</span>
<span id="cb2-9">decoder_state <span class="op" style="color: #5E5E5E;">=</span> np.random.randn(<span class="dv" style="color: #AD0000;">1</span>, hidden_size)</span>
<span id="cb2-10"></span>
<span id="cb2-11"><span class="co" style="color: #5E5E5E;"># Weights for the neural network, these are typically learned through training</span></span>
<span id="cb2-12"><span class="co" style="color: #5E5E5E;"># Use these in the alignment function below as the layer weights</span></span>
<span id="cb2-13">layer_1 <span class="op" style="color: #5E5E5E;">=</span> np.random.randn(<span class="dv" style="color: #AD0000;">2</span><span class="op" style="color: #5E5E5E;">*</span>hidden_size, attention_size)</span>
<span id="cb2-14">layer_2 <span class="op" style="color: #5E5E5E;">=</span> np.random.randn(attention_size, <span class="dv" style="color: #AD0000;">1</span>)</span>
<span id="cb2-15"></span>
<span id="cb2-16"><span class="co" style="color: #5E5E5E;"># Alignment function</span></span>
<span id="cb2-17"><span class="kw" style="color: #003B4F;">def</span> alignment(encoder_states, decoder_state):</span>
<span id="cb2-18">    <span class="co" style="color: #5E5E5E;"># First, concatenate the encoder states and the decoder state</span></span>
<span id="cb2-19">    inputs <span class="op" style="color: #5E5E5E;">=</span> np.concatenate((encoder_states, decoder_state.repeat(input_length, axis<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">0</span>)), axis<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">1</span>)</span>
<span id="cb2-20">    <span class="cf" style="color: #003B4F;">assert</span> inputs.shape <span class="op" style="color: #5E5E5E;">==</span> (input_length, <span class="dv" style="color: #AD0000;">2</span><span class="op" style="color: #5E5E5E;">*</span>hidden_size)</span>
<span id="cb2-21">    </span>
<span id="cb2-22">    <span class="co" style="color: #5E5E5E;"># Matrix multiplication of the concatenated inputs and layer_1, with tanh activation</span></span>
<span id="cb2-23">    activations <span class="op" style="color: #5E5E5E;">=</span> np.tanh(np.matmul(inputs, layer_1))</span>
<span id="cb2-24">    <span class="cf" style="color: #003B4F;">assert</span> activations.shape <span class="op" style="color: #5E5E5E;">==</span> (input_length, attention_size)</span>
<span id="cb2-25">    </span>
<span id="cb2-26">    <span class="co" style="color: #5E5E5E;"># Matrix multiplication of the activations with layer_2. We don't need tanh here</span></span>
<span id="cb2-27">    scores <span class="op" style="color: #5E5E5E;">=</span> np.matmul(activations, layer_2)</span>
<span id="cb2-28">    <span class="cf" style="color: #003B4F;">assert</span> scores.shape <span class="op" style="color: #5E5E5E;">==</span> (input_length, <span class="dv" style="color: #AD0000;">1</span>)</span>
<span id="cb2-29">    </span>
<span id="cb2-30">    <span class="cf" style="color: #003B4F;">return</span> scores</span></code></pre></div>
</div>
<div class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><span class="co" style="color: #5E5E5E;"># Run to test the alignment function</span></span>
<span id="cb3-2">scores <span class="op" style="color: #5E5E5E;">=</span> alignment(encoder_states, decoder_state)</span>
<span id="cb3-3"><span class="bu" style="color: null;">print</span>(scores)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[[4.35790943]
 [5.92373433]
 [4.18673175]
 [2.11437202]
 [0.95767155]]</code></pre>
</div>
</div>
</section>
<section id="turning-alignment-into-weights" class="level2" data-number="5">
<h2 data-number="5" class="anchored" data-anchor-id="turning-alignment-into-weights"><span class="header-section-number">5</span> Turning alignment into weights</h2>
<p>The next step is to calculate the weights from the alignment scores. These weights determine the encoder outputs that are the most important for the decoder output. These weights should be between 0 and 1, and add up to 1. We can use the softmax function already implemented to get these weights from the attention scores. We will pass the attention scores vector to the softmax function to get the weights. Mathematically,</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Clarge%20%5Calpha_%7Bij%7D%20=%20%5Cfrac%7B%5Cexp%7B%5Cleft(e_%7Bij%7D%5Cright)%7D%7D%7B%5Csum_%7Bk=1%7D%5EK%20%5Cexp%7B%5Cleft(e_%7Bik%7D%5Cright)%7D%7D%0A"></p>
<p>This is as described in Appendix section A.2.2 of the paper.</p>
</section>
<section id="weight-the-encoder-output-vectors-and-sum" class="level2" data-number="6">
<h2 data-number="6" class="anchored" data-anchor-id="weight-the-encoder-output-vectors-and-sum"><span class="header-section-number">6</span> Weight the encoder output vectors and sum</h2>
<p>The weights tell us the importance of each input word with respect to the decoder state. In this step, we use the weights to modulate the magnitude of the encoder vectors. Words with little importance will be scaled down relative to important words. We will multiply each encoder vector by its respective weight to get the alignment vectors, then sum up the weighted alignment vectors to get the context vector. Mathematically,</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Clarge%20c_i%20=%20%5Csum_%7Bj=1%7D%5EK%5Calpha_%7Bij%7D%20h_%7Bj%7D%0A"></p>
<p>This is as described in Appendix section A.2.2 of the paper.</p>
<p>We wil implement these steps in the <code>attention</code> function below.</p>
<div class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><span class="co" style="color: #5E5E5E;"># Attention function</span></span>
<span id="cb5-2"><span class="kw" style="color: #003B4F;">def</span> attention(encoder_states, decoder_state):</span>
<span id="cb5-3">    <span class="co" style="color: #5E5E5E;">""" Function that calculates attention, returns the context vector </span></span>
<span id="cb5-4"><span class="co" style="color: #5E5E5E;">    </span></span>
<span id="cb5-5"><span class="co" style="color: #5E5E5E;">        Arguments:</span></span>
<span id="cb5-6"><span class="co" style="color: #5E5E5E;">        encoder_vectors: NxM numpy array, where N is the number of vectors and M is the vector length</span></span>
<span id="cb5-7"><span class="co" style="color: #5E5E5E;">        decoder_vector: 1xM numpy array, M is the vector length, much be the same M as encoder_vectors</span></span>
<span id="cb5-8"><span class="co" style="color: #5E5E5E;">    """</span> </span>
<span id="cb5-9">    </span>
<span id="cb5-10">    <span class="co" style="color: #5E5E5E;"># First, calculate the alignment scores</span></span>
<span id="cb5-11">    scores <span class="op" style="color: #5E5E5E;">=</span> alignment(encoder_states, decoder_state)</span>
<span id="cb5-12">    </span>
<span id="cb5-13">    <span class="co" style="color: #5E5E5E;"># Then take the softmax of the alignment scores to get a weight distribution</span></span>
<span id="cb5-14">    weights <span class="op" style="color: #5E5E5E;">=</span> softmax(scores)</span>
<span id="cb5-15">    </span>
<span id="cb5-16">    <span class="co" style="color: #5E5E5E;"># Multiply each encoder state by its respective weight</span></span>
<span id="cb5-17">    weighted_scores <span class="op" style="color: #5E5E5E;">=</span> encoder_states <span class="op" style="color: #5E5E5E;">*</span> weights</span>
<span id="cb5-18">    </span>
<span id="cb5-19">    <span class="co" style="color: #5E5E5E;"># Sum up weighted alignment vectors to get the context vector and return it</span></span>
<span id="cb5-20">    context <span class="op" style="color: #5E5E5E;">=</span> np.<span class="bu" style="color: null;">sum</span>(weighted_scores, axis<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">0</span>)</span>
<span id="cb5-21">    <span class="cf" style="color: #003B4F;">return</span> context</span>
<span id="cb5-22"></span>
<span id="cb5-23">context_vector <span class="op" style="color: #5E5E5E;">=</span> attention(encoder_states, decoder_state)</span>
<span id="cb5-24"><span class="bu" style="color: null;">print</span>(context_vector)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[-0.63514569  0.04917298 -0.43930867 -0.9268003   1.01903919 -0.43181409
  0.13365099 -0.84746874 -0.37572203  0.18279832 -0.90452701  0.17872958
 -0.58015282 -0.58294027 -0.75457577  1.32985756]</code></pre>
</div>
</div>
<p>This context vector created using the new attention process will hold much more useful information relevant for producing more accurate output and better translations by the decoder of the Seq2Seq model.</p>
</section>
<section id="acknowledgements" class="level2" data-number="7">
<h2 data-number="7" class="anchored" data-anchor-id="acknowledgements"><span class="header-section-number">7</span> Acknowledgements</h2>
<p>I’d like to express my thanks to the great <a href="https://www.coursera.org/learn/attention-models-in-nlp">Natural Language Processing with Attention Models Course</a> which i completed, and acknowledge the use of some images and other materials from the course in this article.</p>


</section>

 ]]></description>
  <category>natural-language-processing</category>
  <category>deep-learning</category>
  <category>research-paper-review</category>
  <category>mathematics</category>
  <guid>http://livingdatalab.com/posts/2023-03-01-improving-seq2seq-language-models-using-basic-attention.html</guid>
  <pubDate>Wed, 01 Mar 2023 00:00:00 GMT</pubDate>
  <media:content url="https://github.com/pranath/blog/raw/master/images/arxiv.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Custom Models and human-in-the-loop pipelines with AWS Augmented AI (A2I)</title>
  <dc:creator>Pranath Fernando</dc:creator>
  <link>http://livingdatalab.com/posts/2023-02-24-custom-models-human-loop-pipelines-aws-augmented-ai.html</link>
  <description><![CDATA[ 




<section id="introduction" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="introduction"><span class="header-section-number">1</span> Introduction</h2>
<p>In <a href="../#category=aws">earlier articles we introduced AWS cloud services for data science</a>, and showed how it can help with different stages of the data science &amp; machine learning workflow.</p>
<p><img src="http://livingdatalab.com/posts/https:/github.com/pranath/blog/raw/master/images/aws_ds_workflow.png" title="The AWS Data Science Workflow" class="img-fluid"></p>
<p>In this project we will create our own human workforce, a human task UI, and then define the human review workflow to perform data labeling for an ML task. We will make the original predictions of the labels with the custom ML model, and then create a human loop if the probability scores are lower than the preset threshold. After the completion of the human loop tasks, we will review the results and prepare data for re-training.</p>
<p>Let’s install and import the required modules.</p>
<div class="cell" data-tags="[]" data-execution_count="10">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;">import</span> boto3</span>
<span id="cb1-2"><span class="im" style="color: #00769E;">import</span> sagemaker</span>
<span id="cb1-3"><span class="im" style="color: #00769E;">import</span> pandas <span class="im" style="color: #00769E;">as</span> pd</span>
<span id="cb1-4"><span class="im" style="color: #00769E;">from</span> pprint <span class="im" style="color: #00769E;">import</span> pprint</span>
<span id="cb1-5"><span class="im" style="color: #00769E;">import</span> botocore</span>
<span id="cb1-6"></span>
<span id="cb1-7">config <span class="op" style="color: #5E5E5E;">=</span> botocore.config.Config(user_agent_extra<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'dlai-pds/c3/w3'</span>)</span>
<span id="cb1-8"></span>
<span id="cb1-9"><span class="co" style="color: #5E5E5E;"># low-level service client of the boto3 session</span></span>
<span id="cb1-10">sm <span class="op" style="color: #5E5E5E;">=</span> boto3.client(service_name<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'sagemaker'</span>, </span>
<span id="cb1-11">                  config<span class="op" style="color: #5E5E5E;">=</span>config)</span>
<span id="cb1-12"></span>
<span id="cb1-13">sm_runtime <span class="op" style="color: #5E5E5E;">=</span> boto3.client(<span class="st" style="color: #20794D;">'sagemaker-runtime'</span>,</span>
<span id="cb1-14">                          config<span class="op" style="color: #5E5E5E;">=</span>config)</span>
<span id="cb1-15"></span>
<span id="cb1-16">sess <span class="op" style="color: #5E5E5E;">=</span> sagemaker.Session(sagemaker_client<span class="op" style="color: #5E5E5E;">=</span>sm,</span>
<span id="cb1-17">                         sagemaker_runtime_client<span class="op" style="color: #5E5E5E;">=</span>sm_runtime)</span>
<span id="cb1-18"></span>
<span id="cb1-19">bucket <span class="op" style="color: #5E5E5E;">=</span> sess.default_bucket()</span>
<span id="cb1-20">role <span class="op" style="color: #5E5E5E;">=</span> sagemaker.get_execution_role()</span>
<span id="cb1-21">region <span class="op" style="color: #5E5E5E;">=</span> sess.boto_region_name</span>
<span id="cb1-22"></span>
<span id="cb1-23">s3 <span class="op" style="color: #5E5E5E;">=</span> boto3.Session().client(service_name<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'s3'</span>, </span>
<span id="cb1-24">                            config<span class="op" style="color: #5E5E5E;">=</span>config)</span>
<span id="cb1-25">cognito_idp <span class="op" style="color: #5E5E5E;">=</span> boto3.Session().client(service_name<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'cognito-idp'</span>, </span>
<span id="cb1-26">                                     config<span class="op" style="color: #5E5E5E;">=</span>config)</span>
<span id="cb1-27">a2i <span class="op" style="color: #5E5E5E;">=</span> boto3.Session().client(service_name<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'sagemaker-a2i-runtime'</span>, </span>
<span id="cb1-28">                             config<span class="op" style="color: #5E5E5E;">=</span>config)</span></code></pre></div>
</div>
</section>
<section id="set-up-amazon-cognito-user-pool-and-define-human-workforce" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="set-up-amazon-cognito-user-pool-and-define-human-workforce"><span class="header-section-number">2</span> Set up Amazon Cognito user pool and define human workforce</h2>
<p>The first step in the creation of the human-in-the-loop pipeline will be to create our own private workforce.</p>
<p><img src="http://livingdatalab.com/posts/https:/github.com/pranath/blog/raw/master/images/human-loop-workflow-1-workforce.png" title="Human in the loop workforce" class="img-fluid"></p>
<p>Amazon Cognito provides authentication, authorization, and user management for apps. This enables our workers to sign in directly to the labeling UI with a username and password.</p>
<p>We will construct an Amazon Cognito user pool, setting up its client, domain, and group. Then we’ll create a SageMaker workforce, linking it to the Cognito user pool. Followed by the creation of a SageMaker workteam, linking it to the Cognito user pool and group. And finally, we will create a pool user and add it to the group.</p>
<p>To get started, let’s construct the user pool and user pool client names.</p>
<div class="cell" data-tags="[]" data-execution_count="11">
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="im" style="color: #00769E;">import</span> time</span>
<span id="cb2-2">timestamp <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">int</span>(time.time())</span>
<span id="cb2-3"></span>
<span id="cb2-4">user_pool_name <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">'groundtruth-user-pool-</span><span class="sc" style="color: #5E5E5E;">{}</span><span class="st" style="color: #20794D;">'</span>.<span class="bu" style="color: null;">format</span>(timestamp)</span>
<span id="cb2-5">user_pool_client_name <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">'groundtruth-user-pool-client-</span><span class="sc" style="color: #5E5E5E;">{}</span><span class="st" style="color: #20794D;">'</span>.<span class="bu" style="color: null;">format</span>(timestamp)</span>
<span id="cb2-6"></span>
<span id="cb2-7"><span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">"Amazon Cognito user pool name: </span><span class="sc" style="color: #5E5E5E;">{}</span><span class="st" style="color: #20794D;">"</span>.<span class="bu" style="color: null;">format</span>(user_pool_name))</span>
<span id="cb2-8"><span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">"Amazon Cognito user pool client name: </span><span class="sc" style="color: #5E5E5E;">{}</span><span class="st" style="color: #20794D;">"</span>.<span class="bu" style="color: null;">format</span>(user_pool_client_name))</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Amazon Cognito user pool name: groundtruth-user-pool-1677153775
Amazon Cognito user pool client name: groundtruth-user-pool-client-1677153775</code></pre>
</div>
</div>
<section id="create-amazon-cognito-user-pool" class="level3" data-number="2.1">
<h3 data-number="2.1" class="anchored" data-anchor-id="create-amazon-cognito-user-pool"><span class="header-section-number">2.1</span> Create Amazon Cognito user pool</h3>
<p>The function <code>cognito_idp.create_user_pool</code> creates a new Amazon Cognito user pool. Passing the function result into a variable we can get the information about the response. The result is in dictionary format.</p>
<div class="cell" data-tags="[]" data-execution_count="12">
<div class="sourceCode cell-code" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1">create_user_pool_response <span class="op" style="color: #5E5E5E;">=</span> cognito_idp.create_user_pool(PoolName<span class="op" style="color: #5E5E5E;">=</span>user_pool_name)</span>
<span id="cb4-2">user_pool_id <span class="op" style="color: #5E5E5E;">=</span> create_user_pool_response[<span class="st" style="color: #20794D;">'UserPool'</span>][<span class="st" style="color: #20794D;">'Id'</span>]</span>
<span id="cb4-3"></span>
<span id="cb4-4"><span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">"Amazon Cognito user pool ID: </span><span class="sc" style="color: #5E5E5E;">{}</span><span class="st" style="color: #20794D;">"</span>.<span class="bu" style="color: null;">format</span>(user_pool_id))</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Amazon Cognito user pool ID: us-east-1_8s0SOCEPn</code></pre>
</div>
</div>
<p>Let’s pull the Amazon Cognito user pool name from its description.</p>
<div class="cell" data-tags="[]" data-execution_count="13">
<div class="sourceCode cell-code" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><span class="bu" style="color: null;">print</span>(create_user_pool_response[<span class="st" style="color: #20794D;">'UserPool'</span>].keys())</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>dict_keys(['Id', 'Name', 'Policies', 'DeletionProtection', 'LambdaConfig', 'LastModifiedDate', 'CreationDate', 'SchemaAttributes', 'VerificationMessageTemplate', 'UserAttributeUpdateSettings', 'MfaConfiguration', 'EstimatedNumberOfUsers', 'EmailConfiguration', 'AdminCreateUserConfig', 'Arn'])</code></pre>
</div>
</div>
<div class="cell" data-tags="[]" data-execution_count="14">
<div class="sourceCode cell-code" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1">user_pool_name <span class="op" style="color: #5E5E5E;">=</span> create_user_pool_response[<span class="st" style="color: #20794D;">'UserPool'</span>][<span class="st" style="color: #20794D;">'Name'</span>] </span>
<span id="cb8-2"><span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">'Amazon Cognito user pool name: </span><span class="sc" style="color: #5E5E5E;">{}</span><span class="st" style="color: #20794D;">'</span>.<span class="bu" style="color: null;">format</span>(user_pool_name))</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Amazon Cognito user pool name: groundtruth-user-pool-1677153775</code></pre>
</div>
</div>
</section>
<section id="create-amazon-cognito-user-pool-client" class="level3" data-number="2.2">
<h3 data-number="2.2" class="anchored" data-anchor-id="create-amazon-cognito-user-pool-client"><span class="header-section-number">2.2</span> Create Amazon Cognito user pool client</h3>
<p>Now let’s set up the Amazon Cognito user pool client for the created above user pool.</p>
<p>The Amazon Cognito user pool client implements an open standard for authorization framework, <code>OAuth</code>. The standard enables apps to obtain limited access (scopes) to a user’s data without giving away a user’s password. It decouples authentication from authorization and supports multiple use cases addressing different device capabilities.</p>
<p>Lets create the Amazon Cognito user pool client for the constructed user pool.</p>
<div class="cell" data-tags="[]" data-execution_count="16">
<div class="sourceCode cell-code" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1">create_user_pool_client_response <span class="op" style="color: #5E5E5E;">=</span> cognito_idp.create_user_pool_client( <span class="co" style="color: #5E5E5E;"># Replace None</span></span>
<span id="cb10-2">    UserPoolId<span class="op" style="color: #5E5E5E;">=</span>user_pool_id, </span>
<span id="cb10-3">    ClientName<span class="op" style="color: #5E5E5E;">=</span>user_pool_client_name, </span>
<span id="cb10-4">    GenerateSecret<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>, <span class="co" style="color: #5E5E5E;"># boolean to specify whether you want to generate a secret</span></span>
<span id="cb10-5">    <span class="co" style="color: #5E5E5E;"># a list of provider names for the identity providers that are supported on this client, e.g. Cognito, Facebook, Google</span></span>
<span id="cb10-6">    SupportedIdentityProviders<span class="op" style="color: #5E5E5E;">=</span>[</span>
<span id="cb10-7">        <span class="st" style="color: #20794D;">'COGNITO'</span> </span>
<span id="cb10-8">    ],</span>
<span id="cb10-9">    <span class="co" style="color: #5E5E5E;"># a list of the allowed OAuth flows, e.g. code, implicit, client_credentials</span></span>
<span id="cb10-10">    AllowedOAuthFlows<span class="op" style="color: #5E5E5E;">=</span>[</span>
<span id="cb10-11">        <span class="st" style="color: #20794D;">'code'</span>,</span>
<span id="cb10-12">        <span class="st" style="color: #20794D;">'implicit'</span></span>
<span id="cb10-13">    ],</span>
<span id="cb10-14">    <span class="co" style="color: #5E5E5E;"># a list of the allowed OAuth scopes, e.g. phone, email, openid, and profile</span></span>
<span id="cb10-15">    AllowedOAuthScopes<span class="op" style="color: #5E5E5E;">=</span>[</span>
<span id="cb10-16">        <span class="st" style="color: #20794D;">'email'</span>,</span>
<span id="cb10-17">        <span class="st" style="color: #20794D;">'openid'</span>,</span>
<span id="cb10-18">        <span class="st" style="color: #20794D;">'profile'</span></span>
<span id="cb10-19">    ],</span>
<span id="cb10-20">    <span class="co" style="color: #5E5E5E;"># a list of allowed redirect (callback) URLs for the identity providers</span></span>
<span id="cb10-21">    CallbackURLs<span class="op" style="color: #5E5E5E;">=</span>[</span>
<span id="cb10-22">        <span class="st" style="color: #20794D;">'https://datascienceonaws.com'</span>, </span>
<span id="cb10-23">    ],</span>
<span id="cb10-24">    <span class="co" style="color: #5E5E5E;"># set to true if the client is allowed to follow the OAuth protocol when interacting with Cognito user pools</span></span>
<span id="cb10-25">    AllowedOAuthFlowsUserPoolClient<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span></span>
<span id="cb10-26">)</span>
<span id="cb10-27"></span>
<span id="cb10-28">client_id <span class="op" style="color: #5E5E5E;">=</span> create_user_pool_client_response[<span class="st" style="color: #20794D;">'UserPoolClient'</span>][<span class="st" style="color: #20794D;">'ClientId'</span>]</span>
<span id="cb10-29"><span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">'Amazon Cognito user pool client ID: </span><span class="sc" style="color: #5E5E5E;">{}</span><span class="st" style="color: #20794D;">'</span>.<span class="bu" style="color: null;">format</span>(client_id))</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Amazon Cognito user pool client ID: 4ebq1ga0irfdvssomfjhbh5fgq</code></pre>
</div>
</div>
</section>
<section id="create-amazon-cognito-user-pool-domain-and-group" class="level3" data-number="2.3">
<h3 data-number="2.3" class="anchored" data-anchor-id="create-amazon-cognito-user-pool-domain-and-group"><span class="header-section-number">2.3</span> Create Amazon Cognito user pool domain and group</h3>
<p>Now we set up the Amazon Cognito user pool domain for the constructed user pool.</p>
<div class="cell" data-tags="[]" data-execution_count="17">
<div class="sourceCode cell-code" id="cb12" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1">user_pool_domain_name <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">'groundtruth-user-pool-domain-</span><span class="sc" style="color: #5E5E5E;">{}</span><span class="st" style="color: #20794D;">'</span>.<span class="bu" style="color: null;">format</span>(timestamp)</span>
<span id="cb12-2"></span>
<span id="cb12-3"><span class="cf" style="color: #003B4F;">try</span>:</span>
<span id="cb12-4">    cognito_idp.create_user_pool_domain( </span>
<span id="cb12-5">        UserPoolId<span class="op" style="color: #5E5E5E;">=</span>user_pool_id, </span>
<span id="cb12-6">        Domain<span class="op" style="color: #5E5E5E;">=</span>user_pool_domain_name </span>
<span id="cb12-7">    )</span>
<span id="cb12-8">    <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">"Created Amazon Cognito user pool domain: </span><span class="sc" style="color: #5E5E5E;">{}</span><span class="st" style="color: #20794D;">"</span>.<span class="bu" style="color: null;">format</span>(user_pool_domain_name))</span>
<span id="cb12-9"><span class="cf" style="color: #003B4F;">except</span>:</span>
<span id="cb12-10">    <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">"Amazon Cognito user pool domain </span><span class="sc" style="color: #5E5E5E;">{}</span><span class="st" style="color: #20794D;"> already exists"</span>.<span class="bu" style="color: null;">format</span>(user_pool_domain_name))</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Created Amazon Cognito user pool domain: groundtruth-user-pool-domain-1677153775</code></pre>
</div>
</div>
<p>We will use the following function to check if the Amazon Cognito user group already exists.</p>
<div class="cell" data-tags="[]" data-execution_count="18">
<div class="sourceCode cell-code" id="cb14" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><span class="kw" style="color: #003B4F;">def</span> check_user_pool_group_existence(user_pool_id, user_pool_group_name):  </span>
<span id="cb14-2">    <span class="cf" style="color: #003B4F;">for</span> group <span class="kw" style="color: #003B4F;">in</span> cognito_idp.list_groups(UserPoolId<span class="op" style="color: #5E5E5E;">=</span>user_pool_id)[<span class="st" style="color: #20794D;">'Groups'</span>]:</span>
<span id="cb14-3">        <span class="cf" style="color: #003B4F;">if</span> user_pool_group_name <span class="op" style="color: #5E5E5E;">==</span> group[<span class="st" style="color: #20794D;">'GroupName'</span>]:</span>
<span id="cb14-4">            <span class="cf" style="color: #003B4F;">return</span> <span class="va" style="color: #111111;">True</span></span>
<span id="cb14-5">    <span class="cf" style="color: #003B4F;">return</span> <span class="va" style="color: #111111;">False</span></span></code></pre></div>
</div>
<p>Now we will set up the Amazon Cognito user group.</p>
<div class="cell" data-tags="[]" data-execution_count="19">
<div class="sourceCode cell-code" id="cb15" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1">user_pool_group_name <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">'groundtruth-user-pool-group-</span><span class="sc" style="color: #5E5E5E;">{}</span><span class="st" style="color: #20794D;">'</span>.<span class="bu" style="color: null;">format</span>(timestamp)</span>
<span id="cb15-2"></span>
<span id="cb15-3"><span class="cf" style="color: #003B4F;">if</span> <span class="kw" style="color: #003B4F;">not</span> check_user_pool_group_existence(user_pool_id, user_pool_group_name):</span>
<span id="cb15-4">    cognito_idp.create_group( </span>
<span id="cb15-5">        UserPoolId<span class="op" style="color: #5E5E5E;">=</span>user_pool_id, </span>
<span id="cb15-6">        GroupName<span class="op" style="color: #5E5E5E;">=</span>user_pool_group_name</span>
<span id="cb15-7">    )</span>
<span id="cb15-8">    <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">"Created Amazon Cognito user group: </span><span class="sc" style="color: #5E5E5E;">{}</span><span class="st" style="color: #20794D;">"</span>.<span class="bu" style="color: null;">format</span>(user_pool_group_name))</span>
<span id="cb15-9"><span class="cf" style="color: #003B4F;">else</span>:</span>
<span id="cb15-10">    <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">"Amazon Cognito user group </span><span class="sc" style="color: #5E5E5E;">{}</span><span class="st" style="color: #20794D;"> already exists"</span>.<span class="bu" style="color: null;">format</span>(user_pool_group_name))</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Created Amazon Cognito user group: groundtruth-user-pool-group-1677153775</code></pre>
</div>
</div>
</section>
<section id="create-workforce-and-workteam" class="level3" data-number="2.4">
<h3 data-number="2.4" class="anchored" data-anchor-id="create-workforce-and-workteam"><span class="header-section-number">2.4</span> Create workforce and workteam</h3>
<p>We can use the following function to check if the workforce already exists. We can only create one workforce per region, therefore we’ll have to delete any other existing workforce, together with all of the related workteams.</p>
<div class="cell" data-tags="[]" data-execution_count="20">
<div class="sourceCode cell-code" id="cb17" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><span class="kw" style="color: #003B4F;">def</span> check_workforce_existence(workforce_name):  </span>
<span id="cb17-2">    <span class="cf" style="color: #003B4F;">for</span> workforce <span class="kw" style="color: #003B4F;">in</span> sm.list_workforces()[<span class="st" style="color: #20794D;">'Workforces'</span>]:</span>
<span id="cb17-3">        <span class="cf" style="color: #003B4F;">if</span> workforce_name <span class="op" style="color: #5E5E5E;">==</span> workforce[<span class="st" style="color: #20794D;">'WorkforceName'</span>]:</span>
<span id="cb17-4">            <span class="cf" style="color: #003B4F;">return</span> <span class="va" style="color: #111111;">True</span></span>
<span id="cb17-5">        <span class="cf" style="color: #003B4F;">else</span>:</span>
<span id="cb17-6">            <span class="cf" style="color: #003B4F;">for</span> workteam <span class="kw" style="color: #003B4F;">in</span> sm.list_workteams()[<span class="st" style="color: #20794D;">'Workteams'</span>]:</span>
<span id="cb17-7">                sm.delete_workteam(WorkteamName<span class="op" style="color: #5E5E5E;">=</span>workteam[<span class="st" style="color: #20794D;">'WorkteamName'</span>])</span>
<span id="cb17-8">            sm.delete_workforce(WorkforceName<span class="op" style="color: #5E5E5E;">=</span>workforce[<span class="st" style="color: #20794D;">'WorkforceName'</span>])</span>
<span id="cb17-9">    <span class="cf" style="color: #003B4F;">return</span> <span class="va" style="color: #111111;">False</span></span></code></pre></div>
</div>
<p>Lets create a workforce.</p>
<div class="cell" data-tags="[]" data-execution_count="21">
<div class="sourceCode cell-code" id="cb18" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1">workforce_name <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">'groundtruth-workforce-name-</span><span class="sc" style="color: #5E5E5E;">{}</span><span class="st" style="color: #20794D;">'</span>.<span class="bu" style="color: null;">format</span>(timestamp)</span>
<span id="cb18-2"></span>
<span id="cb18-3"><span class="cf" style="color: #003B4F;">if</span> <span class="kw" style="color: #003B4F;">not</span> check_workforce_existence(workforce_name):</span>
<span id="cb18-4">    create_workforce_response <span class="op" style="color: #5E5E5E;">=</span> sm.create_workforce(</span>
<span id="cb18-5">        WorkforceName<span class="op" style="color: #5E5E5E;">=</span>workforce_name,</span>
<span id="cb18-6">        CognitoConfig<span class="op" style="color: #5E5E5E;">=</span>{</span>
<span id="cb18-7">            <span class="st" style="color: #20794D;">'UserPool'</span>: user_pool_id, </span>
<span id="cb18-8">            <span class="st" style="color: #20794D;">'ClientId'</span>: client_id</span>
<span id="cb18-9">        }</span>
<span id="cb18-10">    )</span>
<span id="cb18-11">    <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">"Workforce name: </span><span class="sc" style="color: #5E5E5E;">{}</span><span class="st" style="color: #20794D;">"</span>.<span class="bu" style="color: null;">format</span>(workforce_name))</span>
<span id="cb18-12">    pprint(create_workforce_response)</span>
<span id="cb18-13"><span class="cf" style="color: #003B4F;">else</span>:</span>
<span id="cb18-14">    <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">"Workforce </span><span class="sc" style="color: #5E5E5E;">{}</span><span class="st" style="color: #20794D;"> already exists"</span>.<span class="bu" style="color: null;">format</span>(workforce_name))</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Workforce name: groundtruth-workforce-name-1677153775
{'ResponseMetadata': {'HTTPHeaders': {'content-length': '107',
                                      'content-type': 'application/x-amz-json-1.1',
                                      'date': 'Thu, 23 Feb 2023 12:04:42 GMT',
                                      'x-amzn-requestid': '8e749026-4d1e-4758-949a-ab78fdfaafbe'},
                      'HTTPStatusCode': 200,
                      'RequestId': '8e749026-4d1e-4758-949a-ab78fdfaafbe',
                      'RetryAttempts': 0},
 'WorkforceArn': 'arn:aws:sagemaker:us-east-1:753124839657:workforce/groundtruth-workforce-name-1677153775'}</code></pre>
</div>
</div>
<p>You can use the <code>sm.describe_workforce</code> function to get the information about the workforce.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb20" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1">describe_workforce_response <span class="op" style="color: #5E5E5E;">=</span> sm.describe_workforce(WorkforceName<span class="op" style="color: #5E5E5E;">=</span>workforce_name)</span>
<span id="cb20-2">describe_workforce_response</span></code></pre></div>
</div>
<p>We use the following function to check if the workteam already exists. If there are no workteams in the list, we will give some time for the workforce to set up.</p>
<div class="cell" data-tags="[]" data-execution_count="22">
<div class="sourceCode cell-code" id="cb21" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><span class="kw" style="color: #003B4F;">def</span> check_workteam_existence(workteam_name):  </span>
<span id="cb21-2">    <span class="cf" style="color: #003B4F;">if</span> sm.list_workteams()[<span class="st" style="color: #20794D;">'Workteams'</span>]:</span>
<span id="cb21-3">        <span class="cf" style="color: #003B4F;">for</span> workteam <span class="kw" style="color: #003B4F;">in</span> sm.list_workteams()[<span class="st" style="color: #20794D;">'Workteams'</span>]:</span>
<span id="cb21-4">            <span class="cf" style="color: #003B4F;">if</span> workteam_name <span class="op" style="color: #5E5E5E;">==</span> workteam[<span class="st" style="color: #20794D;">'WorkteamName'</span>]:</span>
<span id="cb21-5">                <span class="cf" style="color: #003B4F;">return</span> <span class="va" style="color: #111111;">True</span></span>
<span id="cb21-6">    <span class="cf" style="color: #003B4F;">else</span>:</span>
<span id="cb21-7">        time.sleep(<span class="dv" style="color: #AD0000;">60</span>)</span>
<span id="cb21-8">        <span class="cf" style="color: #003B4F;">return</span> <span class="va" style="color: #111111;">False</span></span>
<span id="cb21-9">    <span class="cf" style="color: #003B4F;">return</span> <span class="va" style="color: #111111;">False</span></span></code></pre></div>
</div>
<p>Now lets create a workteam.</p>
<div class="cell" data-tags="[]" data-execution_count="23">
<div class="sourceCode cell-code" id="cb22" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1">workteam_name <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">'groundtruth-workteam-</span><span class="sc" style="color: #5E5E5E;">{}</span><span class="st" style="color: #20794D;">'</span>.<span class="bu" style="color: null;">format</span>(timestamp)</span>
<span id="cb22-2"></span>
<span id="cb22-3"><span class="cf" style="color: #003B4F;">if</span> <span class="kw" style="color: #003B4F;">not</span> check_workteam_existence(workteam_name):</span>
<span id="cb22-4">    create_workteam_response <span class="op" style="color: #5E5E5E;">=</span> sm.create_workteam(</span>
<span id="cb22-5">        Description<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'groundtruth workteam'</span>,</span>
<span id="cb22-6">        WorkforceName<span class="op" style="color: #5E5E5E;">=</span>workforce_name,</span>
<span id="cb22-7">        WorkteamName<span class="op" style="color: #5E5E5E;">=</span>workteam_name,</span>
<span id="cb22-8">        <span class="co" style="color: #5E5E5E;"># objects that identify the workers that make up the work team</span></span>
<span id="cb22-9">        MemberDefinitions<span class="op" style="color: #5E5E5E;">=</span>[{</span>
<span id="cb22-10">            <span class="st" style="color: #20794D;">'CognitoMemberDefinition'</span>: {</span>
<span id="cb22-11">                <span class="st" style="color: #20794D;">'UserPool'</span>: user_pool_id, </span>
<span id="cb22-12">                <span class="st" style="color: #20794D;">'ClientId'</span>: client_id, </span>
<span id="cb22-13">                <span class="st" style="color: #20794D;">'UserGroup'</span>: user_pool_group_name </span>
<span id="cb22-14">            }</span>
<span id="cb22-15">        }]</span>
<span id="cb22-16">    )</span>
<span id="cb22-17">    pprint(create_workteam_response)</span>
<span id="cb22-18"><span class="cf" style="color: #003B4F;">else</span>:</span>
<span id="cb22-19">    <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">"Workteam </span><span class="sc" style="color: #5E5E5E;">{}</span><span class="st" style="color: #20794D;"> already exists"</span>.<span class="bu" style="color: null;">format</span>(workteam_name))</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>{'ResponseMetadata': {'HTTPHeaders': {'content-length': '113',
                                      'content-type': 'application/x-amz-json-1.1',
                                      'date': 'Thu, 23 Feb 2023 12:06:06 GMT',
                                      'x-amzn-requestid': 'bd89c3fa-45bb-439b-aa33-f2c685e69d8a'},
                      'HTTPStatusCode': 200,
                      'RequestId': 'bd89c3fa-45bb-439b-aa33-f2c685e69d8a',
                      'RetryAttempts': 0},
 'WorkteamArn': 'arn:aws:sagemaker:us-east-1:753124839657:workteam/private-crowd/groundtruth-workteam-1677153775'}</code></pre>
</div>
</div>
<p>We can use the <code>sm.describe_workteam</code> function to get information about the workteam.</p>
<div class="cell" data-tags="[]" data-execution_count="24">
<div class="sourceCode cell-code" id="cb24" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1">describe_workteam_response <span class="op" style="color: #5E5E5E;">=</span> sm.describe_workteam(WorkteamName<span class="op" style="color: #5E5E5E;">=</span>workteam_name)</span>
<span id="cb24-2">describe_workteam_response</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="24">
<pre><code>{'Workteam': {'WorkteamName': 'groundtruth-workteam-1677153775',
  'MemberDefinitions': [{'CognitoMemberDefinition': {'UserPool': 'us-east-1_8s0SOCEPn',
     'UserGroup': 'groundtruth-user-pool-group-1677153775',
     'ClientId': '4ebq1ga0irfdvssomfjhbh5fgq'}}],
  'WorkteamArn': 'arn:aws:sagemaker:us-east-1:753124839657:workteam/private-crowd/groundtruth-workteam-1677153775',
  'Description': 'groundtruth workteam',
  'SubDomain': 'aqa042udc1.labeling.us-east-1.sagemaker.aws',
  'CreateDate': datetime.datetime(2023, 2, 23, 12, 6, 5, 715000, tzinfo=tzlocal()),
  'LastUpdatedDate': datetime.datetime(2023, 2, 23, 12, 6, 7, 175000, tzinfo=tzlocal()),
  'NotificationConfiguration': {}},
 'ResponseMetadata': {'RequestId': '615a618f-d243-4c27-a8d5-f94290f6c790',
  'HTTPStatusCode': 200,
  'HTTPHeaders': {'x-amzn-requestid': '615a618f-d243-4c27-a8d5-f94290f6c790',
   'content-type': 'application/x-amz-json-1.1',
   'content-length': '544',
   'date': 'Thu, 23 Feb 2023 12:06:06 GMT'},
  'RetryAttempts': 0}}</code></pre>
</div>
</div>
<p>Now we can pull the workteam ARN either from <code>create_workteam_response</code> or <code>describe_workteam_response</code>.</p>
<div class="cell" data-tags="[]" data-execution_count="25">
<div class="sourceCode cell-code" id="cb26" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1">workteam_arn <span class="op" style="color: #5E5E5E;">=</span> describe_workteam_response[<span class="st" style="color: #20794D;">'Workteam'</span>][<span class="st" style="color: #20794D;">'WorkteamArn'</span>]</span>
<span id="cb26-2">workteam_arn</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="25">
<pre><code>'arn:aws:sagemaker:us-east-1:753124839657:workteam/private-crowd/groundtruth-workteam-1677153775'</code></pre>
</div>
</div>
</section>
<section id="create-an-amazon-cognito-user-and-add-the-user-to-the-group" class="level3" data-number="2.5">
<h3 data-number="2.5" class="anchored" data-anchor-id="create-an-amazon-cognito-user-and-add-the-user-to-the-group"><span class="header-section-number">2.5</span> Create an Amazon Cognito user and add the user to the group</h3>
<p>We will use the following function to check if the Amazon Cognito user already exists.</p>
<div class="cell" data-tags="[]" data-execution_count="27">
<div class="sourceCode cell-code" id="cb28" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><span class="kw" style="color: #003B4F;">def</span> check_user_existence(user_pool_id, user_name):  </span>
<span id="cb28-2">    <span class="cf" style="color: #003B4F;">for</span> user <span class="kw" style="color: #003B4F;">in</span> cognito_idp.list_users(UserPoolId<span class="op" style="color: #5E5E5E;">=</span>user_pool_id)[<span class="st" style="color: #20794D;">'Users'</span>]:</span>
<span id="cb28-3">        <span class="cf" style="color: #003B4F;">if</span> user_name <span class="op" style="color: #5E5E5E;">==</span> user[<span class="st" style="color: #20794D;">'Username'</span>]:</span>
<span id="cb28-4">            <span class="cf" style="color: #003B4F;">return</span> <span class="va" style="color: #111111;">True</span></span>
<span id="cb28-5">    <span class="cf" style="color: #003B4F;">return</span> <span class="va" style="color: #111111;">False</span></span></code></pre></div>
</div>
<p>Now we create a user passing the username, temporary password, and the Amazon Cognito user pool ID.</p>
<div class="cell" data-tags="[]" data-execution_count="28">
<div class="sourceCode cell-code" id="cb29" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1">user_name <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">'user-</span><span class="sc" style="color: #5E5E5E;">{}</span><span class="st" style="color: #20794D;">'</span>.<span class="bu" style="color: null;">format</span>(timestamp)</span>
<span id="cb29-2"></span>
<span id="cb29-3">temporary_password <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">'Password@420'</span></span>
<span id="cb29-4"></span>
<span id="cb29-5"><span class="cf" style="color: #003B4F;">if</span> <span class="kw" style="color: #003B4F;">not</span> check_user_existence(user_pool_id, user_name):</span>
<span id="cb29-6">    create_user_response<span class="op" style="color: #5E5E5E;">=</span>cognito_idp.admin_create_user(</span>
<span id="cb29-7">        Username<span class="op" style="color: #5E5E5E;">=</span>user_name,</span>
<span id="cb29-8">        UserPoolId<span class="op" style="color: #5E5E5E;">=</span>user_pool_id,</span>
<span id="cb29-9">        TemporaryPassword<span class="op" style="color: #5E5E5E;">=</span>temporary_password,</span>
<span id="cb29-10">        MessageAction<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'SUPPRESS'</span> <span class="co" style="color: #5E5E5E;"># suppress sending the invitation message to a user that already exists</span></span>
<span id="cb29-11">    )</span>
<span id="cb29-12">    pprint(create_user_response)</span>
<span id="cb29-13"><span class="cf" style="color: #003B4F;">else</span>:</span>
<span id="cb29-14">    <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">"Amazon Cognito user </span><span class="sc" style="color: #5E5E5E;">{}</span><span class="st" style="color: #20794D;"> already exists"</span>.<span class="bu" style="color: null;">format</span>(user_name))</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>{'ResponseMetadata': {'HTTPHeaders': {'connection': 'keep-alive',
                                      'content-length': '242',
                                      'content-type': 'application/x-amz-json-1.1',
                                      'date': 'Thu, 23 Feb 2023 12:06:07 GMT',
                                      'x-amzn-requestid': '9799ecf1-9400-4385-a696-f3067a8ee4ab'},
                      'HTTPStatusCode': 200,
                      'RequestId': '9799ecf1-9400-4385-a696-f3067a8ee4ab',
                      'RetryAttempts': 0},
 'User': {'Attributes': [{'Name': 'sub',
                          'Value': '7e22b0c1-059a-45b4-b69a-e1b378950097'}],
          'Enabled': True,
          'UserCreateDate': datetime.datetime(2023, 2, 23, 12, 6, 7, 848000, tzinfo=tzlocal()),
          'UserLastModifiedDate': datetime.datetime(2023, 2, 23, 12, 6, 7, 848000, tzinfo=tzlocal()),
          'UserStatus': 'FORCE_CHANGE_PASSWORD',
          'Username': 'user-1677153775'}}</code></pre>
</div>
</div>
<p>Add the user into the Amazon Cognito user group.</p>
<div class="cell" data-tags="[]" data-execution_count="29">
<div class="sourceCode cell-code" id="cb31" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1">cognito_idp.admin_add_user_to_group(</span>
<span id="cb31-2">    UserPoolId<span class="op" style="color: #5E5E5E;">=</span>user_pool_id,</span>
<span id="cb31-3">    Username<span class="op" style="color: #5E5E5E;">=</span>user_name,</span>
<span id="cb31-4">    GroupName<span class="op" style="color: #5E5E5E;">=</span>user_pool_group_name</span>
<span id="cb31-5">)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="29">
<pre><code>{'ResponseMetadata': {'RequestId': '18dd685f-63f6-4d5b-8f81-cd22d9304a5e',
  'HTTPStatusCode': 200,
  'HTTPHeaders': {'date': 'Thu, 23 Feb 2023 12:06:08 GMT',
   'content-type': 'application/x-amz-json-1.1',
   'content-length': '0',
   'connection': 'keep-alive',
   'x-amzn-requestid': '18dd685f-63f6-4d5b-8f81-cd22d9304a5e'},
  'RetryAttempts': 0}}</code></pre>
</div>
</div>
</section>
</section>
<section id="create-human-task-ui" class="level2" data-number="3">
<h2 data-number="3" class="anchored" data-anchor-id="create-human-task-ui"><span class="header-section-number">3</span> Create Human Task UI</h2>
<p><img src="http://livingdatalab.com/posts/https:/github.com/pranath/blog/raw/master/images/human-loop-workflow-2-taskUI.png" title="Human in the loop Workflow" class="img-fluid"></p>
<p>We will create a Human Task UI resource, using a worker task UI template. This template will be rendered to the human workers whenever human interaction is required.</p>
<p>Below there is a simple template, that is compatible with the current use case of classifying product reviews into the three sentiment classes. For other pre-built UIs (there are 70+), check: https://github.com/aws-samples/amazon-a2i-sample-task-uis</p>
<div class="cell" data-tags="[]" data-execution_count="30">
<div class="sourceCode cell-code" id="cb33" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1">template <span class="op" style="color: #5E5E5E;">=</span> <span class="vs" style="color: #20794D;">r"""</span></span>
<span id="cb33-2"><span class="vs" style="color: #20794D;">&lt;script src="https://assets.crowd.aws/crowd-html-elements.js"&gt;&lt;/script&gt;</span></span>
<span id="cb33-3"></span>
<span id="cb33-4"><span class="vs" style="color: #20794D;">&lt;crowd-form&gt;</span></span>
<span id="cb33-5"><span class="vs" style="color: #20794D;">    &lt;crowd-classifier name="sentiment"</span></span>
<span id="cb33-6"><span class="vs" style="color: #20794D;">                      categories="['-1', '0', '1']"</span></span>
<span id="cb33-7"><span class="vs" style="color: #20794D;">                      initial-value="</span><span class="sc" style="color: #5E5E5E;">{{</span><span class="vs" style="color: #20794D;"> task.input.initialValue </span><span class="sc" style="color: #5E5E5E;">}}</span><span class="vs" style="color: #20794D;">"</span></span>
<span id="cb33-8"><span class="vs" style="color: #20794D;">                      header="Classify Reviews into Sentiment:  -1 (negative), 0 (neutral), and 1 (positive)"&gt;</span></span>
<span id="cb33-9"><span class="vs" style="color: #20794D;">      </span></span>
<span id="cb33-10"><span class="vs" style="color: #20794D;">        &lt;classification-target&gt;</span></span>
<span id="cb33-11"><span class="vs" style="color: #20794D;">            </span><span class="sc" style="color: #5E5E5E;">{{</span><span class="vs" style="color: #20794D;"> task.input.taskObject </span><span class="sc" style="color: #5E5E5E;">}}</span></span>
<span id="cb33-12"><span class="vs" style="color: #20794D;">        &lt;/classification-target&gt;</span></span>
<span id="cb33-13"><span class="vs" style="color: #20794D;">      </span></span>
<span id="cb33-14"><span class="vs" style="color: #20794D;">        &lt;full-instructions header="Classify reviews into sentiment:  -1 (negative), 0 (neutral), and 1 (positive)"&gt;</span></span>
<span id="cb33-15"><span class="vs" style="color: #20794D;">            &lt;p&gt;&lt;strong&gt;1&lt;/strong&gt;: joy, excitement, delight&lt;/p&gt;       </span></span>
<span id="cb33-16"><span class="vs" style="color: #20794D;">            &lt;p&gt;&lt;strong&gt;0&lt;/strong&gt;: neither positive or negative, such as stating a fact&lt;/p&gt;</span></span>
<span id="cb33-17"><span class="vs" style="color: #20794D;">            &lt;p&gt;&lt;strong&gt;-1&lt;/strong&gt;: anger, sarcasm, anxiety&lt;/p&gt;</span></span>
<span id="cb33-18"><span class="vs" style="color: #20794D;">        &lt;/full-instructions&gt;</span></span>
<span id="cb33-19"></span>
<span id="cb33-20"><span class="vs" style="color: #20794D;">        &lt;short-instructions&gt;</span></span>
<span id="cb33-21"><span class="vs" style="color: #20794D;">            Classify reviews into sentiment:  -1 (negative), 0 (neutral), and 1 (positive)</span></span>
<span id="cb33-22"><span class="vs" style="color: #20794D;">        &lt;/short-instructions&gt;</span></span>
<span id="cb33-23"><span class="vs" style="color: #20794D;">    &lt;/crowd-classifier&gt;</span></span>
<span id="cb33-24"><span class="vs" style="color: #20794D;">&lt;/crowd-form&gt;</span></span>
<span id="cb33-25"><span class="vs" style="color: #20794D;">"""</span></span></code></pre></div>
</div>
<p>We will now create a human task UI resource.</p>
<div class="cell" data-tags="[]" data-execution_count="31">
<div class="sourceCode cell-code" id="cb34" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1"><span class="co" style="color: #5E5E5E;"># Task UI name - this value is unique per account and region. </span></span>
<span id="cb34-2">task_ui_name <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">'ui-</span><span class="sc" style="color: #5E5E5E;">{}</span><span class="st" style="color: #20794D;">'</span>.<span class="bu" style="color: null;">format</span>(timestamp)</span>
<span id="cb34-3"></span>
<span id="cb34-4">human_task_ui_response <span class="op" style="color: #5E5E5E;">=</span> sm.create_human_task_ui(</span>
<span id="cb34-5">    HumanTaskUiName<span class="op" style="color: #5E5E5E;">=</span>task_ui_name,</span>
<span id="cb34-6">    UiTemplate<span class="op" style="color: #5E5E5E;">=</span>{</span>
<span id="cb34-7">        <span class="st" style="color: #20794D;">"Content"</span>: template  </span>
<span id="cb34-8">    }</span>
<span id="cb34-9">)</span>
<span id="cb34-10">human_task_ui_response</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="31">
<pre><code>{'HumanTaskUiArn': 'arn:aws:sagemaker:us-east-1:753124839657:human-task-ui/ui-1677153775',
 'ResponseMetadata': {'RequestId': 'a3561000-dec3-44de-b527-1c26ea8b443d',
  'HTTPStatusCode': 200,
  'HTTPHeaders': {'x-amzn-requestid': 'a3561000-dec3-44de-b527-1c26ea8b443d',
   'content-type': 'application/x-amz-json-1.1',
   'content-length': '89',
   'date': 'Thu, 23 Feb 2023 12:06:08 GMT'},
  'RetryAttempts': 0}}</code></pre>
</div>
</div>
<p>Pull the ARN of the human task UI:</p>
<div class="cell" data-tags="[]" data-execution_count="32">
<div class="sourceCode cell-code" id="cb36" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb36-1">human_task_ui_arn <span class="op" style="color: #5E5E5E;">=</span> human_task_ui_response[<span class="st" style="color: #20794D;">"HumanTaskUiArn"</span>]</span>
<span id="cb36-2"><span class="bu" style="color: null;">print</span>(human_task_ui_arn)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>arn:aws:sagemaker:us-east-1:753124839657:human-task-ui/ui-1677153775</code></pre>
</div>
</div>
</section>
<section id="define-human-review-workflow" class="level2" data-number="4">
<h2 data-number="4" class="anchored" data-anchor-id="define-human-review-workflow"><span class="header-section-number">4</span> Define human review workflow</h2>
<p><img src="http://livingdatalab.com/posts/https:/github.com/pranath/blog/raw/master/images/human-loop-workflow-3-review.png" title="Human in the loop Workflow" class="img-fluid"></p>
<p>In this section, we are going to create a Flow Definition. A flow Definitions allows you to specify:</p>
<ul>
<li>The workforce (in fact, it is a workteam) that our tasks will be sent to.</li>
<li>The instructions that our workforce will receive (worker task template).</li>
<li>The configuration of our worker tasks, including the number of workers that receive a task and time limits to complete tasks.</li>
<li>Where our output data will be stored.</li>
</ul>
<p>Here we are going to use the API, but we can optionally create this workflow definition in the console as well.</p>
<p>For more details and instructions, see: https://docs.aws.amazon.com/sagemaker/latest/dg/a2i-create-flow-definition.html.</p>
<p>Let’s construct the S3 bucket output path.</p>
<div class="cell" data-tags="[]" data-execution_count="33">
<div class="sourceCode cell-code" id="cb38" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb38-1">output_path <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">'s3://</span><span class="sc" style="color: #5E5E5E;">{}</span><span class="st" style="color: #20794D;">/a2i-results-</span><span class="sc" style="color: #5E5E5E;">{}</span><span class="st" style="color: #20794D;">'</span>.<span class="bu" style="color: null;">format</span>(bucket, timestamp)</span>
<span id="cb38-2"><span class="bu" style="color: null;">print</span>(output_path)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>s3://sagemaker-us-east-1-753124839657/a2i-results-1677153775</code></pre>
</div>
</div>
<p>Lets construct the Flow Definition with the workteam and human task UI in the human loop configurations that we created above.</p>
<div class="cell" data-tags="[]" data-execution_count="34">
<div class="sourceCode cell-code" id="cb40" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb40-1"><span class="co" style="color: #5E5E5E;"># Flow definition name - this value is unique per account and region</span></span>
<span id="cb40-2">flow_definition_name <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">'fd-</span><span class="sc" style="color: #5E5E5E;">{}</span><span class="st" style="color: #20794D;">'</span>.<span class="bu" style="color: null;">format</span>(timestamp)</span>
<span id="cb40-3"></span>
<span id="cb40-4">create_workflow_definition_response <span class="op" style="color: #5E5E5E;">=</span> sm.create_flow_definition(</span>
<span id="cb40-5">    FlowDefinitionName<span class="op" style="color: #5E5E5E;">=</span>flow_definition_name,</span>
<span id="cb40-6">    RoleArn<span class="op" style="color: #5E5E5E;">=</span>role,</span>
<span id="cb40-7">    HumanLoopConfig<span class="op" style="color: #5E5E5E;">=</span>{</span>
<span id="cb40-8">        <span class="st" style="color: #20794D;">"WorkteamArn"</span>: workteam_arn, </span>
<span id="cb40-9">        <span class="st" style="color: #20794D;">"HumanTaskUiArn"</span>: human_task_ui_arn, </span>
<span id="cb40-10">        <span class="st" style="color: #20794D;">"TaskCount"</span>: <span class="dv" style="color: #AD0000;">1</span>, <span class="co" style="color: #5E5E5E;"># the number of workers that receive a task</span></span>
<span id="cb40-11">        <span class="st" style="color: #20794D;">"TaskDescription"</span>: <span class="st" style="color: #20794D;">"Classify Reviews into sentiment:  -1 (negative), 0 (neutral), 1 (positive)"</span>,</span>
<span id="cb40-12">        <span class="st" style="color: #20794D;">"TaskTitle"</span>: <span class="st" style="color: #20794D;">"Classify Reviews into sentiment:  -1 (negative), 0 (neutral), 1 (positive)"</span>,</span>
<span id="cb40-13">    },</span>
<span id="cb40-14">    OutputConfig<span class="op" style="color: #5E5E5E;">=</span>{<span class="st" style="color: #20794D;">"S3OutputPath"</span>: output_path},</span>
<span id="cb40-15">)</span>
<span id="cb40-16"></span>
<span id="cb40-17">augmented_ai_flow_definition_arn <span class="op" style="color: #5E5E5E;">=</span> create_workflow_definition_response[<span class="st" style="color: #20794D;">"FlowDefinitionArn"</span>]</span></code></pre></div>
</div>
<p>You can pull information about the Flow Definition with the function <code>sm.describe_flow_definition</code> and wait for its status value <code>FlowDefinitionStatus</code> to become <code>Active</code>.</p>
<div class="cell" data-scrolled="true" data-tags="[]" data-execution_count="35">
<div class="sourceCode cell-code" id="cb41" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1"><span class="cf" style="color: #003B4F;">for</span> _ <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">range</span>(<span class="dv" style="color: #AD0000;">60</span>):</span>
<span id="cb41-2">    describe_flow_definition_response <span class="op" style="color: #5E5E5E;">=</span> sm.describe_flow_definition(FlowDefinitionName<span class="op" style="color: #5E5E5E;">=</span>flow_definition_name)</span>
<span id="cb41-3">    <span class="bu" style="color: null;">print</span>(describe_flow_definition_response[<span class="st" style="color: #20794D;">"FlowDefinitionStatus"</span>])</span>
<span id="cb41-4">    <span class="cf" style="color: #003B4F;">if</span> describe_flow_definition_response[<span class="st" style="color: #20794D;">"FlowDefinitionStatus"</span>] <span class="op" style="color: #5E5E5E;">==</span> <span class="st" style="color: #20794D;">"Active"</span>:</span>
<span id="cb41-5">        <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">"Flow Definition is active"</span>)</span>
<span id="cb41-6">        <span class="cf" style="color: #003B4F;">break</span></span>
<span id="cb41-7">    time.sleep(<span class="dv" style="color: #AD0000;">2</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Active
Flow Definition is active</code></pre>
</div>
</div>
</section>
<section id="start-human-loop-with-custom-ml-model" class="level2" data-number="5">
<h2 data-number="5" class="anchored" data-anchor-id="start-human-loop-with-custom-ml-model"><span class="header-section-number">5</span> Start human loop with custom ML model</h2>
<p><img src="http://livingdatalab.com/posts/https:/github.com/pranath/blog/raw/master/images/human-loop-workflow-4-start.png" title="Human in the loop Workflow" class="img-fluid"></p>
<p>We will now deploy a custom ML model into an endpoint and call it to predict labels for some sample reviews. We need to check the confidence score for each prediction. If it is smaller than the threshold, we will engage our workforce for a human review, starting a human loop. We can fix the labels by completing the human loop tasks and review the results.</p>
<p><img src="http://livingdatalab.com/posts/https:/github.com/pranath/blog/raw/master/images/augmented-ai-loop.png" title="Human in the loop Workflow" class="img-fluid"></p>
<p>Lets set up a sentiment predictor class to be wrapped later into the PyTorch Model.</p>
<div class="cell" data-tags="[]" data-execution_count="36">
<div class="sourceCode cell-code" id="cb43" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb43-1"><span class="im" style="color: #00769E;">from</span> sagemaker.predictor <span class="im" style="color: #00769E;">import</span> Predictor</span>
<span id="cb43-2"><span class="im" style="color: #00769E;">from</span> sagemaker.serializers <span class="im" style="color: #00769E;">import</span> JSONLinesSerializer</span>
<span id="cb43-3"><span class="im" style="color: #00769E;">from</span> sagemaker.deserializers <span class="im" style="color: #00769E;">import</span> JSONLinesDeserializer</span>
<span id="cb43-4"></span>
<span id="cb43-5"><span class="kw" style="color: #003B4F;">class</span> SentimentPredictor(Predictor):</span>
<span id="cb43-6">    <span class="kw" style="color: #003B4F;">def</span> <span class="fu" style="color: #4758AB;">__init__</span>(<span class="va" style="color: #111111;">self</span>, endpoint_name, sagemaker_session):</span>
<span id="cb43-7">        <span class="bu" style="color: null;">super</span>().<span class="fu" style="color: #4758AB;">__init__</span>(</span>
<span id="cb43-8">            endpoint_name, </span>
<span id="cb43-9">            sagemaker_session<span class="op" style="color: #5E5E5E;">=</span>sagemaker_session,</span>
<span id="cb43-10">            serializer<span class="op" style="color: #5E5E5E;">=</span>JSONLinesSerializer(), </span>
<span id="cb43-11">            deserializer<span class="op" style="color: #5E5E5E;">=</span>JSONLinesDeserializer() </span>
<span id="cb43-12">        )</span></code></pre></div>
</div>
<p>Now we create a SageMaker model based on the model artifact saved in the S3 bucket.</p>
<div class="cell" data-tags="[]" data-execution_count="37">
<div class="sourceCode cell-code" id="cb44" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb44-1"><span class="im" style="color: #00769E;">from</span> sagemaker.pytorch.model <span class="im" style="color: #00769E;">import</span> PyTorchModel</span>
<span id="cb44-2"></span>
<span id="cb44-3">pytorch_model_name <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">'model-</span><span class="sc" style="color: #5E5E5E;">{}</span><span class="st" style="color: #20794D;">'</span>.<span class="bu" style="color: null;">format</span>(timestamp)</span>
<span id="cb44-4"></span>
<span id="cb44-5">model <span class="op" style="color: #5E5E5E;">=</span> PyTorchModel(name<span class="op" style="color: #5E5E5E;">=</span>pytorch_model_name,</span>
<span id="cb44-6">                     model_data<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'s3://dlai-practical-data-science/models/ab/variant_a/model.tar.gz'</span>,</span>
<span id="cb44-7">                     predictor_cls<span class="op" style="color: #5E5E5E;">=</span>SentimentPredictor,</span>
<span id="cb44-8">                     entry_point<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'inference.py'</span>,</span>
<span id="cb44-9">                     source_dir<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'src'</span>,</span>
<span id="cb44-10">                     framework_version<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'1.6.0'</span>,</span>
<span id="cb44-11">                     py_version<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'py3'</span>,</span>
<span id="cb44-12">                     role<span class="op" style="color: #5E5E5E;">=</span>role)</span></code></pre></div>
</div>
<p>Now we will create a SageMaker Endpoint from the model. For the purposes of this project, we will use a relatively small instance type. Please refer to <a href="https://aws.amazon.com/sagemaker/pricing/">this link</a> for additional instance types that may work for your use cases outside of this lab.</p>
<div class="cell" data-tags="[]" data-execution_count="38">
<div class="sourceCode cell-code" id="cb45" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb45-1"><span class="op" style="color: #5E5E5E;">%%</span>time</span>
<span id="cb45-2"></span>
<span id="cb45-3">pytorch_endpoint_name <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">'endpoint-</span><span class="sc" style="color: #5E5E5E;">{}</span><span class="st" style="color: #20794D;">'</span>.<span class="bu" style="color: null;">format</span>(timestamp)</span>
<span id="cb45-4"></span>
<span id="cb45-5">predictor <span class="op" style="color: #5E5E5E;">=</span> model.deploy(initial_instance_count<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">1</span>, </span>
<span id="cb45-6">                         instance_type<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'ml.m5.large'</span>, </span>
<span id="cb45-7">                         endpoint_name<span class="op" style="color: #5E5E5E;">=</span>pytorch_endpoint_name)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>----------!CPU times: user 2min 15s, sys: 9.67 s, total: 2min 24s
Wall time: 7min 24s</code></pre>
</div>
</div>
<section id="start-the-human-loop" class="level3" data-number="5.1">
<h3 data-number="5.1" class="anchored" data-anchor-id="start-the-human-loop"><span class="header-section-number">5.1</span> Start the human loop</h3>
<p>Let’s create a list of sample reviews.</p>
<div class="cell" data-tags="[]" data-execution_count="40">
<div class="sourceCode cell-code" id="cb47" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb47-1">reviews <span class="op" style="color: #5E5E5E;">=</span> [<span class="st" style="color: #20794D;">"I enjoy this product"</span>, </span>
<span id="cb47-2">           <span class="st" style="color: #20794D;">"I am unhappy with this product"</span>, </span>
<span id="cb47-3">           <span class="st" style="color: #20794D;">"It is okay"</span>, </span>
<span id="cb47-4">           <span class="st" style="color: #20794D;">"sometimes it works"</span>]</span></code></pre></div>
</div>
<p>Now we can send each of the sample reviews to the model via the <code>predictor.predict()</code> API call. Note that we need to pass the reviews in the JSON format that model expects as input. Then, we parse the model’s response to obtain the predicted label and the confidence score.</p>
<p>After that, we check the condition for when you want to engage a human for review. We can check whether the returned confidence score is under the defined threshold of 90%, which would mean that we would want to start the human loop with the predicted label and the review as inputs. Finally, we start the human loop passing the input content and Flow Definition defined above.</p>
<div class="cell" data-tags="[]" data-execution_count="41">
<div class="sourceCode cell-code" id="cb48" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb48-1"><span class="im" style="color: #00769E;">import</span> json</span>
<span id="cb48-2"></span>
<span id="cb48-3">human_loops_started <span class="op" style="color: #5E5E5E;">=</span> []</span>
<span id="cb48-4"></span>
<span id="cb48-5">CONFIDENCE_SCORE_THRESHOLD <span class="op" style="color: #5E5E5E;">=</span> <span class="fl" style="color: #AD0000;">0.90</span></span>
<span id="cb48-6"></span>
<span id="cb48-7"><span class="cf" style="color: #003B4F;">for</span> review <span class="kw" style="color: #003B4F;">in</span> reviews:</span>
<span id="cb48-8">    inputs <span class="op" style="color: #5E5E5E;">=</span> [</span>
<span id="cb48-9">        {<span class="st" style="color: #20794D;">"features"</span>: [review]},</span>
<span id="cb48-10">    ]</span>
<span id="cb48-11"></span>
<span id="cb48-12">    response <span class="op" style="color: #5E5E5E;">=</span> predictor.predict(inputs)</span>
<span id="cb48-13">    <span class="bu" style="color: null;">print</span>(response)</span>
<span id="cb48-14">    prediction <span class="op" style="color: #5E5E5E;">=</span> response[<span class="dv" style="color: #AD0000;">0</span>][<span class="st" style="color: #20794D;">'predicted_label'</span>]</span>
<span id="cb48-15">    confidence_score <span class="op" style="color: #5E5E5E;">=</span> response[<span class="dv" style="color: #AD0000;">0</span>][<span class="st" style="color: #20794D;">'probability'</span>]</span>
<span id="cb48-16"></span>
<span id="cb48-17">    <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">'Checking prediction confidence </span><span class="sc" style="color: #5E5E5E;">{}</span><span class="st" style="color: #20794D;"> for sample review: "</span><span class="sc" style="color: #5E5E5E;">{}</span><span class="st" style="color: #20794D;">"'</span>.<span class="bu" style="color: null;">format</span>(confidence_score, review))</span>
<span id="cb48-18"></span>
<span id="cb48-19">    <span class="co" style="color: #5E5E5E;"># condition for when we want to engage a human for review</span></span>
<span id="cb48-20">    <span class="cf" style="color: #003B4F;">if</span> confidence_score <span class="op" style="color: #5E5E5E;">&lt;</span> CONFIDENCE_SCORE_THRESHOLD:</span>
<span id="cb48-21">        human_loop_name <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">str</span>(time.time()).replace(<span class="st" style="color: #20794D;">'.'</span>, <span class="st" style="color: #20794D;">'-'</span>) <span class="co" style="color: #5E5E5E;"># using milliseconds</span></span>
<span id="cb48-22">        input_content <span class="op" style="color: #5E5E5E;">=</span> {</span>
<span id="cb48-23">            <span class="st" style="color: #20794D;">"initialValue"</span>: prediction, </span>
<span id="cb48-24">            <span class="st" style="color: #20794D;">"taskObject"</span>: review </span>
<span id="cb48-25">        }</span>
<span id="cb48-26">        start_loop_response <span class="op" style="color: #5E5E5E;">=</span> a2i.start_human_loop(</span>
<span id="cb48-27">            HumanLoopName<span class="op" style="color: #5E5E5E;">=</span>human_loop_name,</span>
<span id="cb48-28">            FlowDefinitionArn<span class="op" style="color: #5E5E5E;">=</span>augmented_ai_flow_definition_arn,</span>
<span id="cb48-29">            HumanLoopInput<span class="op" style="color: #5E5E5E;">=</span>{<span class="st" style="color: #20794D;">"InputContent"</span>: json.dumps(input_content)},</span>
<span id="cb48-30">        )</span>
<span id="cb48-31"></span>
<span id="cb48-32">        human_loops_started.append(human_loop_name)</span>
<span id="cb48-33"></span>
<span id="cb48-34">        <span class="bu" style="color: null;">print</span>(</span>
<span id="cb48-35">            <span class="ss" style="color: #20794D;">f"Confidence score of </span><span class="sc" style="color: #5E5E5E;">{</span>confidence_score <span class="op" style="color: #5E5E5E;">*</span> <span class="dv" style="color: #AD0000;">100</span><span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">% for prediction of </span><span class="sc" style="color: #5E5E5E;">{</span>prediction<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;"> is less than the threshold of </span><span class="sc" style="color: #5E5E5E;">{</span>CONFIDENCE_SCORE_THRESHOLD <span class="op" style="color: #5E5E5E;">*</span> <span class="dv" style="color: #AD0000;">100</span><span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">%"</span></span>
<span id="cb48-36">        )</span>
<span id="cb48-37">        <span class="bu" style="color: null;">print</span>(<span class="ss" style="color: #20794D;">f"*** ==&gt; Starting human loop with name: </span><span class="sc" style="color: #5E5E5E;">{</span>human_loop_name<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">  </span><span class="ch" style="color: #20794D;">\n</span><span class="ss" style="color: #20794D;">"</span>)</span>
<span id="cb48-38">    <span class="cf" style="color: #003B4F;">else</span>:</span>
<span id="cb48-39">        <span class="bu" style="color: null;">print</span>(</span>
<span id="cb48-40">            <span class="ss" style="color: #20794D;">f"Confidence score of </span><span class="sc" style="color: #5E5E5E;">{</span>confidence_score <span class="op" style="color: #5E5E5E;">*</span> <span class="dv" style="color: #AD0000;">100</span><span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">% for star rating of </span><span class="sc" style="color: #5E5E5E;">{</span>prediction<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;"> is above threshold of </span><span class="sc" style="color: #5E5E5E;">{</span>CONFIDENCE_SCORE_THRESHOLD <span class="op" style="color: #5E5E5E;">*</span> <span class="dv" style="color: #AD0000;">100</span><span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">%"</span></span>
<span id="cb48-41">        )</span>
<span id="cb48-42">        <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">"Human loop not needed. </span><span class="ch" style="color: #20794D;">\n</span><span class="st" style="color: #20794D;">"</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[{'probability': 0.9376369118690491, 'predicted_label': 1}]
Checking prediction confidence 0.9376369118690491 for sample review: "I enjoy this product"
Confidence score of 93.76369118690491% for star rating of 1 is above threshold of 90.0%
Human loop not needed. 

[{'probability': 0.6340296864509583, 'predicted_label': -1}]
Checking prediction confidence 0.6340296864509583 for sample review: "I am unhappy with this product"
Confidence score of 63.402968645095825% for prediction of -1 is less than the threshold of 90.0%
*** ==&gt; Starting human loop with name: 1677154445-9813657  

[{'probability': 0.5422114729881287, 'predicted_label': 1}]
Checking prediction confidence 0.5422114729881287 for sample review: "It is okay"
Confidence score of 54.221147298812866% for prediction of 1 is less than the threshold of 90.0%
*** ==&gt; Starting human loop with name: 1677154446-4558146  

[{'probability': 0.3931102454662323, 'predicted_label': 1}]
Checking prediction confidence 0.3931102454662323 for sample review: "sometimes it works"
Confidence score of 39.31102454662323% for prediction of 1 is less than the threshold of 90.0%
*** ==&gt; Starting human loop with name: 1677154446-8940263  
</code></pre>
</div>
</div>
<p>Three of the sample reviews with the probability scores lower than the threshold went into the human loop. The original predicted labels are passed together with the review text and will be seen in the task.</p>
</section>
<section id="check-status-of-the-human-loop" class="level3" data-number="5.2">
<h3 data-number="5.2" class="anchored" data-anchor-id="check-status-of-the-human-loop"><span class="header-section-number">5.2</span> Check status of the human loop</h3>
<p>Function <code>a2i.describe_human_loop</code> can be used to pull the information about the human loop.</p>
<div class="cell" data-tags="[]" data-execution_count="42">
<div class="sourceCode cell-code" id="cb50" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb50-1">completed_human_loops <span class="op" style="color: #5E5E5E;">=</span> []</span>
<span id="cb50-2"><span class="cf" style="color: #003B4F;">for</span> human_loop_name <span class="kw" style="color: #003B4F;">in</span> human_loops_started:</span>
<span id="cb50-3">    resp <span class="op" style="color: #5E5E5E;">=</span> a2i.describe_human_loop(HumanLoopName<span class="op" style="color: #5E5E5E;">=</span>human_loop_name)</span>
<span id="cb50-4">    <span class="bu" style="color: null;">print</span>(<span class="ss" style="color: #20794D;">f"HumanLoop Name: </span><span class="sc" style="color: #5E5E5E;">{</span>human_loop_name<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">"</span>)</span>
<span id="cb50-5">    <span class="bu" style="color: null;">print</span>(<span class="ss" style="color: #20794D;">f'HumanLoop Status: </span><span class="sc" style="color: #5E5E5E;">{</span>resp[<span class="st" style="color: #20794D;">"HumanLoopStatus"</span>]<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">'</span>)</span>
<span id="cb50-6">    <span class="bu" style="color: null;">print</span>(<span class="ss" style="color: #20794D;">f'HumanLoop Output Destination: </span><span class="sc" style="color: #5E5E5E;">{</span>resp[<span class="st" style="color: #20794D;">"HumanLoopOutput"</span>]<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">'</span>)</span>
<span id="cb50-7">    <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">""</span>)</span>
<span id="cb50-8"></span>
<span id="cb50-9">    <span class="cf" style="color: #003B4F;">if</span> resp[<span class="st" style="color: #20794D;">"HumanLoopStatus"</span>] <span class="op" style="color: #5E5E5E;">==</span> <span class="st" style="color: #20794D;">"Completed"</span>:</span>
<span id="cb50-10">        completed_human_loops.append(resp)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>HumanLoop Name: 1677154445-9813657
HumanLoop Status: InProgress
HumanLoop Output Destination: {'OutputS3Uri': 's3://sagemaker-us-east-1-753124839657/a2i-results-1677153775/fd-1677153775/2023/02/23/12/14/06/1677154445-9813657/output.json'}

HumanLoop Name: 1677154446-4558146
HumanLoop Status: InProgress
HumanLoop Output Destination: {'OutputS3Uri': 's3://sagemaker-us-east-1-753124839657/a2i-results-1677153775/fd-1677153775/2023/02/23/12/14/06/1677154446-4558146/output.json'}

HumanLoop Name: 1677154446-8940263
HumanLoop Status: InProgress
HumanLoop Output Destination: {'OutputS3Uri': 's3://sagemaker-us-east-1-753124839657/a2i-results-1677153775/fd-1677153775/2023/02/23/12/14/06/1677154446-8940263/output.json'}
</code></pre>
</div>
</div>
</section>
<section id="complete-the-human-loop-tasks" class="level3" data-number="5.3">
<h3 data-number="5.3" class="anchored" data-anchor-id="complete-the-human-loop-tasks"><span class="header-section-number">5.3</span> Complete the human loop tasks</h3>
<p>Now we will pull the labeling UI from the workteam information to get into the human loop tasks in the AWS console.</p>
<div class="cell" data-tags="[]" data-execution_count="43">
<div class="sourceCode cell-code" id="cb52" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb52-1">labeling_ui <span class="op" style="color: #5E5E5E;">=</span> sm.describe_workteam(WorkteamName<span class="op" style="color: #5E5E5E;">=</span>workteam_name)[<span class="st" style="color: #20794D;">"Workteam"</span>][<span class="st" style="color: #20794D;">"SubDomain"</span>]</span>
<span id="cb52-2"><span class="bu" style="color: null;">print</span>(labeling_ui)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>aqa042udc1.labeling.us-east-1.sagemaker.aws</code></pre>
</div>
</div>
<p>We will navigate to a link and login with the defined username and password.</p>
<p><img src="http://livingdatalab.com/posts/https:/github.com/pranath/blog/raw/master/images/label-data-job-instructions.png" title="Human in the loop Workflow" class="img-fluid"></p>
</section>
<section id="verify-that-the-human-loops-were-completed-by-the-workforce" class="level3" data-number="5.4">
<h3 data-number="5.4" class="anchored" data-anchor-id="verify-that-the-human-loops-were-completed-by-the-workforce"><span class="header-section-number">5.4</span> Verify that the human loops were completed by the workforce</h3>
<div class="cell" data-tags="[]" data-execution_count="45">
<div class="sourceCode cell-code" id="cb54" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb54-1"><span class="im" style="color: #00769E;">import</span> time</span>
<span id="cb54-2"></span>
<span id="cb54-3">completed_human_loops <span class="op" style="color: #5E5E5E;">=</span> []</span>
<span id="cb54-4"><span class="cf" style="color: #003B4F;">for</span> human_loop_name <span class="kw" style="color: #003B4F;">in</span> human_loops_started:</span>
<span id="cb54-5">    resp <span class="op" style="color: #5E5E5E;">=</span> a2i.describe_human_loop(HumanLoopName<span class="op" style="color: #5E5E5E;">=</span>human_loop_name)</span>
<span id="cb54-6">    <span class="bu" style="color: null;">print</span>(<span class="ss" style="color: #20794D;">f"HumanLoop Name: </span><span class="sc" style="color: #5E5E5E;">{</span>human_loop_name<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">"</span>)</span>
<span id="cb54-7">    <span class="bu" style="color: null;">print</span>(<span class="ss" style="color: #20794D;">f'HumanLoop Status: </span><span class="sc" style="color: #5E5E5E;">{</span>resp[<span class="st" style="color: #20794D;">"HumanLoopStatus"</span>]<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">'</span>)</span>
<span id="cb54-8">    <span class="bu" style="color: null;">print</span>(<span class="ss" style="color: #20794D;">f'HumanLoop Output Destination: </span><span class="sc" style="color: #5E5E5E;">{</span>resp[<span class="st" style="color: #20794D;">"HumanLoopOutput"</span>]<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">'</span>)</span>
<span id="cb54-9">    <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">""</span>)</span>
<span id="cb54-10">    <span class="cf" style="color: #003B4F;">while</span> resp[<span class="st" style="color: #20794D;">"HumanLoopStatus"</span>] <span class="op" style="color: #5E5E5E;">!=</span> <span class="st" style="color: #20794D;">"Completed"</span>:</span>
<span id="cb54-11">        <span class="bu" style="color: null;">print</span>(<span class="ss" style="color: #20794D;">f"Waiting for HumanLoop to complete."</span>)</span>
<span id="cb54-12">        time.sleep(<span class="dv" style="color: #AD0000;">10</span>)</span>
<span id="cb54-13">        resp <span class="op" style="color: #5E5E5E;">=</span> a2i.describe_human_loop(HumanLoopName<span class="op" style="color: #5E5E5E;">=</span>human_loop_name)</span>
<span id="cb54-14">    <span class="cf" style="color: #003B4F;">if</span> resp[<span class="st" style="color: #20794D;">"HumanLoopStatus"</span>] <span class="op" style="color: #5E5E5E;">==</span> <span class="st" style="color: #20794D;">"Completed"</span>:</span>
<span id="cb54-15">        completed_human_loops.append(resp)</span>
<span id="cb54-16">        <span class="bu" style="color: null;">print</span>(<span class="ss" style="color: #20794D;">f"Completed!"</span>)</span>
<span id="cb54-17">        <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">""</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>HumanLoop Name: 1677154445-9813657
HumanLoop Status: InProgress
HumanLoop Output Destination: {'OutputS3Uri': 's3://sagemaker-us-east-1-753124839657/a2i-results-1677153775/fd-1677153775/2023/02/23/12/14/06/1677154445-9813657/output.json'}

Waiting for HumanLoop to complete.
Waiting for HumanLoop to complete.
Waiting for HumanLoop to complete.
Waiting for HumanLoop to complete.
Waiting for HumanLoop to complete.
Waiting for HumanLoop to complete.
Waiting for HumanLoop to complete.
Waiting for HumanLoop to complete.
Waiting for HumanLoop to complete.
Waiting for HumanLoop to complete.
Waiting for HumanLoop to complete.
Waiting for HumanLoop to complete.
Waiting for HumanLoop to complete.
Waiting for HumanLoop to complete.
Waiting for HumanLoop to complete.
Completed!

HumanLoop Name: 1677154446-4558146
HumanLoop Status: Completed
HumanLoop Output Destination: {'OutputS3Uri': 's3://sagemaker-us-east-1-753124839657/a2i-results-1677153775/fd-1677153775/2023/02/23/12/14/06/1677154446-4558146/output.json'}

Completed!

HumanLoop Name: 1677154446-8940263
HumanLoop Status: Completed
HumanLoop Output Destination: {'OutputS3Uri': 's3://sagemaker-us-east-1-753124839657/a2i-results-1677153775/fd-1677153775/2023/02/23/12/14/06/1677154446-8940263/output.json'}

Completed!
</code></pre>
</div>
</div>
<p><strong>This process ^^ above ^^ will not complete until we label the data following the instructions above.</strong></p>
</section>
<section id="view-human-labels-and-prepare-the-data-for-re-training" class="level3" data-number="5.5">
<h3 data-number="5.5" class="anchored" data-anchor-id="view-human-labels-and-prepare-the-data-for-re-training"><span class="header-section-number">5.5</span> View human labels and prepare the data for re-training</h3>
<p>Once the work is complete, Amazon A2I stores the results in the specified S3 bucket and sends a Cloudwatch Event. Let’s check the S3 contents.</p>
<div class="cell" data-scrolled="true" data-tags="[]" data-execution_count="46">
<div class="sourceCode cell-code" id="cb56" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb56-1"><span class="im" style="color: #00769E;">import</span> re</span>
<span id="cb56-2"><span class="im" style="color: #00769E;">from</span> pprint <span class="im" style="color: #00769E;">import</span> pprint</span>
<span id="cb56-3"></span>
<span id="cb56-4">fixed_items <span class="op" style="color: #5E5E5E;">=</span> []</span>
<span id="cb56-5"></span>
<span id="cb56-6"><span class="cf" style="color: #003B4F;">for</span> resp <span class="kw" style="color: #003B4F;">in</span> completed_human_loops:</span>
<span id="cb56-7">    split_string <span class="op" style="color: #5E5E5E;">=</span> re.split(<span class="st" style="color: #20794D;">"s3://"</span> <span class="op" style="color: #5E5E5E;">+</span> bucket <span class="op" style="color: #5E5E5E;">+</span> <span class="st" style="color: #20794D;">"/"</span>, resp[<span class="st" style="color: #20794D;">"HumanLoopOutput"</span>][<span class="st" style="color: #20794D;">"OutputS3Uri"</span>])</span>
<span id="cb56-8">    output_bucket_key <span class="op" style="color: #5E5E5E;">=</span> split_string[<span class="dv" style="color: #AD0000;">1</span>]</span>
<span id="cb56-9"></span>
<span id="cb56-10">    response <span class="op" style="color: #5E5E5E;">=</span> s3.get_object(Bucket<span class="op" style="color: #5E5E5E;">=</span>bucket, Key<span class="op" style="color: #5E5E5E;">=</span>output_bucket_key)</span>
<span id="cb56-11">    content <span class="op" style="color: #5E5E5E;">=</span> response[<span class="st" style="color: #20794D;">"Body"</span>].read().decode(<span class="st" style="color: #20794D;">"utf-8"</span>)</span>
<span id="cb56-12">    json_output <span class="op" style="color: #5E5E5E;">=</span> json.loads(content)</span>
<span id="cb56-13">    pprint(json_output)</span>
<span id="cb56-14"></span>
<span id="cb56-15">    input_content <span class="op" style="color: #5E5E5E;">=</span> json_output[<span class="st" style="color: #20794D;">"inputContent"</span>]</span>
<span id="cb56-16">    human_answer <span class="op" style="color: #5E5E5E;">=</span> json_output[<span class="st" style="color: #20794D;">"humanAnswers"</span>][<span class="dv" style="color: #AD0000;">0</span>][<span class="st" style="color: #20794D;">"answerContent"</span>]</span>
<span id="cb56-17">    fixed_item <span class="op" style="color: #5E5E5E;">=</span> {<span class="st" style="color: #20794D;">"input_content"</span>: input_content, <span class="st" style="color: #20794D;">"human_answer"</span>: human_answer}</span>
<span id="cb56-18">    fixed_items.append(fixed_item)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>{'flowDefinitionArn': 'arn:aws:sagemaker:us-east-1:753124839657:flow-definition/fd-1677153775',
 'humanAnswers': [{'acceptanceTime': '2023-02-23T12:16:28.736Z',
                   'answerContent': {'sentiment': {'label': '-1'}},
                   'submissionTime': '2023-02-23T12:16:33.547Z',
                   'timeSpentInSeconds': 4.811,
                   'workerId': '0e31fea759d04da1',
                   'workerMetadata': {'identityData': {'identityProviderType': 'Cognito',
                                                       'issuer': 'https://cognito-idp.us-east-1.amazonaws.com/us-east-1_8s0SOCEPn',
                                                       'sub': '7e22b0c1-059a-45b4-b69a-e1b378950097'}}}],
 'humanLoopName': '1677154445-9813657',
 'inputContent': {'initialValue': -1,
                  'taskObject': 'I am unhappy with this product'}}
{'flowDefinitionArn': 'arn:aws:sagemaker:us-east-1:753124839657:flow-definition/fd-1677153775',
 'humanAnswers': [{'acceptanceTime': '2023-02-23T12:16:06.376Z',
                   'answerContent': {'sentiment': {'label': '0'}},
                   'submissionTime': '2023-02-23T12:16:23.626Z',
                   'timeSpentInSeconds': 17.25,
                   'workerId': '0e31fea759d04da1',
                   'workerMetadata': {'identityData': {'identityProviderType': 'Cognito',
                                                       'issuer': 'https://cognito-idp.us-east-1.amazonaws.com/us-east-1_8s0SOCEPn',
                                                       'sub': '7e22b0c1-059a-45b4-b69a-e1b378950097'}}}],
 'humanLoopName': '1677154446-4558146',
 'inputContent': {'initialValue': 1, 'taskObject': 'It is okay'}}
{'flowDefinitionArn': 'arn:aws:sagemaker:us-east-1:753124839657:flow-definition/fd-1677153775',
 'humanAnswers': [{'acceptanceTime': '2023-02-23T12:16:23.694Z',
                   'answerContent': {'sentiment': {'label': '0'}},
                   'submissionTime': '2023-02-23T12:16:28.668Z',
                   'timeSpentInSeconds': 4.974,
                   'workerId': '0e31fea759d04da1',
                   'workerMetadata': {'identityData': {'identityProviderType': 'Cognito',
                                                       'issuer': 'https://cognito-idp.us-east-1.amazonaws.com/us-east-1_8s0SOCEPn',
                                                       'sub': '7e22b0c1-059a-45b4-b69a-e1b378950097'}}}],
 'humanLoopName': '1677154446-8940263',
 'inputContent': {'initialValue': 1, 'taskObject': 'sometimes it works'}}</code></pre>
</div>
</div>
<p>Now we can prepare the data for re-training.</p>
<div class="cell" data-tags="[]" data-execution_count="47">
<div class="sourceCode cell-code" id="cb58" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb58-1">df_fixed_items <span class="op" style="color: #5E5E5E;">=</span> pd.DataFrame(fixed_items)  </span>
<span id="cb58-2">df_fixed_items.head()</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="47">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>input_content</th>
      <th>human_answer</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>{'initialValue': -1, 'taskObject': 'I am unhap...</td>
      <td>{'sentiment': {'label': '-1'}}</td>
    </tr>
    <tr>
      <th>1</th>
      <td>{'initialValue': 1, 'taskObject': 'It is okay'}</td>
      <td>{'sentiment': {'label': '0'}}</td>
    </tr>
    <tr>
      <th>2</th>
      <td>{'initialValue': 1, 'taskObject': 'sometimes i...</td>
      <td>{'sentiment': {'label': '0'}}</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
</section>
</section>
<section id="acknowledgements" class="level2" data-number="6">
<h2 data-number="6" class="anchored" data-anchor-id="acknowledgements"><span class="header-section-number">6</span> Acknowledgements</h2>
<p>I’d like to express my thanks to the great <a href="https://www.deeplearning.ai/courses/practical-data-science-specialization/">Deep Learning AI Practical Data Science on AWS Specialisation Course</a> which i completed, and acknowledge the use of some images and other materials from the training course in this article.</p>


</section>

 ]]></description>
  <category>aws</category>
  <category>cloud-data-science</category>
  <category>natural-language-processing</category>
  <category>deep-learning</category>
  <guid>http://livingdatalab.com/posts/2023-02-24-custom-models-human-loop-pipelines-aws-augmented-ai.html</guid>
  <pubDate>Fri, 24 Feb 2023 00:00:00 GMT</pubDate>
  <media:content url="https://github.com/pranath/blog/raw/master/images/aws4.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Advanced Model Deployment on AWS - A/B testing traffic shifting and autoscaling</title>
  <dc:creator>Pranath Fernando</dc:creator>
  <link>http://livingdatalab.com/posts/2023-02-22-advanced-model-deployment-on-aws.html</link>
  <description><![CDATA[ 




<section id="introduction" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="introduction"><span class="header-section-number">1</span> Introduction</h2>
<p>In <a href="../#category=aws">earlier articles we introduced AWS cloud services for data science</a>, and showed how it can help with different stages of the data science &amp; machine learning workflow.</p>
<p><img src="http://livingdatalab.com/posts/https:/github.com/pranath/blog/raw/master/images/aws_ds_workflow.png" title="The AWS Data Science Workflow" class="img-fluid"></p>
<p>AWS Sagemaker offers many options for deploying models, in this project we will create an endpoint for a text classification model, splitting the traffic between them. Then after testing and reviewing the endpoint performance metrics, we will shift the traffic to one variant and configure it to autoscale.</p>
</section>
<section id="deployment-options" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="deployment-options"><span class="header-section-number">2</span> Deployment Options</h2>
<p>There are normally 3 main deployment options available for cloud computing services such as AWS.</p>
<ul>
<li><strong>Real-Time Inference:</strong> This involves a continually running process that responds to individual prediction requests on demand</li>
<li><strong>Batch Inference:</strong> This involves spinning up computing resources, performing a batch of predictions in one go, then switching off these resources when the process is complete</li>
<li><strong>Edge:</strong> This involves optimising a model for running closer to the user on edge devices such as mobile phones to generate predictions there</li>
</ul>
<p>Real time inference can be useful to respond to requests on demand, such as allowing quick responses to negative customer reviews.</p>
<p><img src="http://livingdatalab.com/posts/https:/github.com/pranath/blog/raw/master/images/aws_deploy1.png" title="Deployment Options" class="img-fluid"></p>
<p>Batch inference can be useful when time is less critical, for example if we want to indentify a vendor with potential quality issues, we would want to look at a large number of reviews over time.</p>
<p><img src="http://livingdatalab.com/posts/https:/github.com/pranath/blog/raw/master/images/aws_deploy2.png" title="Deployment Options" class="img-fluid"></p>
<p>Edge deployment can be useful when we want to provide predictions on the device itself, for example when privacy is a concern and we want to keep the data on the users device.</p>
<p><img src="http://livingdatalab.com/posts/https:/github.com/pranath/blog/raw/master/images/aws_deploy3.png" title="Deployment Options" class="img-fluid"></p>
<p>When should we use each option? this will depend on your use case and a number of factors such as cost and how quickly and where the predictions are needed.</p>
<p><img src="http://livingdatalab.com/posts/https:/github.com/pranath/blog/raw/master/images/aws_deploy4.png" title="Deployment Options" class="img-fluid"></p>
<p>As a general rule, you should use the option that meets your use case and is the most cost effective.</p>
</section>
<section id="deployment-strategies-autoscaling" class="level2" data-number="3">
<h2 data-number="3" class="anchored" data-anchor-id="deployment-strategies-autoscaling"><span class="header-section-number">3</span> Deployment Strategies &amp; Autoscaling</h2>
<p>When we deploy models we have 3 key objectives:</p>
<ul>
<li>Minimise risk</li>
<li>Minimise down time</li>
<li>Measure model performance</li>
</ul>
<p>There are a range of possible deployment strategies including:</p>
<p><img src="http://livingdatalab.com/posts/https:/github.com/pranath/blog/raw/master/images/aws_deploystrat2.png" title="Deployment Strategies" class="img-fluid"></p>
<p>In this project we will be using A/B testing.</p>
<p><img src="http://livingdatalab.com/posts/https:/github.com/pranath/blog/raw/master/images/aws_deploystrat3.png" title="Deployment Strategies" class="img-fluid"></p>
<p>Another interesting strategy thats more dynamic is Multi Armed Bandits which use machine learning to switch between different models dynamically depending on changing performance.</p>
<p><img src="http://livingdatalab.com/posts/https:/github.com/pranath/blog/raw/master/images/aws_deploystrat4.png" title="Deployment Strategies" class="img-fluid"></p>
<p>But we will be using A/B testing.</p>
<p>We will also be using AWS Sagemaker Hosting to automatically scale our resources depending on demand.</p>
<p><img src="http://livingdatalab.com/posts/https:/github.com/pranath/blog/raw/master/images/aws_autoscale2.png" title="Deployment Strategies" class="img-fluid"></p>
</section>
<section id="setup" class="level2" data-number="4">
<h2 data-number="4" class="anchored" data-anchor-id="setup"><span class="header-section-number">4</span> Setup</h2>
<p>Let’s install and import the required modules.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;">import</span> matplotlib.pyplot <span class="im" style="color: #00769E;">as</span> plt</span>
<span id="cb1-2"><span class="op" style="color: #5E5E5E;">%</span>matplotlib inline</span>
<span id="cb1-3"><span class="op" style="color: #5E5E5E;">%</span>config InlineBackend.figure_format<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'retina'</span></span></code></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="im" style="color: #00769E;">import</span> boto3</span>
<span id="cb2-2"><span class="im" style="color: #00769E;">import</span> sagemaker</span>
<span id="cb2-3"><span class="im" style="color: #00769E;">import</span> pandas <span class="im" style="color: #00769E;">as</span> pd</span>
<span id="cb2-4"><span class="im" style="color: #00769E;">import</span> botocore</span>
<span id="cb2-5"></span>
<span id="cb2-6">config <span class="op" style="color: #5E5E5E;">=</span> botocore.config.Config(user_agent_extra<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'dlai-pds/c3/w2'</span>)</span>
<span id="cb2-7"></span>
<span id="cb2-8"><span class="co" style="color: #5E5E5E;"># low-level service client of the boto3 session</span></span>
<span id="cb2-9">sm <span class="op" style="color: #5E5E5E;">=</span> boto3.client(service_name<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'sagemaker'</span>, </span>
<span id="cb2-10">                  config<span class="op" style="color: #5E5E5E;">=</span>config)</span>
<span id="cb2-11"></span>
<span id="cb2-12">sm_runtime <span class="op" style="color: #5E5E5E;">=</span> boto3.client(<span class="st" style="color: #20794D;">'sagemaker-runtime'</span>,</span>
<span id="cb2-13">                          config<span class="op" style="color: #5E5E5E;">=</span>config)</span>
<span id="cb2-14"></span>
<span id="cb2-15">sess <span class="op" style="color: #5E5E5E;">=</span> sagemaker.Session(sagemaker_client<span class="op" style="color: #5E5E5E;">=</span>sm,</span>
<span id="cb2-16">                         sagemaker_runtime_client<span class="op" style="color: #5E5E5E;">=</span>sm_runtime)</span>
<span id="cb2-17"></span>
<span id="cb2-18">bucket <span class="op" style="color: #5E5E5E;">=</span> sess.default_bucket()</span>
<span id="cb2-19">role <span class="op" style="color: #5E5E5E;">=</span> sagemaker.get_execution_role()</span>
<span id="cb2-20">region <span class="op" style="color: #5E5E5E;">=</span> sess.boto_region_name</span>
<span id="cb2-21"></span>
<span id="cb2-22">cw <span class="op" style="color: #5E5E5E;">=</span> boto3.client(service_name<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'cloudwatch'</span>, </span>
<span id="cb2-23">                  config<span class="op" style="color: #5E5E5E;">=</span>config)</span>
<span id="cb2-24"></span>
<span id="cb2-25">autoscale <span class="op" style="color: #5E5E5E;">=</span> boto3.client(service_name<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"application-autoscaling"</span>, </span>
<span id="cb2-26">                         config<span class="op" style="color: #5E5E5E;">=</span>config)</span></code></pre></div>
</div>
</section>
<section id="create-an-endpoint-with-multiple-variants" class="level2" data-number="5">
<h2 data-number="5" class="anchored" data-anchor-id="create-an-endpoint-with-multiple-variants"><span class="header-section-number">5</span> Create an endpoint with multiple variants</h2>
<p>We have two models trained to analyze customer feedback and classify the messages into positive (1), neutral (0), and negative (-1) sentiments are saved in the following S3 bucket paths. These <code>tar.gz</code> files contain the model artifacts, which result from model training.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1">model_a_s3_uri <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">'s3://dlai-practical-data-science/models/ab/variant_a/model.tar.gz'</span></span>
<span id="cb3-2">model_b_s3_uri <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">'s3://dlai-practical-data-science/models/ab/variant_b/model.tar.gz'</span></span></code></pre></div>
</div>
<p>Let’s deploy an endpoint splitting the traffic between these two models 50/50 to perform A/B Testing. Instead of creating a PyTorch Model object and calling <code>model.deploy()</code> function, we will create an <code>Endpoint configuration</code> with multiple model variants. Here is the workflow we will follow to create an endpoint:</p>
<p><img src="http://livingdatalab.com/posts/https:/github.com/pranath/blog/raw/master/images/endpoint-workflow.png" title="Endpoint Workflow" class="img-fluid"></p>
<section id="construct-docker-image-uri" class="level3" data-number="5.1">
<h3 data-number="5.1" class="anchored" data-anchor-id="construct-docker-image-uri"><span class="header-section-number">5.1</span> Construct Docker Image URI</h3>
<p>We will need to create the models in Amazon SageMaker, which retrieves the URI for the pre-built SageMaker Docker image stored in Amazon Elastic Container Re gistry (ECR). Let’s construct the ECR URI which we will pass into the <code>create_model</code> function later.</p>
<p>Now lets set the instance type. For the purposes of this project, we will use a relatively small instance. Please refer to <a href="https://aws.amazon.com/sagemaker/pricing/">this link</a> for additional instance types that may work for your use cases.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1">inference_instance_type <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">'ml.m5.large'</span></span></code></pre></div>
</div>
<p>Let’s create an ECR URI using the <code>'PyTorch'</code> framework.</p>
<div class="cell" data-outputid="86feb216-d666-4b46-cad8-1a542370ec59">
<div class="sourceCode cell-code" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1">inference_image_uri <span class="op" style="color: #5E5E5E;">=</span> sagemaker.image_uris.retrieve(</span>
<span id="cb5-2">    framework<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'pytorch'</span>, </span>
<span id="cb5-3">    version<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'1.6.0'</span>,</span>
<span id="cb5-4">    instance_type<span class="op" style="color: #5E5E5E;">=</span>inference_instance_type,</span>
<span id="cb5-5">    region<span class="op" style="color: #5E5E5E;">=</span>region,</span>
<span id="cb5-6">    py_version<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'py3'</span>,</span>
<span id="cb5-7">    image_scope<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'inference'</span></span>
<span id="cb5-8">)</span>
<span id="cb5-9"><span class="bu" style="color: null;">print</span>(inference_image_uri)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>763104351884.dkr.ecr.us-east-1.amazonaws.com/pytorch-inference:1.6.0-cpu-py3</code></pre>
</div>
</div>
</section>
<section id="create-amazon-sagemaker-models" class="level3" data-number="5.2">
<h3 data-number="5.2" class="anchored" data-anchor-id="create-amazon-sagemaker-models"><span class="header-section-number">5.2</span> Create Amazon SageMaker Models</h3>
<p>Amazon SageMaker Model includes information such as the S3 location of the model, the container image that can be used for inference with that model, the execution role, and the model name.</p>
<p>Let’s construct the model names.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><span class="im" style="color: #00769E;">import</span> time</span>
<span id="cb7-2"><span class="im" style="color: #00769E;">from</span> pprint <span class="im" style="color: #00769E;">import</span> pprint</span>
<span id="cb7-3"></span>
<span id="cb7-4">timestamp <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">int</span>(time.time())</span>
<span id="cb7-5"></span>
<span id="cb7-6">model_name_a <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">'</span><span class="sc" style="color: #5E5E5E;">{}</span><span class="st" style="color: #20794D;">-</span><span class="sc" style="color: #5E5E5E;">{}</span><span class="st" style="color: #20794D;">'</span>.<span class="bu" style="color: null;">format</span>(<span class="st" style="color: #20794D;">'a'</span>, timestamp)</span>
<span id="cb7-7">model_name_b <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">'</span><span class="sc" style="color: #5E5E5E;">{}</span><span class="st" style="color: #20794D;">-</span><span class="sc" style="color: #5E5E5E;">{}</span><span class="st" style="color: #20794D;">'</span>.<span class="bu" style="color: null;">format</span>(<span class="st" style="color: #20794D;">'b'</span>, timestamp)</span></code></pre></div>
</div>
<p>We will use the following function to check if the model already exists in Amazon SageMaker.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><span class="kw" style="color: #003B4F;">def</span> check_model_existence(model_name):</span>
<span id="cb8-2">    <span class="cf" style="color: #003B4F;">for</span> model <span class="kw" style="color: #003B4F;">in</span> sm.list_models()[<span class="st" style="color: #20794D;">'Models'</span>]:</span>
<span id="cb8-3">        <span class="cf" style="color: #003B4F;">if</span> model_name <span class="op" style="color: #5E5E5E;">==</span> model[<span class="st" style="color: #20794D;">'ModelName'</span>]:</span>
<span id="cb8-4">            <span class="cf" style="color: #003B4F;">return</span> <span class="va" style="color: #111111;">True</span></span>
<span id="cb8-5">    <span class="cf" style="color: #003B4F;">return</span> <span class="va" style="color: #111111;">False</span></span></code></pre></div>
</div>
<p>Now we shall create an Amazon SageMaker Model based on the <code>model_a_s3_uri</code> data.</p>
<p>We will use the <code>sm.create_model</code> function, which requires the model name, Amazon SageMaker execution role and a primary container description (<code>PrimaryContainer</code> dictionary). The <code>PrimaryContainer</code> includes the S3 bucket location of the model artifacts (<code>ModelDataUrl</code> key) and ECR URI (<code>Image</code> key).</p>
<div class="cell" data-outputid="869025f6-49ee-4893-d99e-205ef7841156">
<div class="sourceCode cell-code" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><span class="cf" style="color: #003B4F;">if</span> <span class="kw" style="color: #003B4F;">not</span> check_model_existence(model_name_a):</span>
<span id="cb9-2">    model_a <span class="op" style="color: #5E5E5E;">=</span> sm.create_model(</span>
<span id="cb9-3">        ModelName<span class="op" style="color: #5E5E5E;">=</span>model_name_a,</span>
<span id="cb9-4">        ExecutionRoleArn<span class="op" style="color: #5E5E5E;">=</span>role,</span>
<span id="cb9-5">        PrimaryContainer<span class="op" style="color: #5E5E5E;">=</span>{</span>
<span id="cb9-6">            <span class="st" style="color: #20794D;">'ModelDataUrl'</span>: model_a_s3_uri,</span>
<span id="cb9-7">            <span class="st" style="color: #20794D;">'Image'</span>: inference_image_uri </span>
<span id="cb9-8">        }</span>
<span id="cb9-9">    )</span>
<span id="cb9-10">    pprint(model_a)</span>
<span id="cb9-11"><span class="cf" style="color: #003B4F;">else</span>:</span>
<span id="cb9-12">    <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">"Model </span><span class="sc" style="color: #5E5E5E;">{}</span><span class="st" style="color: #20794D;"> already exists"</span>.<span class="bu" style="color: null;">format</span>(model_name_a))</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>{'ModelArn': 'arn:aws:sagemaker:us-east-1:266291165402:model/a-1677082486',
 'ResponseMetadata': {'HTTPHeaders': {'content-length': '74',
                                      'content-type': 'application/x-amz-json-1.1',
                                      'date': 'Wed, 22 Feb 2023 16:15:03 GMT',
                                      'x-amzn-requestid': '8f653536-35b7-40ee-8b7f-de44570c71b9'},
                      'HTTPStatusCode': 200,
                      'RequestId': '8f653536-35b7-40ee-8b7f-de44570c71b9',
                      'RetryAttempts': 0}}</code></pre>
</div>
</div>
<p>Now lets create an Amazon SageMaker Model based on the <code>model_b_s3_uri</code> data.</p>
<div class="cell" data-outputid="cabdbd7d-8679-40ac-b13b-32219ea1dcc0">
<div class="sourceCode cell-code" id="cb11" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><span class="cf" style="color: #003B4F;">if</span> <span class="kw" style="color: #003B4F;">not</span> check_model_existence(model_name_b):</span>
<span id="cb11-2">    model_b <span class="op" style="color: #5E5E5E;">=</span> sm.create_model(</span>
<span id="cb11-3">        ModelName<span class="op" style="color: #5E5E5E;">=</span>model_name_b, </span>
<span id="cb11-4">        ExecutionRoleArn<span class="op" style="color: #5E5E5E;">=</span>role, </span>
<span id="cb11-5">        PrimaryContainer<span class="op" style="color: #5E5E5E;">=</span>{</span>
<span id="cb11-6">            <span class="st" style="color: #20794D;">'ModelDataUrl'</span>: model_b_s3_uri, </span>
<span id="cb11-7">            <span class="st" style="color: #20794D;">'Image'</span>: inference_image_uri</span>
<span id="cb11-8">        }</span>
<span id="cb11-9">    )</span>
<span id="cb11-10">    pprint(model_b)</span>
<span id="cb11-11"><span class="cf" style="color: #003B4F;">else</span>:</span>
<span id="cb11-12">    <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">"Model </span><span class="sc" style="color: #5E5E5E;">{}</span><span class="st" style="color: #20794D;"> already exists"</span>.<span class="bu" style="color: null;">format</span>(model_name_b))</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>{'ModelArn': 'arn:aws:sagemaker:us-east-1:266291165402:model/b-1677082486',
 'ResponseMetadata': {'HTTPHeaders': {'content-length': '74',
                                      'content-type': 'application/x-amz-json-1.1',
                                      'date': 'Wed, 22 Feb 2023 16:15:23 GMT',
                                      'x-amzn-requestid': 'a58a4de2-8ba0-4388-99b8-4f10031c606d'},
                      'HTTPStatusCode': 200,
                      'RequestId': 'a58a4de2-8ba0-4388-99b8-4f10031c606d',
                      'RetryAttempts': 0}}</code></pre>
</div>
</div>
</section>
<section id="set-up-amazon-sagemaker-production-variants" class="level3" data-number="5.3">
<h3 data-number="5.3" class="anchored" data-anchor-id="set-up-amazon-sagemaker-production-variants"><span class="header-section-number">5.3</span> Set up Amazon SageMaker production variants</h3>
<p>A production variant is a packaged SageMaker Model combined with the configuration related to how that model will be hosted.</p>
<p>We have constructed the model in the section above. The hosting resources configuration includes information on how we want that model to be hosted: the number and type of instances, a pointer to the SageMaker package model, as well as a variant name and variant weight. A single SageMaker Endpoint can actually include multiple production variants.</p>
<p>Let’s create an Amazon SageMaker production variant for the SageMaker Model with the <code>model_name_a</code>.</p>
<div class="cell" data-outputid="0b32393f-161e-43fc-bcf4-2e36f3a51773">
<div class="sourceCode cell-code" id="cb13" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><span class="im" style="color: #00769E;">from</span> sagemaker.session <span class="im" style="color: #00769E;">import</span> production_variant</span>
<span id="cb13-2"></span>
<span id="cb13-3">variantA <span class="op" style="color: #5E5E5E;">=</span> production_variant(</span>
<span id="cb13-4">    model_name<span class="op" style="color: #5E5E5E;">=</span>model_name_a, </span>
<span id="cb13-5">    instance_type<span class="op" style="color: #5E5E5E;">=</span>inference_instance_type, </span>
<span id="cb13-6">    initial_weight<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">50</span>,</span>
<span id="cb13-7">    initial_instance_count<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">1</span>,</span>
<span id="cb13-8">    variant_name<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'VariantA'</span>,</span>
<span id="cb13-9">)</span>
<span id="cb13-10"><span class="bu" style="color: null;">print</span>(variantA)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>{'ModelName': 'a-1677082486', 'InstanceType': 'ml.m5.large', 'InitialInstanceCount': 1, 'VariantName': 'VariantA', 'InitialVariantWeight': 50}</code></pre>
</div>
</div>
<p>Now lets create an Amazon SageMaker production variant for the SageMaker Model with the <code>model_name_b</code>.</p>
<div class="cell" data-outputid="20ff2b26-1a2f-4775-fcb2-073a9e7e33ec">
<div class="sourceCode cell-code" id="cb15" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1">variantB <span class="op" style="color: #5E5E5E;">=</span> production_variant(</span>
<span id="cb15-2">    model_name<span class="op" style="color: #5E5E5E;">=</span>model_name_b, </span>
<span id="cb15-3">    instance_type<span class="op" style="color: #5E5E5E;">=</span>inference_instance_type, </span>
<span id="cb15-4">    initial_weight<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">50</span>, </span>
<span id="cb15-5">    initial_instance_count<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">1</span>,</span>
<span id="cb15-6">    variant_name<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'VariantB'</span></span>
<span id="cb15-7">)</span>
<span id="cb15-8"><span class="bu" style="color: null;">print</span>(variantB)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>{'ModelName': 'b-1677082486', 'InstanceType': 'ml.m5.large', 'InitialInstanceCount': 1, 'VariantName': 'VariantB', 'InitialVariantWeight': 50}</code></pre>
</div>
</div>
</section>
<section id="configure-and-create-the-endpoint" class="level3" data-number="5.4">
<h3 data-number="5.4" class="anchored" data-anchor-id="configure-and-create-the-endpoint"><span class="header-section-number">5.4</span> Configure and create the endpoint</h3>
<p>We will use the following functions to check if the endpoint configuration and endpoint itself already exist in Amazon SageMaker.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb17" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><span class="kw" style="color: #003B4F;">def</span> check_endpoint_config_existence(endpoint_config_name):</span>
<span id="cb17-2">    <span class="cf" style="color: #003B4F;">for</span> endpoint_config <span class="kw" style="color: #003B4F;">in</span> sm.list_endpoint_configs()[<span class="st" style="color: #20794D;">'EndpointConfigs'</span>]:</span>
<span id="cb17-3">        <span class="cf" style="color: #003B4F;">if</span> endpoint_config_name <span class="op" style="color: #5E5E5E;">==</span> endpoint_config[<span class="st" style="color: #20794D;">'EndpointConfigName'</span>]:</span>
<span id="cb17-4">            <span class="cf" style="color: #003B4F;">return</span> <span class="va" style="color: #111111;">True</span></span>
<span id="cb17-5">    <span class="cf" style="color: #003B4F;">return</span> <span class="va" style="color: #111111;">False</span></span>
<span id="cb17-6"></span>
<span id="cb17-7"><span class="kw" style="color: #003B4F;">def</span> check_endpoint_existence(endpoint_name):</span>
<span id="cb17-8">    <span class="cf" style="color: #003B4F;">for</span> endpoint <span class="kw" style="color: #003B4F;">in</span> sm.list_endpoints()[<span class="st" style="color: #20794D;">'Endpoints'</span>]:</span>
<span id="cb17-9">        <span class="cf" style="color: #003B4F;">if</span> endpoint_name <span class="op" style="color: #5E5E5E;">==</span> endpoint[<span class="st" style="color: #20794D;">'EndpointName'</span>]:</span>
<span id="cb17-10">            <span class="cf" style="color: #003B4F;">return</span> <span class="va" style="color: #111111;">True</span></span>
<span id="cb17-11">    <span class="cf" style="color: #003B4F;">return</span> <span class="va" style="color: #111111;">False</span></span></code></pre></div>
</div>
<p>We create the endpoint configuration by specifying the name and pointing to the two production variants that we just configured that tell SageMaker how we want to host those models.</p>
<div class="cell" data-outputid="66a28e4e-384c-4b60-eaea-42825e53e3e3">
<div class="sourceCode cell-code" id="cb18" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1">endpoint_config_name <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">'</span><span class="sc" style="color: #5E5E5E;">{}</span><span class="st" style="color: #20794D;">-</span><span class="sc" style="color: #5E5E5E;">{}</span><span class="st" style="color: #20794D;">'</span>.<span class="bu" style="color: null;">format</span>(<span class="st" style="color: #20794D;">'ab'</span>, timestamp)</span>
<span id="cb18-2"></span>
<span id="cb18-3"><span class="cf" style="color: #003B4F;">if</span> <span class="kw" style="color: #003B4F;">not</span> check_endpoint_config_existence(endpoint_config_name):</span>
<span id="cb18-4">    endpoint_config <span class="op" style="color: #5E5E5E;">=</span> sm.create_endpoint_config(</span>
<span id="cb18-5">        EndpointConfigName<span class="op" style="color: #5E5E5E;">=</span>endpoint_config_name, </span>
<span id="cb18-6">        ProductionVariants<span class="op" style="color: #5E5E5E;">=</span>[variantA, variantB]</span>
<span id="cb18-7">    )</span>
<span id="cb18-8">    pprint(endpoint_config)</span>
<span id="cb18-9"><span class="cf" style="color: #003B4F;">else</span>:</span>
<span id="cb18-10">    <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">"Endpoint configuration </span><span class="sc" style="color: #5E5E5E;">{}</span><span class="st" style="color: #20794D;"> already exists"</span>.<span class="bu" style="color: null;">format</span>(endpoint_config_name))</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>{'EndpointConfigArn': 'arn:aws:sagemaker:us-east-1:266291165402:endpoint-config/ab-1677082486',
 'ResponseMetadata': {'HTTPHeaders': {'content-length': '94',
                                      'content-type': 'application/x-amz-json-1.1',
                                      'date': 'Wed, 22 Feb 2023 16:16:04 GMT',
                                      'x-amzn-requestid': 'caa4197d-8d8a-4b0e-ab55-e20d5bfe31d6'},
                      'HTTPStatusCode': 200,
                      'RequestId': 'caa4197d-8d8a-4b0e-ab55-e20d5bfe31d6',
                      'RetryAttempts': 0}}</code></pre>
</div>
</div>
<p>Construct the endpoint name.</p>
<div class="cell" data-outputid="c9a67886-c5c9-4ed9-cdfe-c92a6e93c5ee">
<div class="sourceCode cell-code" id="cb20" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1">model_ab_endpoint_name <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">'</span><span class="sc" style="color: #5E5E5E;">{}</span><span class="st" style="color: #20794D;">-</span><span class="sc" style="color: #5E5E5E;">{}</span><span class="st" style="color: #20794D;">'</span>.<span class="bu" style="color: null;">format</span>(<span class="st" style="color: #20794D;">'ab'</span>, timestamp)</span>
<span id="cb20-2"><span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">'Endpoint name: </span><span class="sc" style="color: #5E5E5E;">{}</span><span class="st" style="color: #20794D;">'</span>.<span class="bu" style="color: null;">format</span>(model_ab_endpoint_name))</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Endpoint name: ab-1677082486</code></pre>
</div>
</div>
<p>Lets create an endpoint with the endpoint name and configuration defined above.</p>
<div class="cell" data-outputid="407b9d29-b278-4944-ada4-c0b013801046">
<div class="sourceCode cell-code" id="cb22" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><span class="cf" style="color: #003B4F;">if</span> <span class="kw" style="color: #003B4F;">not</span> check_endpoint_existence(model_ab_endpoint_name):</span>
<span id="cb22-2">    endpoint_response <span class="op" style="color: #5E5E5E;">=</span> sm.create_endpoint(</span>
<span id="cb22-3">        EndpointName<span class="op" style="color: #5E5E5E;">=</span>model_ab_endpoint_name, </span>
<span id="cb22-4">        EndpointConfigName<span class="op" style="color: #5E5E5E;">=</span>endpoint_config_name</span>
<span id="cb22-5">    )</span>
<span id="cb22-6">    <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">'Creating endpoint </span><span class="sc" style="color: #5E5E5E;">{}</span><span class="st" style="color: #20794D;">'</span>.<span class="bu" style="color: null;">format</span>(model_ab_endpoint_name))</span>
<span id="cb22-7">    pprint(endpoint_response)</span>
<span id="cb22-8"><span class="cf" style="color: #003B4F;">else</span>:</span>
<span id="cb22-9">    <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">"Endpoint </span><span class="sc" style="color: #5E5E5E;">{}</span><span class="st" style="color: #20794D;"> already exists"</span>.<span class="bu" style="color: null;">format</span>(model_ab_endpoint_name))</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Creating endpoint ab-1677082486
{'EndpointArn': 'arn:aws:sagemaker:us-east-1:266291165402:endpoint/ab-1677082486',
 'ResponseMetadata': {'HTTPHeaders': {'content-length': '81',
                                      'content-type': 'application/x-amz-json-1.1',
                                      'date': 'Wed, 22 Feb 2023 16:16:24 GMT',
                                      'x-amzn-requestid': '0d5dd2d5-519a-4618-ab29-809c0e3e28da'},
                      'HTTPStatusCode': 200,
                      'RequestId': '0d5dd2d5-519a-4618-ab29-809c0e3e28da',
                      'RetryAttempts': 0}}</code></pre>
</div>
</div>
<p>Now we wait for the endpoint to deploy.</p>
<div class="cell" data-outputid="94aef061-5938-4e6a-a283-462310c69b20">
<div class="sourceCode cell-code" id="cb24" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><span class="op" style="color: #5E5E5E;">%%</span>time</span>
<span id="cb24-2"></span>
<span id="cb24-3">waiter <span class="op" style="color: #5E5E5E;">=</span> sm.get_waiter(<span class="st" style="color: #20794D;">'endpoint_in_service'</span>)</span>
<span id="cb24-4">waiter.wait(EndpointName<span class="op" style="color: #5E5E5E;">=</span>model_ab_endpoint_name)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>CPU times: user 133 ms, sys: 21 ms, total: 154 ms
Wall time: 5min 1s</code></pre>
</div>
</div>
</section>
</section>
<section id="test-model" class="level2" data-number="6">
<h2 data-number="6" class="anchored" data-anchor-id="test-model"><span class="header-section-number">6</span> Test model</h2>
<section id="test-the-model-on-a-few-sample-strings" class="level3" data-number="6.1">
<h3 data-number="6.1" class="anchored" data-anchor-id="test-the-model-on-a-few-sample-strings"><span class="header-section-number">6.1</span> Test the model on a few sample strings</h3>
<p>Here, we will pass sample strings of text to the endpoint in order to see the sentiment. We give one example of each.</p>
<p>Now we create an Amazon SageMaker Predictor based on the deployed endpoint.</p>
<p>We will use the <code>Predictor</code> object with the following parameters. We pass JSON serializer and deserializer objects here, calling them with the functions <code>JSONLinesSerializer()</code> and <code>JSONLinesDeserializer()</code>, respectively. More information about the serializers can be found <a href="https://sagemaker.readthedocs.io/en/stable/api/inference/serializers.html">here</a>.</p>
<div class="cell" data-outputid="cfc735a5-c2e0-4385-f206-cabeb05bb66f">
<div class="sourceCode cell-code" id="cb26" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><span class="im" style="color: #00769E;">from</span> sagemaker.predictor <span class="im" style="color: #00769E;">import</span> Predictor</span>
<span id="cb26-2"><span class="im" style="color: #00769E;">from</span> sagemaker.serializers <span class="im" style="color: #00769E;">import</span> JSONLinesSerializer</span>
<span id="cb26-3"><span class="im" style="color: #00769E;">from</span> sagemaker.deserializers <span class="im" style="color: #00769E;">import</span> JSONLinesDeserializer</span>
<span id="cb26-4"></span>
<span id="cb26-5">inputs <span class="op" style="color: #5E5E5E;">=</span> [</span>
<span id="cb26-6">    {<span class="st" style="color: #20794D;">"features"</span>: [<span class="st" style="color: #20794D;">"I love this product!"</span>]},</span>
<span id="cb26-7">    {<span class="st" style="color: #20794D;">"features"</span>: [<span class="st" style="color: #20794D;">"OK, but not great."</span>]},</span>
<span id="cb26-8">    {<span class="st" style="color: #20794D;">"features"</span>: [<span class="st" style="color: #20794D;">"This is not the right product."</span>]},</span>
<span id="cb26-9">]</span>
<span id="cb26-10"></span>
<span id="cb26-11">predictor <span class="op" style="color: #5E5E5E;">=</span> Predictor(</span>
<span id="cb26-12">    endpoint_name<span class="op" style="color: #5E5E5E;">=</span>model_ab_endpoint_name, </span>
<span id="cb26-13">    serializer<span class="op" style="color: #5E5E5E;">=</span>JSONLinesSerializer(), </span>
<span id="cb26-14">    deserializer<span class="op" style="color: #5E5E5E;">=</span>JSONLinesDeserializer(), </span>
<span id="cb26-15">    sagemaker_session<span class="op" style="color: #5E5E5E;">=</span>sess</span>
<span id="cb26-16">)</span>
<span id="cb26-17"></span>
<span id="cb26-18">predicted_classes <span class="op" style="color: #5E5E5E;">=</span> predictor.predict(inputs)</span>
<span id="cb26-19"></span>
<span id="cb26-20"><span class="cf" style="color: #003B4F;">for</span> predicted_class <span class="kw" style="color: #003B4F;">in</span> predicted_classes:</span>
<span id="cb26-21">    <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">"Predicted class </span><span class="sc" style="color: #5E5E5E;">{}</span><span class="st" style="color: #20794D;"> with probability </span><span class="sc" style="color: #5E5E5E;">{}</span><span class="st" style="color: #20794D;">"</span>.<span class="bu" style="color: null;">format</span>(predicted_class[<span class="st" style="color: #20794D;">'predicted_label'</span>], predicted_class[<span class="st" style="color: #20794D;">'probability'</span>]))</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Predicted class 1 with probability 0.9605445861816406
Predicted class 0 with probability 0.5798221230506897
Predicted class -1 with probability 0.7667604684829712</code></pre>
</div>
</div>
</section>
<section id="generate-traffic-and-review-the-endpoint-performance-metrics" class="level3" data-number="6.2">
<h3 data-number="6.2" class="anchored" data-anchor-id="generate-traffic-and-review-the-endpoint-performance-metrics"><span class="header-section-number">6.2</span> Generate traffic and review the endpoint performance metrics</h3>
<p>Now we will generate some traffic. To analyze the endpoint performance we will review some of the metrics that Amazon SageMaker emits in CloudWatch: CPU Utilization, Latency and Invocations.</p>
<p>A full list of namespaces and metrics can be found <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/monitoring-cloudwatch.html">here</a>. CloudWatch <code>get_metric_statistics</code> documentation can be found <a href="https://docs.aws.amazon.com/AmazonCloudWatch/latest/APIReference/API_GetMetricStatistics.html">here</a>.</p>
<p>But before that, let’s create a function that will help to extract the results from CloudWatch and plot them.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb28" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><span class="kw" style="color: #003B4F;">def</span> plot_endpoint_metrics_for_variants(endpoint_name, </span>
<span id="cb28-2">                                       namespace_name, </span>
<span id="cb28-3">                                       metric_name, </span>
<span id="cb28-4">                                       variant_names, </span>
<span id="cb28-5">                                       start_time, </span>
<span id="cb28-6">                                       end_time):</span>
<span id="cb28-7">    </span>
<span id="cb28-8">    <span class="cf" style="color: #003B4F;">try</span>:</span>
<span id="cb28-9">        joint_variant_metrics <span class="op" style="color: #5E5E5E;">=</span> <span class="va" style="color: #111111;">None</span></span>
<span id="cb28-10"></span>
<span id="cb28-11">        <span class="cf" style="color: #003B4F;">for</span> variant_name <span class="kw" style="color: #003B4F;">in</span> variant_names:</span>
<span id="cb28-12">            metrics <span class="op" style="color: #5E5E5E;">=</span> cw.get_metric_statistics( <span class="co" style="color: #5E5E5E;"># extracts the results in a dictionary format</span></span>
<span id="cb28-13">                Namespace<span class="op" style="color: #5E5E5E;">=</span>namespace_name, <span class="co" style="color: #5E5E5E;"># the namespace of the metric, e.g. "AWS/SageMaker"</span></span>
<span id="cb28-14">                MetricName<span class="op" style="color: #5E5E5E;">=</span>metric_name, <span class="co" style="color: #5E5E5E;"># the name of the metric, e.g. "CPUUtilization"</span></span>
<span id="cb28-15">                StartTime<span class="op" style="color: #5E5E5E;">=</span>start_time, <span class="co" style="color: #5E5E5E;"># the time stamp that determines the first data point to return</span></span>
<span id="cb28-16">                EndTime<span class="op" style="color: #5E5E5E;">=</span>end_time, <span class="co" style="color: #5E5E5E;"># the time stamp that determines the last data point to return</span></span>
<span id="cb28-17">                Period<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">60</span>, <span class="co" style="color: #5E5E5E;"># the granularity, in seconds, of the returned data points</span></span>
<span id="cb28-18">                Statistics<span class="op" style="color: #5E5E5E;">=</span>[<span class="st" style="color: #20794D;">"Sum"</span>], <span class="co" style="color: #5E5E5E;"># the metric statistics</span></span>
<span id="cb28-19">                Dimensions<span class="op" style="color: #5E5E5E;">=</span>[ <span class="co" style="color: #5E5E5E;"># dimensions, as CloudWatch treats each unique combination of dimensions as a separate metric</span></span>
<span id="cb28-20">                    {<span class="st" style="color: #20794D;">"Name"</span>: <span class="st" style="color: #20794D;">"EndpointName"</span>, <span class="st" style="color: #20794D;">"Value"</span>: endpoint_name}, </span>
<span id="cb28-21">                    {<span class="st" style="color: #20794D;">"Name"</span>: <span class="st" style="color: #20794D;">"VariantName"</span>, <span class="st" style="color: #20794D;">"Value"</span>: variant_name}</span>
<span id="cb28-22">                ],</span>
<span id="cb28-23">            )</span>
<span id="cb28-24">            </span>
<span id="cb28-25">            <span class="cf" style="color: #003B4F;">if</span> metrics[<span class="st" style="color: #20794D;">"Datapoints"</span>]: <span class="co" style="color: #5E5E5E;"># access the results from the distionary using the key "Datapoints"</span></span>
<span id="cb28-26">                df_metrics <span class="op" style="color: #5E5E5E;">=</span> pd.DataFrame(metrics[<span class="st" style="color: #20794D;">"Datapoints"</span>]) <span class="op" style="color: #5E5E5E;">\</span></span>
<span id="cb28-27">                    .sort_values(<span class="st" style="color: #20794D;">"Timestamp"</span>) <span class="op" style="color: #5E5E5E;">\</span></span>
<span id="cb28-28">                    .set_index(<span class="st" style="color: #20794D;">"Timestamp"</span>) <span class="op" style="color: #5E5E5E;">\</span></span>
<span id="cb28-29">                    .drop(<span class="st" style="color: #20794D;">"Unit"</span>, axis<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">1</span>) <span class="op" style="color: #5E5E5E;">\</span></span>
<span id="cb28-30">                    .rename(columns<span class="op" style="color: #5E5E5E;">=</span>{<span class="st" style="color: #20794D;">"Sum"</span>: variant_name}) <span class="co" style="color: #5E5E5E;"># rename the column with the metric results as a variant_name</span></span>
<span id="cb28-31">                </span>
<span id="cb28-32">                <span class="cf" style="color: #003B4F;">if</span> joint_variant_metrics <span class="kw" style="color: #003B4F;">is</span> <span class="va" style="color: #111111;">None</span>:</span>
<span id="cb28-33">                    joint_variant_metrics <span class="op" style="color: #5E5E5E;">=</span> df_metrics</span>
<span id="cb28-34">                <span class="cf" style="color: #003B4F;">else</span>:</span>
<span id="cb28-35">                    joint_variant_metrics <span class="op" style="color: #5E5E5E;">=</span> joint_variant_metrics.join(df_metrics, how<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"outer"</span>)</span>
<span id="cb28-36">        </span>
<span id="cb28-37">        joint_variant_metrics.plot(title<span class="op" style="color: #5E5E5E;">=</span>metric_name)</span>
<span id="cb28-38">    <span class="cf" style="color: #003B4F;">except</span>:</span>
<span id="cb28-39">        <span class="cf" style="color: #003B4F;">pass</span></span></code></pre></div>
</div>
<p>We must establish wide enough time bounds to show all the charts using the same timeframe:</p>
<div class="cell" data-outputid="0a306d5a-4efb-429b-f768-d26e436ead4d">
<div class="sourceCode cell-code" id="cb29" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><span class="im" style="color: #00769E;">from</span> datetime <span class="im" style="color: #00769E;">import</span> datetime, timedelta</span>
<span id="cb29-2"></span>
<span id="cb29-3">start_time <span class="op" style="color: #5E5E5E;">=</span> datetime.now() <span class="op" style="color: #5E5E5E;">-</span> timedelta(minutes<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">30</span>)</span>
<span id="cb29-4">end_time <span class="op" style="color: #5E5E5E;">=</span> datetime.now() <span class="op" style="color: #5E5E5E;">+</span> timedelta(minutes<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">30</span>)</span>
<span id="cb29-5"></span>
<span id="cb29-6"><span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">'Start Time: </span><span class="sc" style="color: #5E5E5E;">{}</span><span class="st" style="color: #20794D;">'</span>.<span class="bu" style="color: null;">format</span>(start_time))</span>
<span id="cb29-7"><span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">'End Time: </span><span class="sc" style="color: #5E5E5E;">{}</span><span class="st" style="color: #20794D;">'</span>.<span class="bu" style="color: null;">format</span>(end_time))</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Start Time: 2023-02-22 15:52:19.078234
End Time: 2023-02-22 16:52:19.078289</code></pre>
</div>
</div>
<p>Set the list of the the variant names to analyze.</p>
<div class="cell" data-outputid="9e038c7b-050a-43cc-d819-10b94cb4f8ae">
<div class="sourceCode cell-code" id="cb31" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1">variant_names <span class="op" style="color: #5E5E5E;">=</span> [variantA[<span class="st" style="color: #20794D;">"VariantName"</span>], variantB[<span class="st" style="color: #20794D;">"VariantName"</span>]]</span>
<span id="cb31-2"></span>
<span id="cb31-3"><span class="bu" style="color: null;">print</span>(variant_names)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>['VariantA', 'VariantB']</code></pre>
</div>
</div>
<p>Now run some predictions and view the metrics for each variant.</p>
<div class="cell" data-outputid="4cbc34f7-ab23-4bb0-a400-d99b467c19f4">
<div class="sourceCode cell-code" id="cb33" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><span class="op" style="color: #5E5E5E;">%%</span>time</span>
<span id="cb33-2"></span>
<span id="cb33-3"><span class="cf" style="color: #003B4F;">for</span> i <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">range</span>(<span class="dv" style="color: #AD0000;">0</span>, <span class="dv" style="color: #AD0000;">100</span>):</span>
<span id="cb33-4">    predicted_classes <span class="op" style="color: #5E5E5E;">=</span> predictor.predict(inputs)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>CPU times: user 239 ms, sys: 4.17 ms, total: 243 ms
Wall time: 1min 28s</code></pre>
</div>
</div>
<p>Let’s query CloudWatch to get a few metrics that are split across variants.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb35" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1">time.sleep(<span class="dv" style="color: #AD0000;">30</span>) <span class="co" style="color: #5E5E5E;"># Sleep to accomodate a slight delay in metrics gathering</span></span></code></pre></div>
</div>
<div class="cell" data-outputid="64b5f9fe-a87b-4015-c900-fb65110bcdf6">
<div class="sourceCode cell-code" id="cb36" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb36-1"><span class="co" style="color: #5E5E5E;"># CPUUtilization</span></span>
<span id="cb36-2"><span class="co" style="color: #5E5E5E;"># The sum of each individual CPU core's utilization. </span></span>
<span id="cb36-3"><span class="co" style="color: #5E5E5E;"># The CPU utilization of each core can range between 0 and 100. For example, if there are four CPUs, CPUUtilization can range from 0% to 400%.</span></span>
<span id="cb36-4">plot_endpoint_metrics_for_variants(</span>
<span id="cb36-5">    endpoint_name<span class="op" style="color: #5E5E5E;">=</span>model_ab_endpoint_name, </span>
<span id="cb36-6">    namespace_name<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"/aws/sagemaker/Endpoints"</span>, </span>
<span id="cb36-7">    metric_name<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"CPUUtilization"</span>,</span>
<span id="cb36-8">    variant_names<span class="op" style="color: #5E5E5E;">=</span>variant_names,</span>
<span id="cb36-9">    start_time<span class="op" style="color: #5E5E5E;">=</span>start_time,</span>
<span id="cb36-10">    end_time<span class="op" style="color: #5E5E5E;">=</span>end_time</span>
<span id="cb36-11">)</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="http://livingdatalab.com/posts/2023-02-22-advanced-model-deployment-on-aws_files/figure-html/cell-25-output-1.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-outputid="41d5eee9-7ce5-4724-d6ef-cbe383b2e7d5">
<div class="sourceCode cell-code" id="cb37" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb37-1"><span class="co" style="color: #5E5E5E;"># Invocations</span></span>
<span id="cb37-2"><span class="co" style="color: #5E5E5E;"># The number of requests sent to a model endpoint.</span></span>
<span id="cb37-3">plot_endpoint_metrics_for_variants(</span>
<span id="cb37-4">    endpoint_name<span class="op" style="color: #5E5E5E;">=</span>model_ab_endpoint_name, </span>
<span id="cb37-5">    namespace_name<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"AWS/SageMaker"</span>, </span>
<span id="cb37-6">    metric_name<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"Invocations"</span>,</span>
<span id="cb37-7">    variant_names<span class="op" style="color: #5E5E5E;">=</span>variant_names,</span>
<span id="cb37-8">    start_time<span class="op" style="color: #5E5E5E;">=</span>start_time,</span>
<span id="cb37-9">    end_time<span class="op" style="color: #5E5E5E;">=</span>end_time    </span>
<span id="cb37-10">)</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="http://livingdatalab.com/posts/2023-02-22-advanced-model-deployment-on-aws_files/figure-html/cell-26-output-1.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-outputid="ad929f1d-4e6f-46e8-8f85-a0ddcdb226e5">
<div class="sourceCode cell-code" id="cb38" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb38-1"><span class="co" style="color: #5E5E5E;"># InvocationsPerInstance</span></span>
<span id="cb38-2"><span class="co" style="color: #5E5E5E;"># The number of invocations sent to a model, normalized by InstanceCount in each production variant.</span></span>
<span id="cb38-3">plot_endpoint_metrics_for_variants(</span>
<span id="cb38-4">    endpoint_name<span class="op" style="color: #5E5E5E;">=</span>model_ab_endpoint_name, </span>
<span id="cb38-5">    namespace_name<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"AWS/SageMaker"</span>, </span>
<span id="cb38-6">    metric_name<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"InvocationsPerInstance"</span>,</span>
<span id="cb38-7">    variant_names<span class="op" style="color: #5E5E5E;">=</span>variant_names,</span>
<span id="cb38-8">    start_time<span class="op" style="color: #5E5E5E;">=</span>start_time,</span>
<span id="cb38-9">    end_time<span class="op" style="color: #5E5E5E;">=</span>end_time</span>
<span id="cb38-10">)</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="http://livingdatalab.com/posts/2023-02-22-advanced-model-deployment-on-aws_files/figure-html/cell-27-output-1.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-outputid="ff52adee-6936-44e8-d9b7-12a4cd64cdf8">
<div class="sourceCode cell-code" id="cb39" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1"><span class="co" style="color: #5E5E5E;"># ModelLatency</span></span>
<span id="cb39-2"><span class="co" style="color: #5E5E5E;"># The interval of time taken by a model to respond as viewed from SageMaker (in microseconds).</span></span>
<span id="cb39-3">plot_endpoint_metrics_for_variants(</span>
<span id="cb39-4">    endpoint_name<span class="op" style="color: #5E5E5E;">=</span>model_ab_endpoint_name, </span>
<span id="cb39-5">    namespace_name<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"AWS/SageMaker"</span>, </span>
<span id="cb39-6">    metric_name<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"ModelLatency"</span>,</span>
<span id="cb39-7">    variant_names<span class="op" style="color: #5E5E5E;">=</span>variant_names,</span>
<span id="cb39-8">    start_time<span class="op" style="color: #5E5E5E;">=</span>start_time,</span>
<span id="cb39-9">    end_time<span class="op" style="color: #5E5E5E;">=</span>end_time</span>
<span id="cb39-10">)</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="http://livingdatalab.com/posts/2023-02-22-advanced-model-deployment-on-aws_files/figure-html/cell-28-output-1.png" class="img-fluid"></p>
</div>
</div>
</section>
</section>
<section id="shift-the-traffic-to-one-variant-and-review-the-endpoint-performance-metrics" class="level2" data-number="7">
<h2 data-number="7" class="anchored" data-anchor-id="shift-the-traffic-to-one-variant-and-review-the-endpoint-performance-metrics"><span class="header-section-number">7</span> Shift the traffic to one variant and review the endpoint performance metrics</h2>
<p>Generally, the winning model would need to be chosen. The decision would be made based on the endpoint performance metrics and some other business related evaluations. Here we will assume that the winning model is in the Variant B and shift all traffic to it.</p>
<p>Let’s now construct a list with the updated endpoint weights.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb40" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb40-1">updated_endpoint_config <span class="op" style="color: #5E5E5E;">=</span> [</span>
<span id="cb40-2">    {</span>
<span id="cb40-3">        <span class="st" style="color: #20794D;">"VariantName"</span>: variantA[<span class="st" style="color: #20794D;">"VariantName"</span>],</span>
<span id="cb40-4">        <span class="st" style="color: #20794D;">"DesiredWeight"</span>: <span class="dv" style="color: #AD0000;">0</span>,</span>
<span id="cb40-5">    },</span>
<span id="cb40-6">    {</span>
<span id="cb40-7">        <span class="st" style="color: #20794D;">"VariantName"</span>: variantB[<span class="st" style="color: #20794D;">"VariantName"</span>],</span>
<span id="cb40-8">        <span class="st" style="color: #20794D;">"DesiredWeight"</span>: <span class="dv" style="color: #AD0000;">100</span>,</span>
<span id="cb40-9">    },</span>
<span id="cb40-10">]</span></code></pre></div>
</div>
<p>Now we update variant weights in the configuration of the existing endpoint.</p>
<p>We will use the <code>sm.update_endpoint_weights_and_capacities</code> function, passing the endpoint name and list of updated weights for each of the variants that we defined above.</p>
<div class="cell" data-outputid="9357749c-ae5a-40e6-b2f3-2b818fcbf2b5">
<div class="sourceCode cell-code" id="cb41" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1">sm.update_endpoint_weights_and_capacities(</span>
<span id="cb41-2">    EndpointName<span class="op" style="color: #5E5E5E;">=</span>model_ab_endpoint_name, </span>
<span id="cb41-3">    DesiredWeightsAndCapacities<span class="op" style="color: #5E5E5E;">=</span>updated_endpoint_config </span>
<span id="cb41-4">)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="33">
<pre><code>{'EndpointArn': 'arn:aws:sagemaker:us-east-1:266291165402:endpoint/ab-1677082486',
 'ResponseMetadata': {'RequestId': 'd150d0c7-90d9-48bd-b9fd-06aed5f7c4b7',
  'HTTPStatusCode': 200,
  'HTTPHeaders': {'x-amzn-requestid': 'd150d0c7-90d9-48bd-b9fd-06aed5f7c4b7',
   'content-type': 'application/x-amz-json-1.1',
   'content-length': '81',
   'date': 'Wed, 22 Feb 2023 16:24:19 GMT'},
  'RetryAttempts': 0}}</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb43" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb43-1">waiter <span class="op" style="color: #5E5E5E;">=</span> sm.get_waiter(<span class="st" style="color: #20794D;">"endpoint_in_service"</span>)</span>
<span id="cb43-2">waiter.wait(EndpointName<span class="op" style="color: #5E5E5E;">=</span>model_ab_endpoint_name)</span></code></pre></div>
</div>
<p>Now run some more predictions and view the metrics for each variant.</p>
<div class="cell" data-outputid="da6a1da3-5f2d-4458-9a01-77b0c102f4b2">
<div class="sourceCode cell-code" id="cb44" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb44-1"><span class="op" style="color: #5E5E5E;">%%</span>time</span>
<span id="cb44-2"></span>
<span id="cb44-3"><span class="cf" style="color: #003B4F;">for</span> i <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">range</span>(<span class="dv" style="color: #AD0000;">0</span>, <span class="dv" style="color: #AD0000;">100</span>):</span>
<span id="cb44-4">    predicted_classes <span class="op" style="color: #5E5E5E;">=</span> predictor.predict(inputs)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>CPU times: user 256 ms, sys: 3.23 ms, total: 259 ms
Wall time: 1min 27s</code></pre>
</div>
</div>
<div class="cell" data-outputid="e119b348-3703-4af6-b941-a45cfbfd45d1">
<div class="sourceCode cell-code" id="cb46" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb46-1"><span class="co" style="color: #5E5E5E;"># CPUUtilization</span></span>
<span id="cb46-2"><span class="co" style="color: #5E5E5E;"># The sum of each individual CPU core's utilization. </span></span>
<span id="cb46-3"><span class="co" style="color: #5E5E5E;"># The CPU utilization of each core can range between 0 and 100. For example, if there are four CPUs, CPUUtilization can range from 0% to 400%.</span></span>
<span id="cb46-4">plot_endpoint_metrics_for_variants(</span>
<span id="cb46-5">    endpoint_name<span class="op" style="color: #5E5E5E;">=</span>model_ab_endpoint_name, </span>
<span id="cb46-6">    namespace_name<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"/aws/sagemaker/Endpoints"</span>,</span>
<span id="cb46-7">    metric_name<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"CPUUtilization"</span>,</span>
<span id="cb46-8">    variant_names<span class="op" style="color: #5E5E5E;">=</span>variant_names,</span>
<span id="cb46-9">    start_time<span class="op" style="color: #5E5E5E;">=</span>start_time,</span>
<span id="cb46-10">    end_time<span class="op" style="color: #5E5E5E;">=</span>end_time</span>
<span id="cb46-11">)</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="http://livingdatalab.com/posts/2023-02-22-advanced-model-deployment-on-aws_files/figure-html/cell-33-output-1.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-outputid="b1a13d87-90ba-4aa9-e11f-c7683d031b90">
<div class="sourceCode cell-code" id="cb47" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb47-1"><span class="co" style="color: #5E5E5E;"># Invocations</span></span>
<span id="cb47-2"><span class="co" style="color: #5E5E5E;"># The number of requests sent to a model endpoint.</span></span>
<span id="cb47-3">plot_endpoint_metrics_for_variants(</span>
<span id="cb47-4">    endpoint_name<span class="op" style="color: #5E5E5E;">=</span>model_ab_endpoint_name, </span>
<span id="cb47-5">    namespace_name<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"AWS/SageMaker"</span>, </span>
<span id="cb47-6">    metric_name<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"Invocations"</span>,</span>
<span id="cb47-7">    variant_names<span class="op" style="color: #5E5E5E;">=</span>variant_names,</span>
<span id="cb47-8">    start_time<span class="op" style="color: #5E5E5E;">=</span>start_time,</span>
<span id="cb47-9">    end_time<span class="op" style="color: #5E5E5E;">=</span>end_time    </span>
<span id="cb47-10">)</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="http://livingdatalab.com/posts/2023-02-22-advanced-model-deployment-on-aws_files/figure-html/cell-34-output-1.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-outputid="f395a3b6-57f1-456b-d532-c96a54464f63">
<div class="sourceCode cell-code" id="cb48" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb48-1"><span class="co" style="color: #5E5E5E;"># InvocationsPerInstance</span></span>
<span id="cb48-2"><span class="co" style="color: #5E5E5E;"># The number of invocations sent to a model, normalized by InstanceCount in each production variant.</span></span>
<span id="cb48-3">plot_endpoint_metrics_for_variants(</span>
<span id="cb48-4">    endpoint_name<span class="op" style="color: #5E5E5E;">=</span>model_ab_endpoint_name, </span>
<span id="cb48-5">    namespace_name<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"AWS/SageMaker"</span>, </span>
<span id="cb48-6">    metric_name<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"InvocationsPerInstance"</span>,</span>
<span id="cb48-7">    variant_names<span class="op" style="color: #5E5E5E;">=</span>variant_names,</span>
<span id="cb48-8">    start_time<span class="op" style="color: #5E5E5E;">=</span>start_time,</span>
<span id="cb48-9">    end_time<span class="op" style="color: #5E5E5E;">=</span>end_time    </span>
<span id="cb48-10">)</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="http://livingdatalab.com/posts/2023-02-22-advanced-model-deployment-on-aws_files/figure-html/cell-35-output-1.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-outputid="49321bfa-73df-4178-9657-73159fcbb7a5">
<div class="sourceCode cell-code" id="cb49" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb49-1"><span class="co" style="color: #5E5E5E;"># ModelLatency</span></span>
<span id="cb49-2"><span class="co" style="color: #5E5E5E;"># The interval of time taken by a model to respond as viewed from SageMaker (in microseconds).</span></span>
<span id="cb49-3">plot_endpoint_metrics_for_variants(</span>
<span id="cb49-4">    endpoint_name<span class="op" style="color: #5E5E5E;">=</span>model_ab_endpoint_name, </span>
<span id="cb49-5">    namespace_name<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"AWS/SageMaker"</span>, </span>
<span id="cb49-6">    metric_name<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"ModelLatency"</span>,</span>
<span id="cb49-7">    variant_names<span class="op" style="color: #5E5E5E;">=</span>variant_names,</span>
<span id="cb49-8">    start_time<span class="op" style="color: #5E5E5E;">=</span>start_time,</span>
<span id="cb49-9">    end_time<span class="op" style="color: #5E5E5E;">=</span>end_time    </span>
<span id="cb49-10">)</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="http://livingdatalab.com/posts/2023-02-22-advanced-model-deployment-on-aws_files/figure-html/cell-36-output-1.png" class="img-fluid"></p>
</div>
</div>
</section>
<section id="configure-one-variant-to-autoscale" class="level2" data-number="8">
<h2 data-number="8" class="anchored" data-anchor-id="configure-one-variant-to-autoscale"><span class="header-section-number">8</span> Configure one variant to autoscale</h2>
<p>Let’s configure Variant B to autoscale. We would not autoscale Variant A since no traffic is being passed to it at this time.</p>
<p>First, we need to define a scalable target. It is an AWS resource and in this case you want to scale a <code>sagemaker</code> resource as indicated in the <code>ServiceNameSpace</code> parameter. Then the <code>ResourceId</code> is a SageMaker Endpoint. Because autoscaling is used by other AWS resources, we’ll see a few parameters that will remain static for scaling SageMaker Endpoints. Thus the <code>ScalableDimension</code> is a set value for SageMaker Endpoint scaling.</p>
<p>We also need to specify a few key parameters that control the min and max behavior for our Machine Learning instances. The <code>MinCapacity</code> indicates the minimum number of instances we plan to scale in to. The <code>MaxCapacity</code> is the maximum number of instances we want to scale out to. So in this case we always want to have at least 1 instance running and a maximum of 2 during peak periods.</p>
<div class="cell" data-outputid="614b0b70-6abd-4eb4-cc68-314fcf099a54">
<div class="sourceCode cell-code" id="cb50" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb50-1">autoscale.register_scalable_target(</span>
<span id="cb50-2">    ServiceNamespace<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"sagemaker"</span>,</span>
<span id="cb50-3">    ResourceId<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"endpoint/"</span> <span class="op" style="color: #5E5E5E;">+</span> model_ab_endpoint_name <span class="op" style="color: #5E5E5E;">+</span> <span class="st" style="color: #20794D;">"/variant/VariantB"</span>,</span>
<span id="cb50-4">    ScalableDimension<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"sagemaker:variant:DesiredInstanceCount"</span>,</span>
<span id="cb50-5">    MinCapacity<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">1</span>,</span>
<span id="cb50-6">    MaxCapacity<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">2</span>,</span>
<span id="cb50-7">    RoleARN<span class="op" style="color: #5E5E5E;">=</span>role,</span>
<span id="cb50-8">    SuspendedState<span class="op" style="color: #5E5E5E;">=</span>{</span>
<span id="cb50-9">        <span class="st" style="color: #20794D;">"DynamicScalingInSuspended"</span>: <span class="va" style="color: #111111;">False</span>,</span>
<span id="cb50-10">        <span class="st" style="color: #20794D;">"DynamicScalingOutSuspended"</span>: <span class="va" style="color: #111111;">False</span>,</span>
<span id="cb50-11">        <span class="st" style="color: #20794D;">"ScheduledScalingSuspended"</span>: <span class="va" style="color: #111111;">False</span>,</span>
<span id="cb50-12">    },</span>
<span id="cb50-13">)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="41">
<pre><code>{'ResponseMetadata': {'RequestId': '1df51ac9-60ae-4b21-9c3a-2b676e32802c',
  'HTTPStatusCode': 200,
  'HTTPHeaders': {'x-amzn-requestid': '1df51ac9-60ae-4b21-9c3a-2b676e32802c',
   'content-type': 'application/x-amz-json-1.1',
   'content-length': '2',
   'date': 'Wed, 22 Feb 2023 16:27:20 GMT'},
  'RetryAttempts': 0}}</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb52" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb52-1">waiter <span class="op" style="color: #5E5E5E;">=</span> sm.get_waiter(<span class="st" style="color: #20794D;">"endpoint_in_service"</span>)</span>
<span id="cb52-2">waiter.wait(EndpointName<span class="op" style="color: #5E5E5E;">=</span>model_ab_endpoint_name)</span></code></pre></div>
</div>
<p>Check that the parameters from the function above are in the description of the scalable target:</p>
<div class="cell" data-outputid="d6e26b2b-9a67-4a44-9471-2fceab47737e">
<div class="sourceCode cell-code" id="cb53" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb53-1">autoscale.describe_scalable_targets(</span>
<span id="cb53-2">    ServiceNamespace<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"sagemaker"</span>,</span>
<span id="cb53-3">    MaxResults<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">100</span>,</span>
<span id="cb53-4">)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="43">
<pre><code>{'ScalableTargets': [{'ServiceNamespace': 'sagemaker',
   'ResourceId': 'endpoint/ab-1677082486/variant/VariantB',
   'ScalableDimension': 'sagemaker:variant:DesiredInstanceCount',
   'MinCapacity': 1,
   'MaxCapacity': 2,
   'RoleARN': 'arn:aws:iam::266291165402:role/aws-service-role/sagemaker.application-autoscaling.amazonaws.com/AWSServiceRoleForApplicationAutoScaling_SageMakerEndpoint',
   'CreationTime': datetime.datetime(2023, 2, 22, 16, 27, 20, 908000, tzinfo=tzlocal()),
   'SuspendedState': {'DynamicScalingInSuspended': False,
    'DynamicScalingOutSuspended': False,
    'ScheduledScalingSuspended': False}}],
 'ResponseMetadata': {'RequestId': 'bd518cbf-fc90-40e5-9d45-56f2252dfe71',
  'HTTPStatusCode': 200,
  'HTTPHeaders': {'x-amzn-requestid': 'bd518cbf-fc90-40e5-9d45-56f2252dfe71',
   'content-type': 'application/x-amz-json-1.1',
   'content-length': '522',
   'date': 'Wed, 22 Feb 2023 16:27:20 GMT'},
  'RetryAttempts': 0}}</code></pre>
</div>
</div>
<p>Define and apply scaling policy using the <code>put_scaling_policy</code> function. The scaling policy provides additional information about the scaling behavior for our instance. <code>TargetTrackingScaling</code> refers to a specific autoscaling type supported by SageMaker, that uses a scaling metric and a target value as the indicator to scale.</p>
<p>In the scaling policy configuration, we have the predefined metric <code>PredefinedMetricSpecification</code> which is the number of invocations on our instance and the <code>TargetValue</code> which indicates the number of invocations per ML instance we want to allow before triggering your scaling policy. A scale out cooldown of 60 seconds means that after autoscaling successfully scales out it starts to calculate the cooldown time. The scaling policy won’t increase the desired capacity again until the cooldown period ends.</p>
<p>The scale in cooldown setting of 300 seconds means that SageMaker will not attempt to start another cooldown policy within 300 seconds of when the last one completed.</p>
<div class="cell" data-outputid="3812a528-43a1-4a65-8e2b-371e68a49650">
<div class="sourceCode cell-code" id="cb55" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb55-1">autoscale.put_scaling_policy(</span>
<span id="cb55-2">    PolicyName<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"bert-reviews-autoscale-policy"</span>,</span>
<span id="cb55-3">    ServiceNamespace<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"sagemaker"</span>,</span>
<span id="cb55-4">    ResourceId<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"endpoint/"</span> <span class="op" style="color: #5E5E5E;">+</span> model_ab_endpoint_name <span class="op" style="color: #5E5E5E;">+</span> <span class="st" style="color: #20794D;">"/variant/VariantB"</span>,</span>
<span id="cb55-5">    ScalableDimension<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"sagemaker:variant:DesiredInstanceCount"</span>,</span>
<span id="cb55-6">    PolicyType<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"TargetTrackingScaling"</span>,</span>
<span id="cb55-7">    TargetTrackingScalingPolicyConfiguration<span class="op" style="color: #5E5E5E;">=</span>{</span>
<span id="cb55-8">        <span class="st" style="color: #20794D;">"TargetValue"</span>: <span class="fl" style="color: #AD0000;">2.0</span>, <span class="co" style="color: #5E5E5E;"># the number of invocations per ML instance you want to allow before triggering your scaling policy</span></span>
<span id="cb55-9">        <span class="st" style="color: #20794D;">"PredefinedMetricSpecification"</span>: {</span>
<span id="cb55-10">            <span class="st" style="color: #20794D;">"PredefinedMetricType"</span>: <span class="st" style="color: #20794D;">"SageMakerVariantInvocationsPerInstance"</span>, <span class="co" style="color: #5E5E5E;"># scaling metric</span></span>
<span id="cb55-11">        },</span>
<span id="cb55-12">        <span class="st" style="color: #20794D;">"ScaleOutCooldown"</span>: <span class="dv" style="color: #AD0000;">60</span>, <span class="co" style="color: #5E5E5E;"># wait time, in seconds, before beginning another scale out activity after last one completes</span></span>
<span id="cb55-13">        <span class="st" style="color: #20794D;">"ScaleInCooldown"</span>: <span class="dv" style="color: #AD0000;">300</span>, <span class="co" style="color: #5E5E5E;"># wait time, in seconds, before beginning another scale in activity after last one completes</span></span>
<span id="cb55-14">    },</span>
<span id="cb55-15">)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="44">
<pre><code>{'PolicyARN': 'arn:aws:autoscaling:us-east-1:266291165402:scalingPolicy:913d3148-a6ef-4773-a62f-44892892074e:resource/sagemaker/endpoint/ab-1677082486/variant/VariantB:policyName/bert-reviews-autoscale-policy',
 'Alarms': [{'AlarmName': 'TargetTracking-endpoint/ab-1677082486/variant/VariantB-AlarmHigh-c3f6ea38-0824-48ec-b42f-dbacfbe50cc4',
   'AlarmARN': 'arn:aws:cloudwatch:us-east-1:266291165402:alarm:TargetTracking-endpoint/ab-1677082486/variant/VariantB-AlarmHigh-c3f6ea38-0824-48ec-b42f-dbacfbe50cc4'},
  {'AlarmName': 'TargetTracking-endpoint/ab-1677082486/variant/VariantB-AlarmLow-15074d95-12ab-446d-8ebe-b17964112be7',
   'AlarmARN': 'arn:aws:cloudwatch:us-east-1:266291165402:alarm:TargetTracking-endpoint/ab-1677082486/variant/VariantB-AlarmLow-15074d95-12ab-446d-8ebe-b17964112be7'}],
 'ResponseMetadata': {'RequestId': 'c82eb21e-613e-4143-a40c-3a852ac5b1e8',
  'HTTPStatusCode': 200,
  'HTTPHeaders': {'x-amzn-requestid': 'c82eb21e-613e-4143-a40c-3a852ac5b1e8',
   'content-type': 'application/x-amz-json-1.1',
   'content-length': '780',
   'date': 'Wed, 22 Feb 2023 16:27:20 GMT'},
  'RetryAttempts': 0}}</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb57" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb57-1">waiter <span class="op" style="color: #5E5E5E;">=</span> sm.get_waiter(<span class="st" style="color: #20794D;">"endpoint_in_service"</span>)</span>
<span id="cb57-2">waiter.wait(EndpointName<span class="op" style="color: #5E5E5E;">=</span>model_ab_endpoint_name)</span></code></pre></div>
</div>
</section>
<section id="acknowledgements" class="level2" data-number="9">
<h2 data-number="9" class="anchored" data-anchor-id="acknowledgements"><span class="header-section-number">9</span> Acknowledgements</h2>
<p>I’d like to express my thanks to the great <a href="https://www.deeplearning.ai/courses/practical-data-science-specialization/">Deep Learning AI Practical Data Science on AWS Specialisation Course</a> which i completed, and acknowledge the use of some images and other materials from the training course in this article.</p>


</section>

 ]]></description>
  <category>aws</category>
  <category>cloud-data-science</category>
  <category>natural-language-processing</category>
  <category>deep-learning</category>
  <guid>http://livingdatalab.com/posts/2023-02-22-advanced-model-deployment-on-aws.html</guid>
  <pubDate>Wed, 22 Feb 2023 00:00:00 GMT</pubDate>
  <media:content url="https://github.com/pranath/blog/raw/master/images/aws2.png" medium="image" type="image/png"/>
</item>
<item>
  <title>Optimize Models in the Cloud using AWS Automatic Model Tuning</title>
  <dc:creator>Pranath Fernando</dc:creator>
  <link>http://livingdatalab.com/posts/2023-02-14-optimize-models-in-the-cloud-using-aws-automatic-model-tuning.html</link>
  <description><![CDATA[ 




<section id="introduction" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="introduction"><span class="header-section-number">1</span> Introduction</h2>
<p>In <a href="../#category=aws">earlier articles we introduced AWS cloud services for data science</a>, and showed how it can help with different stages of the data science &amp; machine learning workflow.</p>
<p><img src="http://livingdatalab.com/posts/https:/github.com/pranath/blog/raw/master/images/aws_ds_workflow.png" title="The AWS Data Science Workflow" class="img-fluid"></p>
<p>When training ML models, hyperparameter tuning is a step taken to find the best performing training model. In this project we will apply a random algorithm of Automated Hyperparameter Tuning to train a BERT-based natural language processing (NLP) classifier.</p>
<p>We will use the raw <a href="https://www.kaggle.com/nicapotato/womens-ecommerce-clothing-reviews">Women’s Clothing Reviews</a> dataset - and will prepare it to train a deep learning BERT-based natural language processing (NLP) model. The model will be used to classify customer reviews into positive (1), neutral (0) and negative (-1) sentiment.</p>
<p>Amazon SageMaker supports Automated Hyperparameter Tuning. It runs multiple training jobs on the training dataset using the hyperparameter ranges specified by the user. Then it chooses the combination of hyperparameters that leads to the best model candidate. The choice is made based on the objective metrics, e.g.&nbsp;maximization of the validation accuracy.</p>
<p>For the choice of hyperparameters combinations, SageMaker supports two different types of tuning strategies: random and Bayesian. This capability can be further extended by providing an implementation of a custom tuning strategy as a Docker container.</p>
<p><img src="http://livingdatalab.com/posts/https:/github.com/pranath/blog/raw/master/images/hpt.png" title="Hyperparameter Tuning" class="img-fluid"></p>
<p>In this project we will perform the following three steps:</p>
<p><img src="http://livingdatalab.com/posts/https:/github.com/pranath/blog/raw/master/images/sagemaker_hpt.png" title="Hyperparameter Tuning with AWS" class="img-fluid"></p>
<p>First, let’s install and import the required modules.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;">import</span> boto3</span>
<span id="cb1-2"><span class="im" style="color: #00769E;">import</span> sagemaker</span>
<span id="cb1-3"><span class="im" style="color: #00769E;">import</span> pandas <span class="im" style="color: #00769E;">as</span> pd</span>
<span id="cb1-4"><span class="im" style="color: #00769E;">import</span> botocore</span>
<span id="cb1-5"></span>
<span id="cb1-6">config <span class="op" style="color: #5E5E5E;">=</span> botocore.config.Config(user_agent_extra<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'dlai-pds/c3/w1'</span>)</span>
<span id="cb1-7"></span>
<span id="cb1-8"><span class="co" style="color: #5E5E5E;"># low-level service client of the boto3 session</span></span>
<span id="cb1-9">sm <span class="op" style="color: #5E5E5E;">=</span> boto3.client(service_name<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'sagemaker'</span>, </span>
<span id="cb1-10">                  config<span class="op" style="color: #5E5E5E;">=</span>config)</span>
<span id="cb1-11"></span>
<span id="cb1-12">sess <span class="op" style="color: #5E5E5E;">=</span> sagemaker.Session(sagemaker_client<span class="op" style="color: #5E5E5E;">=</span>sm)</span>
<span id="cb1-13"></span>
<span id="cb1-14">bucket <span class="op" style="color: #5E5E5E;">=</span> sess.default_bucket()</span>
<span id="cb1-15">role <span class="op" style="color: #5E5E5E;">=</span> sagemaker.get_execution_role()</span>
<span id="cb1-16">region <span class="op" style="color: #5E5E5E;">=</span> sess.boto_region_name</span></code></pre></div>
</div>
</section>
<section id="configure-dataset-and-hyperparameter-tuning-job-htp" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="configure-dataset-and-hyperparameter-tuning-job-htp"><span class="header-section-number">2</span> Configure dataset and Hyperparameter Tuning Job (HTP)</h2>
<section id="configure-dataset" class="level3" data-number="2.1">
<h3 data-number="2.1" class="anchored" data-anchor-id="configure-dataset"><span class="header-section-number">2.1</span> Configure dataset</h3>
<p>Let’s set up the paths and copy the data to the S3 bucket:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1">processed_train_data_s3_uri <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">'s3://</span><span class="sc" style="color: #5E5E5E;">{}</span><span class="st" style="color: #20794D;">/transformed/data/sentiment-train/'</span>.<span class="bu" style="color: null;">format</span>(bucket)</span>
<span id="cb2-2">processed_validation_data_s3_uri <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">'s3://</span><span class="sc" style="color: #5E5E5E;">{}</span><span class="st" style="color: #20794D;">/transformed/data/sentiment-validation/'</span>.<span class="bu" style="color: null;">format</span>(bucket)</span>
<span id="cb2-3">processed_test_data_s3_uri <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">'s3://</span><span class="sc" style="color: #5E5E5E;">{}</span><span class="st" style="color: #20794D;">/transformed/data/sentiment-test/'</span>.<span class="bu" style="color: null;">format</span>(bucket)</span></code></pre></div>
</div>
<p>Upload the data to the S3 bucket:</p>
<div class="cell" data-outputid="f6dbc801-1f8d-4a03-ce2d-d2630517774f">
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><span class="op" style="color: #5E5E5E;">!</span>aws s3 cp <span class="op" style="color: #5E5E5E;">--</span>recursive .<span class="op" style="color: #5E5E5E;">/</span>data<span class="op" style="color: #5E5E5E;">/</span>sentiment<span class="op" style="color: #5E5E5E;">-</span>train $processed_train_data_s3_uri</span>
<span id="cb3-2"><span class="op" style="color: #5E5E5E;">!</span>aws s3 cp <span class="op" style="color: #5E5E5E;">--</span>recursive .<span class="op" style="color: #5E5E5E;">/</span>data<span class="op" style="color: #5E5E5E;">/</span>sentiment<span class="op" style="color: #5E5E5E;">-</span>validation $processed_validation_data_s3_uri</span>
<span id="cb3-3"><span class="op" style="color: #5E5E5E;">!</span>aws s3 cp <span class="op" style="color: #5E5E5E;">--</span>recursive .<span class="op" style="color: #5E5E5E;">/</span>data<span class="op" style="color: #5E5E5E;">/</span>sentiment<span class="op" style="color: #5E5E5E;">-</span>test $processed_test_data_s3_uri</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>upload: data/sentiment-train/part-algo-1-womens_clothing_ecommerce_reviews.tsv to s3://sagemaker-us-east-1-058323655887/transformed/data/sentiment-train/part-algo-1-womens_clothing_ecommerce_reviews.tsv
upload: data/sentiment-validation/part-algo-1-womens_clothing_ecommerce_reviews.tsv to s3://sagemaker-us-east-1-058323655887/transformed/data/sentiment-validation/part-algo-1-womens_clothing_ecommerce_reviews.tsv
upload: data/sentiment-test/part-algo-1-womens_clothing_ecommerce_reviews.tsv to s3://sagemaker-us-east-1-058323655887/transformed/data/sentiment-test/part-algo-1-womens_clothing_ecommerce_reviews.tsv</code></pre>
</div>
</div>
<p>Check the existence of those files in the S3 bucket:</p>
<div class="cell" data-outputid="c6058d35-bbf8-49c7-b9be-8c9c46d5b93c">
<div class="sourceCode cell-code" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><span class="op" style="color: #5E5E5E;">!</span>aws s3 ls <span class="op" style="color: #5E5E5E;">--</span>recursive $processed_train_data_s3_uri</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>2023-02-13 17:36:41    4894416 transformed/data/sentiment-train/part-algo-1-womens_clothing_ecommerce_reviews.tsv</code></pre>
</div>
</div>
<div class="cell" data-outputid="736b7a72-d04b-46ed-c94d-2da565beeddf">
<div class="sourceCode cell-code" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><span class="op" style="color: #5E5E5E;">!</span>aws s3 ls <span class="op" style="color: #5E5E5E;">--</span>recursive $processed_validation_data_s3_uri</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>2023-02-13 17:36:42     276522 transformed/data/sentiment-validation/part-algo-1-womens_clothing_ecommerce_reviews.tsv</code></pre>
</div>
</div>
<div class="cell" data-outputid="c26e1338-e788-4b01-ebc9-663aa02ed54d">
<div class="sourceCode cell-code" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><span class="op" style="color: #5E5E5E;">!</span>aws s3 ls <span class="op" style="color: #5E5E5E;">--</span>recursive $processed_test_data_s3_uri</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>2023-02-13 17:36:43     273414 transformed/data/sentiment-test/part-algo-1-womens_clothing_ecommerce_reviews.tsv</code></pre>
</div>
</div>
<p>Now we set up a dictionary of the input training and validation data channels, wrapping the corresponding S3 locations in a <code>TrainingInput</code> object.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb11" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><span class="im" style="color: #00769E;">from</span> sagemaker.inputs <span class="im" style="color: #00769E;">import</span> TrainingInput</span>
<span id="cb11-2"></span>
<span id="cb11-3">data_channels <span class="op" style="color: #5E5E5E;">=</span> {</span>
<span id="cb11-4">    <span class="st" style="color: #20794D;">'train'</span>: processed_train_data_s3_uri, </span>
<span id="cb11-5">    <span class="st" style="color: #20794D;">'validation'</span>: processed_validation_data_s3_uri </span>
<span id="cb11-6">}</span></code></pre></div>
</div>
<p>There is no need to create a test data channel, as the test data is used later at the evaluation stage and does not need to be wrapped into the <code>sagemaker.inputs.TrainingInput</code> function.</p>
</section>
<section id="configure-hyperparameter-tuning-job" class="level3" data-number="2.2">
<h3 data-number="2.2" class="anchored" data-anchor-id="configure-hyperparameter-tuning-job"><span class="header-section-number">2.2</span> Configure Hyperparameter Tuning Job</h3>
<p>Model hyperparameters need to be set prior to starting the model training as they control the process of learning. Some of the hyperparameters you will set up as static - they will not be explored during the tuning job. For the non-static hyperparameters we will set the range of possible values to be explored.</p>
<p>First, we configure static hyperparameters including the instance type, instance count, maximum sequence length, etc. For the purposes of this project, we will use a relatively small instance type. Please refer to <a href="https://aws.amazon.com/sagemaker/pricing/">this link</a> for additional instance types that may work for your use cases.</p>
<div class="cell" data-scrolled="true">
<div class="sourceCode cell-code" id="cb12" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1">max_seq_length<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">128</span> <span class="co" style="color: #5E5E5E;"># maximum number of input tokens passed to BERT model</span></span>
<span id="cb12-2">freeze_bert_layer<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">False</span> <span class="co" style="color: #5E5E5E;"># specifies the depth of training within the network</span></span>
<span id="cb12-3">epochs<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">3</span></span>
<span id="cb12-4">train_steps_per_epoch<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">50</span></span>
<span id="cb12-5">validation_batch_size<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">64</span></span>
<span id="cb12-6">validation_steps_per_epoch<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">50</span></span>
<span id="cb12-7">seed<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">42</span></span>
<span id="cb12-8"></span>
<span id="cb12-9">train_instance_count<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">1</span></span>
<span id="cb12-10">train_instance_type<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'ml.c5.9xlarge'</span></span>
<span id="cb12-11">train_volume_size<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">256</span></span>
<span id="cb12-12">input_mode<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'File'</span></span>
<span id="cb12-13">run_validation<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span></span></code></pre></div>
</div>
<p>Some of these will be passed into the PyTorch estimator and tuner in the hyperparameters argument. Let’s set up the dictionary for that:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb13" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1">hyperparameters_static<span class="op" style="color: #5E5E5E;">=</span>{</span>
<span id="cb13-2">    <span class="st" style="color: #20794D;">'freeze_bert_layer'</span>: freeze_bert_layer,</span>
<span id="cb13-3">    <span class="st" style="color: #20794D;">'max_seq_length'</span>: max_seq_length,</span>
<span id="cb13-4">    <span class="st" style="color: #20794D;">'epochs'</span>: epochs,</span>
<span id="cb13-5">    <span class="st" style="color: #20794D;">'train_steps_per_epoch'</span>: train_steps_per_epoch,</span>
<span id="cb13-6">    <span class="st" style="color: #20794D;">'validation_batch_size'</span>: validation_batch_size,</span>
<span id="cb13-7">    <span class="st" style="color: #20794D;">'validation_steps_per_epoch'</span>: validation_steps_per_epoch,</span>
<span id="cb13-8">    <span class="st" style="color: #20794D;">'seed'</span>: seed,</span>
<span id="cb13-9">    <span class="st" style="color: #20794D;">'run_validation'</span>: run_validation</span>
<span id="cb13-10">}</span></code></pre></div>
</div>
<p>Now we configure hyperparameter ranges to explore in the Tuning Job. The values of the ranges typically come from prior experience, research papers, or other models similar to the task you are trying to do.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb14" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><span class="im" style="color: #00769E;">from</span> sagemaker.tuner <span class="im" style="color: #00769E;">import</span> IntegerParameter</span>
<span id="cb14-2"><span class="im" style="color: #00769E;">from</span> sagemaker.tuner <span class="im" style="color: #00769E;">import</span> ContinuousParameter</span>
<span id="cb14-3"><span class="im" style="color: #00769E;">from</span> sagemaker.tuner <span class="im" style="color: #00769E;">import</span> CategoricalParameter</span>
<span id="cb14-4">                                                </span>
<span id="cb14-5">hyperparameter_ranges <span class="op" style="color: #5E5E5E;">=</span> {</span>
<span id="cb14-6">    <span class="st" style="color: #20794D;">'learning_rate'</span>: ContinuousParameter(<span class="fl" style="color: #AD0000;">0.00001</span>, <span class="fl" style="color: #AD0000;">0.00005</span>, scaling_type<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'Linear'</span>), <span class="co" style="color: #5E5E5E;"># specifying continuous variable type, the tuning job will explore the range of values</span></span>
<span id="cb14-7">    <span class="st" style="color: #20794D;">'train_batch_size'</span>: CategoricalParameter([<span class="dv" style="color: #AD0000;">128</span>, <span class="dv" style="color: #AD0000;">256</span>]), <span class="co" style="color: #5E5E5E;"># specifying categorical variable type, the tuning job will explore only listed values</span></span>
<span id="cb14-8">}</span></code></pre></div>
</div>
</section>
<section id="set-up-evaluation-metrics" class="level3" data-number="2.3">
<h3 data-number="2.3" class="anchored" data-anchor-id="set-up-evaluation-metrics"><span class="header-section-number">2.3</span> Set up evaluation metrics</h3>
<p>Choose loss and accuracy as the evaluation metrics. The regular expressions <code>Regex</code> will capture the values of metrics that the algorithm will emit.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb15" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1">metric_definitions <span class="op" style="color: #5E5E5E;">=</span> [</span>
<span id="cb15-2">     {<span class="st" style="color: #20794D;">'Name'</span>: <span class="st" style="color: #20794D;">'validation:loss'</span>, <span class="st" style="color: #20794D;">'Regex'</span>: <span class="st" style="color: #20794D;">'val_loss: ([0-9.]+)'</span>},</span>
<span id="cb15-3">     {<span class="st" style="color: #20794D;">'Name'</span>: <span class="st" style="color: #20794D;">'validation:accuracy'</span>, <span class="st" style="color: #20794D;">'Regex'</span>: <span class="st" style="color: #20794D;">'val_acc: ([0-9.]+)'</span>},</span>
<span id="cb15-4">]</span></code></pre></div>
</div>
<p>In the Tuning Job, we will be maximizing validation accuracy as the objective metric.</p>
</section>
</section>
<section id="run-tuning-job" class="level2" data-number="3">
<h2 data-number="3" class="anchored" data-anchor-id="run-tuning-job"><span class="header-section-number">3</span> Run Tuning Job</h2>
<section id="set-up-the-roberta-and-pytorch-script-to-run-on-sagemaker" class="level3" data-number="3.1">
<h3 data-number="3.1" class="anchored" data-anchor-id="set-up-the-roberta-and-pytorch-script-to-run-on-sagemaker"><span class="header-section-number">3.1</span> Set up the RoBERTa and PyTorch script to run on SageMaker</h3>
<p>We will now prepare the PyTorch model to run as a SageMaker Training Job. The estimator takes into the entry point a separate Python file, which will be called during the training. We can open and review this file <a href="https://pranath.github.io/pds/tuning/train.py">src/train.py</a>.</p>
<p>For more information on the <code>PyTorchEstimator</code>, see the documentation here: https://sagemaker.readthedocs.io/</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb16" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><span class="im" style="color: #00769E;">from</span> sagemaker.pytorch <span class="im" style="color: #00769E;">import</span> PyTorch <span class="im" style="color: #00769E;">as</span> PyTorchEstimator</span>
<span id="cb16-2"><span class="co" style="color: #5E5E5E;"># Note: we don't have to rename the PyTorch estimator,</span></span>
<span id="cb16-3"><span class="co" style="color: #5E5E5E;"># but this is useful for code clarity, especially when a few modules of 'sagemaker.pytorch' are used</span></span>
<span id="cb16-4"></span>
<span id="cb16-5">estimator <span class="op" style="color: #5E5E5E;">=</span> PyTorchEstimator(</span>
<span id="cb16-6">    entry_point<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'train.py'</span>,</span>
<span id="cb16-7">    source_dir<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'src'</span>,</span>
<span id="cb16-8">    role<span class="op" style="color: #5E5E5E;">=</span>role,</span>
<span id="cb16-9">    instance_count<span class="op" style="color: #5E5E5E;">=</span>train_instance_count,</span>
<span id="cb16-10">    instance_type<span class="op" style="color: #5E5E5E;">=</span>train_instance_type,</span>
<span id="cb16-11">    volume_size<span class="op" style="color: #5E5E5E;">=</span>train_volume_size,</span>
<span id="cb16-12">    py_version<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'py3'</span>,</span>
<span id="cb16-13">    framework_version<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'1.6.0'</span>,</span>
<span id="cb16-14">    hyperparameters<span class="op" style="color: #5E5E5E;">=</span>hyperparameters_static,</span>
<span id="cb16-15">    metric_definitions<span class="op" style="color: #5E5E5E;">=</span>metric_definitions,</span>
<span id="cb16-16">    input_mode<span class="op" style="color: #5E5E5E;">=</span>input_mode,</span>
<span id="cb16-17">)</span></code></pre></div>
</div>
</section>
<section id="launch-the-hyperparameter-tuning-job" class="level3" data-number="3.2">
<h3 data-number="3.2" class="anchored" data-anchor-id="launch-the-hyperparameter-tuning-job"><span class="header-section-number">3.2</span> Launch the Hyperparameter Tuning Job</h3>
<p>A hyperparameter tuning job runs a series of training jobs that each test a combination of hyperparameters for a given objective metric (i.e.&nbsp;<code>validation:accuracy</code>). In this project, we will use a <code>Random</code> search strategy to determine the combinations of hyperparameters - within the specific ranges - to use for each training job within the tuning job. For more information on hyperparameter tuning search strategies, please see the following documentation: https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-how-it-works.html</p>
<p>When the tuning job completes, we can select the hyperparameters used by the best-performing training job relative to the objective metric.</p>
<p>The <code>max_jobs</code> parameter is a stop criteria that limits the number of overall training jobs (and therefore hyperparameter combinations) to run within the tuning job.</p>
<p>The <code>max_parallel_jobs</code> parameter limits the number of training jobs (and therefore hyperparameter combinations) to run in parallel within the tuning job. This parameter is often used in combination with the <code>Bayesian</code> search strategy when you want to test a smaller set of training jobs (less than the <code>max_jobs</code>), learn from the smaller set of training jobs, then apply Bayesian methods to determine the next set of hyperparameters used by the next set of training jobs. Bayesian methods can improve hyperparameter-tuning performance in some cases.</p>
<p>The <code>early_stopping_type</code> parameter is used by SageMaker hyper-parameter tuning jobs to automatically stop a training job if the job is not improving the objective metrics (i.e.&nbsp;<code>validation:accuracy</code>) relative to previous training jobs within the tuning job. For more information on early stopping, please see the following documentation: https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-early-stopping.html.</p>
<p>Let’s set up the Hyperparameter Tuner.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb17" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><span class="im" style="color: #00769E;">from</span> sagemaker.tuner <span class="im" style="color: #00769E;">import</span> HyperparameterTuner</span>
<span id="cb17-2"></span>
<span id="cb17-3">tuner <span class="op" style="color: #5E5E5E;">=</span> HyperparameterTuner(</span>
<span id="cb17-4">    estimator<span class="op" style="color: #5E5E5E;">=</span>estimator, </span>
<span id="cb17-5">    hyperparameter_ranges<span class="op" style="color: #5E5E5E;">=</span>hyperparameter_ranges, </span>
<span id="cb17-6">    metric_definitions<span class="op" style="color: #5E5E5E;">=</span>metric_definitions, </span>
<span id="cb17-7">    strategy<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'Random'</span>, </span>
<span id="cb17-8">    objective_type<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'Maximize'</span>,</span>
<span id="cb17-9">    objective_metric_name<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'validation:accuracy'</span>,</span>
<span id="cb17-10">    max_jobs<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">2</span>, <span class="co" style="color: #5E5E5E;"># maximum number of jobs to run</span></span>
<span id="cb17-11">    max_parallel_jobs<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">2</span>, <span class="co" style="color: #5E5E5E;"># maximum number of jobs to run in parallel</span></span>
<span id="cb17-12">    early_stopping_type<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'Auto'</span> <span class="co" style="color: #5E5E5E;"># early stopping criteria</span></span>
<span id="cb17-13">)</span></code></pre></div>
</div>
<p>Now we launch the SageMaker Hyper-Parameter Tuning (HPT) Job.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb18" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1">tuner.fit(</span>
<span id="cb18-2">    inputs<span class="op" style="color: #5E5E5E;">=</span>data_channels, </span>
<span id="cb18-3">    include_cls_metadata<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">False</span>,</span>
<span id="cb18-4">    wait<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">False</span></span>
<span id="cb18-5">)</span></code></pre></div>
</div>
</section>
<section id="check-tuning-job-status" class="level3" data-number="3.3">
<h3 data-number="3.3" class="anchored" data-anchor-id="check-tuning-job-status"><span class="header-section-number">3.3</span> Check Tuning Job status</h3>
<p>We can see the Tuning Job status in the console.</p>
<div class="cell" data-outputid="18d3bff8-09d1-4c2f-e4f8-092a9f9fd450" data-scrolled="true">
<div class="sourceCode cell-code" id="cb19" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1">tuning_job_name <span class="op" style="color: #5E5E5E;">=</span> tuner.latest_tuning_job.job_name</span>
<span id="cb19-2"><span class="bu" style="color: null;">print</span>(tuning_job_name)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>pytorch-training-230213-1736</code></pre>
</div>
</div>
<div class="cell" data-outputid="885c59c6-02a5-4410-fa72-8e5c4061c397">
<div class="sourceCode cell-code" id="cb21" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><span class="op" style="color: #5E5E5E;">%%</span>time</span>
<span id="cb21-2"></span>
<span id="cb21-3">tuner.wait()</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>.....................................................................................................................................................................................................................................................................................................!
CPU times: user 1.37 s, sys: 191 ms, total: 1.56 s
Wall time: 24min 53s</code></pre>
</div>
</div>
<p>The results of the SageMaker Hyperparameter Tuning Job are available on the <code>analytics</code> of the <code>tuner object</code>. The <code>dataframe</code> function converts the result directly into the dataframe. We can explore the results with the following lines of the code:</p>
<div class="cell" data-outputid="b87d480a-0a86-4216-d88b-0e89b1face48">
<div class="sourceCode cell-code" id="cb23" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><span class="im" style="color: #00769E;">import</span> time</span>
<span id="cb23-2"></span>
<span id="cb23-3">time.sleep(<span class="dv" style="color: #AD0000;">10</span>) <span class="co" style="color: #5E5E5E;"># slight delay to allow the analytics to be calculated</span></span>
<span id="cb23-4"></span>
<span id="cb23-5">df_results <span class="op" style="color: #5E5E5E;">=</span> tuner.analytics().dataframe()</span>
<span id="cb23-6">df_results.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="20">
<pre><code>(2, 8)</code></pre>
</div>
</div>
<div class="cell" data-outputid="53838327-3ae5-4bf2-fc7b-cb46ee637777">
<div class="sourceCode cell-code" id="cb25" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1">df_results.sort_values(<span class="st" style="color: #20794D;">'FinalObjectiveValue'</span>, ascending<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">0</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="21">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>learning_rate</th>
      <th>train_batch_size</th>
      <th>TrainingJobName</th>
      <th>TrainingJobStatus</th>
      <th>FinalObjectiveValue</th>
      <th>TrainingStartTime</th>
      <th>TrainingEndTime</th>
      <th>TrainingElapsedTimeSeconds</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.000020</td>
      <td>"128"</td>
      <td>pytorch-training-230213-1736-002-23e15b91</td>
      <td>Completed</td>
      <td>73.050003</td>
      <td>2023-02-13 17:38:06+00:00</td>
      <td>2023-02-13 18:01:09+00:00</td>
      <td>1383.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.000017</td>
      <td>"128"</td>
      <td>pytorch-training-230213-1736-001-44bd7477</td>
      <td>Completed</td>
      <td>72.269997</td>
      <td>2023-02-13 17:38:02+00:00</td>
      <td>2023-02-13 18:01:24+00:00</td>
      <td>1402.0</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<p>When training and tuning at scale, it is important to continuously monitor and use the right compute resources. While we have the flexibility of choosing different compute options how do you choose the specific instance types and sizes to use? There is no standard answer for this. It comes down to understanding the workload and running empirical testing to determine the best compute resources to use for the training.</p>
<p>SageMaker Training Jobs emit CloudWatch metrics for resource utilization. We can review them in the AWS console.</p>
</section>
</section>
<section id="evaluate-the-results" class="level2" data-number="4">
<h2 data-number="4" class="anchored" data-anchor-id="evaluate-the-results"><span class="header-section-number">4</span> Evaluate the results</h2>
<p>An important part of developing a model is evaluating the model with a test data set - one that the model has never seen during its training process. The final metrics resulting from this evaluation can be used to compare competing machine learning models. The higher the value of these metrics, the better the model is able to generalize.</p>
<section id="show-the-best-candidate" class="level3" data-number="4.1">
<h3 data-number="4.1" class="anchored" data-anchor-id="show-the-best-candidate"><span class="header-section-number">4.1</span> Show the best candidate</h3>
<p>Let’s now show the best candidate - the one with the highest accuracy result.</p>
<div class="cell" data-outputid="58699c9c-5c70-4df3-b231-b1ef3ad2b716">
<div class="sourceCode cell-code" id="cb26" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1">df_results.sort_values(</span>
<span id="cb26-2">    <span class="st" style="color: #20794D;">'FinalObjectiveValue'</span>, </span>
<span id="cb26-3">    ascending<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">0</span>).head(<span class="dv" style="color: #AD0000;">1</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="23">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>learning_rate</th>
      <th>train_batch_size</th>
      <th>TrainingJobName</th>
      <th>TrainingJobStatus</th>
      <th>FinalObjectiveValue</th>
      <th>TrainingStartTime</th>
      <th>TrainingEndTime</th>
      <th>TrainingElapsedTimeSeconds</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.00002</td>
      <td>"128"</td>
      <td>pytorch-training-230213-1736-002-23e15b91</td>
      <td>Completed</td>
      <td>73.050003</td>
      <td>2023-02-13 17:38:06+00:00</td>
      <td>2023-02-13 18:01:09+00:00</td>
      <td>1383.0</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
</section>
<section id="evaluate-the-best-candidate" class="level3" data-number="4.2">
<h3 data-number="4.2" class="anchored" data-anchor-id="evaluate-the-best-candidate"><span class="header-section-number">4.2</span> Evaluate the best candidate</h3>
<p>Let’s pull the information about the best candidate from the dataframe and then take the Training Job name from the column <code>TrainingJobName</code>.</p>
<div class="cell" data-outputid="d000d21b-8e0b-4fe4-a726-0864b589a731">
<div class="sourceCode cell-code" id="cb27" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1">best_candidate <span class="op" style="color: #5E5E5E;">=</span> df_results.sort_values(<span class="st" style="color: #20794D;">'FinalObjectiveValue'</span>, ascending<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">0</span>).iloc[<span class="dv" style="color: #AD0000;">0</span>]</span>
<span id="cb27-2"></span>
<span id="cb27-3">best_candidate_training_job_name <span class="op" style="color: #5E5E5E;">=</span> best_candidate[<span class="st" style="color: #20794D;">'TrainingJobName'</span>]</span>
<span id="cb27-4"><span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">'Best candidate Training Job name: </span><span class="sc" style="color: #5E5E5E;">{}</span><span class="st" style="color: #20794D;">'</span>.<span class="bu" style="color: null;">format</span>(best_candidate_training_job_name))</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Best candidate Training Job name: pytorch-training-230213-1736-002-23e15b91</code></pre>
</div>
</div>
<p>Now lets show the accuracy result for the best candidate.</p>
<div class="cell" data-outputid="1d6a7aee-827a-40b3-d89c-27cb8218d653">
<div class="sourceCode cell-code" id="cb29" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1">best_candidate_accuracy <span class="op" style="color: #5E5E5E;">=</span> best_candidate[<span class="st" style="color: #20794D;">'FinalObjectiveValue'</span>] </span>
<span id="cb29-2"></span>
<span id="cb29-3"><span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">'Best candidate accuracy result: </span><span class="sc" style="color: #5E5E5E;">{}</span><span class="st" style="color: #20794D;">'</span>.<span class="bu" style="color: null;">format</span>(best_candidate_accuracy))</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Best candidate accuracy result: 73.05000305175781</code></pre>
</div>
</div>
<p>We can use the function <code>describe_training_job</code> of the service client to get some more information about the best candidate. The result is in dictionary format. Let’s check that it has the same Training Job name:</p>
<div class="cell" data-outputid="f6804e74-19d9-415f-9549-c9a09b7aecd6">
<div class="sourceCode cell-code" id="cb31" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1">best_candidate_description <span class="op" style="color: #5E5E5E;">=</span> sm.describe_training_job(TrainingJobName<span class="op" style="color: #5E5E5E;">=</span>best_candidate_training_job_name)</span>
<span id="cb31-2"></span>
<span id="cb31-3">best_candidate_training_job_name2 <span class="op" style="color: #5E5E5E;">=</span> best_candidate_description[<span class="st" style="color: #20794D;">'TrainingJobName'</span>]</span>
<span id="cb31-4"></span>
<span id="cb31-5"><span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">'Training Job name: </span><span class="sc" style="color: #5E5E5E;">{}</span><span class="st" style="color: #20794D;">'</span>.<span class="bu" style="color: null;">format</span>(best_candidate_training_job_name2))</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Training Job name: pytorch-training-230213-1736-002-23e15b91</code></pre>
</div>
</div>
<p>Now lets pull the Tuning Job and Training Job Amazon Resource Name (ARN) from the best candidate training job description.</p>
<div class="cell" data-outputid="3528b282-76f7-45ff-bbeb-c1656bd77280">
<div class="sourceCode cell-code" id="cb33" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><span class="bu" style="color: null;">print</span>(best_candidate_description.keys())</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>dict_keys(['TrainingJobName', 'TrainingJobArn', 'TuningJobArn', 'ModelArtifacts', 'TrainingJobStatus', 'SecondaryStatus', 'HyperParameters', 'AlgorithmSpecification', 'RoleArn', 'InputDataConfig', 'OutputDataConfig', 'ResourceConfig', 'StoppingCondition', 'CreationTime', 'TrainingStartTime', 'TrainingEndTime', 'LastModifiedTime', 'SecondaryStatusTransitions', 'FinalMetricDataList', 'EnableNetworkIsolation', 'EnableInterContainerTrafficEncryption', 'EnableManagedSpotTraining', 'TrainingTimeInSeconds', 'BillableTimeInSeconds', 'ProfilingStatus', 'WarmPoolStatus', 'ResponseMetadata'])</code></pre>
</div>
</div>
<div class="cell" data-outputid="cf019137-fd79-4c70-e931-a39b98fbc0b8">
<div class="sourceCode cell-code" id="cb35" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1">best_candidate_tuning_job_arn <span class="op" style="color: #5E5E5E;">=</span> best_candidate_description[<span class="st" style="color: #20794D;">'TuningJobArn'</span>] </span>
<span id="cb35-2">best_candidate_training_job_arn <span class="op" style="color: #5E5E5E;">=</span> best_candidate_description[<span class="st" style="color: #20794D;">'TrainingJobArn'</span>] </span>
<span id="cb35-3"><span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">'Best candidate Tuning Job ARN: </span><span class="sc" style="color: #5E5E5E;">{}</span><span class="st" style="color: #20794D;">'</span>.<span class="bu" style="color: null;">format</span>(best_candidate_tuning_job_arn))</span>
<span id="cb35-4"><span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">'Best candidate Training Job ARN: </span><span class="sc" style="color: #5E5E5E;">{}</span><span class="st" style="color: #20794D;">'</span>.<span class="bu" style="color: null;">format</span>(best_candidate_training_job_arn))</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Best candidate Tuning Job ARN: arn:aws:sagemaker:us-east-1:058323655887:hyper-parameter-tuning-job/pytorch-training-230213-1736
Best candidate Training Job ARN: arn:aws:sagemaker:us-east-1:058323655887:training-job/pytorch-training-230213-1736-002-23e15b91</code></pre>
</div>
</div>
<p>Next, we pull the path of the best candidate model in the S3 bucket. We will need it later to set up the Processing Job for the evaluation.</p>
<div class="cell" data-outputid="107f7d5d-d89b-47ba-9484-f707d1d7d9e7">
<div class="sourceCode cell-code" id="cb37" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb37-1">model_tar_s3_uri <span class="op" style="color: #5E5E5E;">=</span> sm.describe_training_job(TrainingJobName<span class="op" style="color: #5E5E5E;">=</span>best_candidate_training_job_name)[<span class="st" style="color: #20794D;">'ModelArtifacts'</span>][<span class="st" style="color: #20794D;">'S3ModelArtifacts'</span>]</span>
<span id="cb37-2"><span class="bu" style="color: null;">print</span>(model_tar_s3_uri)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>s3://sagemaker-us-east-1-058323655887/pytorch-training-230213-1736-002-23e15b91/output/model.tar.gz</code></pre>
</div>
</div>
<p>To perform model evaluation we will use a scikit-learn-based Processing Job. This is essentially a generic Python Processing Job with scikit-learn pre-installed. We can specify the version of scikit-learn we wish to use. Also we need to pass the SageMaker execution role, processing instance type and instance count.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb39" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1"><span class="im" style="color: #00769E;">from</span> sagemaker.sklearn.processing <span class="im" style="color: #00769E;">import</span> SKLearnProcessor</span>
<span id="cb39-2"></span>
<span id="cb39-3">processing_instance_type <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">"ml.c5.2xlarge"</span></span>
<span id="cb39-4">processing_instance_count <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">1</span></span>
<span id="cb39-5"></span>
<span id="cb39-6">processor <span class="op" style="color: #5E5E5E;">=</span> SKLearnProcessor(</span>
<span id="cb39-7">    framework_version<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"0.23-1"</span>,</span>
<span id="cb39-8">    role<span class="op" style="color: #5E5E5E;">=</span>role,</span>
<span id="cb39-9">    instance_type<span class="op" style="color: #5E5E5E;">=</span>processing_instance_type,</span>
<span id="cb39-10">    instance_count<span class="op" style="color: #5E5E5E;">=</span>processing_instance_count,</span>
<span id="cb39-11">    max_runtime_in_seconds<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">7200</span>,</span>
<span id="cb39-12">)</span></code></pre></div>
</div>
<p>The model evaluation Processing Job will be running the Python code from the file <a href="https://pranath.github.io/pds/tuning/evaluate_model_metrics.py">src/evaluate_model_metrics.py</a>. You can open and review the file.</p>
<p>Let’s launch the Processing Job, passing the defined above parameters, custom script, path and the S3 bucket location of the test data.</p>
<div class="cell" data-outputid="a4d26510-3c5e-4bd1-bb75-edd8619d257d">
<div class="sourceCode cell-code" id="cb40" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb40-1"><span class="im" style="color: #00769E;">from</span> sagemaker.processing <span class="im" style="color: #00769E;">import</span> ProcessingInput, ProcessingOutput</span>
<span id="cb40-2"></span>
<span id="cb40-3">processor.run(</span>
<span id="cb40-4">    code<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"src/evaluate_model_metrics.py"</span>,</span>
<span id="cb40-5">    inputs<span class="op" style="color: #5E5E5E;">=</span>[</span>
<span id="cb40-6">        ProcessingInput(  </span>
<span id="cb40-7">            input_name<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"model-tar-s3-uri"</span>,                        </span>
<span id="cb40-8">            source<span class="op" style="color: #5E5E5E;">=</span>model_tar_s3_uri,                               </span>
<span id="cb40-9">            destination<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"/opt/ml/processing/input/model/"</span></span>
<span id="cb40-10">        ),</span>
<span id="cb40-11">        ProcessingInput(</span>
<span id="cb40-12">            input_name<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"evaluation-data-s3-uri"</span>,</span>
<span id="cb40-13">            source<span class="op" style="color: #5E5E5E;">=</span>processed_test_data_s3_uri,                                    </span>
<span id="cb40-14">            destination<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"/opt/ml/processing/input/data/"</span>,</span>
<span id="cb40-15">        ),</span>
<span id="cb40-16">    ],</span>
<span id="cb40-17">    outputs<span class="op" style="color: #5E5E5E;">=</span>[</span>
<span id="cb40-18">        ProcessingOutput(s3_upload_mode<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"EndOfJob"</span>, output_name<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"metrics"</span>, source<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"/opt/ml/processing/output/metrics"</span>),</span>
<span id="cb40-19">    ],</span>
<span id="cb40-20">    arguments<span class="op" style="color: #5E5E5E;">=</span>[<span class="st" style="color: #20794D;">"--max-seq-length"</span>, <span class="bu" style="color: null;">str</span>(max_seq_length)],</span>
<span id="cb40-21">    logs<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>,</span>
<span id="cb40-22">    wait<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">False</span>,</span>
<span id="cb40-23">)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Job Name:  sagemaker-scikit-learn-2023-02-13-18-04-08-342
Inputs:  [{'InputName': 'model-tar-s3-uri', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-058323655887/pytorch-training-230213-1736-002-23e15b91/output/model.tar.gz', 'LocalPath': '/opt/ml/processing/input/model/', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}, {'InputName': 'evaluation-data-s3-uri', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-058323655887/transformed/data/sentiment-test/', 'LocalPath': '/opt/ml/processing/input/data/', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}, {'InputName': 'code', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-058323655887/sagemaker-scikit-learn-2023-02-13-18-04-08-342/input/code/evaluate_model_metrics.py', 'LocalPath': '/opt/ml/processing/input/code', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}]
Outputs:  [{'OutputName': 'metrics', 'AppManaged': False, 'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-058323655887/sagemaker-scikit-learn-2023-02-13-18-04-08-342/output/metrics', 'LocalPath': '/opt/ml/processing/output/metrics', 'S3UploadMode': 'EndOfJob'}}]</code></pre>
</div>
</div>
<p>We can see the information about the Processing Jobs using the <code>describe</code> function. The result is in dictionary format. Let’s pull the Processing Job name:</p>
<div class="cell" data-outputid="3fe215be-7c07-4f9d-dbc8-4bf43a0746a8">
<div class="sourceCode cell-code" id="cb42" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb42-1">scikit_processing_job_name <span class="op" style="color: #5E5E5E;">=</span> processor.jobs[<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>].describe()[<span class="st" style="color: #20794D;">"ProcessingJobName"</span>]</span>
<span id="cb42-2"></span>
<span id="cb42-3"><span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">'Processing Job name: </span><span class="sc" style="color: #5E5E5E;">{}</span><span class="st" style="color: #20794D;">'</span>.<span class="bu" style="color: null;">format</span>(scikit_processing_job_name))</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Processing Job name: sagemaker-scikit-learn-2023-02-13-18-04-08-342</code></pre>
</div>
</div>
<p>Now lets pull the Processing Job status from the Processing Job description.</p>
<div class="cell" data-outputid="833388eb-4228-423f-a974-4623df207ace">
<div class="sourceCode cell-code" id="cb44" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb44-1"><span class="bu" style="color: null;">print</span>(processor.jobs[<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>].describe().keys())</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>dict_keys(['ProcessingInputs', 'ProcessingOutputConfig', 'ProcessingJobName', 'ProcessingResources', 'StoppingCondition', 'AppSpecification', 'RoleArn', 'ProcessingJobArn', 'ProcessingJobStatus', 'LastModifiedTime', 'CreationTime', 'ResponseMetadata'])</code></pre>
</div>
</div>
<div class="cell" data-outputid="1c84660f-929d-4b8a-eea4-736f6bc82e21">
<div class="sourceCode cell-code" id="cb46" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb46-1">scikit_processing_job_status <span class="op" style="color: #5E5E5E;">=</span> processor.jobs[<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>].describe()[<span class="st" style="color: #20794D;">'ProcessingJobStatus'</span>] </span>
<span id="cb46-2"><span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">'Processing job status: </span><span class="sc" style="color: #5E5E5E;">{}</span><span class="st" style="color: #20794D;">'</span>.<span class="bu" style="color: null;">format</span>(scikit_processing_job_status))</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Processing job status: InProgress</code></pre>
</div>
</div>
<p>Let’s monitor the Processing Job.</p>
<div class="cell" data-outputid="40404e21-48fe-49ff-ee39-5eb801a174db">
<div class="sourceCode cell-code" id="cb48" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb48-1"><span class="im" style="color: #00769E;">from</span> pprint <span class="im" style="color: #00769E;">import</span> pprint</span>
<span id="cb48-2"></span>
<span id="cb48-3">running_processor <span class="op" style="color: #5E5E5E;">=</span> sagemaker.processing.ProcessingJob.from_processing_name(</span>
<span id="cb48-4">    processing_job_name<span class="op" style="color: #5E5E5E;">=</span>scikit_processing_job_name, sagemaker_session<span class="op" style="color: #5E5E5E;">=</span>sess</span>
<span id="cb48-5">)</span>
<span id="cb48-6"></span>
<span id="cb48-7">processing_job_description <span class="op" style="color: #5E5E5E;">=</span> running_processor.describe()</span>
<span id="cb48-8"></span>
<span id="cb48-9">pprint(processing_job_description)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>{'AppSpecification': {'ContainerArguments': ['--max-seq-length', '128'],
                      'ContainerEntrypoint': ['python3',
                                              '/opt/ml/processing/input/code/evaluate_model_metrics.py'],
                      'ImageUri': '683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-scikit-learn:0.23-1-cpu-py3'},
 'CreationTime': datetime.datetime(2023, 2, 13, 18, 4, 9, 1000, tzinfo=tzlocal()),
 'LastModifiedTime': datetime.datetime(2023, 2, 13, 18, 4, 9, 766000, tzinfo=tzlocal()),
 'ProcessingInputs': [{'AppManaged': False,
                       'InputName': 'model-tar-s3-uri',
                       'S3Input': {'LocalPath': '/opt/ml/processing/input/model/',
                                   'S3CompressionType': 'None',
                                   'S3DataDistributionType': 'FullyReplicated',
                                   'S3DataType': 'S3Prefix',
                                   'S3InputMode': 'File',
                                   'S3Uri': 's3://sagemaker-us-east-1-058323655887/pytorch-training-230213-1736-002-23e15b91/output/model.tar.gz'}},
                      {'AppManaged': False,
                       'InputName': 'evaluation-data-s3-uri',
                       'S3Input': {'LocalPath': '/opt/ml/processing/input/data/',
                                   'S3CompressionType': 'None',
                                   'S3DataDistributionType': 'FullyReplicated',
                                   'S3DataType': 'S3Prefix',
                                   'S3InputMode': 'File',
                                   'S3Uri': 's3://sagemaker-us-east-1-058323655887/transformed/data/sentiment-test/'}},
                      {'AppManaged': False,
                       'InputName': 'code',
                       'S3Input': {'LocalPath': '/opt/ml/processing/input/code',
                                   'S3CompressionType': 'None',
                                   'S3DataDistributionType': 'FullyReplicated',
                                   'S3DataType': 'S3Prefix',
                                   'S3InputMode': 'File',
                                   'S3Uri': 's3://sagemaker-us-east-1-058323655887/sagemaker-scikit-learn-2023-02-13-18-04-08-342/input/code/evaluate_model_metrics.py'}}],
 'ProcessingJobArn': 'arn:aws:sagemaker:us-east-1:058323655887:processing-job/sagemaker-scikit-learn-2023-02-13-18-04-08-342',
 'ProcessingJobName': 'sagemaker-scikit-learn-2023-02-13-18-04-08-342',
 'ProcessingJobStatus': 'InProgress',
 'ProcessingOutputConfig': {'Outputs': [{'AppManaged': False,
                                         'OutputName': 'metrics',
                                         'S3Output': {'LocalPath': '/opt/ml/processing/output/metrics',
                                                      'S3UploadMode': 'EndOfJob',
                                                      'S3Uri': 's3://sagemaker-us-east-1-058323655887/sagemaker-scikit-learn-2023-02-13-18-04-08-342/output/metrics'}}]},
 'ProcessingResources': {'ClusterConfig': {'InstanceCount': 1,
                                           'InstanceType': 'ml.c5.2xlarge',
                                           'VolumeSizeInGB': 30}},
 'ResponseMetadata': {'HTTPHeaders': {'content-length': '2328',
                                      'content-type': 'application/x-amz-json-1.1',
                                      'date': 'Mon, 13 Feb 2023 18:04:09 GMT',
                                      'x-amzn-requestid': '27108fc5-7782-41b6-ac72-25de5e9245dc'},
                      'HTTPStatusCode': 200,
                      'RequestId': '27108fc5-7782-41b6-ac72-25de5e9245dc',
                      'RetryAttempts': 0},
 'RoleArn': 'arn:aws:iam::058323655887:role/sagemaker-studio-vpc-firewall-us-east-1-sagemaker-execution-role',
 'StoppingCondition': {'MaxRuntimeInSeconds': 7200}}</code></pre>
</div>
</div>
<div class="cell" data-outputid="28e8fc5e-cf8d-4f8d-8d20-c840b94af512">
<div class="sourceCode cell-code" id="cb50" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb50-1"><span class="op" style="color: #5E5E5E;">%%</span>time</span>
<span id="cb50-2"></span>
<span id="cb50-3">running_processor.wait(logs<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">False</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>.........................................................................!CPU times: user 338 ms, sys: 40.8 ms, total: 379 ms
Wall time: 6min 9s</code></pre>
</div>
</div>
</section>
<section id="inspect-the-processed-output-data" class="level3" data-number="4.3">
<h3 data-number="4.3" class="anchored" data-anchor-id="inspect-the-processed-output-data"><span class="header-section-number">4.3</span> Inspect the processed output data</h3>
<p>Let’s take a look at the results of the Processing Job. Get the S3 bucket location of the output metrics:</p>
<div class="cell" data-outputid="f3ba6a45-9a70-40e4-e490-35ef80f49d5f">
<div class="sourceCode cell-code" id="cb52" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb52-1">processing_job_description <span class="op" style="color: #5E5E5E;">=</span> running_processor.describe()</span>
<span id="cb52-2"></span>
<span id="cb52-3">output_config <span class="op" style="color: #5E5E5E;">=</span> processing_job_description[<span class="st" style="color: #20794D;">"ProcessingOutputConfig"</span>]</span>
<span id="cb52-4"><span class="cf" style="color: #003B4F;">for</span> output <span class="kw" style="color: #003B4F;">in</span> output_config[<span class="st" style="color: #20794D;">"Outputs"</span>]:</span>
<span id="cb52-5">    <span class="cf" style="color: #003B4F;">if</span> output[<span class="st" style="color: #20794D;">"OutputName"</span>] <span class="op" style="color: #5E5E5E;">==</span> <span class="st" style="color: #20794D;">"metrics"</span>:</span>
<span id="cb52-6">        processed_metrics_s3_uri <span class="op" style="color: #5E5E5E;">=</span> output[<span class="st" style="color: #20794D;">"S3Output"</span>][<span class="st" style="color: #20794D;">"S3Uri"</span>]</span>
<span id="cb52-7"></span>
<span id="cb52-8"><span class="bu" style="color: null;">print</span>(processed_metrics_s3_uri)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>s3://sagemaker-us-east-1-058323655887/sagemaker-scikit-learn-2023-02-13-18-04-08-342/output/metrics</code></pre>
</div>
</div>
<p>List the content of the folder:</p>
<div class="cell" data-outputid="c00b6ef0-b45e-44dc-a5a2-1aa6bae5d1ba">
<div class="sourceCode cell-code" id="cb54" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb54-1"><span class="op" style="color: #5E5E5E;">!</span>aws s3 ls $processed_metrics_s3_uri<span class="op" style="color: #5E5E5E;">/</span></span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>2023-02-13 18:10:13      21764 confusion_matrix.png
2023-02-13 18:10:13         56 evaluation.json</code></pre>
</div>
</div>
<p>The test accuracy can be pulled from the <code>evaluation.json</code> file.</p>
<div class="cell" data-outputid="884bea2a-63bc-49d7-b47b-550759874538">
<div class="sourceCode cell-code" id="cb56" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb56-1"><span class="im" style="color: #00769E;">import</span> json</span>
<span id="cb56-2"><span class="im" style="color: #00769E;">from</span> pprint <span class="im" style="color: #00769E;">import</span> pprint</span>
<span id="cb56-3"></span>
<span id="cb56-4">metrics_json <span class="op" style="color: #5E5E5E;">=</span> sagemaker.s3.S3Downloader.read_file(<span class="st" style="color: #20794D;">"</span><span class="sc" style="color: #5E5E5E;">{}</span><span class="st" style="color: #20794D;">/evaluation.json"</span>.<span class="bu" style="color: null;">format</span>(</span>
<span id="cb56-5">    processed_metrics_s3_uri</span>
<span id="cb56-6">))</span>
<span id="cb56-7"></span>
<span id="cb56-8"><span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">'Test accuracy: </span><span class="sc" style="color: #5E5E5E;">{}</span><span class="st" style="color: #20794D;">'</span>.<span class="bu" style="color: null;">format</span>(json.loads(metrics_json)))</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Test accuracy: {'metrics': {'accuracy': {'value': 0.7378640776699029}}}</code></pre>
</div>
</div>
<p>Copy image with the confusion matrix generated during the model evaluation into the folder <code>generated</code>.</p>
<div class="cell" data-outputid="708667b1-9f41-4beb-92ca-1dc68ab2538d">
<div class="sourceCode cell-code" id="cb58" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb58-1"><span class="op" style="color: #5E5E5E;">!</span>aws s3 cp $processed_metrics_s3_uri<span class="op" style="color: #5E5E5E;">/</span>confusion_matrix.png .<span class="op" style="color: #5E5E5E;">/</span>generated<span class="op" style="color: #5E5E5E;">/</span></span>
<span id="cb58-2"></span>
<span id="cb58-3"><span class="im" style="color: #00769E;">import</span> time</span>
<span id="cb58-4">time.sleep(<span class="dv" style="color: #AD0000;">10</span>) <span class="co" style="color: #5E5E5E;"># Slight delay for our notebook to recognize the newly-downloaded file</span></span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>download: s3://sagemaker-us-east-1-058323655887/sagemaker-scikit-learn-2023-02-13-18-04-08-342/output/metrics/confusion_matrix.png to generated/confusion_matrix.png</code></pre>
</div>
</div>
<p>Lets show and review the confusion matrix, which is a table of all combinations of true (actual) and predicted labels. Each cell contains the number of the reviews for the corresponding sentiments.</p>
<p><img src="http://livingdatalab.com/posts/https:/github.com/pranath/blog/raw/master/images/confusion_matrix.png" title="Confusion Matrix" class="img-fluid"></p>
<p>We can see that the highest numbers of the reviews appear in the diagonal cells, which are the correct predictions for each sentiment class.</p>
</section>
</section>
<section id="acknowledgements" class="level2" data-number="5">
<h2 data-number="5" class="anchored" data-anchor-id="acknowledgements"><span class="header-section-number">5</span> Acknowledgements</h2>
<p>I’d like to express my thanks to the great <a href="https://www.deeplearning.ai/courses/practical-data-science-specialization/">Deep Learning AI Practical Data Science on AWS Specialisation Course</a> which i completed, and acknowledge the use of some images and other materials from the training course in this article.</p>


</section>

 ]]></description>
  <category>aws</category>
  <category>cloud-data-science</category>
  <category>natural-language-processing</category>
  <category>deep-learning</category>
  <guid>http://livingdatalab.com/posts/2023-02-14-optimize-models-in-the-cloud-using-aws-automatic-model-tuning.html</guid>
  <pubDate>Tue, 14 Feb 2023 00:00:00 GMT</pubDate>
  <media:content url="https://github.com/pranath/blog/raw/master/images/aws.png" medium="image" type="image/png"/>
</item>
<item>
  <title>Building an AWS SageMaker Pipeline for a BERT Based text classifier</title>
  <dc:creator>Pranath Fernando</dc:creator>
  <link>http://livingdatalab.com/posts/2023-02-12-building-aws-sagemaker-pipeline-train-deploy-bert-text-classifier.html</link>
  <description><![CDATA[ 




<section id="introduction" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="introduction"><span class="header-section-number">1</span> Introduction</h2>
<p>In <a href="../#category=aws">earlier articles we introduced AWS cloud services for data science</a>, and showed how it can help with different stages of the data science &amp; machine learning workflow.</p>
<p><img src="http://livingdatalab.com/posts/https:/github.com/pranath/blog/raw/master/images/aws_ds_workflow.png" title="The AWS Data Science Workflow" class="img-fluid"></p>
<p>In this project will look at the deploy and manage phase for the workflow using <strong>AWS Sagemaker Pipelines</strong>, which will actually involve all previous phases.</p>
<p>In particular we will do the following:</p>
<ul>
<li>Define and run a pipeline using a directed acyclic graph (DAG) with specific pipeline parameters and model hyper-parameters</li>
<li>Define a processing step that cleans, balances, transforms, and splits our dataset into train, validation, and test dataset</li>
<li>Define a training step that trains a model using the train and validation datasets</li>
<li>Define a processing step that evaluates the trained model’s performance on the test dataset</li>
<li>Define a register model step that creates a model package from the trained model</li>
<li>Define a conditional step that checks the model’s performance and conditionally registers the model for deployment</li>
</ul>
<p>Using the raw <a href="https://www.kaggle.com/nicapotato/womens-ecommerce-clothing-reviews">Women’s Clothing Reviews</a> dataset - we will prepare it to train a deep learning BERT-based natural language processing (NLP) model. The model will be used to classify customer reviews into positive (1), neutral (0) and negative (-1) sentiment.</p>
</section>
<section id="what-are-mlops" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="what-are-mlops"><span class="header-section-number">2</span> What are MLOPS ?</h2>
<p>MLOPS stands for Machine Learning Operations - but what does that mean?</p>
<p>MLOps builds on DevOps practices that encompass people, process, and technology. However, MLOps also includes considerations and practices that are really unique to machine learning workloads. All of these practices aim to be able to deliver machine learning workloads quickly to production while still maintaining high quality consistency and ensuring end-to-end traceability.</p>
<p><img src="http://livingdatalab.com/posts/https:/github.com/pranath/blog/raw/master/images/aws_path_mlmodels.png" title="Consideratons" class="img-fluid"></p>
<p>It’s important to consider that the machine learning development life cycle is very different than the software development life cycle for a variety of reasons.</p>
<p><img src="http://livingdatalab.com/posts/https:/github.com/pranath/blog/raw/master/images/aws_path_mlmodels2.png" title="Challenges" class="img-fluid"></p>
<p>First, the model development life cycle is difficult to plan for from a project management perspective. It typically includes longer experimentation cycles than you would see in a standard agile software development process. Also the development of machine learning models includes data tasks like feature engineering and data preparation. You also have data processing code, as well as new inputs and artifacts to consider for versioning. You also have additional pipeline task as well. When you start to look at automating the machine learning workflow, the inputs and artifacts that are generated across these tasks result in multiple disparate pipelines with dependencies that can be a bit more challenging, stitched together than a typical software development workflow.</p>
<p><img src="http://livingdatalab.com/posts/https:/github.com/pranath/blog/raw/master/images/aws_opml.png" title="Goals" class="img-fluid"></p>
<p>Second, some models exist by themselves where you might be manually reading prediction requests and getting responses through a batch process or even within your notebook on an ad hoc basis. This is especially true in research environments. However, in many cases, a model is typically a small part of an overall solution that incorporates machine-learning. While that model is still a very key component to that solution, most often there is a need for other components that need to be built or integrated. As an example, consider your product review use case and your model that is predicting the classes of sentiment for a product review. That model itself will be able to classify the sentiment related to a product, but you also need to consider how that prediction will actually be used and potentially integrated into other existing applications. For this, there may be additional tasks like creating a rest API as a common interface for other applications to integrate with your model or even building applications that can respond to those reviews. This could mean creating automation to initiate back-end processes that allow for customer support engineers to quickly react and respond to any negative reviews.</p>
<p><img src="http://livingdatalab.com/posts/https:/github.com/pranath/blog/raw/master/images/aws_opml2.png" title="Path to production" class="img-fluid"></p>
<p>A third consideration is that where typically multiple personas span the machine learning development lifecycle, and all are really needed to ultimately be able to build, deploy, integrate, and operate a machine learning workload. This can create challenges as these personas often have competing priorities and needs. There may also be skill gaps in building an operating machine learning workloads. As an example, a data scientist may not have a traditional IT background. While they may be very comfortable in creating a model that meets the performance objectives that have been identified for your particular machine learning use case, they may not know how to host that model in a way that it can be consumed by other applications or other systems. In this case, there may be a need to have a deployment engineer that is also engaged to help in building out the infrastructure and the resources that are needed to operate and host that model.</p>
<p><img src="http://livingdatalab.com/posts/https:/github.com/pranath/blog/raw/master/images/aws_opml3.png" title="Accelerating the path to production" class="img-fluid"></p>
<p>Also, you might need to integrate that hosted model with another application. In this case, you’re likely to depend on a software engineer to perform that integration. If there isn’t a cross-functional team with the same project goals in place, competing priorities and skill gaps across these personas make it really difficult to provide that path to production for your model.</p>
<p><img src="http://livingdatalab.com/posts/https:/github.com/pranath/blog/raw/master/images/aws_opml4.png" title="Improving the Quality of Deployed Models" class="img-fluid"></p>
<p>Finally, many teams have processes in place supporting different regulatory or even internal corporate requirements. This means that when you’re creating your machine learning pipeline, sometimes you also need to be able to ensure that traditional practices can be included inside the steps of your pipeline. Something like change management as an example here. This may mean that within your pipeline, you’re going to automatically open a change ticket anytime a new model gets deployed to production. Or maybe it’s a manual approval that’s required before your model can deploy to production. All of these processes may need to be incorporated inside your machine learning pipeline.</p>
<p><img src="http://livingdatalab.com/posts/https:/github.com/pranath/blog/raw/master/images/aws_opml5.png" title="Key Considerations" class="img-fluid"></p>
<p><strong>MLOps aims to provide the most efficient path to production by reducing manual hand-offs between the steps in your workflow, increasing automation within those steps in your workflow, and then going a step further to orchestrate the steps across your workflow.</strong></p>
</section>
<section id="aws-pipelines-terminology" class="level2" data-number="3">
<h2 data-number="3" class="anchored" data-anchor-id="aws-pipelines-terminology"><span class="header-section-number">3</span> AWS Pipelines Terminology</h2>
<p>This project focuses on the following features of Amazon SageMaker Pipelines:</p>
<ul>
<li><strong>Pipelines</strong> - a directed acyclic graph (DAG) of steps and conditions to orchestrate SageMaker jobs and resource creation</li>
<li><strong>Processing job steps</strong> - a simplified, managed experience on SageMaker to run data processing workloads, such as feature engineering, data validation, model evaluation, and model explainability</li>
<li><strong>Training job steps</strong> - an iterative process that teaches a model to make predictions on new data by presenting examples from a training dataset</li>
<li><strong>Conditional step execution</strong> - provides conditional execution of branches in a pipeline</li>
<li><strong>Registering models</strong> - register a model in a model registry to create a deployable models in Amazon SageMaker</li>
<li><strong>Parameterized pipeline executions</strong> - allows pipeline executions to vary by supplied parameters</li>
<li><strong>Model endpoint</strong> - hosts the model as a REST endpoint to serve predictions from new data</li>
</ul>
</section>
<section id="creating-a-bert-pipeline" class="level2" data-number="4">
<h2 data-number="4" class="anchored" data-anchor-id="creating-a-bert-pipeline"><span class="header-section-number">4</span> Creating a BERT Pipeline</h2>
<p>The pipeline that we will create follows a typical machine learning application pattern of pre-processing, training, evaluation, and model registration.</p>
<p>In the processing step, we will perform feature engineering to transform the <code>review_body</code> text into BERT embeddings using the pre-trained BERT model and split the dataset into train, validation and test files. The transformed dataset is stored in a feature store. To optimize for Tensorflow training, the transformed dataset files are saved using the TFRecord format in Amazon S3.</p>
<p>In the training step, we will fine-tune the BERT model to the customer reviews dataset and add a new classification layer to predict the <code>sentiment</code> for a given <code>review_body</code>.</p>
<p>In the evaluation step, we will take the trained model and a test dataset as input, and produce a JSON file containing classification evaluation metrics.</p>
<p>In the condition step, we will register the trained model if the accuracy of the model, as determined by our evaluation step, exceeds a given threshold value.</p>
<p><img src="http://livingdatalab.com/posts/https:/github.com/pranath/blog/raw/master/images/bert_sagemaker_pipeline.png" title="BERT Sagemaker Pipelines" class="img-fluid"></p>
<p>First, let’s install the required modules.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;">import</span> os</span>
<span id="cb1-2"><span class="im" style="color: #00769E;">import</span> sagemaker</span>
<span id="cb1-3"><span class="im" style="color: #00769E;">import</span> logging</span>
<span id="cb1-4"><span class="im" style="color: #00769E;">import</span> boto3</span>
<span id="cb1-5"><span class="im" style="color: #00769E;">import</span> sagemaker</span>
<span id="cb1-6"><span class="im" style="color: #00769E;">import</span> pandas <span class="im" style="color: #00769E;">as</span> pd</span>
<span id="cb1-7"><span class="im" style="color: #00769E;">import</span> json</span>
<span id="cb1-8"><span class="im" style="color: #00769E;">import</span> botocore</span>
<span id="cb1-9"><span class="im" style="color: #00769E;">from</span> botocore.exceptions <span class="im" style="color: #00769E;">import</span> ClientError</span>
<span id="cb1-10"></span>
<span id="cb1-11">config <span class="op" style="color: #5E5E5E;">=</span> botocore.config.Config(user_agent_extra<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'dlai-pds/c2/w3'</span>)</span>
<span id="cb1-12"></span>
<span id="cb1-13"><span class="co" style="color: #5E5E5E;"># low-level service client of the boto3 session</span></span>
<span id="cb1-14">sm <span class="op" style="color: #5E5E5E;">=</span> boto3.client(service_name<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'sagemaker'</span>, </span>
<span id="cb1-15">                  config<span class="op" style="color: #5E5E5E;">=</span>config)</span>
<span id="cb1-16"></span>
<span id="cb1-17">sm_runtime <span class="op" style="color: #5E5E5E;">=</span> boto3.client(<span class="st" style="color: #20794D;">'sagemaker-runtime'</span>,</span>
<span id="cb1-18">                          config<span class="op" style="color: #5E5E5E;">=</span>config)</span>
<span id="cb1-19"></span>
<span id="cb1-20">sess <span class="op" style="color: #5E5E5E;">=</span> sagemaker.Session(sagemaker_client<span class="op" style="color: #5E5E5E;">=</span>sm,</span>
<span id="cb1-21">                         sagemaker_runtime_client<span class="op" style="color: #5E5E5E;">=</span>sm_runtime)</span>
<span id="cb1-22"></span>
<span id="cb1-23">bucket <span class="op" style="color: #5E5E5E;">=</span> sess.default_bucket()</span>
<span id="cb1-24">role <span class="op" style="color: #5E5E5E;">=</span> sagemaker.get_execution_role()</span>
<span id="cb1-25">region <span class="op" style="color: #5E5E5E;">=</span> sess.boto_region_name</span></code></pre></div>
</div>
<p>Let’s setup the pipeline name.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="im" style="color: #00769E;">import</span> time</span>
<span id="cb2-2">timestamp <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">int</span>(time.time())</span>
<span id="cb2-3"></span>
<span id="cb2-4">pipeline_name <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">'BERT-pipeline-</span><span class="sc" style="color: #5E5E5E;">{}</span><span class="st" style="color: #20794D;">'</span>.<span class="bu" style="color: null;">format</span>(timestamp)</span></code></pre></div>
</div>
</section>
<section id="configure-the-dataset-and-processing-step" class="level2" data-number="5">
<h2 data-number="5" class="anchored" data-anchor-id="configure-the-dataset-and-processing-step"><span class="header-section-number">5</span> Configure the dataset and processing step</h2>
<section id="configure-s3-path-for-raw-input-data" class="level3" data-number="5.1">
<h3 data-number="5.1" class="anchored" data-anchor-id="configure-s3-path-for-raw-input-data"><span class="header-section-number">5.1</span> Configure S3 path for raw input data</h3>
<p>The raw dataset is in the public S3 bucket. Let’s start by specifying the S3 location of it:</p>
<div class="cell" data-outputid="bf6a9f74-3ac8-41f3-9687-cd1b46820068">
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1">raw_input_data_s3_uri <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">'s3://dlai-practical-data-science/data/raw/'</span></span>
<span id="cb3-2"><span class="bu" style="color: null;">print</span>(raw_input_data_s3_uri)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>s3://dlai-practical-data-science/data/raw/</code></pre>
</div>
</div>
<p>List the files in the S3 bucket (in this case it will be just one file):</p>
<div class="cell" data-outputid="704edfd2-2e74-445d-fd0a-d261ce456342">
<div class="sourceCode cell-code" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><span class="op" style="color: #5E5E5E;">!</span>aws s3 ls $raw_input_data_s3_uri</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>2021-04-30 02:21:06    8457214 womens_clothing_ecommerce_reviews.csv</code></pre>
</div>
</div>
</section>
<section id="configure-processing-step" class="level3" data-number="5.2">
<h3 data-number="5.2" class="anchored" data-anchor-id="configure-processing-step"><span class="header-section-number">5.2</span> Configure processing step</h3>
<p>For the pipeline workflow we will need to create workflow parameters of a specific type: integer, string, or float.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><span class="im" style="color: #00769E;">from</span> sagemaker.workflow.parameters <span class="im" style="color: #00769E;">import</span> (</span>
<span id="cb7-2">    ParameterInteger,</span>
<span id="cb7-3">    ParameterString,</span>
<span id="cb7-4">    ParameterFloat,</span>
<span id="cb7-5">)</span></code></pre></div>
</div>
<p>Now set the parameters for the processing step.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1">processing_instance_type <span class="op" style="color: #5E5E5E;">=</span> ParameterString(</span>
<span id="cb8-2">    name<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"ProcessingInstanceType"</span>,</span>
<span id="cb8-3">    default_value<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"ml.c5.2xlarge"</span></span>
<span id="cb8-4">)</span>
<span id="cb8-5"></span>
<span id="cb8-6">processing_instance_count <span class="op" style="color: #5E5E5E;">=</span> ParameterInteger(</span>
<span id="cb8-7">    name<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"ProcessingInstanceCount"</span>,</span>
<span id="cb8-8">    default_value<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">1</span></span>
<span id="cb8-9">)</span>
<span id="cb8-10"></span>
<span id="cb8-11">train_split_percentage <span class="op" style="color: #5E5E5E;">=</span> ParameterFloat(</span>
<span id="cb8-12">    name<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"TrainSplitPercentage"</span>,</span>
<span id="cb8-13">    default_value<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">0.90</span>,</span>
<span id="cb8-14">)</span>
<span id="cb8-15"></span>
<span id="cb8-16">validation_split_percentage <span class="op" style="color: #5E5E5E;">=</span> ParameterFloat(</span>
<span id="cb8-17">    name<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"ValidationSplitPercentage"</span>,</span>
<span id="cb8-18">    default_value<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">0.05</span>,</span>
<span id="cb8-19">)</span>
<span id="cb8-20"></span>
<span id="cb8-21">test_split_percentage <span class="op" style="color: #5E5E5E;">=</span> ParameterFloat(</span>
<span id="cb8-22">    name<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"TestSplitPercentage"</span>,</span>
<span id="cb8-23">    default_value<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">0.05</span>,</span>
<span id="cb8-24">)</span>
<span id="cb8-25"></span>
<span id="cb8-26">balance_dataset <span class="op" style="color: #5E5E5E;">=</span> ParameterString(</span>
<span id="cb8-27">    name<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"BalanceDataset"</span>,</span>
<span id="cb8-28">    default_value<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"True"</span>,</span>
<span id="cb8-29">)</span>
<span id="cb8-30"></span>
<span id="cb8-31">max_seq_length <span class="op" style="color: #5E5E5E;">=</span> ParameterInteger(</span>
<span id="cb8-32">    name<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"MaxSeqLength"</span>,</span>
<span id="cb8-33">    default_value<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">128</span>,</span>
<span id="cb8-34">)</span>
<span id="cb8-35"></span>
<span id="cb8-36">feature_store_offline_prefix <span class="op" style="color: #5E5E5E;">=</span> ParameterString(</span>
<span id="cb8-37">    name<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"FeatureStoreOfflinePrefix"</span>,</span>
<span id="cb8-38">    default_value<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"reviews-feature-store-"</span> <span class="op" style="color: #5E5E5E;">+</span> <span class="bu" style="color: null;">str</span>(timestamp),</span>
<span id="cb8-39">)</span>
<span id="cb8-40"></span>
<span id="cb8-41">feature_group_name <span class="op" style="color: #5E5E5E;">=</span> ParameterString(</span>
<span id="cb8-42">    name<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"FeatureGroupName"</span>,</span>
<span id="cb8-43">    default_value<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"reviews-feature-group-"</span> <span class="op" style="color: #5E5E5E;">+</span> <span class="bu" style="color: null;">str</span>(timestamp)</span>
<span id="cb8-44">)</span>
<span id="cb8-45"></span>
<span id="cb8-46">input_data <span class="op" style="color: #5E5E5E;">=</span> ParameterString(</span>
<span id="cb8-47">    name<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"InputData"</span>,</span>
<span id="cb8-48">    default_value<span class="op" style="color: #5E5E5E;">=</span>raw_input_data_s3_uri,</span>
<span id="cb8-49">)</span></code></pre></div>
</div>
<p>Setting up scikit-learn-based processor, pass the SageMaker execution role, processing instance type and instance count.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><span class="im" style="color: #00769E;">from</span> sagemaker.sklearn.processing <span class="im" style="color: #00769E;">import</span> SKLearnProcessor</span>
<span id="cb9-2"></span>
<span id="cb9-3">processor <span class="op" style="color: #5E5E5E;">=</span> SKLearnProcessor(</span>
<span id="cb9-4">    framework_version<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'0.23-1'</span>,</span>
<span id="cb9-5">    role<span class="op" style="color: #5E5E5E;">=</span>role,</span>
<span id="cb9-6">    instance_type<span class="op" style="color: #5E5E5E;">=</span>processing_instance_type,</span>
<span id="cb9-7">    instance_count<span class="op" style="color: #5E5E5E;">=</span>processing_instance_count,</span>
<span id="cb9-8">    env<span class="op" style="color: #5E5E5E;">=</span>{<span class="st" style="color: #20794D;">'AWS_DEFAULT_REGION'</span>: region},                             </span>
<span id="cb9-9">)</span></code></pre></div>
</div>
<p>Now we will use the processor instance to construct a <code>ProcessingStep</code>, along with the input and output channels and the code that will be executed when the pipeline invokes pipeline execution. This is very similar to a processor instance’s <code>run</code> method, for those familiar with the existing Python SDK.</p>
<p>Note the <code>"sentiment-train"</code>, <code>"sentiment-validation"</code> and <code>"sentiment-test"</code> named channels specified in the output configuration for the processing job. Such step <code>Properties</code> can be used in subsequent steps and will resolve to their runtime values at execution. In particular, we will call out this usage defining the training step.</p>
<div class="cell" data-outputid="cccebd03-d359-47d4-cb04-6cb53cde120a">
<div class="sourceCode cell-code" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><span class="im" style="color: #00769E;">from</span> sagemaker.processing <span class="im" style="color: #00769E;">import</span> ProcessingInput, ProcessingOutput</span>
<span id="cb10-2"><span class="im" style="color: #00769E;">from</span> sagemaker.workflow.steps <span class="im" style="color: #00769E;">import</span> ProcessingStep</span>
<span id="cb10-3"></span>
<span id="cb10-4">processing_inputs<span class="op" style="color: #5E5E5E;">=</span>[</span>
<span id="cb10-5">    ProcessingInput(</span>
<span id="cb10-6">        input_name<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'raw-input-data'</span>,</span>
<span id="cb10-7">        source<span class="op" style="color: #5E5E5E;">=</span>input_data,</span>
<span id="cb10-8">        destination<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'/opt/ml/processing/input/data/'</span>,</span>
<span id="cb10-9">        s3_data_distribution_type<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'ShardedByS3Key'</span></span>
<span id="cb10-10">    )</span>
<span id="cb10-11">]</span>
<span id="cb10-12"></span>
<span id="cb10-13">processing_outputs<span class="op" style="color: #5E5E5E;">=</span>[</span>
<span id="cb10-14">    ProcessingOutput(output_name<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'sentiment-train'</span>,</span>
<span id="cb10-15">                     source<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'/opt/ml/processing/output/sentiment/train'</span>,</span>
<span id="cb10-16">                     s3_upload_mode<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'EndOfJob'</span>),</span>
<span id="cb10-17">    ProcessingOutput(output_name<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'sentiment-validation'</span>,</span>
<span id="cb10-18">                     source<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'/opt/ml/processing/output/sentiment/validation'</span>,</span>
<span id="cb10-19">                     s3_upload_mode<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'EndOfJob'</span>),</span>
<span id="cb10-20">    ProcessingOutput(output_name<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'sentiment-test'</span>,</span>
<span id="cb10-21">                     source<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'/opt/ml/processing/output/sentiment/test'</span>,</span>
<span id="cb10-22">                     s3_upload_mode<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'EndOfJob'</span>)</span>
<span id="cb10-23">]        </span>
<span id="cb10-24"></span>
<span id="cb10-25">processing_step <span class="op" style="color: #5E5E5E;">=</span> ProcessingStep(</span>
<span id="cb10-26">    name<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'Processing'</span>, </span>
<span id="cb10-27">    code<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'src/prepare_data.py'</span>,</span>
<span id="cb10-28">    processor<span class="op" style="color: #5E5E5E;">=</span>processor,</span>
<span id="cb10-29">    inputs<span class="op" style="color: #5E5E5E;">=</span>processing_inputs,</span>
<span id="cb10-30">    outputs<span class="op" style="color: #5E5E5E;">=</span>processing_outputs,</span>
<span id="cb10-31">    job_arguments<span class="op" style="color: #5E5E5E;">=</span>[<span class="st" style="color: #20794D;">'--train-split-percentage'</span>, <span class="bu" style="color: null;">str</span>(train_split_percentage.default_value),                   </span>
<span id="cb10-32">                   <span class="st" style="color: #20794D;">'--validation-split-percentage'</span>, <span class="bu" style="color: null;">str</span>(validation_split_percentage.default_value),</span>
<span id="cb10-33">                   <span class="st" style="color: #20794D;">'--test-split-percentage'</span>, <span class="bu" style="color: null;">str</span>(test_split_percentage.default_value),</span>
<span id="cb10-34">                   <span class="st" style="color: #20794D;">'--balance-dataset'</span>, <span class="bu" style="color: null;">str</span>(balance_dataset.default_value),</span>
<span id="cb10-35">                   <span class="st" style="color: #20794D;">'--max-seq-length'</span>, <span class="bu" style="color: null;">str</span>(max_seq_length.default_value),                   </span>
<span id="cb10-36">                   <span class="st" style="color: #20794D;">'--feature-store-offline-prefix'</span>, <span class="bu" style="color: null;">str</span>(feature_store_offline_prefix.default_value),</span>
<span id="cb10-37">                   <span class="st" style="color: #20794D;">'--feature-group-name'</span>, <span class="bu" style="color: null;">str</span>(feature_group_name.default_value)</span>
<span id="cb10-38">                  ]</span>
<span id="cb10-39">)        </span>
<span id="cb10-40"></span>
<span id="cb10-41"><span class="bu" style="color: null;">print</span>(processing_step)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>ProcessingStep(name='Processing', step_type=&lt;StepTypeEnum.PROCESSING: 'Processing'&gt;)</code></pre>
</div>
</div>
<p>Now we can call out the properties of the processing job as an object using the command <code>processing_step.properties</code>. To print out and explore the attributes use <code>__dict__</code> method.</p>
<div class="cell" data-outputid="24eec809-fdf8-45c0-dc04-721ac29153c2">
<div class="sourceCode cell-code" id="cb12" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><span class="co" style="color: #5E5E5E;"># print out the list of the processing job properties</span></span>
<span id="cb12-2"><span class="bu" style="color: null;">print</span>(json.dumps(</span>
<span id="cb12-3">    processing_step.properties.__dict__,</span>
<span id="cb12-4">    indent<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">4</span>, sort_keys<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>, default<span class="op" style="color: #5E5E5E;">=</span><span class="bu" style="color: null;">str</span></span>
<span id="cb12-5">))</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>{
    "AppSpecification": "&lt;sagemaker.workflow.properties.Properties object at 0x7fcdf5298a10&gt;",
    "AutoMLJobArn": "&lt;sagemaker.workflow.properties.Properties object at 0x7fcdf5431d10&gt;",
    "CreationTime": "&lt;sagemaker.workflow.properties.Properties object at 0x7fcdf5431950&gt;",
    "Environment": "&lt;sagemaker.workflow.properties.Properties object at 0x7fcdf5298690&gt;",
    "ExitMessage": "&lt;sagemaker.workflow.properties.Properties object at 0x7fcdf5431d50&gt;",
    "ExperimentConfig": "&lt;sagemaker.workflow.properties.Properties object at 0x7fcdf52a0b10&gt;",
    "FailureReason": "&lt;sagemaker.workflow.properties.Properties object at 0x7fcdf5431750&gt;",
    "LastModifiedTime": "&lt;sagemaker.workflow.properties.Properties object at 0x7fcdf5431a10&gt;",
    "MonitoringScheduleArn": "&lt;sagemaker.workflow.properties.Properties object at 0x7fcdf5431190&gt;",
    "NetworkConfig": "&lt;sagemaker.workflow.properties.Properties object at 0x7fcdf5298b90&gt;",
    "ProcessingEndTime": "&lt;sagemaker.workflow.properties.Properties object at 0x7fcdf5431610&gt;",
    "ProcessingInputs": "&lt;sagemaker.workflow.properties.PropertiesList object at 0x7fcdf5298350&gt;",
    "ProcessingJobArn": "&lt;sagemaker.workflow.properties.Properties object at 0x7fcdf5431410&gt;",
    "ProcessingJobName": "&lt;sagemaker.workflow.properties.Properties object at 0x7fcdf5298590&gt;",
    "ProcessingJobStatus": "&lt;sagemaker.workflow.properties.Properties object at 0x7fcdf5431310&gt;",
    "ProcessingOutputConfig": "&lt;sagemaker.workflow.properties.Properties object at 0x7fcdf5298510&gt;",
    "ProcessingResources": "&lt;sagemaker.workflow.properties.Properties object at 0x7fcdf52984d0&gt;",
    "ProcessingStartTime": "&lt;sagemaker.workflow.properties.Properties object at 0x7fcdf5431ed0&gt;",
    "RoleArn": "&lt;sagemaker.workflow.properties.Properties object at 0x7fcdf5298650&gt;",
    "StoppingCondition": "&lt;sagemaker.workflow.properties.Properties object at 0x7fcdf5298a50&gt;",
    "TrainingJobArn": "&lt;sagemaker.workflow.properties.Properties object at 0x7fcdf5431bd0&gt;",
    "_path": "Steps.Processing",
    "_shape_name": "DescribeProcessingJobResponse"
}</code></pre>
</div>
</div>
<p>Pull the channel <code>sentiment-train</code> from the output configuration of the processing job. Print out the attributes of the resulting object:</p>
<div class="cell" data-outputid="1a5369ca-8996-42cc-a2d7-6db70c5aede9">
<div class="sourceCode cell-code" id="cb14" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><span class="bu" style="color: null;">print</span>(json.dumps(</span>
<span id="cb14-2">    processing_step.properties.ProcessingOutputConfig.Outputs[<span class="st" style="color: #20794D;">'sentiment-train'</span>].__dict__, </span>
<span id="cb14-3">    indent<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">4</span>, sort_keys<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>, default<span class="op" style="color: #5E5E5E;">=</span><span class="bu" style="color: null;">str</span></span>
<span id="cb14-4">))</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>{
    "AppManaged": "&lt;sagemaker.workflow.properties.Properties object at 0x7fcdf543c490&gt;",
    "FeatureStoreOutput": "&lt;sagemaker.workflow.properties.Properties object at 0x7fcdf54d4510&gt;",
    "OutputName": "&lt;sagemaker.workflow.properties.Properties object at 0x7fcdf5384650&gt;",
    "S3Output": "&lt;sagemaker.workflow.properties.Properties object at 0x7fcdf53845d0&gt;",
    "_path": "Steps.Processing.ProcessingOutputConfig.Outputs['sentiment-train']",
    "_shape_name": "ProcessingOutput"
}</code></pre>
</div>
</div>
<p>Now we can pull and print out attributes of the S3 output path related to the <code>sentiment-train</code> output channel:</p>
<div class="cell" data-outputid="dfa191f0-ccff-4e84-c304-4a64f757b7f7">
<div class="sourceCode cell-code" id="cb16" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><span class="bu" style="color: null;">print</span>(json.dumps(</span>
<span id="cb16-2">    processing_step.properties.ProcessingOutputConfig.Outputs[<span class="st" style="color: #20794D;">'sentiment-train'</span>].S3Output.S3Uri.__dict__,</span>
<span id="cb16-3">    indent<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">4</span>, sort_keys<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>, default<span class="op" style="color: #5E5E5E;">=</span><span class="bu" style="color: null;">str</span></span>
<span id="cb16-4">))</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>{
    "__str__": "S3Uri",
    "_path": "Steps.Processing.ProcessingOutputConfig.Outputs['sentiment-train'].S3Output.S3Uri",
    "_shape_name": "S3Uri"
}</code></pre>
</div>
</div>
<p>Let’s pull and print out attributes of the S3 output path object related to the <code>sentiment-test</code> output channel.</p>
<div class="cell" data-outputid="da8c78c7-73fc-49b9-ae1b-de5351dd2c23">
<div class="sourceCode cell-code" id="cb18" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><span class="bu" style="color: null;">print</span>(json.dumps(</span>
<span id="cb18-2">    processing_step.properties.ProcessingOutputConfig.Outputs[<span class="st" style="color: #20794D;">'sentiment-test'</span>].S3Output.S3Uri.__dict__, </span>
<span id="cb18-3">    indent<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">4</span>, sort_keys<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>, default<span class="op" style="color: #5E5E5E;">=</span><span class="bu" style="color: null;">str</span></span>
<span id="cb18-4">))</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>{
    "__str__": "S3Uri",
    "_path": "Steps.Processing.ProcessingOutputConfig.Outputs['sentiment-test'].S3Output.S3Uri",
    "_shape_name": "S3Uri"
}</code></pre>
</div>
</div>
<p>These objects can be passed into the next steps of the workflow. Also, we can pull the arguments of the processing step with the corresponding function. The result is in the dictionary format.</p>
<div class="cell" data-outputid="1cad757e-7257-4de9-9839-87e1064dbb23">
<div class="sourceCode cell-code" id="cb20" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1">processing_step.arguments.keys()</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="15">
<pre><code>dict_keys(['ProcessingResources', 'AppSpecification', 'RoleArn', 'ProcessingInputs', 'ProcessingOutputConfig', 'Environment'])</code></pre>
</div>
</div>
<p>Let’s pull and review processing inputs from the arguments of the processing step:</p>
<div class="cell" data-outputid="d923a819-de37-4576-ce4a-f121a31e5b25">
<div class="sourceCode cell-code" id="cb22" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1">processing_step.arguments[<span class="st" style="color: #20794D;">'ProcessingInputs'</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="16">
<pre><code>[{'InputName': 'raw-input-data',
  'AppManaged': False,
  'S3Input': {'S3Uri': ParameterString(name='InputData', parameter_type=&lt;ParameterTypeEnum.STRING: 'String'&gt;, default_value='s3://dlai-practical-data-science/data/raw/'),
   'LocalPath': '/opt/ml/processing/input/data/',
   'S3DataType': 'S3Prefix',
   'S3InputMode': 'File',
   'S3DataDistributionType': 'ShardedByS3Key',
   'S3CompressionType': 'None'}},
 {'InputName': 'code',
  'AppManaged': False,
  'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-912822595625/sagemaker-scikit-learn-2023-02-12-13-32-22-918/input/code/prepare_data.py',
   'LocalPath': '/opt/ml/processing/input/code',
   'S3DataType': 'S3Prefix',
   'S3InputMode': 'File',
   'S3DataDistributionType': 'FullyReplicated',
   'S3CompressionType': 'None'}}]</code></pre>
</div>
</div>
<p>Let’s now pull and review configuration of the processing outputs from the arguments of the processing step.</p>
<div class="cell" data-outputid="b1a5bc56-0416-441d-a771-8e40ca39c1ec">
<div class="sourceCode cell-code" id="cb24" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1">processing_step.arguments[<span class="st" style="color: #20794D;">'ProcessingOutputConfig'</span>] </span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="18">
<pre><code>{'Outputs': [{'OutputName': 'sentiment-train',
   'AppManaged': False,
   'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-912822595625/sagemaker-scikit-learn-2023-02-12-13-32-20-378/output/sentiment-train',
    'LocalPath': '/opt/ml/processing/output/sentiment/train',
    'S3UploadMode': 'EndOfJob'}},
  {'OutputName': 'sentiment-validation',
   'AppManaged': False,
   'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-912822595625/sagemaker-scikit-learn-2023-02-12-13-32-20-378/output/sentiment-validation',
    'LocalPath': '/opt/ml/processing/output/sentiment/validation',
    'S3UploadMode': 'EndOfJob'}},
  {'OutputName': 'sentiment-test',
   'AppManaged': False,
   'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-912822595625/sagemaker-scikit-learn-2023-02-12-13-32-20-378/output/sentiment-test',
    'LocalPath': '/opt/ml/processing/output/sentiment/test',
    'S3UploadMode': 'EndOfJob'}}]}</code></pre>
</div>
</div>
</section>
</section>
<section id="configure-training-step" class="level2" data-number="6">
<h2 data-number="6" class="anchored" data-anchor-id="configure-training-step"><span class="header-section-number">6</span> Configure training step</h2>
<section id="define-parameters" class="level3" data-number="6.1">
<h3 data-number="6.1" class="anchored" data-anchor-id="define-parameters"><span class="header-section-number">6.1</span> Define parameters</h3>
<p>Setup the parameters for the workflow.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb26" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1">freeze_bert_layer <span class="op" style="color: #5E5E5E;">=</span> ParameterString(</span>
<span id="cb26-2">    name<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"FreezeBertLayer"</span>,</span>
<span id="cb26-3">    default_value<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"False"</span>,</span>
<span id="cb26-4">)</span>
<span id="cb26-5"></span>
<span id="cb26-6">epochs <span class="op" style="color: #5E5E5E;">=</span> ParameterInteger(</span>
<span id="cb26-7">    name<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"Epochs"</span>,</span>
<span id="cb26-8">    default_value<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">3</span></span>
<span id="cb26-9">)</span>
<span id="cb26-10">    </span>
<span id="cb26-11">learning_rate <span class="op" style="color: #5E5E5E;">=</span> ParameterFloat(</span>
<span id="cb26-12">    name<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"LearningRate"</span>,</span>
<span id="cb26-13">    default_value<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">0.00001</span></span>
<span id="cb26-14">) </span>
<span id="cb26-15">    </span>
<span id="cb26-16">train_batch_size <span class="op" style="color: #5E5E5E;">=</span> ParameterInteger(</span>
<span id="cb26-17">    name<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"TrainBatchSize"</span>,</span>
<span id="cb26-18">    default_value<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">64</span></span>
<span id="cb26-19">)</span>
<span id="cb26-20"></span>
<span id="cb26-21">train_steps_per_epoch <span class="op" style="color: #5E5E5E;">=</span> ParameterInteger(</span>
<span id="cb26-22">    name<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"TrainStepsPerEpoch"</span>,</span>
<span id="cb26-23">    default_value<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">50</span></span>
<span id="cb26-24">)</span>
<span id="cb26-25"></span>
<span id="cb26-26">validation_batch_size <span class="op" style="color: #5E5E5E;">=</span> ParameterInteger(</span>
<span id="cb26-27">    name<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"ValidationBatchSize"</span>,</span>
<span id="cb26-28">    default_value<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">64</span></span>
<span id="cb26-29">)</span>
<span id="cb26-30"></span>
<span id="cb26-31">validation_steps_per_epoch <span class="op" style="color: #5E5E5E;">=</span> ParameterInteger(</span>
<span id="cb26-32">    name<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"ValidationStepsPerEpoch"</span>,</span>
<span id="cb26-33">    default_value<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">50</span></span>
<span id="cb26-34">)</span>
<span id="cb26-35"></span>
<span id="cb26-36">seed <span class="op" style="color: #5E5E5E;">=</span> ParameterInteger(</span>
<span id="cb26-37">    name<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"Seed"</span>,</span>
<span id="cb26-38">    default_value<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">42</span></span>
<span id="cb26-39">)</span>
<span id="cb26-40"></span>
<span id="cb26-41">run_validation <span class="op" style="color: #5E5E5E;">=</span> ParameterString(</span>
<span id="cb26-42">    name<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"RunValidation"</span>,</span>
<span id="cb26-43">    default_value<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"True"</span>,</span>
<span id="cb26-44">)</span>
<span id="cb26-45"></span>
<span id="cb26-46">train_instance_count <span class="op" style="color: #5E5E5E;">=</span> ParameterInteger(</span>
<span id="cb26-47">    name<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"TrainInstanceCount"</span>,</span>
<span id="cb26-48">    default_value<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">1</span></span>
<span id="cb26-49">)</span>
<span id="cb26-50"></span>
<span id="cb26-51">train_instance_type <span class="op" style="color: #5E5E5E;">=</span> ParameterString(</span>
<span id="cb26-52">    name<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"TrainInstanceType"</span>,</span>
<span id="cb26-53">    default_value<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"ml.c5.9xlarge"</span></span>
<span id="cb26-54">)</span>
<span id="cb26-55"></span>
<span id="cb26-56">train_volume_size <span class="op" style="color: #5E5E5E;">=</span> ParameterInteger(</span>
<span id="cb26-57">    name<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"TrainVolumeSize"</span>,</span>
<span id="cb26-58">    default_value<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">256</span></span>
<span id="cb26-59">) </span>
<span id="cb26-60"></span>
<span id="cb26-61">input_mode <span class="op" style="color: #5E5E5E;">=</span> ParameterString(</span>
<span id="cb26-62">    name<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"InputMode"</span>,</span>
<span id="cb26-63">    default_value<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"File"</span>,</span>
<span id="cb26-64">)</span></code></pre></div>
</div>
</section>
<section id="configure-hyper-parameters" class="level3" data-number="6.2">
<h3 data-number="6.2" class="anchored" data-anchor-id="configure-hyper-parameters"><span class="header-section-number">6.2</span> Configure hyper-parameters</h3>
<p>Setup the dictionary that will be passed into the hyperparameters argument.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb27" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1">hyperparameters<span class="op" style="color: #5E5E5E;">=</span>{</span>
<span id="cb27-2">    <span class="st" style="color: #20794D;">'max_seq_length'</span>: max_seq_length,</span>
<span id="cb27-3">    <span class="st" style="color: #20794D;">'freeze_bert_layer'</span>: freeze_bert_layer,</span>
<span id="cb27-4">    <span class="st" style="color: #20794D;">'epochs'</span>: epochs,</span>
<span id="cb27-5">    <span class="st" style="color: #20794D;">'learning_rate'</span>: learning_rate,</span>
<span id="cb27-6">    <span class="st" style="color: #20794D;">'train_batch_size'</span>: train_batch_size,</span>
<span id="cb27-7">    <span class="st" style="color: #20794D;">'train_steps_per_epoch'</span>: train_steps_per_epoch,</span>
<span id="cb27-8">    <span class="st" style="color: #20794D;">'validation_batch_size'</span>: validation_batch_size,</span>
<span id="cb27-9">    <span class="st" style="color: #20794D;">'validation_steps_per_epoch'</span>: validation_steps_per_epoch,</span>
<span id="cb27-10">    <span class="st" style="color: #20794D;">'seed'</span>: seed,</span>
<span id="cb27-11">    <span class="st" style="color: #20794D;">'run_validation'</span>: run_validation</span>
<span id="cb27-12">}</span></code></pre></div>
</div>
</section>
<section id="configure-model-evaluation-metrics" class="level3" data-number="6.3">
<h3 data-number="6.3" class="anchored" data-anchor-id="configure-model-evaluation-metrics"><span class="header-section-number">6.3</span> Configure model-evaluation metrics</h3>
<p>Choose loss and accuracy as the evaluation metrics.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb28" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1">metric_definitions <span class="op" style="color: #5E5E5E;">=</span> [</span>
<span id="cb28-2">     {<span class="st" style="color: #20794D;">'Name'</span>: <span class="st" style="color: #20794D;">'validation:loss'</span>, <span class="st" style="color: #20794D;">'Regex'</span>: <span class="st" style="color: #20794D;">'val_loss: ([0-9.]+)'</span>},</span>
<span id="cb28-3">     {<span class="st" style="color: #20794D;">'Name'</span>: <span class="st" style="color: #20794D;">'validation:accuracy'</span>, <span class="st" style="color: #20794D;">'Regex'</span>: <span class="st" style="color: #20794D;">'val_acc: ([0-9.]+)'</span>},</span>
<span id="cb28-4">]</span></code></pre></div>
</div>
</section>
<section id="configure-the-pytorchestimator" class="level3" data-number="6.4">
<h3 data-number="6.4" class="anchored" data-anchor-id="configure-the-pytorchestimator"><span class="header-section-number">6.4</span> Configure the <code>PyTorchEstimator</code></h3>
<p>Let’s configure an estimator and the input dataset. A typical training script loads data from the input channels, configures training with hyperparameters, trains a model, and saves a model to <code>model_dir</code> so that it can be hosted later.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb29" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><span class="im" style="color: #00769E;">from</span> sagemaker.pytorch <span class="im" style="color: #00769E;">import</span> PyTorch <span class="im" style="color: #00769E;">as</span> PyTorchEstimator</span>
<span id="cb29-2"></span>
<span id="cb29-3">estimator <span class="op" style="color: #5E5E5E;">=</span> PyTorchEstimator(</span>
<span id="cb29-4">    entry_point<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'train.py'</span>,</span>
<span id="cb29-5">    source_dir<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'src'</span>,</span>
<span id="cb29-6">    role<span class="op" style="color: #5E5E5E;">=</span>role,</span>
<span id="cb29-7">    instance_count<span class="op" style="color: #5E5E5E;">=</span>train_instance_count,</span>
<span id="cb29-8">    instance_type<span class="op" style="color: #5E5E5E;">=</span>train_instance_type,</span>
<span id="cb29-9">    volume_size<span class="op" style="color: #5E5E5E;">=</span>train_volume_size,</span>
<span id="cb29-10">    py_version<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'py3'</span>,</span>
<span id="cb29-11">    framework_version<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'1.6.0'</span>,</span>
<span id="cb29-12">    hyperparameters<span class="op" style="color: #5E5E5E;">=</span>hyperparameters,</span>
<span id="cb29-13">    metric_definitions<span class="op" style="color: #5E5E5E;">=</span>metric_definitions,</span>
<span id="cb29-14">    input_mode<span class="op" style="color: #5E5E5E;">=</span>input_mode</span>
<span id="cb29-15">)</span></code></pre></div>
</div>
</section>
<section id="setup-pipeline-step-caching" class="level3" data-number="6.5">
<h3 data-number="6.5" class="anchored" data-anchor-id="setup-pipeline-step-caching"><span class="header-section-number">6.5</span> Setup pipeline step caching</h3>
<p>Step signature caching allows SageMaker Pipelines, before executing a step, to find a previous execution of a step that was called using the same arguments. Cache hit gets created if the previous execution is found. Then during execution instead of recomputing the step, pipelines propagates the values from the cache hit.</p>
<p>Timeout period is defined using <a href="https://en.wikipedia.org/wiki/ISO_8601#Durations">ISO 8601</a> format, it can contain a year, month, week, day, hour, and minute value.</p>
<p>More details on SageMaker Pipeline step caching can be found <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/pipelines-caching.html">here</a>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb30" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><span class="im" style="color: #00769E;">from</span> sagemaker.workflow.steps <span class="im" style="color: #00769E;">import</span> CacheConfig</span>
<span id="cb30-2"></span>
<span id="cb30-3">cache_config <span class="op" style="color: #5E5E5E;">=</span> CacheConfig(enable_caching<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>, expire_after<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"PT1H"</span>) <span class="co" style="color: #5E5E5E;"># PT1H represents `one hour`</span></span></code></pre></div>
</div>
</section>
<section id="configure-the-trainingstep" class="level3" data-number="6.6">
<h3 data-number="6.6" class="anchored" data-anchor-id="configure-the-trainingstep"><span class="header-section-number">6.6</span> Configure the <code>TrainingStep</code></h3>
<p>Now we configure the <code>TrainingStep</code> calling the outputs of the processing step:</p>
<div class="cell" data-outputid="1cb4774c-ee9a-4e9d-c088-b062621abaa9">
<div class="sourceCode cell-code" id="cb31" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><span class="im" style="color: #00769E;">from</span> sagemaker.inputs <span class="im" style="color: #00769E;">import</span> TrainingInput</span>
<span id="cb31-2"><span class="im" style="color: #00769E;">from</span> sagemaker.workflow.steps <span class="im" style="color: #00769E;">import</span> TrainingStep</span>
<span id="cb31-3"></span>
<span id="cb31-4">training_step <span class="op" style="color: #5E5E5E;">=</span> TrainingStep(</span>
<span id="cb31-5">    name<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'Train'</span>,</span>
<span id="cb31-6">    estimator<span class="op" style="color: #5E5E5E;">=</span>estimator,</span>
<span id="cb31-7">    inputs<span class="op" style="color: #5E5E5E;">=</span>{</span>
<span id="cb31-8">        <span class="st" style="color: #20794D;">'train'</span>: TrainingInput(</span>
<span id="cb31-9">            s3_data<span class="op" style="color: #5E5E5E;">=</span>processing_step.properties.ProcessingOutputConfig.Outputs[</span>
<span id="cb31-10">                <span class="st" style="color: #20794D;">'sentiment-train'</span></span>
<span id="cb31-11">            ].S3Output.S3Uri,</span>
<span id="cb31-12">            content_type<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'text/csv'</span></span>
<span id="cb31-13">        ),</span>
<span id="cb31-14">        <span class="st" style="color: #20794D;">'validation'</span>: TrainingInput(</span>
<span id="cb31-15">            s3_data<span class="op" style="color: #5E5E5E;">=</span>processing_step.properties.ProcessingOutputConfig.Outputs[</span>
<span id="cb31-16">                <span class="st" style="color: #20794D;">'sentiment-validation'</span></span>
<span id="cb31-17">            ].S3Output.S3Uri,</span>
<span id="cb31-18">            content_type<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'text/csv'</span></span>
<span id="cb31-19">        )</span>
<span id="cb31-20">    },</span>
<span id="cb31-21">    cache_config<span class="op" style="color: #5E5E5E;">=</span>cache_config</span>
<span id="cb31-22">)</span>
<span id="cb31-23"></span>
<span id="cb31-24"><span class="bu" style="color: null;">print</span>(training_step)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>TrainingStep(name='Train', step_type=&lt;StepTypeEnum.TRAINING: 'Training'&gt;)</code></pre>
</div>
</div>
<p>We will use the <code>__dict__</code> method to print out attributes of the training step properties. Briefly review the result. The attributes match the object model of the <a href="https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_DescribeTrainingJob.html">DescribeTrainingJob</a> response object.</p>
<div class="cell" data-outputid="593d96f5-84ad-46e2-c89e-c2d19fe5f68a">
<div class="sourceCode cell-code" id="cb33" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1">training_step.properties.__dict__ </span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="71">
<pre><code>{'_path': 'Steps.Train',
 '_shape_name': 'DescribeTrainingJobResponse',
 'TrainingJobName': &lt;sagemaker.workflow.properties.Properties at 0x7fcdf5101310&gt;,
 'TrainingJobArn': &lt;sagemaker.workflow.properties.Properties at 0x7fcdf5101350&gt;,
 'TuningJobArn': &lt;sagemaker.workflow.properties.Properties at 0x7fcdf5101390&gt;,
 'LabelingJobArn': &lt;sagemaker.workflow.properties.Properties at 0x7fcdf51013d0&gt;,
 'AutoMLJobArn': &lt;sagemaker.workflow.properties.Properties at 0x7fcdf5101210&gt;,
 'ModelArtifacts': &lt;sagemaker.workflow.properties.Properties at 0x7fcdf5101250&gt;,
 'TrainingJobStatus': &lt;sagemaker.workflow.properties.Properties at 0x7fcdf51012d0&gt;,
 'SecondaryStatus': &lt;sagemaker.workflow.properties.Properties at 0x7fcdf5101110&gt;,
 'FailureReason': &lt;sagemaker.workflow.properties.Properties at 0x7fcdf5101150&gt;,
 'HyperParameters': &lt;sagemaker.workflow.properties.Properties at 0x7fcdf5101190&gt;,
 'AlgorithmSpecification': &lt;sagemaker.workflow.properties.Properties at 0x7fcdf51011d0&gt;,
 'RoleArn': &lt;sagemaker.workflow.properties.Properties at 0x7fcdf5101850&gt;,
 'InputDataConfig': &lt;sagemaker.workflow.properties.PropertiesList at 0x7fcdf5101750&gt;,
 'OutputDataConfig': &lt;sagemaker.workflow.properties.Properties at 0x7fcdf5101490&gt;,
 'ResourceConfig': &lt;sagemaker.workflow.properties.Properties at 0x7fcdf51015d0&gt;,
 'VpcConfig': &lt;sagemaker.workflow.properties.Properties at 0x7fcdf5424e10&gt;,
 'StoppingCondition': &lt;sagemaker.workflow.properties.Properties at 0x7fcdf5424350&gt;,
 'CreationTime': &lt;sagemaker.workflow.properties.Properties at 0x7fcdf5424910&gt;,
 'TrainingStartTime': &lt;sagemaker.workflow.properties.Properties at 0x7fcdf5424750&gt;,
 'TrainingEndTime': &lt;sagemaker.workflow.properties.Properties at 0x7fcdf5424950&gt;,
 'LastModifiedTime': &lt;sagemaker.workflow.properties.Properties at 0x7fcdf5424550&gt;,
 'SecondaryStatusTransitions': &lt;sagemaker.workflow.properties.PropertiesList at 0x7fcdf5424a10&gt;,
 'FinalMetricDataList': &lt;sagemaker.workflow.properties.PropertiesList at 0x7fcdf5424590&gt;,
 'EnableNetworkIsolation': &lt;sagemaker.workflow.properties.Properties at 0x7fcdf5424e50&gt;,
 'EnableInterContainerTrafficEncryption': &lt;sagemaker.workflow.properties.Properties at 0x7fcdf5424690&gt;,
 'EnableManagedSpotTraining': &lt;sagemaker.workflow.properties.Properties at 0x7fcdf5424150&gt;,
 'CheckpointConfig': &lt;sagemaker.workflow.properties.Properties at 0x7fcdf5424fd0&gt;,
 'TrainingTimeInSeconds': &lt;sagemaker.workflow.properties.Properties at 0x7fcdf5424490&gt;,
 'BillableTimeInSeconds': &lt;sagemaker.workflow.properties.Properties at 0x7fcdf5424ad0&gt;,
 'DebugHookConfig': &lt;sagemaker.workflow.properties.Properties at 0x7fcdf54246d0&gt;,
 'ExperimentConfig': &lt;sagemaker.workflow.properties.Properties at 0x7fcdf53a7d50&gt;,
 'DebugRuleConfigurations': &lt;sagemaker.workflow.properties.PropertiesList at 0x7fcdf53a7890&gt;,
 'TensorBoardOutputConfig': &lt;sagemaker.workflow.properties.Properties at 0x7fcdf53a7e50&gt;,
 'DebugRuleEvaluationStatuses': &lt;sagemaker.workflow.properties.PropertiesList at 0x7fcdf53a7dd0&gt;,
 'ProfilerConfig': &lt;sagemaker.workflow.properties.Properties at 0x7fcdf53a7d90&gt;,
 'ProfilerRuleConfigurations': &lt;sagemaker.workflow.properties.PropertiesList at 0x7fcdf53a79d0&gt;,
 'ProfilerRuleEvaluationStatuses': &lt;sagemaker.workflow.properties.PropertiesList at 0x7fcdf53a7410&gt;,
 'ProfilingStatus': &lt;sagemaker.workflow.properties.Properties at 0x7fcdf53a7ad0&gt;,
 'RetryStrategy': &lt;sagemaker.workflow.properties.Properties at 0x7fcdf53a7a10&gt;,
 'Environment': &lt;sagemaker.workflow.properties.Properties at 0x7fcdf53a7950&gt;,
 'WarmPoolStatus': &lt;sagemaker.workflow.properties.Properties at 0x7fcdf53a7f10&gt;}</code></pre>
</div>
</div>
</section>
</section>
<section id="configure-model-evaluation-step" class="level2" data-number="7">
<h2 data-number="7" class="anchored" data-anchor-id="configure-model-evaluation-step"><span class="header-section-number">7</span> Configure model-evaluation step</h2>
<p>First, we will develop an evaluation script that will be specified in the model evaluation processing step. The evaluation script users the trained model and the test dataset to produce a JSON file with classification evaluation metrics such as accuracy.</p>
<p>The evaluation script performs the following steps: * loads in the model * reads in the test data * issues a bunch of predictions against the test data * builds a classification report, including accuracy * saves the evaluation report to the evaluation directory</p>
<p>Create an instance of the <code>SKLearnProcessor</code> to run our evaluation script as a scikit-learn-based SageMaker processing job.</p>
<div class="cell" data-scrolled="true">
<div class="sourceCode cell-code" id="cb35" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><span class="im" style="color: #00769E;">from</span> sagemaker.sklearn.processing <span class="im" style="color: #00769E;">import</span> SKLearnProcessor</span>
<span id="cb35-2"></span>
<span id="cb35-3">evaluation_processor <span class="op" style="color: #5E5E5E;">=</span> SKLearnProcessor(</span>
<span id="cb35-4">    framework_version<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'0.23-1'</span>,</span>
<span id="cb35-5">    role<span class="op" style="color: #5E5E5E;">=</span>role,</span>
<span id="cb35-6">    instance_type<span class="op" style="color: #5E5E5E;">=</span>processing_instance_type,</span>
<span id="cb35-7">    instance_count<span class="op" style="color: #5E5E5E;">=</span>processing_instance_count,</span>
<span id="cb35-8">    env<span class="op" style="color: #5E5E5E;">=</span>{<span class="st" style="color: #20794D;">'AWS_DEFAULT_REGION'</span>: region},</span>
<span id="cb35-9">    max_runtime_in_seconds<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">7200</span></span>
<span id="cb35-10">)</span></code></pre></div>
</div>
<p>Setup the output <code>PropertyFile</code>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb36" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb36-1"><span class="im" style="color: #00769E;">from</span> sagemaker.workflow.properties <span class="im" style="color: #00769E;">import</span> PropertyFile</span>
<span id="cb36-2"></span>
<span id="cb36-3">evaluation_report <span class="op" style="color: #5E5E5E;">=</span> PropertyFile(</span>
<span id="cb36-4">    name<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'EvaluationReport'</span>,</span>
<span id="cb36-5">    output_name<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'metrics'</span>,</span>
<span id="cb36-6">    path<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'evaluation.json'</span></span>
<span id="cb36-7">)</span></code></pre></div>
</div>
<p>Now we use the processor instance to construct a <code>ProcessingStep</code>, along with the input and output channels and the code that will be executed when the pipeline invokes pipeline execution. This is very similar to a processor instance’s <code>run</code> method.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb37" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb37-1"><span class="im" style="color: #00769E;">from</span> sagemaker.processing <span class="im" style="color: #00769E;">import</span> ProcessingInput, ProcessingOutput</span>
<span id="cb37-2"></span>
<span id="cb37-3">evaluation_step <span class="op" style="color: #5E5E5E;">=</span> ProcessingStep(</span>
<span id="cb37-4">    name<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'EvaluateModel'</span>,</span>
<span id="cb37-5">    processor<span class="op" style="color: #5E5E5E;">=</span>evaluation_processor,</span>
<span id="cb37-6">    code<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'src/evaluate_model_metrics.py'</span>,</span>
<span id="cb37-7">    inputs<span class="op" style="color: #5E5E5E;">=</span>[</span>
<span id="cb37-8">        ProcessingInput(</span>
<span id="cb37-9">            source<span class="op" style="color: #5E5E5E;">=</span>training_step.properties.ModelArtifacts.S3ModelArtifacts,</span>
<span id="cb37-10">            destination<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'/opt/ml/processing/input/model'</span></span>
<span id="cb37-11">        ),</span>
<span id="cb37-12">        ProcessingInput(</span>
<span id="cb37-13">            source<span class="op" style="color: #5E5E5E;">=</span>processing_step.properties.ProcessingOutputConfig.Outputs[<span class="st" style="color: #20794D;">'sentiment-test'</span>].S3Output.S3Uri,</span>
<span id="cb37-14">            destination<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'/opt/ml/processing/input/data'</span></span>
<span id="cb37-15">        )</span>
<span id="cb37-16">    ],</span>
<span id="cb37-17">    outputs<span class="op" style="color: #5E5E5E;">=</span>[</span>
<span id="cb37-18">        ProcessingOutput(output_name<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'metrics'</span>, </span>
<span id="cb37-19">                         s3_upload_mode<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'EndOfJob'</span>,</span>
<span id="cb37-20">                         source<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'/opt/ml/processing/output/metrics/'</span>),</span>
<span id="cb37-21">    ],</span>
<span id="cb37-22">    job_arguments<span class="op" style="color: #5E5E5E;">=</span>[</span>
<span id="cb37-23">        <span class="st" style="color: #20794D;">'--max-seq-length'</span>, <span class="bu" style="color: null;">str</span>(max_seq_length.default_value),</span>
<span id="cb37-24">    ],</span>
<span id="cb37-25">    property_files<span class="op" style="color: #5E5E5E;">=</span>[evaluation_report],</span>
<span id="cb37-26">)</span></code></pre></div>
</div>
</section>
<section id="configure-and-register-model-step" class="level2" data-number="8">
<h2 data-number="8" class="anchored" data-anchor-id="configure-and-register-model-step"><span class="header-section-number">8</span> Configure and register model step</h2>
<section id="configure-the-model-for-deployment" class="level3" data-number="8.1">
<h3 data-number="8.1" class="anchored" data-anchor-id="configure-the-model-for-deployment"><span class="header-section-number">8.1</span> Configure the model for deployment</h3>
<p>We will now use the estimator instance that was used for the training step to construct an instance of <code>RegisterModel</code>. The result of executing <code>RegisterModel</code> in a pipeline is a model package. A model package is a reusable model artifacts abstraction that packages all ingredients necessary for inference. Primarily, it consists of an inference specification that defines the inference image to use along with an optional model weights location.</p>
<p>A model package group is a collection of model packages. You can create a model package group for a specific ML business problem, and you can keep adding versions/model packages into it. Typically, customers are expected to create a ModelPackageGroup for a SageMaker workflow pipeline so that they can keep adding versions/model packages to the group for every workflow pipeline run.</p>
<p>The construction of <code>RegisterModel</code> is very similar to an estimator instance’s <code>register</code> method, for those familiar with the existing Python SDK.</p>
<p>In particular, we will pass in the <code>S3ModelArtifacts</code> from the <code>training_step</code> properties.</p>
<p>Of note, here we will be provided a specific model package group name which will be used in the Model Registry and Continuous Integration/Continuous Deployment (CI/CD) work later on. Let’s setup the variables.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb38" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb38-1">model_approval_status <span class="op" style="color: #5E5E5E;">=</span> ParameterString(</span>
<span id="cb38-2">    name<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"ModelApprovalStatus"</span>,</span>
<span id="cb38-3">    default_value<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"PendingManualApproval"</span></span>
<span id="cb38-4">)</span>
<span id="cb38-5"></span>
<span id="cb38-6">deploy_instance_type <span class="op" style="color: #5E5E5E;">=</span> ParameterString(</span>
<span id="cb38-7">    name<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"DeployInstanceType"</span>,</span>
<span id="cb38-8">    default_value<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"ml.m5.large"</span></span>
<span id="cb38-9">)</span>
<span id="cb38-10"></span>
<span id="cb38-11">deploy_instance_count <span class="op" style="color: #5E5E5E;">=</span> ParameterInteger(</span>
<span id="cb38-12">    name<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"DeployInstanceCount"</span>,</span>
<span id="cb38-13">    default_value<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">1</span></span>
<span id="cb38-14">)</span></code></pre></div>
</div>
<div class="cell" data-outputid="801217b4-4c41-46bd-c1e7-e3eecf95cb47">
<div class="sourceCode cell-code" id="cb39" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1">model_package_group_name <span class="op" style="color: #5E5E5E;">=</span> <span class="ss" style="color: #20794D;">f"BERT-Reviews-</span><span class="sc" style="color: #5E5E5E;">{</span>timestamp<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">"</span></span>
<span id="cb39-2"></span>
<span id="cb39-3"><span class="bu" style="color: null;">print</span>(model_package_group_name)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>BERT-Reviews-1676208665</code></pre>
</div>
</div>
<p>Configure the <code>ModelMetrics</code> to be stored as metadata.</p>
<div class="cell" data-outputid="686e843f-9bf2-49ea-c0cb-e530838f774a">
<div class="sourceCode cell-code" id="cb41" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1"><span class="im" style="color: #00769E;">from</span> sagemaker.model_metrics <span class="im" style="color: #00769E;">import</span> MetricsSource, ModelMetrics </span>
<span id="cb41-2"></span>
<span id="cb41-3">model_metrics <span class="op" style="color: #5E5E5E;">=</span> ModelMetrics(</span>
<span id="cb41-4">    model_statistics<span class="op" style="color: #5E5E5E;">=</span>MetricsSource(</span>
<span id="cb41-5">        s3_uri<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"</span><span class="sc" style="color: #5E5E5E;">{}</span><span class="st" style="color: #20794D;">/evaluation.json"</span>.<span class="bu" style="color: null;">format</span>(</span>
<span id="cb41-6">            evaluation_step.arguments[<span class="st" style="color: #20794D;">"ProcessingOutputConfig"</span>][<span class="st" style="color: #20794D;">"Outputs"</span>][<span class="dv" style="color: #AD0000;">0</span>][<span class="st" style="color: #20794D;">"S3Output"</span>][<span class="st" style="color: #20794D;">"S3Uri"</span>]</span>
<span id="cb41-7">        ),</span>
<span id="cb41-8">        content_type<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"application/json"</span></span>
<span id="cb41-9">    )</span>
<span id="cb41-10">)</span>
<span id="cb41-11"></span>
<span id="cb41-12"><span class="bu" style="color: null;">print</span>(model_metrics)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>&lt;sagemaker.model_metrics.ModelMetrics object at 0x7fcdf40cd5d0&gt;</code></pre>
</div>
</div>
<p>Define deployment image for inference.</p>
<div class="cell" data-outputid="c9e17fee-616b-4f13-8431-c3eab06105c8">
<div class="sourceCode cell-code" id="cb43" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb43-1">inference_image_uri <span class="op" style="color: #5E5E5E;">=</span> sagemaker.image_uris.retrieve(</span>
<span id="cb43-2">    framework<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"pytorch"</span>,</span>
<span id="cb43-3">    region<span class="op" style="color: #5E5E5E;">=</span>region,</span>
<span id="cb43-4">    version<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"1.6.0"</span>,</span>
<span id="cb43-5">    py_version<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"py36"</span>,</span>
<span id="cb43-6">    instance_type<span class="op" style="color: #5E5E5E;">=</span>deploy_instance_type,</span>
<span id="cb43-7">    image_scope<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"inference"</span></span>
<span id="cb43-8">)</span>
<span id="cb43-9"><span class="bu" style="color: null;">print</span>(inference_image_uri)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>763104351884.dkr.ecr.us-east-1.amazonaws.com/pytorch-inference:1.6.0-cpu-py36</code></pre>
</div>
</div>
</section>
<section id="register-the-model-for-deployment" class="level3" data-number="8.2">
<h3 data-number="8.2" class="anchored" data-anchor-id="register-the-model-for-deployment"><span class="header-section-number">8.2</span> Register the model for deployment</h3>
<p>Let’s now configure the register model step.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb45" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb45-1"><span class="im" style="color: #00769E;">from</span> sagemaker.workflow.step_collections <span class="im" style="color: #00769E;">import</span> RegisterModel</span>
<span id="cb45-2"></span>
<span id="cb45-3">register_step <span class="op" style="color: #5E5E5E;">=</span> RegisterModel(</span>
<span id="cb45-4">    name<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"RegisterModel"</span>,</span>
<span id="cb45-5">    estimator<span class="op" style="color: #5E5E5E;">=</span>estimator,</span>
<span id="cb45-6">    image_uri<span class="op" style="color: #5E5E5E;">=</span>inference_image_uri, </span>
<span id="cb45-7">    model_data<span class="op" style="color: #5E5E5E;">=</span>training_step.properties.ModelArtifacts.S3ModelArtifacts,</span>
<span id="cb45-8">    content_types<span class="op" style="color: #5E5E5E;">=</span>[<span class="st" style="color: #20794D;">"application/jsonlines"</span>],</span>
<span id="cb45-9">    response_types<span class="op" style="color: #5E5E5E;">=</span>[<span class="st" style="color: #20794D;">"application/jsonlines"</span>],</span>
<span id="cb45-10">    inference_instances<span class="op" style="color: #5E5E5E;">=</span>[deploy_instance_type],</span>
<span id="cb45-11">    transform_instances<span class="op" style="color: #5E5E5E;">=</span>[deploy_instance_type], </span>
<span id="cb45-12">    model_package_group_name<span class="op" style="color: #5E5E5E;">=</span>model_package_group_name,</span>
<span id="cb45-13">    approval_status<span class="op" style="color: #5E5E5E;">=</span>model_approval_status,</span>
<span id="cb45-14">    model_metrics<span class="op" style="color: #5E5E5E;">=</span>model_metrics</span>
<span id="cb45-15">)</span></code></pre></div>
</div>
</section>
</section>
<section id="create-model-for-deployment-step" class="level2" data-number="9">
<h2 data-number="9" class="anchored" data-anchor-id="create-model-for-deployment-step"><span class="header-section-number">9</span> Create model for deployment step</h2>
<p>Let’s configure the model for deployment.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb46" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb46-1"><span class="im" style="color: #00769E;">from</span> sagemaker.model <span class="im" style="color: #00769E;">import</span> Model</span>
<span id="cb46-2"></span>
<span id="cb46-3">model_name <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">'bert-model-</span><span class="sc" style="color: #5E5E5E;">{}</span><span class="st" style="color: #20794D;">'</span>.<span class="bu" style="color: null;">format</span>(timestamp)</span>
<span id="cb46-4"></span>
<span id="cb46-5">model <span class="op" style="color: #5E5E5E;">=</span> Model(</span>
<span id="cb46-6">    name<span class="op" style="color: #5E5E5E;">=</span>model_name,</span>
<span id="cb46-7">    image_uri<span class="op" style="color: #5E5E5E;">=</span>inference_image_uri, </span>
<span id="cb46-8">    model_data<span class="op" style="color: #5E5E5E;">=</span>training_step.properties.ModelArtifacts.S3ModelArtifacts,</span>
<span id="cb46-9">    sagemaker_session<span class="op" style="color: #5E5E5E;">=</span>sess,</span>
<span id="cb46-10">    role<span class="op" style="color: #5E5E5E;">=</span>role,</span>
<span id="cb46-11">)</span></code></pre></div>
</div>
<p>Now we configure create model input:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb47" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb47-1"><span class="im" style="color: #00769E;">from</span> sagemaker.inputs <span class="im" style="color: #00769E;">import</span> CreateModelInput</span>
<span id="cb47-2"></span>
<span id="cb47-3">create_inputs <span class="op" style="color: #5E5E5E;">=</span> CreateModelInput(</span>
<span id="cb47-4">    instance_type<span class="op" style="color: #5E5E5E;">=</span>deploy_instance_type, </span>
<span id="cb47-5">)</span></code></pre></div>
</div>
<p>Lastly we configure the create model step for the workflow.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb48" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb48-1"><span class="im" style="color: #00769E;">from</span> sagemaker.workflow.steps <span class="im" style="color: #00769E;">import</span> CreateModelStep</span>
<span id="cb48-2"></span>
<span id="cb48-3">create_step <span class="op" style="color: #5E5E5E;">=</span> CreateModelStep(</span>
<span id="cb48-4">    name<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"CreateModel"</span>,</span>
<span id="cb48-5">    model<span class="op" style="color: #5E5E5E;">=</span>model, </span>
<span id="cb48-6">    inputs<span class="op" style="color: #5E5E5E;">=</span>create_inputs, </span>
<span id="cb48-7">)</span></code></pre></div>
</div>
</section>
<section id="check-accuracy-condition-step" class="level2" data-number="10">
<h2 data-number="10" class="anchored" data-anchor-id="check-accuracy-condition-step"><span class="header-section-number">10</span> Check accuracy condition step</h2>
<p>Finally, we would like to only register this model if the accuracy of the model, as determined by our evaluation step <code>evaluation_step</code>, exceeded some value. A <code>ConditionStep</code> allows for pipelines to support conditional execution in the pipeline DAG based on conditions of step properties.</p>
<p>Below, we will:</p>
<ul>
<li>define a minimum accuracy value as a parameter</li>
<li>define a <code>ConditionGreaterThan</code> on the accuracy value found in the output of the evaluation step, <code>evaluation_step</code>.</li>
<li>use the condition in the list of conditions in a <code>ConditionStep</code></li>
<li>pass the <code>RegisterModel</code> step collection into the <code>if_steps</code> of the <code>ConditionStep</code></li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb49" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb49-1">min_accuracy_value <span class="op" style="color: #5E5E5E;">=</span> ParameterFloat(</span>
<span id="cb49-2">    name<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"MinAccuracyValue"</span>,</span>
<span id="cb49-3">    default_value<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">0.33</span> <span class="co" style="color: #5E5E5E;"># random choice from three classes</span></span>
<span id="cb49-4">)</span></code></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb50" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb50-1"><span class="im" style="color: #00769E;">from</span> sagemaker.workflow.conditions <span class="im" style="color: #00769E;">import</span> ConditionGreaterThanOrEqualTo</span>
<span id="cb50-2"><span class="im" style="color: #00769E;">from</span> sagemaker.workflow.condition_step <span class="im" style="color: #00769E;">import</span> (</span>
<span id="cb50-3">    ConditionStep,</span>
<span id="cb50-4">    JsonGet,</span>
<span id="cb50-5">)</span>
<span id="cb50-6"></span>
<span id="cb50-7">minimum_accuracy_condition <span class="op" style="color: #5E5E5E;">=</span> ConditionGreaterThanOrEqualTo(</span>
<span id="cb50-8">    left<span class="op" style="color: #5E5E5E;">=</span>JsonGet(</span>
<span id="cb50-9">        step<span class="op" style="color: #5E5E5E;">=</span>evaluation_step,</span>
<span id="cb50-10">        property_file<span class="op" style="color: #5E5E5E;">=</span>evaluation_report,</span>
<span id="cb50-11">        json_path<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"metrics.accuracy.value"</span>,</span>
<span id="cb50-12">    ),</span>
<span id="cb50-13">    right<span class="op" style="color: #5E5E5E;">=</span>min_accuracy_value <span class="co" style="color: #5E5E5E;"># minimum accuracy threshold</span></span>
<span id="cb50-14">)</span>
<span id="cb50-15"></span>
<span id="cb50-16">minimum_accuracy_condition_step <span class="op" style="color: #5E5E5E;">=</span> ConditionStep(</span>
<span id="cb50-17">    name<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"AccuracyCondition"</span>,</span>
<span id="cb50-18">    conditions<span class="op" style="color: #5E5E5E;">=</span>[minimum_accuracy_condition],</span>
<span id="cb50-19">    if_steps<span class="op" style="color: #5E5E5E;">=</span>[register_step, create_step], <span class="co" style="color: #5E5E5E;"># successfully exceeded or equaled the minimum accuracy, continue with model registration</span></span>
<span id="cb50-20">    else_steps<span class="op" style="color: #5E5E5E;">=</span>[], <span class="co" style="color: #5E5E5E;"># did not exceed the minimum accuracy, the model will not be registered</span></span>
<span id="cb50-21">)</span></code></pre></div>
</div>
</section>
<section id="create-pipeline" class="level2" data-number="11">
<h2 data-number="11" class="anchored" data-anchor-id="create-pipeline"><span class="header-section-number">11</span> Create pipeline</h2>
<section id="define-a-pipeline-of-parameters-steps-and-conditions" class="level3" data-number="11.1">
<h3 data-number="11.1" class="anchored" data-anchor-id="define-a-pipeline-of-parameters-steps-and-conditions"><span class="header-section-number">11.1</span> Define a pipeline of parameters, steps, and conditions</h3>
<p>Let’s tie it all up into a workflow pipeline so we can execute it, and even schedule it.</p>
<p>A pipeline requires a <code>name</code>, <code>parameters</code>, and <code>steps</code>. Names must be unique within an <code>(account, region)</code> pair so you can append the timestamp to the name to reduce the chance of name conflict.</p>
<p>Note:</p>
<ul>
<li>All the parameters used in the definitions must be present.</li>
<li>Steps passed into the pipeline need not be in the order of execution. The SageMaker workflow service will resolve the <em>data dependency</em> DAG as steps the execution complete.</li>
<li>Steps must be unique to either pipeline step list or a single condition step if/else list.</li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb51" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb51-1"><span class="im" style="color: #00769E;">from</span> sagemaker.workflow.pipeline <span class="im" style="color: #00769E;">import</span> Pipeline</span>
<span id="cb51-2"></span>
<span id="cb51-3">pipeline <span class="op" style="color: #5E5E5E;">=</span> Pipeline(</span>
<span id="cb51-4">    name<span class="op" style="color: #5E5E5E;">=</span>pipeline_name,</span>
<span id="cb51-5">    parameters<span class="op" style="color: #5E5E5E;">=</span>[</span>
<span id="cb51-6">        input_data,</span>
<span id="cb51-7">        processing_instance_count,</span>
<span id="cb51-8">        processing_instance_type,</span>
<span id="cb51-9">        max_seq_length,</span>
<span id="cb51-10">        balance_dataset,</span>
<span id="cb51-11">        train_split_percentage,</span>
<span id="cb51-12">        validation_split_percentage,</span>
<span id="cb51-13">        test_split_percentage,</span>
<span id="cb51-14">        feature_store_offline_prefix,</span>
<span id="cb51-15">        feature_group_name,</span>
<span id="cb51-16">        epochs,</span>
<span id="cb51-17">        learning_rate,</span>
<span id="cb51-18">        train_batch_size,</span>
<span id="cb51-19">        train_steps_per_epoch,</span>
<span id="cb51-20">        validation_batch_size,</span>
<span id="cb51-21">        validation_steps_per_epoch,</span>
<span id="cb51-22">        freeze_bert_layer,</span>
<span id="cb51-23">        seed,</span>
<span id="cb51-24">        train_instance_count,</span>
<span id="cb51-25">        train_instance_type,</span>
<span id="cb51-26">        train_volume_size,        </span>
<span id="cb51-27">        input_mode,</span>
<span id="cb51-28">        run_validation,</span>
<span id="cb51-29">        min_accuracy_value,</span>
<span id="cb51-30">        model_approval_status,</span>
<span id="cb51-31">        deploy_instance_type,</span>
<span id="cb51-32">        deploy_instance_count</span>
<span id="cb51-33">    ],</span>
<span id="cb51-34">    steps<span class="op" style="color: #5E5E5E;">=</span>[processing_step, training_step, evaluation_step, minimum_accuracy_condition_step],</span>
<span id="cb51-35">    sagemaker_session<span class="op" style="color: #5E5E5E;">=</span>sess,</span>
<span id="cb51-36">)</span></code></pre></div>
</div>
<p>Let’s examine the JSON of the pipeline definition that meets the SageMaker Workflow Pipeline DSL specification.</p>
<p>By examining the definition, you are also confirming that the pipeline was well-defined, and that the parameters and step properties resolve correctly.</p>
<div class="cell" data-outputid="27f05fa4-8980-4dbb-b3e9-52ba548492b0" data-scrolled="true">
<div class="sourceCode cell-code" id="cb52" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb52-1"><span class="im" style="color: #00769E;">import</span> json</span>
<span id="cb52-2"><span class="im" style="color: #00769E;">from</span> pprint <span class="im" style="color: #00769E;">import</span> pprint</span>
<span id="cb52-3"></span>
<span id="cb52-4">definition <span class="op" style="color: #5E5E5E;">=</span> json.loads(pipeline.definition())</span>
<span id="cb52-5"></span>
<span id="cb52-6">pprint(definition)</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>{'Metadata': {},
 'Parameters': [{'DefaultValue': 's3://dlai-practical-data-science/data/raw/',
                 'Name': 'InputData',
                 'Type': 'String'},
                {'DefaultValue': 1,
                 'Name': 'ProcessingInstanceCount',
                 'Type': 'Integer'},
                {'DefaultValue': 'ml.c5.2xlarge',
                 'Name': 'ProcessingInstanceType',
                 'Type': 'String'},
                {'DefaultValue': 128,
                 'Name': 'MaxSeqLength',
                 'Type': 'Integer'},
                {'DefaultValue': 'True',
                 'Name': 'BalanceDataset',
                 'Type': 'String'},
                {'DefaultValue': 0.9,
                 'Name': 'TrainSplitPercentage',
                 'Type': 'Float'},
                {'DefaultValue': 0.05,
                 'Name': 'ValidationSplitPercentage',
                 'Type': 'Float'},
                {'DefaultValue': 0.05,
                 'Name': 'TestSplitPercentage',
                 'Type': 'Float'},
                {'DefaultValue': 'reviews-feature-store-1676208665',
                 'Name': 'FeatureStoreOfflinePrefix',
                 'Type': 'String'},
                {'DefaultValue': 'reviews-feature-group-1676208665',
                 'Name': 'FeatureGroupName',
                 'Type': 'String'},
                {'DefaultValue': 3, 'Name': 'Epochs', 'Type': 'Integer'},
                {'DefaultValue': 1e-05,
                 'Name': 'LearningRate',
                 'Type': 'Float'},
                {'DefaultValue': 64,
                 'Name': 'TrainBatchSize',
                 'Type': 'Integer'},
                {'DefaultValue': 50,
                 'Name': 'TrainStepsPerEpoch',
                 'Type': 'Integer'},
                {'DefaultValue': 64,
                 'Name': 'ValidationBatchSize',
                 'Type': 'Integer'},
                {'DefaultValue': 50,
                 'Name': 'ValidationStepsPerEpoch',
                 'Type': 'Integer'},
                {'DefaultValue': 'False',
                 'Name': 'FreezeBertLayer',
                 'Type': 'String'},
                {'DefaultValue': 42, 'Name': 'Seed', 'Type': 'Integer'},
                {'DefaultValue': 1,
                 'Name': 'TrainInstanceCount',
                 'Type': 'Integer'},
                {'DefaultValue': 'ml.c5.9xlarge',
                 'Name': 'TrainInstanceType',
                 'Type': 'String'},
                {'DefaultValue': 256,
                 'Name': 'TrainVolumeSize',
                 'Type': 'Integer'},
                {'DefaultValue': 'File', 'Name': 'InputMode', 'Type': 'String'},
                {'DefaultValue': 'True',
                 'Name': 'RunValidation',
                 'Type': 'String'},
                {'DefaultValue': 0.33,
                 'Name': 'MinAccuracyValue',
                 'Type': 'Float'},
                {'DefaultValue': 'PendingManualApproval',
                 'Name': 'ModelApprovalStatus',
                 'Type': 'String'},
                {'DefaultValue': 'ml.m5.large',
                 'Name': 'DeployInstanceType',
                 'Type': 'String'},
                {'DefaultValue': 1,
                 'Name': 'DeployInstanceCount',
                 'Type': 'Integer'}],
 'Steps': [{'Arguments': {'AppSpecification': {'ContainerArguments': ['--train-split-percentage',
                                                                      '0.9',
                                                                      '--validation-split-percentage',
                                                                      '0.05',
                                                                      '--test-split-percentage',
                                                                      '0.05',
                                                                      '--balance-dataset',
                                                                      'True',
                                                                      '--max-seq-length',
                                                                      '128',
                                                                      '--feature-store-offline-prefix',
                                                                      'reviews-feature-store-1676208665',
                                                                      '--feature-group-name',
                                                                      'reviews-feature-group-1676208665'],
                                               'ContainerEntrypoint': ['python3',
                                                                       '/opt/ml/processing/input/code/prepare_data.py'],
                                               'ImageUri': '683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-scikit-learn:0.23-1-cpu-py3'},
                          'Environment': {'AWS_DEFAULT_REGION': 'us-east-1'},
                          'ProcessingInputs': [{'AppManaged': False,
                                                'InputName': 'raw-input-data',
                                                'S3Input': {'LocalPath': '/opt/ml/processing/input/data/',
                                                            'S3CompressionType': 'None',
                                                            'S3DataDistributionType': 'ShardedByS3Key',
                                                            'S3DataType': 'S3Prefix',
                                                            'S3InputMode': 'File',
                                                            'S3Uri': {'Get': 'Parameters.InputData'}}},
                                               {'AppManaged': False,
                                                'InputName': 'code',
                                                'S3Input': {'LocalPath': '/opt/ml/processing/input/code',
                                                            'S3CompressionType': 'None',
                                                            'S3DataDistributionType': 'FullyReplicated',
                                                            'S3DataType': 'S3Prefix',
                                                            'S3InputMode': 'File',
                                                            'S3Uri': 's3://sagemaker-us-east-1-912822595625/sagemaker-scikit-learn-2023-02-12-13-37-28-563/input/code/prepare_data.py'}}],
                          'ProcessingOutputConfig': {'Outputs': [{'AppManaged': False,
                                                                  'OutputName': 'sentiment-train',
                                                                  'S3Output': {'LocalPath': '/opt/ml/processing/output/sentiment/train',
                                                                               'S3UploadMode': 'EndOfJob',
                                                                               'S3Uri': 's3://sagemaker-us-east-1-912822595625/sagemaker-scikit-learn-2023-02-12-13-32-20-378/output/sentiment-train'}},
                                                                 {'AppManaged': False,
                                                                  'OutputName': 'sentiment-validation',
                                                                  'S3Output': {'LocalPath': '/opt/ml/processing/output/sentiment/validation',
                                                                               'S3UploadMode': 'EndOfJob',
                                                                               'S3Uri': 's3://sagemaker-us-east-1-912822595625/sagemaker-scikit-learn-2023-02-12-13-32-20-378/output/sentiment-validation'}},
                                                                 {'AppManaged': False,
                                                                  'OutputName': 'sentiment-test',
                                                                  'S3Output': {'LocalPath': '/opt/ml/processing/output/sentiment/test',
                                                                               'S3UploadMode': 'EndOfJob',
                                                                               'S3Uri': 's3://sagemaker-us-east-1-912822595625/sagemaker-scikit-learn-2023-02-12-13-32-20-378/output/sentiment-test'}}]},
                          'ProcessingResources': {'ClusterConfig': {'InstanceCount': {'Get': 'Parameters.ProcessingInstanceCount'},
                                                                    'InstanceType': {'Get': 'Parameters.ProcessingInstanceType'},
                                                                    'VolumeSizeInGB': 30}},
                          'RoleArn': 'arn:aws:iam::912822595625:role/sagemaker-studio-vpc-firewall-us-east-1-sagemaker-execution-role'},
            'Name': 'Processing',
            'Type': 'Processing'},
           {'Arguments': {'AlgorithmSpecification': {'EnableSageMakerMetricsTimeSeries': True,
                                                     'MetricDefinitions': [{'Name': 'validation:loss',
                                                                            'Regex': 'val_loss: '
                                                                                     '([0-9.]+)'},
                                                                           {'Name': 'validation:accuracy',
                                                                            'Regex': 'val_acc: '
                                                                                     '([0-9.]+)'}],
                                                     'TrainingImage': '763104351884.dkr.ecr.us-east-1.amazonaws.com/pytorch-training:1.6.0-cpu-py3',
                                                     'TrainingInputMode': {'Get': 'Parameters.InputMode'}},
                          'DebugHookConfig': {'CollectionConfigurations': [],
                                              'S3OutputPath': 's3://sagemaker-us-east-1-912822595625/'},
                          'HyperParameters': {'epochs': '3',
                                              'freeze_bert_layer': '"False"',
                                              'learning_rate': '1e-05',
                                              'max_seq_length': '128',
                                              'run_validation': '"True"',
                                              'sagemaker_container_log_level': '20',
                                              'sagemaker_job_name': '"pytorch-training-2023-02-12-13-37-28-707"',
                                              'sagemaker_program': '"train.py"',
                                              'sagemaker_region': '"us-east-1"',
                                              'sagemaker_submit_directory': '"s3://sagemaker-us-east-1-912822595625/pytorch-training-2023-02-12-13-37-28-707/source/sourcedir.tar.gz"',
                                              'seed': '42',
                                              'train_batch_size': '64',
                                              'train_steps_per_epoch': '50',
                                              'validation_batch_size': '64',
                                              'validation_steps_per_epoch': '50'},
                          'InputDataConfig': [{'ChannelName': 'train',
                                               'ContentType': 'text/csv',
                                               'DataSource': {'S3DataSource': {'S3DataDistributionType': 'FullyReplicated',
                                                                               'S3DataType': 'S3Prefix',
                                                                               'S3Uri': {'Get': "Steps.Processing.ProcessingOutputConfig.Outputs['sentiment-train'].S3Output.S3Uri"}}}},
                                              {'ChannelName': 'validation',
                                               'ContentType': 'text/csv',
                                               'DataSource': {'S3DataSource': {'S3DataDistributionType': 'FullyReplicated',
                                                                               'S3DataType': 'S3Prefix',
                                                                               'S3Uri': {'Get': "Steps.Processing.ProcessingOutputConfig.Outputs['sentiment-validation'].S3Output.S3Uri"}}}}],
                          'OutputDataConfig': {'S3OutputPath': 's3://sagemaker-us-east-1-912822595625/'},
                          'ProfilerConfig': {'S3OutputPath': 's3://sagemaker-us-east-1-912822595625/'},
                          'ProfilerRuleConfigurations': [{'RuleConfigurationName': 'ProfilerReport-1676209048',
                                                          'RuleEvaluatorImage': '503895931360.dkr.ecr.us-east-1.amazonaws.com/sagemaker-debugger-rules:latest',
                                                          'RuleParameters': {'rule_to_invoke': 'ProfilerReport'}}],
                          'ResourceConfig': {'InstanceCount': {'Get': 'Parameters.TrainInstanceCount'},
                                             'InstanceType': {'Get': 'Parameters.TrainInstanceType'},
                                             'VolumeSizeInGB': {'Get': 'Parameters.TrainVolumeSize'}},
                          'RoleArn': 'arn:aws:iam::912822595625:role/sagemaker-studio-vpc-firewall-us-east-1-sagemaker-execution-role',
                          'StoppingCondition': {'MaxRuntimeInSeconds': 86400}},
            'CacheConfig': {'Enabled': True, 'ExpireAfter': 'PT1H'},
            'Name': 'Train',
            'Type': 'Training'},
           {'Arguments': {'AppSpecification': {'ContainerArguments': ['--max-seq-length',
                                                                      '128'],
                                               'ContainerEntrypoint': ['python3',
                                                                       '/opt/ml/processing/input/code/evaluate_model_metrics.py'],
                                               'ImageUri': '683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-scikit-learn:0.23-1-cpu-py3'},
                          'Environment': {'AWS_DEFAULT_REGION': 'us-east-1'},
                          'ProcessingInputs': [{'AppManaged': False,
                                                'InputName': 'input-1',
                                                'S3Input': {'LocalPath': '/opt/ml/processing/input/model',
                                                            'S3CompressionType': 'None',
                                                            'S3DataDistributionType': 'FullyReplicated',
                                                            'S3DataType': 'S3Prefix',
                                                            'S3InputMode': 'File',
                                                            'S3Uri': {'Get': 'Steps.Train.ModelArtifacts.S3ModelArtifacts'}}},
                                               {'AppManaged': False,
                                                'InputName': 'input-2',
                                                'S3Input': {'LocalPath': '/opt/ml/processing/input/data',
                                                            'S3CompressionType': 'None',
                                                            'S3DataDistributionType': 'FullyReplicated',
                                                            'S3DataType': 'S3Prefix',
                                                            'S3InputMode': 'File',
                                                            'S3Uri': {'Get': "Steps.Processing.ProcessingOutputConfig.Outputs['sentiment-test'].S3Output.S3Uri"}}},
                                               {'AppManaged': False,
                                                'InputName': 'code',
                                                'S3Input': {'LocalPath': '/opt/ml/processing/input/code',
                                                            'S3CompressionType': 'None',
                                                            'S3DataDistributionType': 'FullyReplicated',
                                                            'S3DataType': 'S3Prefix',
                                                            'S3InputMode': 'File',
                                                            'S3Uri': 's3://sagemaker-us-east-1-912822595625/sagemaker-scikit-learn-2023-02-12-13-37-29-187/input/code/evaluate_model_metrics.py'}}],
                          'ProcessingOutputConfig': {'Outputs': [{'AppManaged': False,
                                                                  'OutputName': 'metrics',
                                                                  'S3Output': {'LocalPath': '/opt/ml/processing/output/metrics/',
                                                                               'S3UploadMode': 'EndOfJob',
                                                                               'S3Uri': 's3://sagemaker-us-east-1-912822595625/sagemaker-scikit-learn-2023-02-12-13-35-32-414/output/metrics'}}]},
                          'ProcessingResources': {'ClusterConfig': {'InstanceCount': {'Get': 'Parameters.ProcessingInstanceCount'},
                                                                    'InstanceType': {'Get': 'Parameters.ProcessingInstanceType'},
                                                                    'VolumeSizeInGB': 30}},
                          'RoleArn': 'arn:aws:iam::912822595625:role/sagemaker-studio-vpc-firewall-us-east-1-sagemaker-execution-role',
                          'StoppingCondition': {'MaxRuntimeInSeconds': 7200}},
            'Name': 'EvaluateModel',
            'PropertyFiles': [{'FilePath': 'evaluation.json',
                               'OutputName': 'metrics',
                               'PropertyFileName': 'EvaluationReport'}],
            'Type': 'Processing'},
           {'Arguments': {'Conditions': [{'LeftValue': {'Std:JsonGet': {'Path': 'metrics.accuracy.value',
                                                                        'PropertyFile': {'Get': 'Steps.EvaluateModel.PropertyFiles.EvaluationReport'}}},
                                          'RightValue': {'Get': 'Parameters.MinAccuracyValue'},
                                          'Type': 'GreaterThanOrEqualTo'}],
                          'ElseSteps': [],
                          'IfSteps': [{'Arguments': {'InferenceSpecification': {'Containers': [{'Image': '763104351884.dkr.ecr.us-east-1.amazonaws.com/pytorch-inference:1.6.0-cpu-py36',
                                                                                                'ModelDataUrl': {'Get': 'Steps.Train.ModelArtifacts.S3ModelArtifacts'}}],
                                                                                'SupportedContentTypes': ['application/jsonlines'],
                                                                                'SupportedRealtimeInferenceInstanceTypes': [{'Get': 'Parameters.DeployInstanceType'}],
                                                                                'SupportedResponseMIMETypes': ['application/jsonlines'],
                                                                                'SupportedTransformInstanceTypes': [{'Get': 'Parameters.DeployInstanceType'}]},
                                                     'ModelApprovalStatus': {'Get': 'Parameters.ModelApprovalStatus'},
                                                     'ModelMetrics': {'ModelQuality': {'Statistics': {'ContentType': 'application/json',
                                                                                                      'S3Uri': 's3://sagemaker-us-east-1-912822595625/sagemaker-scikit-learn-2023-02-12-13-35-32-414/output/metrics/evaluation.json'}}},
                                                     'ModelPackageGroupName': 'BERT-Reviews-1676208665'},
                                       'Name': 'RegisterModel',
                                       'Type': 'RegisterModel'},
                                      {'Arguments': {'ExecutionRoleArn': 'arn:aws:iam::912822595625:role/sagemaker-studio-vpc-firewall-us-east-1-sagemaker-execution-role',
                                                     'PrimaryContainer': {'Environment': {},
                                                                          'Image': '763104351884.dkr.ecr.us-east-1.amazonaws.com/pytorch-inference:1.6.0-cpu-py36',
                                                                          'ModelDataUrl': {'Get': 'Steps.Train.ModelArtifacts.S3ModelArtifacts'}}},
                                       'Name': 'CreateModel',
                                       'Type': 'Model'}]},
            'Name': 'AccuracyCondition',
            'Type': 'Condition'}],
 'Version': '2020-12-01'}</code></pre>
</div>
</div>
<p>Now we create a pipeline using the <code>create</code> method and then print the Amazon Resource Name (ARN) of it.</p>
<div class="cell" data-outputid="8c60e97f-d45b-4ea1-be6e-ee42b7c36822">
<div class="sourceCode cell-code" id="cb55" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb55-1">response <span class="op" style="color: #5E5E5E;">=</span> pipeline.create(role_arn<span class="op" style="color: #5E5E5E;">=</span>role)</span>
<span id="cb55-2"></span>
<span id="cb55-3">pipeline_arn <span class="op" style="color: #5E5E5E;">=</span> response[<span class="st" style="color: #20794D;">"PipelineArn"</span>]</span>
<span id="cb55-4"><span class="bu" style="color: null;">print</span>(pipeline_arn)</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>arn:aws:sagemaker:us-east-1:912822595625:pipeline/bert-pipeline-1676208665</code></pre>
</div>
</div>
</section>
<section id="start-pipeline" class="level3" data-number="11.2">
<h3 data-number="11.2" class="anchored" data-anchor-id="start-pipeline"><span class="header-section-number">11.2</span> Start Pipeline</h3>
<p>Let’s submit our pipeline definition to the Amazon SageMaker Pipeline service. The role passed in will be used by the service to create all the jobs defined in the steps. We will start the pipeline using the parameters passed into the <code>start()</code> function.</p>
<div class="cell" data-outputid="fed7b243-649f-4834-c4ee-42c21e3ce00d">
<div class="sourceCode cell-code" id="cb58" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb58-1">execution <span class="op" style="color: #5E5E5E;">=</span> pipeline.start(</span>
<span id="cb58-2">    parameters<span class="op" style="color: #5E5E5E;">=</span><span class="bu" style="color: null;">dict</span>(</span>
<span id="cb58-3">        InputData<span class="op" style="color: #5E5E5E;">=</span>raw_input_data_s3_uri,</span>
<span id="cb58-4">        ProcessingInstanceCount<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">1</span>,</span>
<span id="cb58-5">        ProcessingInstanceType<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'ml.c5.2xlarge'</span>,</span>
<span id="cb58-6">        MaxSeqLength<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">128</span>,</span>
<span id="cb58-7">        BalanceDataset<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'True'</span>,</span>
<span id="cb58-8">        TrainSplitPercentage<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">0.9</span>,</span>
<span id="cb58-9">        ValidationSplitPercentage<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">0.05</span>,</span>
<span id="cb58-10">        TestSplitPercentage<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">0.05</span>,</span>
<span id="cb58-11">        FeatureStoreOfflinePrefix<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'reviews-feature-store-'</span><span class="op" style="color: #5E5E5E;">+</span><span class="bu" style="color: null;">str</span>(timestamp),</span>
<span id="cb58-12">        FeatureGroupName<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'reviews-feature-group-'</span><span class="op" style="color: #5E5E5E;">+</span><span class="bu" style="color: null;">str</span>(timestamp),</span>
<span id="cb58-13">        Epochs<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">3</span>,</span>
<span id="cb58-14">        LearningRate<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">0.000012</span>,</span>
<span id="cb58-15">        TrainBatchSize<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">64</span>,</span>
<span id="cb58-16">        TrainStepsPerEpoch<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">50</span>,</span>
<span id="cb58-17">        ValidationBatchSize<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">64</span>,</span>
<span id="cb58-18">        ValidationStepsPerEpoch<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">64</span>,</span>
<span id="cb58-19">        FreezeBertLayer<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'False'</span>,</span>
<span id="cb58-20">        Seed<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">42</span>,         </span>
<span id="cb58-21">        TrainInstanceCount<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">1</span>,</span>
<span id="cb58-22">        TrainInstanceType<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'ml.c5.9xlarge'</span>,</span>
<span id="cb58-23">        TrainVolumeSize<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">256</span>,</span>
<span id="cb58-24">        InputMode<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'File'</span>,</span>
<span id="cb58-25">        RunValidation<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'True'</span>,</span>
<span id="cb58-26">        MinAccuracyValue<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">0.01</span>,</span>
<span id="cb58-27">        ModelApprovalStatus<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'PendingManualApproval'</span>, </span>
<span id="cb58-28">        DeployInstanceType<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'ml.m5.large'</span>,</span>
<span id="cb58-29">        DeployInstanceCount<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">1</span> </span>
<span id="cb58-30">    )</span>
<span id="cb58-31">)</span>
<span id="cb58-32"></span>
<span id="cb58-33"><span class="bu" style="color: null;">print</span>(execution.arn)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>arn:aws:sagemaker:us-east-1:912822595625:pipeline/bert-pipeline-1676208665/execution/h4inlmq7fqwk</code></pre>
</div>
</div>
</section>
<section id="wait-for-pipeline-execution" class="level3" data-number="11.3">
<h3 data-number="11.3" class="anchored" data-anchor-id="wait-for-pipeline-execution"><span class="header-section-number">11.3</span> Wait for pipeline execution</h3>
<p>Now we can describe execution instance and list the steps in the execution to find out more about the execution.</p>
<div class="cell" data-outputid="efe604fa-ddc1-4e23-ad4d-203a0aaadfe2">
<div class="sourceCode cell-code" id="cb60" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb60-1"><span class="im" style="color: #00769E;">from</span> pprint <span class="im" style="color: #00769E;">import</span> pprint</span>
<span id="cb60-2"></span>
<span id="cb60-3">execution_run <span class="op" style="color: #5E5E5E;">=</span> execution.describe()</span>
<span id="cb60-4">pprint(execution_run)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>{'CreatedBy': {'DomainId': 'd-h9yolcap5nrc',
               'UserProfileArn': 'arn:aws:sagemaker:us-east-1:912822595625:user-profile/d-h9yolcap5nrc/sagemaker-user-profile-us-east-1',
               'UserProfileName': 'sagemaker-user-profile-us-east-1'},
 'CreationTime': datetime.datetime(2023, 2, 12, 13, 37, 41, 761000, tzinfo=tzlocal()),
 'LastModifiedBy': {'DomainId': 'd-h9yolcap5nrc',
                    'UserProfileArn': 'arn:aws:sagemaker:us-east-1:912822595625:user-profile/d-h9yolcap5nrc/sagemaker-user-profile-us-east-1',
                    'UserProfileName': 'sagemaker-user-profile-us-east-1'},
 'LastModifiedTime': datetime.datetime(2023, 2, 12, 13, 37, 41, 761000, tzinfo=tzlocal()),
 'PipelineArn': 'arn:aws:sagemaker:us-east-1:912822595625:pipeline/bert-pipeline-1676208665',
 'PipelineExecutionArn': 'arn:aws:sagemaker:us-east-1:912822595625:pipeline/bert-pipeline-1676208665/execution/h4inlmq7fqwk',
 'PipelineExecutionDisplayName': 'execution-1676209061894',
 'PipelineExecutionStatus': 'Executing',
 'ResponseMetadata': {'HTTPHeaders': {'content-length': '815',
                                      'content-type': 'application/x-amz-json-1.1',
                                      'date': 'Sun, 12 Feb 2023 13:37:46 GMT',
                                      'x-amzn-requestid': '5d8ec01a-6a95-4737-802b-82302f7ab368'},
                      'HTTPStatusCode': 200,
                      'RequestId': '5d8ec01a-6a95-4737-802b-82302f7ab368',
                      'RetryAttempts': 0}}</code></pre>
</div>
</div>
<p>Print the execution display name and its ARN:</p>
<div class="cell" data-outputid="4da59038-01c5-44fb-8b66-b757f6202406">
<div class="sourceCode cell-code" id="cb62" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb62-1">execution_run_name <span class="op" style="color: #5E5E5E;">=</span> execution_run[<span class="st" style="color: #20794D;">'PipelineExecutionDisplayName'</span>]</span>
<span id="cb62-2"><span class="bu" style="color: null;">print</span>(execution_run_name)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>execution-1676209061894</code></pre>
</div>
</div>
<div class="cell" data-outputid="20e767dc-cde1-493c-b769-fd94a2e32c90">
<div class="sourceCode cell-code" id="cb64" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb64-1">pipeline_execution_arn <span class="op" style="color: #5E5E5E;">=</span> execution_run[<span class="st" style="color: #20794D;">'PipelineExecutionArn'</span>]</span>
<span id="cb64-2"><span class="bu" style="color: null;">print</span>(pipeline_execution_arn)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>arn:aws:sagemaker:us-east-1:912822595625:pipeline/bert-pipeline-1676208665/execution/h4inlmq7fqwk</code></pre>
</div>
</div>
</section>
<section id="describe-completed-pipeline" class="level3" data-number="11.4">
<h3 data-number="11.4" class="anchored" data-anchor-id="describe-completed-pipeline"><span class="header-section-number">11.4</span> Describe completed pipeline</h3>
<p>We will wait for the first step to start running and print the information about it:</p>
<div class="cell" data-outputid="c02195a7-bafb-4e5d-a1e6-91b1d30d3723">
<div class="sourceCode cell-code" id="cb66" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb66-1"><span class="im" style="color: #00769E;">import</span> time</span>
<span id="cb66-2"></span>
<span id="cb66-3">time.sleep(<span class="dv" style="color: #AD0000;">30</span>)</span>
<span id="cb66-4"></span>
<span id="cb66-5">execution.list_steps()</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="46">
<pre><code>[{'StepName': 'Processing',
  'StartTime': datetime.datetime(2023, 2, 12, 13, 37, 42, 570000, tzinfo=tzlocal()),
  'StepStatus': 'Executing',
  'AttemptCount': 0,
  'Metadata': {'ProcessingJob': {'Arn': 'arn:aws:sagemaker:us-east-1:912822595625:processing-job/pipelines-h4inlmq7fqwk-processing-mwnbfz07z3'}}}]</code></pre>
</div>
</div>
</section>
<section id="wait-for-the-pipeline-to-complete" class="level3" data-number="11.5">
<h3 data-number="11.5" class="anchored" data-anchor-id="wait-for-the-pipeline-to-complete"><span class="header-section-number">11.5</span> Wait for the pipeline to complete</h3>
<p>To get the information about the pipeline execution we can use a low-level service client of the boto3 session. It is also useful for other operations that you will see below.</p>
<p>In the code below we will be observing the pipeline execution summary and waiting for the execution status to change from <code>Executing</code> to <code>Succeeded</code>.</p>
<div class="cell" data-outputid="380b6722-6362-4805-8654-9e398e28f874">
<div class="sourceCode cell-code" id="cb68" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb68-1"><span class="op" style="color: #5E5E5E;">%%</span>time</span>
<span id="cb68-2"></span>
<span id="cb68-3"><span class="im" style="color: #00769E;">import</span> time</span>
<span id="cb68-4"><span class="im" style="color: #00769E;">from</span> pprint <span class="im" style="color: #00769E;">import</span> pprint</span>
<span id="cb68-5"></span>
<span id="cb68-6">sm <span class="op" style="color: #5E5E5E;">=</span> boto3.Session().client(service_name<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'sagemaker'</span>, region_name<span class="op" style="color: #5E5E5E;">=</span>region)</span>
<span id="cb68-7"></span>
<span id="cb68-8">executions_response <span class="op" style="color: #5E5E5E;">=</span> sm.list_pipeline_executions(PipelineName<span class="op" style="color: #5E5E5E;">=</span>pipeline_name)[<span class="st" style="color: #20794D;">'PipelineExecutionSummaries'</span>]</span>
<span id="cb68-9">pipeline_execution_status <span class="op" style="color: #5E5E5E;">=</span> executions_response[<span class="dv" style="color: #AD0000;">0</span>][<span class="st" style="color: #20794D;">'PipelineExecutionStatus'</span>]</span>
<span id="cb68-10"><span class="bu" style="color: null;">print</span>(pipeline_execution_status)</span>
<span id="cb68-11"></span>
<span id="cb68-12"><span class="cf" style="color: #003B4F;">while</span> pipeline_execution_status<span class="op" style="color: #5E5E5E;">==</span><span class="st" style="color: #20794D;">'Executing'</span>:</span>
<span id="cb68-13">    <span class="cf" style="color: #003B4F;">try</span>:</span>
<span id="cb68-14">        executions_response <span class="op" style="color: #5E5E5E;">=</span> sm.list_pipeline_executions(PipelineName<span class="op" style="color: #5E5E5E;">=</span>pipeline_name)[<span class="st" style="color: #20794D;">'PipelineExecutionSummaries'</span>]</span>
<span id="cb68-15">        pipeline_execution_status <span class="op" style="color: #5E5E5E;">=</span> executions_response[<span class="dv" style="color: #AD0000;">0</span>][<span class="st" style="color: #20794D;">'PipelineExecutionStatus'</span>]</span>
<span id="cb68-16">    <span class="cf" style="color: #003B4F;">except</span> <span class="pp" style="color: #AD0000;">Exception</span> <span class="im" style="color: #00769E;">as</span> e:</span>
<span id="cb68-17">        <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">'Please wait...'</span>)</span>
<span id="cb68-18">        time.sleep(<span class="dv" style="color: #AD0000;">30</span>)    </span>
<span id="cb68-19">    </span>
<span id="cb68-20">pprint(executions_response)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Executing
Please wait...
Please wait...
Please wait...
Please wait...
Please wait...
Please wait...
Please wait...
Please wait...
Please wait...
Please wait...
Please wait...
Please wait...
Please wait...
Please wait...
Please wait...
Please wait...
Please wait...
Please wait...
Please wait...
[{'PipelineExecutionArn': 'arn:aws:sagemaker:us-east-1:912822595625:pipeline/bert-pipeline-1676208665/execution/h4inlmq7fqwk',
  'PipelineExecutionDisplayName': 'execution-1676209061894',
  'PipelineExecutionStatus': 'Succeeded',
  'StartTime': datetime.datetime(2023, 2, 12, 13, 37, 41, 761000, tzinfo=tzlocal())}]
CPU times: user 14.7 s, sys: 641 ms, total: 15.4 s
Wall time: 32min 38s</code></pre>
</div>
</div>
<p>We can list the execution steps to check out the status and artifacts:</p>
<div class="cell" data-outputid="35bed80d-fa02-4dbf-8dd7-1c049f4f2b14">
<div class="sourceCode cell-code" id="cb70" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb70-1">pipeline_execution_status <span class="op" style="color: #5E5E5E;">=</span> executions_response[<span class="dv" style="color: #AD0000;">0</span>][<span class="st" style="color: #20794D;">'PipelineExecutionStatus'</span>]</span>
<span id="cb70-2"><span class="bu" style="color: null;">print</span>(pipeline_execution_status)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Succeeded</code></pre>
</div>
</div>
<div class="cell" data-outputid="ae57cfe1-cc01-4d7f-9509-0a123e8f5fc5">
<div class="sourceCode cell-code" id="cb72" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb72-1">pipeline_execution_arn <span class="op" style="color: #5E5E5E;">=</span> executions_response[<span class="dv" style="color: #AD0000;">0</span>][<span class="st" style="color: #20794D;">'PipelineExecutionArn'</span>]</span>
<span id="cb72-2"><span class="bu" style="color: null;">print</span>(pipeline_execution_arn)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>arn:aws:sagemaker:us-east-1:912822595625:pipeline/bert-pipeline-1676208665/execution/h4inlmq7fqwk</code></pre>
</div>
</div>
</section>
</section>
<section id="evaluate-the-model" class="level2" data-number="12">
<h2 data-number="12" class="anchored" data-anchor-id="evaluate-the-model"><span class="header-section-number">12</span> Evaluate the model</h2>
<section id="describe-evaluation-metrics" class="level3" data-number="12.1">
<h3 data-number="12.1" class="anchored" data-anchor-id="describe-evaluation-metrics"><span class="header-section-number">12.1</span> Describe evaluation metrics</h3>
<p>Now we examine the resulting model evaluation after the pipeline completes.</p>
<div class="cell" data-outputid="71c01fc4-2b17-4b05-830c-b54ed89c1e7a">
<div class="sourceCode cell-code" id="cb74" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb74-1">processing_job_name <span class="op" style="color: #5E5E5E;">=</span> <span class="va" style="color: #111111;">None</span></span>
<span id="cb74-2"></span>
<span id="cb74-3"><span class="co" style="color: #5E5E5E;"># pull the processing step name</span></span>
<span id="cb74-4"><span class="cf" style="color: #003B4F;">for</span> execution_step <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">reversed</span>(execution.list_steps()):</span>
<span id="cb74-5">    <span class="cf" style="color: #003B4F;">if</span> execution_step[<span class="st" style="color: #20794D;">'StepName'</span>] <span class="op" style="color: #5E5E5E;">==</span> <span class="st" style="color: #20794D;">'Processing'</span>:</span>
<span id="cb74-6">        processing_job_name<span class="op" style="color: #5E5E5E;">=</span>execution_step[<span class="st" style="color: #20794D;">'Metadata'</span>][<span class="st" style="color: #20794D;">'ProcessingJob'</span>][<span class="st" style="color: #20794D;">'Arn'</span>].split(<span class="st" style="color: #20794D;">'/'</span>)[<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>]</span>
<span id="cb74-7"></span>
<span id="cb74-8"><span class="co" style="color: #5E5E5E;"># get the description of the processing job</span></span>
<span id="cb74-9">describe_transform_processing_job_response <span class="op" style="color: #5E5E5E;">=</span> sm.describe_processing_job(ProcessingJobName<span class="op" style="color: #5E5E5E;">=</span>processing_job_name)</span>
<span id="cb74-10"></span>
<span id="cb74-11"><span class="co" style="color: #5E5E5E;"># get the output S3 path</span></span>
<span id="cb74-12">transform_output_s3_uri <span class="op" style="color: #5E5E5E;">=</span> describe_transform_processing_job_response[<span class="st" style="color: #20794D;">'ProcessingOutputConfig'</span>][<span class="st" style="color: #20794D;">'Outputs'</span>][<span class="dv" style="color: #AD0000;">0</span>][<span class="st" style="color: #20794D;">'S3Output'</span>][<span class="st" style="color: #20794D;">'S3Uri'</span>]</span>
<span id="cb74-13"><span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">'Transform output </span><span class="sc" style="color: #5E5E5E;">{}</span><span class="st" style="color: #20794D;">'</span>.<span class="bu" style="color: null;">format</span>(transform_output_s3_uri))</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Transform output s3://sagemaker-us-east-1-912822595625/sagemaker-scikit-learn-2023-02-12-13-32-20-378/output/sentiment-train</code></pre>
</div>
</div>
<div class="cell" data-outputid="9e51d7c5-bbd5-4397-e79b-4a8112a8674d">
<div class="sourceCode cell-code" id="cb76" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb76-1"><span class="co" style="color: #5E5E5E;"># list the files in the resulting output S3 path</span></span>
<span id="cb76-2"><span class="op" style="color: #5E5E5E;">!</span>aws s3 ls <span class="op" style="color: #5E5E5E;">--</span>recursive $transform_output_s3_uri</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>2023-02-12 13:48:45    4882265 sagemaker-scikit-learn-2023-02-12-13-32-20-378/output/sentiment-train/part-algo-1-womens_clothing_ecommerce_reviews.tsv</code></pre>
</div>
</div>
<p>Let’s pull the name of the model-evaluation step and then get the S3 path of the evaluation metrics, which will contain the evaluation report.</p>
<div class="cell" data-outputid="89be571d-1417-4fff-ed89-7429df045686">
<div class="sourceCode cell-code" id="cb78" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb78-1">processing_job_name <span class="op" style="color: #5E5E5E;">=</span> <span class="va" style="color: #111111;">None</span></span>
<span id="cb78-2"></span>
<span id="cb78-3"><span class="cf" style="color: #003B4F;">for</span> execution_step <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">reversed</span>(execution.list_steps()):</span>
<span id="cb78-4">    <span class="cf" style="color: #003B4F;">if</span> execution_step[<span class="st" style="color: #20794D;">'StepName'</span>] <span class="op" style="color: #5E5E5E;">==</span> <span class="st" style="color: #20794D;">'EvaluateModel'</span>: </span>
<span id="cb78-5">        processing_job_name<span class="op" style="color: #5E5E5E;">=</span>execution_step[<span class="st" style="color: #20794D;">'Metadata'</span>][<span class="st" style="color: #20794D;">'ProcessingJob'</span>][<span class="st" style="color: #20794D;">'Arn'</span>].split(<span class="st" style="color: #20794D;">'/'</span>)[<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>]</span>
<span id="cb78-6"></span>
<span id="cb78-7">describe_evaluation_processing_job_response <span class="op" style="color: #5E5E5E;">=</span> sm.describe_processing_job(ProcessingJobName<span class="op" style="color: #5E5E5E;">=</span>processing_job_name)</span>
<span id="cb78-8"></span>
<span id="cb78-9">evaluation_metrics_s3_uri <span class="op" style="color: #5E5E5E;">=</span> describe_evaluation_processing_job_response[<span class="st" style="color: #20794D;">'ProcessingOutputConfig'</span>][<span class="st" style="color: #20794D;">'Outputs'</span>][<span class="dv" style="color: #AD0000;">0</span>][<span class="st" style="color: #20794D;">'S3Output'</span>][<span class="st" style="color: #20794D;">'S3Uri'</span>]</span>
<span id="cb78-10"><span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">'Evaluation output </span><span class="sc" style="color: #5E5E5E;">{}</span><span class="st" style="color: #20794D;">'</span>.<span class="bu" style="color: null;">format</span>(evaluation_metrics_s3_uri))</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Evaluation output s3://sagemaker-us-east-1-912822595625/sagemaker-scikit-learn-2023-02-12-13-35-32-414/output/metrics</code></pre>
</div>
</div>
</section>
<section id="review-the-evaluation-report" class="level3" data-number="12.2">
<h3 data-number="12.2" class="anchored" data-anchor-id="review-the-evaluation-report"><span class="header-section-number">12.2</span> Review the evaluation report</h3>
<p>Download the evaluation report and print the accuracy.</p>
<div class="cell" data-outputid="7b1c79b8-2c63-4392-d604-57888208403b">
<div class="sourceCode cell-code" id="cb80" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb80-1"><span class="im" style="color: #00769E;">from</span> pprint <span class="im" style="color: #00769E;">import</span> pprint</span>
<span id="cb80-2"></span>
<span id="cb80-3">evaluation_json <span class="op" style="color: #5E5E5E;">=</span> sagemaker.s3.S3Downloader.read_file(<span class="st" style="color: #20794D;">"</span><span class="sc" style="color: #5E5E5E;">{}</span><span class="st" style="color: #20794D;">/evaluation.json"</span>.<span class="bu" style="color: null;">format</span>(</span>
<span id="cb80-4">    evaluation_metrics_s3_uri</span>
<span id="cb80-5">))</span>
<span id="cb80-6"></span>
<span id="cb80-7">pprint(json.loads(evaluation_json))</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>{'metrics': {'accuracy': {'value': 0.7313915857605178}}}</code></pre>
</div>
</div>
</section>
<section id="list-pipeline-artifacts" class="level3" data-number="12.3">
<h3 data-number="12.3" class="anchored" data-anchor-id="list-pipeline-artifacts"><span class="header-section-number">12.3</span> List pipeline artifacts</h3>
<p>Now let’s find and print the ARN and job name of the training job.</p>
<div class="cell" data-outputid="7ab73b20-8c68-4d38-b603-d2bea3a64094">
<div class="sourceCode cell-code" id="cb82" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb82-1">training_job_arn<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">None</span></span>
<span id="cb82-2"></span>
<span id="cb82-3"><span class="cf" style="color: #003B4F;">for</span> execution_step <span class="kw" style="color: #003B4F;">in</span> execution.list_steps():</span>
<span id="cb82-4">    <span class="cf" style="color: #003B4F;">if</span> execution_step[<span class="st" style="color: #20794D;">'StepName'</span>] <span class="op" style="color: #5E5E5E;">==</span> <span class="st" style="color: #20794D;">'Train'</span>:</span>
<span id="cb82-5">        training_job_arn <span class="op" style="color: #5E5E5E;">=</span> execution_step[<span class="st" style="color: #20794D;">'Metadata'</span>][<span class="st" style="color: #20794D;">'TrainingJob'</span>][<span class="st" style="color: #20794D;">'Arn'</span>]        </span>
<span id="cb82-6">        pprint(execution_step)</span>
<span id="cb82-7">        <span class="cf" style="color: #003B4F;">break</span></span>
<span id="cb82-8"><span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">'Training job ARN: </span><span class="sc" style="color: #5E5E5E;">{}</span><span class="st" style="color: #20794D;">'</span>.<span class="bu" style="color: null;">format</span>(training_job_arn))</span>
<span id="cb82-9">        </span>
<span id="cb82-10">training_job_name <span class="op" style="color: #5E5E5E;">=</span> training_job_arn.split(<span class="st" style="color: #20794D;">'/'</span>)[<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>]</span>
<span id="cb82-11"><span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">'Training job Name: </span><span class="sc" style="color: #5E5E5E;">{}</span><span class="st" style="color: #20794D;">'</span>.<span class="bu" style="color: null;">format</span>(training_job_name))</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>{'AttemptCount': 0,
 'EndTime': datetime.datetime(2023, 2, 12, 14, 4, 49, 838000, tzinfo=tzlocal()),
 'Metadata': {'TrainingJob': {'Arn': 'arn:aws:sagemaker:us-east-1:912822595625:training-job/pipelines-h4inlmq7fqwk-Train-nYXyWGwBe5'}},
 'StartTime': datetime.datetime(2023, 2, 12, 13, 48, 54, 641000, tzinfo=tzlocal()),
 'StepName': 'Train',
 'StepStatus': 'Succeeded'}
Training job ARN: arn:aws:sagemaker:us-east-1:912822595625:training-job/pipelines-h4inlmq7fqwk-Train-nYXyWGwBe5
Training job Name: pipelines-h4inlmq7fqwk-Train-nYXyWGwBe5</code></pre>
</div>
</div>
<p>Using similar approach we can find and print the pipeline artifacts.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb84" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb84-1">processing_job_name<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">None</span></span>
<span id="cb84-2">training_job_name<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">None</span></span></code></pre></div>
</div>
<div class="cell" data-outputid="0cf68005-c1d1-4277-9e23-ea043e62f970">
<div class="sourceCode cell-code" id="cb85" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb85-1"><span class="im" style="color: #00769E;">import</span> time</span>
<span id="cb85-2"><span class="im" style="color: #00769E;">from</span> sagemaker.lineage.visualizer <span class="im" style="color: #00769E;">import</span> LineageTableVisualizer</span>
<span id="cb85-3"></span>
<span id="cb85-4">viz <span class="op" style="color: #5E5E5E;">=</span> LineageTableVisualizer(sagemaker.session.Session())</span>
<span id="cb85-5"></span>
<span id="cb85-6"><span class="cf" style="color: #003B4F;">for</span> execution_step <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">reversed</span>(execution.list_steps()):</span>
<span id="cb85-7">    pprint(execution_step)</span>
<span id="cb85-8">    <span class="cf" style="color: #003B4F;">if</span> execution_step[<span class="st" style="color: #20794D;">'StepName'</span>] <span class="op" style="color: #5E5E5E;">==</span> <span class="st" style="color: #20794D;">'Processing'</span>:</span>
<span id="cb85-9">        processing_job_name<span class="op" style="color: #5E5E5E;">=</span>execution_step[<span class="st" style="color: #20794D;">'Metadata'</span>][<span class="st" style="color: #20794D;">'ProcessingJob'</span>][<span class="st" style="color: #20794D;">'Arn'</span>].split(<span class="st" style="color: #20794D;">'/'</span>)[<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>]</span>
<span id="cb85-10">        <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">'Processing job name: </span><span class="sc" style="color: #5E5E5E;">{}</span><span class="st" style="color: #20794D;">'</span>.<span class="bu" style="color: null;">format</span>(processing_job_name))</span>
<span id="cb85-11">        display(viz.show(processing_job_name<span class="op" style="color: #5E5E5E;">=</span>processing_job_name))</span>
<span id="cb85-12">    <span class="cf" style="color: #003B4F;">elif</span> execution_step[<span class="st" style="color: #20794D;">'StepName'</span>] <span class="op" style="color: #5E5E5E;">==</span> <span class="st" style="color: #20794D;">'Train'</span>:</span>
<span id="cb85-13">        training_job_name<span class="op" style="color: #5E5E5E;">=</span>execution_step[<span class="st" style="color: #20794D;">'Metadata'</span>][<span class="st" style="color: #20794D;">'TrainingJob'</span>][<span class="st" style="color: #20794D;">'Arn'</span>].split(<span class="st" style="color: #20794D;">'/'</span>)[<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>]</span>
<span id="cb85-14">        <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">'Training job name: </span><span class="sc" style="color: #5E5E5E;">{}</span><span class="st" style="color: #20794D;">'</span>.<span class="bu" style="color: null;">format</span>(training_job_name))</span>
<span id="cb85-15">        display(viz.show(training_job_name<span class="op" style="color: #5E5E5E;">=</span>training_job_name))</span>
<span id="cb85-16">    <span class="cf" style="color: #003B4F;">else</span>:</span>
<span id="cb85-17">        display(viz.show(pipeline_execution_step<span class="op" style="color: #5E5E5E;">=</span>execution_step))</span>
<span id="cb85-18">        time.sleep(<span class="dv" style="color: #AD0000;">5</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>{'AttemptCount': 0,
 'EndTime': datetime.datetime(2023, 2, 12, 13, 48, 53, 920000, tzinfo=tzlocal()),
 'Metadata': {'ProcessingJob': {'Arn': 'arn:aws:sagemaker:us-east-1:912822595625:processing-job/pipelines-h4inlmq7fqwk-processing-mwnbfz07z3'}},
 'StartTime': datetime.datetime(2023, 2, 12, 13, 37, 42, 570000, tzinfo=tzlocal()),
 'StepName': 'Processing',
 'StepStatus': 'Succeeded'}
Processing job name: pipelines-h4inlmq7fqwk-processing-mwnbfz07z3</code></pre>
</div>
<div class="cell-output cell-output-display">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>Name/Source</th>
      <th>Direction</th>
      <th>Type</th>
      <th>Association Type</th>
      <th>Lineage Type</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>s3://...-13-37-36-257/input/code/prepare_data.py</td>
      <td>Input</td>
      <td>DataSet</td>
      <td>ContributedTo</td>
      <td>artifact</td>
    </tr>
    <tr>
      <th>1</th>
      <td>s3://dlai-practical-data-science/data/raw/</td>
      <td>Input</td>
      <td>DataSet</td>
      <td>ContributedTo</td>
      <td>artifact</td>
    </tr>
    <tr>
      <th>2</th>
      <td>68331...om/sagemaker-scikit-learn:0.23-1-cpu-py3</td>
      <td>Input</td>
      <td>Image</td>
      <td>ContributedTo</td>
      <td>artifact</td>
    </tr>
    <tr>
      <th>3</th>
      <td>s3://...02-12-13-32-20-378/output/sentiment-test</td>
      <td>Output</td>
      <td>DataSet</td>
      <td>Produced</td>
      <td>artifact</td>
    </tr>
    <tr>
      <th>4</th>
      <td>s3://...13-32-20-378/output/sentiment-validation</td>
      <td>Output</td>
      <td>DataSet</td>
      <td>Produced</td>
      <td>artifact</td>
    </tr>
    <tr>
      <th>5</th>
      <td>s3://...2-12-13-32-20-378/output/sentiment-train</td>
      <td>Output</td>
      <td>DataSet</td>
      <td>Produced</td>
      <td>artifact</td>
    </tr>
  </tbody>
</table>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>{'AttemptCount': 0,
 'EndTime': datetime.datetime(2023, 2, 12, 14, 4, 49, 838000, tzinfo=tzlocal()),
 'Metadata': {'TrainingJob': {'Arn': 'arn:aws:sagemaker:us-east-1:912822595625:training-job/pipelines-h4inlmq7fqwk-Train-nYXyWGwBe5'}},
 'StartTime': datetime.datetime(2023, 2, 12, 13, 48, 54, 641000, tzinfo=tzlocal()),
 'StepName': 'Train',
 'StepStatus': 'Succeeded'}
Training job name: pipelines-h4inlmq7fqwk-Train-nYXyWGwBe5</code></pre>
</div>
<div class="cell-output cell-output-display">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>Name/Source</th>
      <th>Direction</th>
      <th>Type</th>
      <th>Association Type</th>
      <th>Lineage Type</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>s3://...13-32-20-378/output/sentiment-validation</td>
      <td>Input</td>
      <td>DataSet</td>
      <td>ContributedTo</td>
      <td>artifact</td>
    </tr>
    <tr>
      <th>1</th>
      <td>s3://...2-12-13-32-20-378/output/sentiment-train</td>
      <td>Input</td>
      <td>DataSet</td>
      <td>ContributedTo</td>
      <td>artifact</td>
    </tr>
    <tr>
      <th>2</th>
      <td>76310...onaws.com/pytorch-training:1.6.0-cpu-py3</td>
      <td>Input</td>
      <td>Image</td>
      <td>ContributedTo</td>
      <td>artifact</td>
    </tr>
    <tr>
      <th>3</th>
      <td>s3://...qwk-Train-nYXyWGwBe5/output/model.tar.gz</td>
      <td>Output</td>
      <td>Model</td>
      <td>Produced</td>
      <td>artifact</td>
    </tr>
  </tbody>
</table>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>{'AttemptCount': 0,
 'EndTime': datetime.datetime(2023, 2, 12, 14, 10, 48, 729000, tzinfo=tzlocal()),
 'Metadata': {'ProcessingJob': {'Arn': 'arn:aws:sagemaker:us-east-1:912822595625:processing-job/pipelines-h4inlmq7fqwk-evaluatemodel-uqvunnu2ks'}},
 'StartTime': datetime.datetime(2023, 2, 12, 14, 4, 50, 615000, tzinfo=tzlocal()),
 'StepName': 'EvaluateModel',
 'StepStatus': 'Succeeded'}</code></pre>
</div>
<div class="cell-output cell-output-display">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>Name/Source</th>
      <th>Direction</th>
      <th>Type</th>
      <th>Association Type</th>
      <th>Lineage Type</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>s3://...640/input/code/evaluate_model_metrics.py</td>
      <td>Input</td>
      <td>DataSet</td>
      <td>ContributedTo</td>
      <td>artifact</td>
    </tr>
    <tr>
      <th>1</th>
      <td>s3://...02-12-13-32-20-378/output/sentiment-test</td>
      <td>Input</td>
      <td>DataSet</td>
      <td>ContributedTo</td>
      <td>artifact</td>
    </tr>
    <tr>
      <th>2</th>
      <td>s3://...qwk-Train-nYXyWGwBe5/output/model.tar.gz</td>
      <td>Input</td>
      <td>Model</td>
      <td>ContributedTo</td>
      <td>artifact</td>
    </tr>
    <tr>
      <th>3</th>
      <td>68331...om/sagemaker-scikit-learn:0.23-1-cpu-py3</td>
      <td>Input</td>
      <td>Image</td>
      <td>ContributedTo</td>
      <td>artifact</td>
    </tr>
    <tr>
      <th>4</th>
      <td>s3://...n-2023-02-12-13-35-32-414/output/metrics</td>
      <td>Output</td>
      <td>DataSet</td>
      <td>Produced</td>
      <td>artifact</td>
    </tr>
  </tbody>
</table>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>{'AttemptCount': 0,
 'EndTime': datetime.datetime(2023, 2, 12, 14, 10, 50, 320000, tzinfo=tzlocal()),
 'Metadata': {'Condition': {'Outcome': 'True'}},
 'StartTime': datetime.datetime(2023, 2, 12, 14, 10, 49, 585000, tzinfo=tzlocal()),
 'StepName': 'AccuracyCondition',
 'StepStatus': 'Succeeded'}</code></pre>
</div>
<div class="cell-output cell-output-display">
<pre><code>None</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>{'AttemptCount': 0,
 'EndTime': datetime.datetime(2023, 2, 12, 14, 10, 52, 545000, tzinfo=tzlocal()),
 'Metadata': {'Model': {'Arn': 'arn:aws:sagemaker:us-east-1:912822595625:model/pipelines-h4inlmq7fqwk-createmodel-tu0lobcfq6'}},
 'StartTime': datetime.datetime(2023, 2, 12, 14, 10, 51, 78000, tzinfo=tzlocal()),
 'StepName': 'CreateModel',
 'StepStatus': 'Succeeded'}</code></pre>
</div>
<div class="cell-output cell-output-display">
<pre><code>None</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>{'AttemptCount': 0,
 'EndTime': datetime.datetime(2023, 2, 12, 14, 10, 52, 324000, tzinfo=tzlocal()),
 'Metadata': {'RegisterModel': {'Arn': 'arn:aws:sagemaker:us-east-1:912822595625:model-package/bert-reviews-1676208665/1'}},
 'StartTime': datetime.datetime(2023, 2, 12, 14, 10, 51, 78000, tzinfo=tzlocal()),
 'StepName': 'RegisterModel',
 'StepStatus': 'Succeeded'}</code></pre>
</div>
<div class="cell-output cell-output-display">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>Name/Source</th>
      <th>Direction</th>
      <th>Type</th>
      <th>Association Type</th>
      <th>Lineage Type</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>s3://...qwk-Train-nYXyWGwBe5/output/model.tar.gz</td>
      <td>Input</td>
      <td>Model</td>
      <td>ContributedTo</td>
      <td>artifact</td>
    </tr>
    <tr>
      <th>1</th>
      <td>76310...aws.com/pytorch-inference:1.6.0-cpu-py36</td>
      <td>Input</td>
      <td>Image</td>
      <td>ContributedTo</td>
      <td>artifact</td>
    </tr>
    <tr>
      <th>2</th>
      <td>bert-reviews-1676208665-1-PendingManualApprova...</td>
      <td>Input</td>
      <td>Approval</td>
      <td>ContributedTo</td>
      <td>action</td>
    </tr>
    <tr>
      <th>3</th>
      <td>BERT-Reviews-1676208665-1676211052-aws-model-p...</td>
      <td>Output</td>
      <td>ModelGroup</td>
      <td>AssociatedWith</td>
      <td>context</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
</section>
</section>
<section id="deploy-and-test-the-model" class="level2" data-number="13">
<h2 data-number="13" class="anchored" data-anchor-id="deploy-and-test-the-model"><span class="header-section-number">13</span> Deploy and test the model</h2>
<section id="approve-trained-model" class="level3" data-number="13.1">
<h3 data-number="13.1" class="anchored" data-anchor-id="approve-trained-model"><span class="header-section-number">13.1</span> Approve trained model</h3>
<p>The pipeline created a model package version within the specified model package group and an approval status of <code>PendingManualApproval</code>. This requires a separate step to manually approve the model before deploying to production.</p>
<p>We can approve the model using the SageMaker Studio UI or programmatically as shown below.</p>
<p>Get the model package ARN.</p>
<div class="cell" data-outputid="b5a1f02f-625f-43b6-9c17-18972e1ca6b1">
<div class="sourceCode cell-code" id="cb94" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb94-1"><span class="cf" style="color: #003B4F;">for</span> execution_step <span class="kw" style="color: #003B4F;">in</span> execution.list_steps():</span>
<span id="cb94-2">    <span class="cf" style="color: #003B4F;">if</span> execution_step[<span class="st" style="color: #20794D;">'StepName'</span>] <span class="op" style="color: #5E5E5E;">==</span> <span class="st" style="color: #20794D;">'RegisterModel'</span>:</span>
<span id="cb94-3">        model_package_arn <span class="op" style="color: #5E5E5E;">=</span> execution_step[<span class="st" style="color: #20794D;">'Metadata'</span>][<span class="st" style="color: #20794D;">'RegisterModel'</span>][<span class="st" style="color: #20794D;">'Arn'</span>]</span>
<span id="cb94-4">        <span class="cf" style="color: #003B4F;">break</span></span>
<span id="cb94-5"><span class="bu" style="color: null;">print</span>(model_package_arn)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>arn:aws:sagemaker:us-east-1:912822595625:model-package/bert-reviews-1676208665/1</code></pre>
</div>
</div>
<p>Update the model package with the <code>Approved</code> status to prepare for deployment.</p>
<p>The model must be <code>Approved</code> before it can be deployed.</p>
<div class="cell" data-outputid="49ae389d-3b0b-4529-b77c-09f035f94b9c">
<div class="sourceCode cell-code" id="cb96" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb96-1">model_package_update_response <span class="op" style="color: #5E5E5E;">=</span> sm.update_model_package(</span>
<span id="cb96-2">    ModelPackageArn<span class="op" style="color: #5E5E5E;">=</span>model_package_arn,</span>
<span id="cb96-3">    ModelApprovalStatus<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"Approved"</span>,</span>
<span id="cb96-4">)</span>
<span id="cb96-5"></span>
<span id="cb96-6">pprint(model_package_update_response)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>{'ModelPackageArn': 'arn:aws:sagemaker:us-east-1:912822595625:model-package/bert-reviews-1676208665/1',
 'ResponseMetadata': {'HTTPHeaders': {'content-length': '102',
                                      'content-type': 'application/x-amz-json-1.1',
                                      'date': 'Sun, 12 Feb 2023 14:15:24 GMT',
                                      'x-amzn-requestid': '95e70fcf-b3f0-4925-be40-73450c40a5ec'},
                      'HTTPStatusCode': 200,
                      'RequestId': '95e70fcf-b3f0-4925-be40-73450c40a5ec',
                      'RetryAttempts': 0}}</code></pre>
</div>
</div>
</section>
<section id="deploy-model" class="level3" data-number="13.2">
<h3 data-number="13.2" class="anchored" data-anchor-id="deploy-model"><span class="header-section-number">13.2</span> Deploy model</h3>
<p>Get the model ARN and the model name from it.</p>
<div class="cell" data-outputid="4a79b3a9-63ca-4182-dfed-063d0827cb1b">
<div class="sourceCode cell-code" id="cb98" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb98-1"><span class="cf" style="color: #003B4F;">for</span> execution_step <span class="kw" style="color: #003B4F;">in</span> execution.list_steps():</span>
<span id="cb98-2">    <span class="bu" style="color: null;">print</span>(execution_step[<span class="st" style="color: #20794D;">'StepName'</span>])</span>
<span id="cb98-3">    <span class="cf" style="color: #003B4F;">if</span> execution_step[<span class="st" style="color: #20794D;">'StepName'</span>] <span class="op" style="color: #5E5E5E;">==</span> <span class="st" style="color: #20794D;">'CreateModel'</span>:</span>
<span id="cb98-4">        model_arn <span class="op" style="color: #5E5E5E;">=</span> execution_step[<span class="st" style="color: #20794D;">'Metadata'</span>][<span class="st" style="color: #20794D;">'Model'</span>][<span class="st" style="color: #20794D;">'Arn'</span>]</span>
<span id="cb98-5">        <span class="cf" style="color: #003B4F;">break</span></span>
<span id="cb98-6"><span class="bu" style="color: null;">print</span>(model_arn)</span>
<span id="cb98-7"></span>
<span id="cb98-8">model_name <span class="op" style="color: #5E5E5E;">=</span> model_arn.split(<span class="st" style="color: #20794D;">'/'</span>)[<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>]</span>
<span id="cb98-9"><span class="bu" style="color: null;">print</span>(model_name)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>RegisterModel
CreateModel
arn:aws:sagemaker:us-east-1:912822595625:model/pipelines-h4inlmq7fqwk-createmodel-tu0lobcfq6
pipelines-h4inlmq7fqwk-createmodel-tu0lobcfq6</code></pre>
</div>
</div>
</section>
<section id="create-endpoint-from-registry" class="level3" data-number="13.3">
<h3 data-number="13.3" class="anchored" data-anchor-id="create-endpoint-from-registry"><span class="header-section-number">13.3</span> Create endpoint from registry</h3>
<p>Configure the endpoint.</p>
<div class="cell" data-outputid="8d65d1cc-8ed2-4682-8eae-52ad417070e9">
<div class="sourceCode cell-code" id="cb100" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb100-1">endpoint_config_name <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">'bert-model-epc-</span><span class="sc" style="color: #5E5E5E;">{}</span><span class="st" style="color: #20794D;">'</span>.<span class="bu" style="color: null;">format</span>(timestamp)</span>
<span id="cb100-2"><span class="bu" style="color: null;">print</span>(endpoint_config_name)</span>
<span id="cb100-3"></span>
<span id="cb100-4">create_endpoint_config_response <span class="op" style="color: #5E5E5E;">=</span> sm.create_endpoint_config(</span>
<span id="cb100-5">    EndpointConfigName <span class="op" style="color: #5E5E5E;">=</span> endpoint_config_name,</span>
<span id="cb100-6">    ProductionVariants<span class="op" style="color: #5E5E5E;">=</span>[{</span>
<span id="cb100-7">        <span class="st" style="color: #20794D;">'InstanceType'</span>:<span class="st" style="color: #20794D;">'ml.m5.xlarge'</span>,</span>
<span id="cb100-8">        <span class="st" style="color: #20794D;">'InitialVariantWeight'</span>:<span class="dv" style="color: #AD0000;">1</span>,</span>
<span id="cb100-9">        <span class="st" style="color: #20794D;">'InitialInstanceCount'</span>:<span class="dv" style="color: #AD0000;">1</span>,</span>
<span id="cb100-10">        <span class="st" style="color: #20794D;">'ModelName'</span>: model_name,</span>
<span id="cb100-11">        <span class="st" style="color: #20794D;">'VariantName'</span>:<span class="st" style="color: #20794D;">'AllTraffic'</span>}])</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>bert-model-epc-1676208665</code></pre>
</div>
</div>
<p>Create the endpoint.</p>
<div class="cell" data-outputid="8e6c05ae-6a88-4e71-fc09-307995983c70">
<div class="sourceCode cell-code" id="cb102" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb102-1">pipeline_endpoint_name <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">'bert-model-ep-</span><span class="sc" style="color: #5E5E5E;">{}</span><span class="st" style="color: #20794D;">'</span>.<span class="bu" style="color: null;">format</span>(timestamp)</span>
<span id="cb102-2"><span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">"EndpointName=</span><span class="sc" style="color: #5E5E5E;">{}</span><span class="st" style="color: #20794D;">"</span>.<span class="bu" style="color: null;">format</span>(pipeline_endpoint_name))</span>
<span id="cb102-3"></span>
<span id="cb102-4">create_endpoint_response <span class="op" style="color: #5E5E5E;">=</span> sm.create_endpoint(</span>
<span id="cb102-5">    EndpointName<span class="op" style="color: #5E5E5E;">=</span>pipeline_endpoint_name,</span>
<span id="cb102-6">    EndpointConfigName<span class="op" style="color: #5E5E5E;">=</span>endpoint_config_name)</span>
<span id="cb102-7"><span class="bu" style="color: null;">print</span>(create_endpoint_response[<span class="st" style="color: #20794D;">'EndpointArn'</span>])</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>EndpointName=bert-model-ep-1676208665
arn:aws:sagemaker:us-east-1:912822595625:endpoint/bert-model-ep-1676208665</code></pre>
</div>
</div>
<div class="cell" data-outputid="816fc01f-bff8-404c-fe80-f4d416405b6a">
<div class="sourceCode cell-code" id="cb104" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb104-1"><span class="op" style="color: #5E5E5E;">%%</span>time</span>
<span id="cb104-2"></span>
<span id="cb104-3"><span class="cf" style="color: #003B4F;">while</span> <span class="va" style="color: #111111;">True</span>:</span>
<span id="cb104-4">    <span class="cf" style="color: #003B4F;">try</span>: </span>
<span id="cb104-5">        waiter <span class="op" style="color: #5E5E5E;">=</span> sm.get_waiter(<span class="st" style="color: #20794D;">'endpoint_in_service'</span>)</span>
<span id="cb104-6">        <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">'Waiting for endpoint to be in `InService`...'</span>)</span>
<span id="cb104-7">        waiter.wait(EndpointName<span class="op" style="color: #5E5E5E;">=</span>pipeline_endpoint_name)</span>
<span id="cb104-8">        <span class="cf" style="color: #003B4F;">break</span><span class="op" style="color: #5E5E5E;">;</span></span>
<span id="cb104-9">    <span class="cf" style="color: #003B4F;">except</span>:</span>
<span id="cb104-10">        <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">'Waiting for endpoint...'</span>)</span>
<span id="cb104-11">        endpoint_status <span class="op" style="color: #5E5E5E;">=</span> sm.describe_endpoint(EndpointName<span class="op" style="color: #5E5E5E;">=</span>pipeline_endpoint_name)[<span class="st" style="color: #20794D;">'EndpointStatus'</span>]</span>
<span id="cb104-12">        <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">'Endpoint status: </span><span class="sc" style="color: #5E5E5E;">{}</span><span class="st" style="color: #20794D;">'</span>.<span class="bu" style="color: null;">format</span>(endpoint_status))</span>
<span id="cb104-13">        <span class="cf" style="color: #003B4F;">if</span> endpoint_status <span class="op" style="color: #5E5E5E;">==</span> <span class="st" style="color: #20794D;">'Failed'</span>:</span>
<span id="cb104-14">            <span class="cf" style="color: #003B4F;">break</span></span>
<span id="cb104-15">        time.sleep(<span class="dv" style="color: #AD0000;">30</span>)</span>
<span id="cb104-16">        </span>
<span id="cb104-17"><span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">'Endpoint deployed.'</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Waiting for endpoint to be in `InService`...
Endpoint deployed.
CPU times: user 109 ms, sys: 30.6 ms, total: 140 ms
Wall time: 4min 31s</code></pre>
</div>
</div>
</section>
<section id="test-model" class="level3" data-number="13.4">
<h3 data-number="13.4" class="anchored" data-anchor-id="test-model"><span class="header-section-number">13.4</span> Test model</h3>
<p>Let’s predict the <code>sentiment</code> with <code>review_body</code> samples and review the result:</p>
<div class="cell" data-outputid="09f68f38-d201-44c0-a111-5ff2b2b7da19">
<div class="sourceCode cell-code" id="cb106" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb106-1"><span class="im" style="color: #00769E;">from</span> sagemaker.predictor <span class="im" style="color: #00769E;">import</span> Predictor</span>
<span id="cb106-2"><span class="im" style="color: #00769E;">from</span> sagemaker.serializers <span class="im" style="color: #00769E;">import</span> JSONLinesSerializer</span>
<span id="cb106-3"><span class="im" style="color: #00769E;">from</span> sagemaker.deserializers <span class="im" style="color: #00769E;">import</span> JSONLinesDeserializer</span>
<span id="cb106-4"></span>
<span id="cb106-5">inputs <span class="op" style="color: #5E5E5E;">=</span> [</span>
<span id="cb106-6">    {<span class="st" style="color: #20794D;">"features"</span>: [<span class="st" style="color: #20794D;">"I love this product!"</span>]},</span>
<span id="cb106-7">    {<span class="st" style="color: #20794D;">"features"</span>: [<span class="st" style="color: #20794D;">"OK, but not great."</span>]},</span>
<span id="cb106-8">    {<span class="st" style="color: #20794D;">"features"</span>: [<span class="st" style="color: #20794D;">"This is not the right product."</span>]},</span>
<span id="cb106-9">]</span>
<span id="cb106-10"></span>
<span id="cb106-11">predictor <span class="op" style="color: #5E5E5E;">=</span> Predictor(</span>
<span id="cb106-12">    endpoint_name<span class="op" style="color: #5E5E5E;">=</span>pipeline_endpoint_name,</span>
<span id="cb106-13">    serializer<span class="op" style="color: #5E5E5E;">=</span>JSONLinesSerializer(),</span>
<span id="cb106-14">    deserializer<span class="op" style="color: #5E5E5E;">=</span>JSONLinesDeserializer(),</span>
<span id="cb106-15">    sagemaker_session<span class="op" style="color: #5E5E5E;">=</span>sess</span>
<span id="cb106-16">)</span>
<span id="cb106-17"></span>
<span id="cb106-18">predicted_classes <span class="op" style="color: #5E5E5E;">=</span> predictor.predict(inputs)</span>
<span id="cb106-19"></span>
<span id="cb106-20"><span class="cf" style="color: #003B4F;">for</span> predicted_class <span class="kw" style="color: #003B4F;">in</span> predicted_classes:</span>
<span id="cb106-21">    <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">"Predicted class </span><span class="sc" style="color: #5E5E5E;">{}</span><span class="st" style="color: #20794D;"> with probability </span><span class="sc" style="color: #5E5E5E;">{}</span><span class="st" style="color: #20794D;">"</span>.<span class="bu" style="color: null;">format</span>(predicted_class[<span class="st" style="color: #20794D;">'predicted_label'</span>], predicted_class[<span class="st" style="color: #20794D;">'probability'</span>]))</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Predicted class 1 with probability 0.9203698635101318
Predicted class 0 with probability 0.44024962186813354
Predicted class -1 with probability 0.778016209602356</code></pre>
</div>
</div>
</section>
<section id="sagemaker-studio-extensions" class="level3" data-number="13.5">
<h3 data-number="13.5" class="anchored" data-anchor-id="sagemaker-studio-extensions"><span class="header-section-number">13.5</span> SageMaker Studio extensions</h3>
<p>SageMaker Studio provides a rich set of features to visually inspect SageMaker resources including pipelines, training jobs, and endpoints.</p>
<p><img src="http://livingdatalab.com/posts/https:/github.com/pranath/blog/raw/master/images/sm_studio_extensions_pipelines.png" title="Sagemaker Studio Extensions" class="img-fluid"></p>
</section>
</section>
<section id="acknowledgements" class="level2" data-number="14">
<h2 data-number="14" class="anchored" data-anchor-id="acknowledgements"><span class="header-section-number">14</span> Acknowledgements</h2>
<p>I’d like to express my thanks to the great <a href="https://www.deeplearning.ai/courses/practical-data-science-specialization/">Deep Learning AI Practical Data Science on AWS Specialisation Course</a> which i completed, and acknowledge the use of some images and other materials from the training course in this article.</p>


</section>

 ]]></description>
  <category>aws</category>
  <category>cloud-data-science</category>
  <category>natural-language-processing</category>
  <category>deep-learning</category>
  <guid>http://livingdatalab.com/posts/2023-02-12-building-aws-sagemaker-pipeline-train-deploy-bert-text-classifier.html</guid>
  <pubDate>Sun, 12 Feb 2023 00:00:00 GMT</pubDate>
  <media:content url="https://github.com/pranath/blog/raw/master/images/aws3.png" medium="image" type="image/png"/>
</item>
<item>
  <title>Train a Review Classifier with BERT and Amazon SageMaker</title>
  <dc:creator>Pranath Fernando</dc:creator>
  <link>http://livingdatalab.com/posts/2023-02-11-train-reviews-text-classifier-with-bert-and-aws-sagemaker.html</link>
  <description><![CDATA[ 




<section id="introduction" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="introduction"><span class="header-section-number">1</span> Introduction</h2>
<p>In the previous article we performed <a href="2023-02-08-feature-transformation-aws-sagemaker-processing-job-feature-store.html">Feature Engineering on a raw dataset of product text reviews</a> using AWS Sagemaker, preparing it for training the model. Now we will train a text classifier using a variant of BERT called <a href="https://arxiv.org/abs/1907.11692">RoBERTa</a> - a Robustly Optimized BERT Pretraining Approach - within a PyTorch model ran as a SageMaker Training Job.</p>
<p>Let’s review the Amazon SageMaker “Bring Your Own Script” scheme:</p>
<p><img src="http://livingdatalab.com/posts/https:/github.com/pranath/blog/raw/master/images/sagemaker_scriptmode.png" title="AWS Bring your own script scheme" class="img-fluid"></p>
<p>In this project we will cover each part of this scheme. First, we need to install and import the required modules:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;">import</span> boto3</span>
<span id="cb1-2"><span class="im" style="color: #00769E;">import</span> sagemaker</span>
<span id="cb1-3"><span class="im" style="color: #00769E;">import</span> pandas <span class="im" style="color: #00769E;">as</span> pd</span>
<span id="cb1-4"><span class="im" style="color: #00769E;">import</span> numpy <span class="im" style="color: #00769E;">as</span> np</span>
<span id="cb1-5"><span class="im" style="color: #00769E;">import</span> botocore</span>
<span id="cb1-6"></span>
<span id="cb1-7">config <span class="op" style="color: #5E5E5E;">=</span> botocore.config.Config(user_agent_extra<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'dlai-pds/c2/w2'</span>)</span>
<span id="cb1-8"></span>
<span id="cb1-9"><span class="co" style="color: #5E5E5E;"># low-level service client of the boto3 session</span></span>
<span id="cb1-10">sm <span class="op" style="color: #5E5E5E;">=</span> boto3.client(service_name<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'sagemaker'</span>, </span>
<span id="cb1-11">                  config<span class="op" style="color: #5E5E5E;">=</span>config)</span>
<span id="cb1-12"></span>
<span id="cb1-13">sm_runtime <span class="op" style="color: #5E5E5E;">=</span> boto3.client(<span class="st" style="color: #20794D;">'sagemaker-runtime'</span>,</span>
<span id="cb1-14">                          config<span class="op" style="color: #5E5E5E;">=</span>config)</span>
<span id="cb1-15"></span>
<span id="cb1-16">sess <span class="op" style="color: #5E5E5E;">=</span> sagemaker.Session(sagemaker_client<span class="op" style="color: #5E5E5E;">=</span>sm,</span>
<span id="cb1-17">                         sagemaker_runtime_client<span class="op" style="color: #5E5E5E;">=</span>sm_runtime)</span>
<span id="cb1-18"></span>
<span id="cb1-19">bucket <span class="op" style="color: #5E5E5E;">=</span> sess.default_bucket()</span>
<span id="cb1-20">role <span class="op" style="color: #5E5E5E;">=</span> sagemaker.get_execution_role()</span>
<span id="cb1-21">region <span class="op" style="color: #5E5E5E;">=</span> sess.boto_region_name</span></code></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="im" style="color: #00769E;">import</span> matplotlib.pyplot <span class="im" style="color: #00769E;">as</span> plt</span>
<span id="cb2-2"><span class="op" style="color: #5E5E5E;">%</span>matplotlib inline</span>
<span id="cb2-3"><span class="op" style="color: #5E5E5E;">%</span>config InlineBackend.figure_format<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'retina'</span></span></code></pre></div>
</div>
</section>
<section id="aws-built-in-algorithms-vs-pre-trained-models" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="aws-built-in-algorithms-vs-pre-trained-models"><span class="header-section-number">2</span> AWS Built-in algorithms vs Pre-Trained Models</h2>
<p>Training an NLP model from scratch can be a very time-consuming and expensive. For example, training the BERT models 110 or 340 million parameters from scratch could take multiple days, depending on the CPU or GPU resources you have available. Luckily, there are many pretrained models available, which you can use to simply adapt them to your use case and your data set.</p>
<p>Lets also highlight the differences between AWS built-in algorithms and pretrained models. In <a href="https://livingdatalab.com/categories/#aws">earlier articles</a>, we looked at how to use built-in AWS algorithms, for example, the blazing text algorithm, to quickly train a model.</p>
<p>The built-in algorithm all required code to train the text classifier. We just pointed the algorithm to the prepared training data. In this project, we will work with pretrained models. <strong>The main difference here is that the model has already been trained on large collections of text data.</strong> For example, wikipedia text data.</p>
<p>We looked at <a href="https://livingdatalab.com/categories/#fastai">pre-trained deep learning models previously as the Fastai deep learning library provides these by default</a>.</p>
<p>With pre-trained models there are usually 2 steps:</p>
<ul>
<li><strong>Model pre-training</strong>: a task to help the model understand language better e.g.&nbsp;to predict the next word in a sequence</li>
<li><strong>Model fine-tuning</strong>: the main task at hand, where we use the pre-trained model that already understands language well and then customise that for a task e.g.&nbsp;classify text for sentiment</li>
</ul>
<p><img src="http://livingdatalab.com/posts/https:/github.com/pranath/blog/raw/master/images/aws_model_pretrain_finetune.png" title="Pre-training and fine tuning models" class="img-fluid"></p>
<p>This helps improve the speed and performance of training a deep learning model by using a pre-training step, as opposed to say training a deep learning text classifier from scratch. This concept is also known as <em>transfer learning</em>.</p>
<p>Here using AWS we will provide specific text data, the product reviews data, to adapt a pre-trained model to our text domain and also provide the task and model training code. We wll be telling the pretrained model to perform a text classification task, with the three sentiment classes supplied.</p>
</section>
<section id="pre-trained-bert-and-roberta-models" class="level2" data-number="3">
<h2 data-number="3" class="anchored" data-anchor-id="pre-trained-bert-and-roberta-models"><span class="header-section-number">3</span> Pre-Trained BERT and Roberta Models</h2>
<p>While you can use BERT as is without training from scratch, it’s useful to understand how BERT uses word masking and next sentence prediction in parallel to learn and understand language. As BERT sees new text, the model masks 15 percent of the words in each sentence. BERT then predicts the masked words and corrects itself, meaning it updates the model weights when it predicts incorrectly.</p>
<p>This step is called <em>masked language model or masked LM</em>. Masking forces the model to learn the surrounding words for each sentence. At the same time, BERT is masking and predicting words, or to be more precise, input tokens. It is also performing next sentence prediction, or NSP, on pairs of input sequences.</p>
<p><img src="http://livingdatalab.com/posts/https:/github.com/pranath/blog/raw/master/images/aws_bert_pretrain.png" title="Pretraining a BERT Model" class="img-fluid"></p>
<p>To perform NSP, BERT randomly chooses 50 percent of the sentence pairs and replaces one of the two sentences with a random sentence from another part of the document. BERT then predicts if the two sentences are a valid sentence pair or not. BERT again will correct itself when it predicts incorrectly. Both of those training tasks are performed in parallel to create a single accuracy score for the combined training efforts.</p>
<p>This results in a more robust model capable of performing word and sentence level predictive tasks. The input data is large collections of unlabeled text.</p>
<p><img src="http://livingdatalab.com/posts/https:/github.com/pranath/blog/raw/master/images/aws_bert_finetune.png" title="Finetuning a BERT Model" class="img-fluid"></p>
<p>Since BERT has already been pre-trained on millions of public documents from Wikipedia and the Google Books corpus, the vocabulary and learned representations are indeed transferable to a large number of NLP and NLU tasks across a wide variety of domains.</p>
<p>In the fine-tuning step, you also configure the model for the actual NLP task, such as question and answer, text classification, or a named entity recognition. Fine-tuning is implemented as supervised learning and no masking or next sentence prediction happens. As a result, fine-tuning is very fast and requires a relatively small number of samples or product reviews, in our case.</p>
<p>The RoBERTa model architecture builds on BERT’s language masking strategy, but removes the next sentence pre-training objective. It also trains with much larger mini-batches and learning rates and with a 160 gigabyte of text, RoBERTa also uses much more training data compared to BERT, which is pre-trained with 16 gigabytes of text data.</p>
<p><img src="http://livingdatalab.com/posts/https:/github.com/pranath/blog/raw/master/images/aws_roberta.png" title="AWS Pretrain &amp; Finetune a Roberta Model" class="img-fluid"></p>
<p>These model architecture changes focus on building an even better performing masked language model for the NLP downstream tasks, such as text classification.</p>
</section>
<section id="configure-dataset-hyper-parameters-and-evaluation-metrics" class="level2" data-number="4">
<h2 data-number="4" class="anchored" data-anchor-id="configure-dataset-hyper-parameters-and-evaluation-metrics"><span class="header-section-number">4</span> Configure dataset, hyper-parameters and evaluation metrics</h2>
<section id="configure-dataset" class="level3" data-number="4.1">
<h3 data-number="4.1" class="anchored" data-anchor-id="configure-dataset"><span class="header-section-number">4.1</span> Configure dataset</h3>
<p>We have already transformed and balanced the data into a format that the model expects. Let’s copy this data to S3. We will be using training and validation datasets to train the model. The test dataset will be used for tuning later.</p>
<p>Let’s setup the paths:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1">processed_train_data_s3_uri <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">'s3://</span><span class="sc" style="color: #5E5E5E;">{}</span><span class="st" style="color: #20794D;">/data/sentiment-train/'</span>.<span class="bu" style="color: null;">format</span>(bucket)</span>
<span id="cb3-2">processed_validation_data_s3_uri <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">'s3://</span><span class="sc" style="color: #5E5E5E;">{}</span><span class="st" style="color: #20794D;">/data/sentiment-validation/'</span>.<span class="bu" style="color: null;">format</span>(bucket)</span></code></pre></div>
</div>
<p>Upload the data to S3 bucket:</p>
<div class="cell" data-outputid="48c9d0c2-2eb4-4c7b-a335-b5dd46a30dbb">
<div class="sourceCode cell-code" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><span class="op" style="color: #5E5E5E;">!</span>aws s3 cp <span class="op" style="color: #5E5E5E;">--</span>recursive .<span class="op" style="color: #5E5E5E;">/</span>data<span class="op" style="color: #5E5E5E;">/</span>sentiment<span class="op" style="color: #5E5E5E;">-</span>train $processed_train_data_s3_uri</span>
<span id="cb4-2"><span class="op" style="color: #5E5E5E;">!</span>aws s3 cp <span class="op" style="color: #5E5E5E;">--</span>recursive .<span class="op" style="color: #5E5E5E;">/</span>data<span class="op" style="color: #5E5E5E;">/</span>sentiment<span class="op" style="color: #5E5E5E;">-</span>validation $processed_validation_data_s3_uri</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>upload: data/sentiment-train/part-algo-1-womens_clothing_ecommerce_reviews.tsv to s3://sagemaker-us-east-1-215290792315/data/sentiment-train/part-algo-1-womens_clothing_ecommerce_reviews.tsv
upload: data/sentiment-validation/part-algo-1-womens_clothing_ecommerce_reviews.tsv to s3://sagemaker-us-east-1-215290792315/data/sentiment-validation/part-algo-1-womens_clothing_ecommerce_reviews.tsv</code></pre>
</div>
</div>
<p>Check the existence of those files in the S3 bucket:</p>
<div class="cell" data-outputid="ef3a5da4-a37e-4137-94f9-e3cce56b85b2">
<div class="sourceCode cell-code" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><span class="op" style="color: #5E5E5E;">!</span>aws s3 ls <span class="op" style="color: #5E5E5E;">--</span>recursive $processed_train_data_s3_uri</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>2023-02-11 11:21:43    4894416 data/sentiment-train/part-algo-1-womens_clothing_ecommerce_reviews.tsv</code></pre>
</div>
</div>
<div class="cell" data-outputid="46dd16e0-7745-4a9f-dc96-e3cc57e84bed">
<div class="sourceCode cell-code" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><span class="op" style="color: #5E5E5E;">!</span>aws s3 ls <span class="op" style="color: #5E5E5E;">--</span>recursive $processed_validation_data_s3_uri</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>2023-02-11 11:21:44     276522 data/sentiment-validation/part-algo-1-womens_clothing_ecommerce_reviews.tsv</code></pre>
</div>
</div>
<p>We need to setup the input data channels, wrapping the S3 locations in a <code>TrainingInput</code> object to use with the SageMaker Training Job. This can be organized as a dictionary where training and validation data are the Amazon SageMaker channels for S3 input data sources.</p>
<p>Let’s create a train data channel.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1">s3_input_train_data <span class="op" style="color: #5E5E5E;">=</span> sagemaker.inputs.TrainingInput(</span>
<span id="cb10-2">    s3_data<span class="op" style="color: #5E5E5E;">=</span>processed_train_data_s3_uri </span>
<span id="cb10-3">)</span></code></pre></div>
</div>
<p>Now create a validation data channel.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb11" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1">s3_input_validation_data <span class="op" style="color: #5E5E5E;">=</span> sagemaker.inputs.TrainingInput(</span>
<span id="cb11-2">    s3_data<span class="op" style="color: #5E5E5E;">=</span>processed_validation_data_s3_uri </span>
<span id="cb11-3">)</span></code></pre></div>
</div>
<p>Organize the data channels defined above as a dictionary.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb12" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1">data_channels <span class="op" style="color: #5E5E5E;">=</span> {</span>
<span id="cb12-2">    <span class="st" style="color: #20794D;">'train'</span>: s3_input_train_data, </span>
<span id="cb12-3">    <span class="st" style="color: #20794D;">'validation'</span>: s3_input_validation_data </span>
<span id="cb12-4">}</span></code></pre></div>
</div>
</section>
<section id="configure-model-hyper-parameters" class="level3" data-number="4.2">
<h3 data-number="4.2" class="anchored" data-anchor-id="configure-model-hyper-parameters"><span class="header-section-number">4.2</span> Configure model hyper-parameters</h3>
<p>Now we need to set the Training Job parameters including the instance type, instance count, learning rate, batch size etc. For the purposes of this project, we will use a relatively small instance type. Please refer to <a href="https://aws.amazon.com/sagemaker/pricing/">this link</a> for additional instance types that may work for your use cases.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb13" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1">max_seq_length<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">128</span> <span class="co" style="color: #5E5E5E;"># maximum number of input tokens passed to BERT model</span></span>
<span id="cb13-2">freeze_bert_layer<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">False</span> <span class="co" style="color: #5E5E5E;"># specifies the depth of training within the network</span></span>
<span id="cb13-3">epochs<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">3</span></span>
<span id="cb13-4">learning_rate<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">2e-5</span></span>
<span id="cb13-5">train_batch_size<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">256</span></span>
<span id="cb13-6">train_steps_per_epoch<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">50</span></span>
<span id="cb13-7">validation_batch_size<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">256</span></span>
<span id="cb13-8">validation_steps_per_epoch<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">50</span></span>
<span id="cb13-9">seed<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">42</span></span>
<span id="cb13-10">run_validation<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span></span>
<span id="cb13-11"></span>
<span id="cb13-12">train_instance_count<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">1</span></span>
<span id="cb13-13">train_instance_type<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'ml.c5.9xlarge'</span></span>
<span id="cb13-14">train_volume_size<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">256</span></span>
<span id="cb13-15">input_mode<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'File'</span></span></code></pre></div>
</div>
<p>Some of them will be passed into the PyTorch estimator in the hyperparameters argument. Let’s setup the dictionary for that:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb14" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1">hyperparameters<span class="op" style="color: #5E5E5E;">=</span>{</span>
<span id="cb14-2">    <span class="st" style="color: #20794D;">'max_seq_length'</span>: max_seq_length,</span>
<span id="cb14-3">    <span class="st" style="color: #20794D;">'freeze_bert_layer'</span>: freeze_bert_layer,</span>
<span id="cb14-4">    <span class="st" style="color: #20794D;">'epochs'</span>: epochs,</span>
<span id="cb14-5">    <span class="st" style="color: #20794D;">'learning_rate'</span>: learning_rate,</span>
<span id="cb14-6">    <span class="st" style="color: #20794D;">'train_batch_size'</span>: train_batch_size,</span>
<span id="cb14-7">    <span class="st" style="color: #20794D;">'train_steps_per_epoch'</span>: train_steps_per_epoch,</span>
<span id="cb14-8">    <span class="st" style="color: #20794D;">'validation_batch_size'</span>: validation_batch_size,</span>
<span id="cb14-9">    <span class="st" style="color: #20794D;">'validation_steps_per_epoch'</span>: validation_steps_per_epoch,    </span>
<span id="cb14-10">    <span class="st" style="color: #20794D;">'seed'</span>: seed,</span>
<span id="cb14-11">    <span class="st" style="color: #20794D;">'run_validation'</span>: run_validation</span>
<span id="cb14-12">}</span></code></pre></div>
</div>
</section>
<section id="setup-evaluation-metrics" class="level3" data-number="4.3">
<h3 data-number="4.3" class="anchored" data-anchor-id="setup-evaluation-metrics"><span class="header-section-number">4.3</span> Setup evaluation metrics</h3>
<p>We will choose loss and accuracy as the evaluation metrics. The regular expressions <code>Regex</code> will capture the values of metrics that the algorithm will emit.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb15" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1">metric_definitions <span class="op" style="color: #5E5E5E;">=</span> [</span>
<span id="cb15-2">     {<span class="st" style="color: #20794D;">'Name'</span>: <span class="st" style="color: #20794D;">'validation:loss'</span>, <span class="st" style="color: #20794D;">'Regex'</span>: <span class="st" style="color: #20794D;">'val_loss: ([0-9.]+)'</span>},</span>
<span id="cb15-3">     {<span class="st" style="color: #20794D;">'Name'</span>: <span class="st" style="color: #20794D;">'validation:accuracy'</span>, <span class="st" style="color: #20794D;">'Regex'</span>: <span class="st" style="color: #20794D;">'val_acc: ([0-9.]+)'</span>},</span>
<span id="cb15-4">]</span></code></pre></div>
</div>
<p>For example, these sample log lines…</p>
<pre><code>[step: 100] val_loss: 0.76 - val_acc: 70.92%</code></pre>
<p>…will produce the following metrics in CloudWatch:</p>
<p><code>validation:loss</code> = 0.76</p>
<p><code>validation:accuracy</code> = 70.92</p>
<p><img src="http://livingdatalab.com/posts/https:/github.com/pranath/blog/raw/master/images/cloudwatch_validation_metrics.png" title="Evaluation metrics" class="img-fluid"></p>
</section>
<section id="setup-debugger-and-profiler" class="level3" data-number="4.4">
<h3 data-number="4.4" class="anchored" data-anchor-id="setup-debugger-and-profiler"><span class="header-section-number">4.4</span> Setup Debugger and Profiler</h3>
<p>Amazon SageMaker Debugger can be used to profile machine learning models, helping to identify and fix training issues caused by hardware resource usage. Setting some parameters in the SageMaker estimator, without any change to the training code, can enable the collection of infrastructure and model metrics such as: CPU and GPU, RAM and GPU RAM, data loading time, time spent in ML operators running on CPU and GPU, distributed training metrics and many more.</p>
<p>In addition, we can visualize how much time is spent in different phases, such as preprocessing, training loop, and postprocessing. If needed, you can drill down on each training epoch, and even on each function in your training script.</p>
<p>You can define Debugger Rules as are described here: https://docs.aws.amazon.com/sagemaker/latest/dg/debugger-built-in-rules.html</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb17" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><span class="im" style="color: #00769E;">from</span> sagemaker.debugger <span class="im" style="color: #00769E;">import</span> Rule, ProfilerRule, rule_configs</span>
<span id="cb17-2"><span class="im" style="color: #00769E;">from</span> sagemaker.debugger <span class="im" style="color: #00769E;">import</span> DebuggerHookConfig</span>
<span id="cb17-3"><span class="im" style="color: #00769E;">from</span> sagemaker.debugger <span class="im" style="color: #00769E;">import</span> ProfilerConfig, FrameworkProfile</span></code></pre></div>
</div>
<p><code>DebuggerHookConfig</code> provides options to customize how debugging information is emitted and saved. <code>s3_output_path</code> argument value defines the location in Amazon S3 to store the output.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb18" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1">debugger_hook_config <span class="op" style="color: #5E5E5E;">=</span> DebuggerHookConfig(</span>
<span id="cb18-2">    s3_output_path<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'s3://</span><span class="sc" style="color: #5E5E5E;">{}</span><span class="st" style="color: #20794D;">'</span>.<span class="bu" style="color: null;">format</span>(bucket),</span>
<span id="cb18-3">)</span></code></pre></div>
</div>
<p><code>ProfilerConfig</code> sets the configuration for collecting system and framework metrics of SageMaker Training Jobs. Parameter <code>system_monitor_interval_millis</code> sets the time interval to collect system metrics (in milliseconds). Parameter <code>framework_profile_params</code> is the object for framework metrics profiling. Here we will set its local path, the step at which to start profiling, <code>start_step</code>, and the number of steps to profile, <code>num_steps</code>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb19" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><span class="im" style="color: #00769E;">from</span> sagemaker.debugger <span class="im" style="color: #00769E;">import</span> ProfilerConfig, FrameworkProfile</span>
<span id="cb19-2"></span>
<span id="cb19-3">profiler_config <span class="op" style="color: #5E5E5E;">=</span> ProfilerConfig(</span>
<span id="cb19-4">    system_monitor_interval_millis<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">500</span>,</span>
<span id="cb19-5">    framework_profile_params<span class="op" style="color: #5E5E5E;">=</span>FrameworkProfile(local_path<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"/opt/ml/output/profiler/"</span>, start_step<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">5</span>, num_steps<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">10</span>)</span>
<span id="cb19-6">)</span></code></pre></div>
</div>
<p>For monitoring and profiling the built-in rules we can use the <code>ProfilerReport</code>. It creates a profiling report and updates when the individual rules are triggered. If you trigger this <code>ProfilerReport</code> rule without any customized parameter as in the cell below, then the <code>ProfilerReport</code> rule triggers all of the built-in rules for monitoring and profiling with their default parameter values.</p>
<p>The profiling report can be downloaded while the Training Job is running or after the job has finished.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb20" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1">rules<span class="op" style="color: #5E5E5E;">=</span>[ProfilerRule.sagemaker(rule_configs.ProfilerReport())]</span></code></pre></div>
</div>
</section>
</section>
<section id="train-model" class="level2" data-number="5">
<h2 data-number="5" class="anchored" data-anchor-id="train-model"><span class="header-section-number">5</span> Train model</h2>
<section id="setup-the-roberta-and-pytorch-script-to-run-on-sagemaker" class="level3" data-number="5.1">
<h3 data-number="5.1" class="anchored" data-anchor-id="setup-the-roberta-and-pytorch-script-to-run-on-sagemaker"><span class="header-section-number">5.1</span> Setup the RoBERTa and PyTorch script to run on SageMaker</h3>
<p>We will prepare the PyTorch model to run as a SageMaker Training Job in a separate Python file, which will be called during the training.</p>
<p>Here we will be using the pre-trained model <code>roberta-base</code>. The information about the available models can be found in the <a href="https://huggingface.co/models">Hugging Face website</a>.</p>
<div class="cell" data-outputid="c2e3988f-0967-4dd0-8353-d13e7f71b752">
<div class="sourceCode cell-code" id="cb21" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><span class="im" style="color: #00769E;">import</span> sys, importlib</span>
<span id="cb21-2">sys.path.append(<span class="st" style="color: #20794D;">'src/'</span>)</span>
<span id="cb21-3"></span>
<span id="cb21-4"><span class="im" style="color: #00769E;">import</span> train</span>
<span id="cb21-5"></span>
<span id="cb21-6"><span class="co" style="color: #5E5E5E;"># reload the module if it has been previously loaded</span></span>
<span id="cb21-7"><span class="cf" style="color: #003B4F;">if</span> <span class="st" style="color: #20794D;">'train'</span> <span class="kw" style="color: #003B4F;">in</span> sys.modules:</span>
<span id="cb21-8">    importlib.<span class="bu" style="color: null;">reload</span>(train)</span>
<span id="cb21-9"></span>
<span id="cb21-10"><span class="co" style="color: #5E5E5E;"># Ignore warnings below</span></span>
<span id="cb21-11">config <span class="op" style="color: #5E5E5E;">=</span> train.configure_model()</span>
<span id="cb21-12"></span>
<span id="cb21-13">label_0 <span class="op" style="color: #5E5E5E;">=</span> config.id2label[<span class="dv" style="color: #AD0000;">0</span>]</span>
<span id="cb21-14">label_1 <span class="op" style="color: #5E5E5E;">=</span> config.id2label[<span class="dv" style="color: #AD0000;">1</span>]</span>
<span id="cb21-15">label_2 <span class="op" style="color: #5E5E5E;">=</span> config.id2label[<span class="dv" style="color: #AD0000;">2</span>]</span>
<span id="cb21-16"></span>
<span id="cb21-17">updated_correctly <span class="op" style="color: #5E5E5E;">=</span> <span class="va" style="color: #111111;">False</span></span>
<span id="cb21-18"></span>
<span id="cb21-19"><span class="cf" style="color: #003B4F;">if</span> label_0 <span class="op" style="color: #5E5E5E;">!=</span> <span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span> <span class="kw" style="color: #003B4F;">or</span> label_1 <span class="op" style="color: #5E5E5E;">!=</span> <span class="dv" style="color: #AD0000;">0</span> <span class="kw" style="color: #003B4F;">or</span> label_2 <span class="op" style="color: #5E5E5E;">!=</span> <span class="dv" style="color: #AD0000;">1</span>:</span>
<span id="cb21-20">    <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">'#######################################################################################'</span>)</span>
<span id="cb21-21">    <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">'Check that the function </span><span class="ch" style="color: #20794D;">\'</span><span class="st" style="color: #20794D;">configure_model</span><span class="ch" style="color: #20794D;">\'</span><span class="st" style="color: #20794D;"> in the file src/train.py is complete.'</span>)</span>
<span id="cb21-22">    <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">'########################################################################################'</span>)</span>
<span id="cb21-23">    <span class="cf" style="color: #003B4F;">raise</span> <span class="pp" style="color: #AD0000;">Exception</span>(<span class="st" style="color: #20794D;">'Check that the function </span><span class="ch" style="color: #20794D;">\'</span><span class="st" style="color: #20794D;">configure_model</span><span class="ch" style="color: #20794D;">\'</span><span class="st" style="color: #20794D;"> in the file src/train.py is complete.'</span>)</span>
<span id="cb21-24"><span class="cf" style="color: #003B4F;">else</span>:</span>
<span id="cb21-25">    <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">'##################'</span>)    </span>
<span id="cb21-26">    <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">'Updated correctly!'</span>)        </span>
<span id="cb21-27">    <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">'##################'</span>)        </span>
<span id="cb21-28"></span>
<span id="cb21-29">    updated_correctly <span class="op" style="color: #5E5E5E;">=</span> <span class="va" style="color: #111111;">True</span></span></code></pre></div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"3913195754df496ab1e9b41497fc6739","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>
##################
Updated correctly!
##################</code></pre>
</div>
</div>
<p>Setup the PyTorch estimator to train our model. For more information on the PyTorch estimator, see the documentation <a href="https://sagemaker.readthedocs.io/en/stable/frameworks/pytorch/sagemaker.pytorch.html">here</a>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb23" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><span class="im" style="color: #00769E;">from</span> sagemaker.pytorch <span class="im" style="color: #00769E;">import</span> PyTorch <span class="im" style="color: #00769E;">as</span> PyTorchEstimator</span>
<span id="cb23-2"></span>
<span id="cb23-3"><span class="cf" style="color: #003B4F;">if</span> updated_correctly:</span>
<span id="cb23-4">    estimator <span class="op" style="color: #5E5E5E;">=</span> PyTorchEstimator(</span>
<span id="cb23-5">        entry_point<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'train.py'</span>,</span>
<span id="cb23-6">        source_dir<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'src'</span>,</span>
<span id="cb23-7">        role<span class="op" style="color: #5E5E5E;">=</span>role,</span>
<span id="cb23-8">        instance_count<span class="op" style="color: #5E5E5E;">=</span>train_instance_count,</span>
<span id="cb23-9">        instance_type<span class="op" style="color: #5E5E5E;">=</span>train_instance_type,</span>
<span id="cb23-10">        volume_size<span class="op" style="color: #5E5E5E;">=</span>train_volume_size,</span>
<span id="cb23-11">        py_version<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'py3'</span>, <span class="co" style="color: #5E5E5E;"># dynamically retrieves the correct training image (Python 3)</span></span>
<span id="cb23-12">        framework_version<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'1.6.0'</span>, <span class="co" style="color: #5E5E5E;"># dynamically retrieves the correct training image (PyTorch)</span></span>
<span id="cb23-13">        hyperparameters<span class="op" style="color: #5E5E5E;">=</span>hyperparameters,</span>
<span id="cb23-14">        metric_definitions<span class="op" style="color: #5E5E5E;">=</span>metric_definitions,</span>
<span id="cb23-15">        input_mode<span class="op" style="color: #5E5E5E;">=</span>input_mode,</span>
<span id="cb23-16">        debugger_hook_config<span class="op" style="color: #5E5E5E;">=</span>debugger_hook_config,</span>
<span id="cb23-17">        profiler_config<span class="op" style="color: #5E5E5E;">=</span>profiler_config,</span>
<span id="cb23-18">        rules<span class="op" style="color: #5E5E5E;">=</span>rules</span>
<span id="cb23-19">    )</span></code></pre></div>
</div>
<p>Lets now launch the SageMaker Training Job which will be fitting the model to the dataset. We can use the <code>estimator.fit</code> function, passing the configured train and validation inputs (data channels).</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb24" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1">estimator.fit(</span>
<span id="cb24-2">    inputs<span class="op" style="color: #5E5E5E;">=</span>data_channels, </span>
<span id="cb24-3">    wait<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">False</span></span>
<span id="cb24-4">)</span></code></pre></div>
</div>
<p>We can refer to the last Training Job using the estimator function <code>latest_training_job</code>. Then the Training Job name can be found with the <code>name</code> function:</p>
<div class="cell" data-outputid="985f7efd-a155-4784-b1bd-5e2c9a5a2ec5">
<div class="sourceCode cell-code" id="cb25" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1">training_job_name <span class="op" style="color: #5E5E5E;">=</span> estimator.latest_training_job.name</span>
<span id="cb25-2"></span>
<span id="cb25-3"><span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">'Training Job name: </span><span class="sc" style="color: #5E5E5E;">{}</span><span class="st" style="color: #20794D;">'</span>.<span class="bu" style="color: null;">format</span>(training_job_name))</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Training Job name: pytorch-training-2023-02-11-11-22-02-024</code></pre>
</div>
</div>
<p>We can also load the information about the Training Job using the function <code>describe()</code>. The result is in dictionary format. Let’s check that it has the same Training Job name:</p>
<div class="cell" data-outputid="83c51a67-93dc-436a-9b22-b682c806c683">
<div class="sourceCode cell-code" id="cb27" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1">training_job_name <span class="op" style="color: #5E5E5E;">=</span> estimator.latest_training_job.describe()[<span class="st" style="color: #20794D;">'TrainingJobName'</span>]</span>
<span id="cb27-2"></span>
<span id="cb27-3"><span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">'Training Job name: </span><span class="sc" style="color: #5E5E5E;">{}</span><span class="st" style="color: #20794D;">'</span>.<span class="bu" style="color: null;">format</span>(training_job_name))</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Training Job name: pytorch-training-2023-02-11-11-22-02-024</code></pre>
</div>
</div>
<p>Let’s pull the Training Job status from the Training Job description.</p>
<div class="cell" data-outputid="17e1fd2c-3db0-458f-ead5-bc7391134802">
<div class="sourceCode cell-code" id="cb29" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><span class="bu" style="color: null;">print</span>(estimator.latest_training_job.describe().keys())</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>dict_keys(['TrainingJobName', 'TrainingJobArn', 'TrainingJobStatus', 'SecondaryStatus', 'HyperParameters', 'AlgorithmSpecification', 'RoleArn', 'InputDataConfig', 'OutputDataConfig', 'ResourceConfig', 'StoppingCondition', 'CreationTime', 'LastModifiedTime', 'SecondaryStatusTransitions', 'EnableNetworkIsolation', 'EnableInterContainerTrafficEncryption', 'EnableManagedSpotTraining', 'DebugHookConfig', 'ProfilerConfig', 'ProfilerRuleConfigurations', 'ProfilerRuleEvaluationStatuses', 'ProfilingStatus', 'ResponseMetadata'])</code></pre>
</div>
</div>
<div class="cell" data-outputid="8f57ce0a-fa4c-48ba-b246-db24734663c5">
<div class="sourceCode cell-code" id="cb31" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1">training_job_status_primary <span class="op" style="color: #5E5E5E;">=</span> estimator.latest_training_job.describe()[<span class="st" style="color: #20794D;">'TrainingJobStatus'</span>] </span>
<span id="cb31-2"><span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">'Training Job status: </span><span class="sc" style="color: #5E5E5E;">{}</span><span class="st" style="color: #20794D;">'</span>.<span class="bu" style="color: null;">format</span>(training_job_status_primary))</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Training Job status: InProgress</code></pre>
</div>
</div>
<p>Wait for the Training Job to complete.</p>
<div class="cell" data-outputid="752461d7-2cf6-4cd7-d043-1a143e0f5281">
<div class="sourceCode cell-code" id="cb33" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><span class="op" style="color: #5E5E5E;">%%</span>time</span>
<span id="cb33-2"></span>
<span id="cb33-3">estimator.latest_training_job.wait(logs<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">False</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
2023-02-11 11:44:39 Starting - Preparing the instances for training
2023-02-11 11:44:39 Downloading - Downloading input data
2023-02-11 11:44:39 Training - Training image download completed. Training in progress.....................................................................................................................................................................................................................
2023-02-11 12:02:56 Uploading - Uploading generated training model....................................
2023-02-11 12:06:06 Completed - Training job completed
CPU times: user 1.19 s, sys: 131 ms, total: 1.32 s
Wall time: 21min 9s</code></pre>
</div>
</div>
<p>Review the training metrics.</p>
<div class="cell" data-outputid="a8344d15-8a6f-498c-9457-da067937674c">
<div class="sourceCode cell-code" id="cb35" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1">df_metrics <span class="op" style="color: #5E5E5E;">=</span> estimator.training_job_analytics.dataframe()</span>
<span id="cb35-2">df_metrics</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="34">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>timestamp</th>
      <th>metric_name</th>
      <th>value</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.0</td>
      <td>validation:loss</td>
      <td>1.10</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1320.0</td>
      <td>validation:loss</td>
      <td>1.02</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1800.0</td>
      <td>validation:loss</td>
      <td>0.66</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.0</td>
      <td>validation:accuracy</td>
      <td>34.77</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1320.0</td>
      <td>validation:accuracy</td>
      <td>50.39</td>
    </tr>
    <tr>
      <th>5</th>
      <td>1800.0</td>
      <td>validation:accuracy</td>
      <td>69.14</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<p>We can query and plot the training metrics:</p>
<div class="cell" data-outputid="6a84ab14-11fb-40ce-d96d-0e29e4dd3ae5">
<div class="sourceCode cell-code" id="cb36" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb36-1">df_metrics.query(<span class="st" style="color: #20794D;">"metric_name=='validation:accuracy'"</span>).plot(x<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'timestamp'</span>, y<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'value'</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="35">
<pre><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x7f40865b1a90&gt;</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="http://livingdatalab.com/posts/2023-02-11-train-reviews-text-classifier-with-bert-and-aws-sagemaker_files/figure-html/cell-28-output-2.png" class="img-fluid"></p>
</div>
</div>
</section>
<section id="download-sagemaker-debugger-profiling-report" class="level3" data-number="5.2">
<h3 data-number="5.2" class="anchored" data-anchor-id="download-sagemaker-debugger-profiling-report"><span class="header-section-number">5.2</span> Download SageMaker debugger profiling report</h3>
<p>We can download and review the debugger profiling report.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb38" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb38-1">profiler_report_s3_uri <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">"s3://</span><span class="sc" style="color: #5E5E5E;">{}</span><span class="st" style="color: #20794D;">/</span><span class="sc" style="color: #5E5E5E;">{}</span><span class="st" style="color: #20794D;">/rule-output/ProfilerReport/profiler-output"</span>.<span class="bu" style="color: null;">format</span>(bucket, training_job_name)</span></code></pre></div>
</div>
<p>Then we can list the report files:</p>
<div class="cell" data-outputid="89304a1b-e467-4bcc-b7c8-03d89d655527">
<div class="sourceCode cell-code" id="cb39" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1"><span class="op" style="color: #5E5E5E;">!</span>aws s3 ls $profiler_report_s3_uri<span class="op" style="color: #5E5E5E;">/</span></span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>                           PRE profiler-reports/
2023-02-11 12:03:09     364394 profiler-report.html
2023-02-11 12:03:08     211444 profiler-report.ipynb</code></pre>
</div>
</div>
<p>The folder <code>profiler-reports</code> contains the built-in rule analysis components, stored in JSON and a Jupyter notebook. They are aggregated into the report.</p>
<div class="cell" data-outputid="f391389f-c01c-4fa4-9687-9711abd67366">
<div class="sourceCode cell-code" id="cb41" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1"><span class="op" style="color: #5E5E5E;">!</span>aws s3 cp <span class="op" style="color: #5E5E5E;">--</span>recursive $profiler_report_s3_uri .<span class="op" style="color: #5E5E5E;">/</span>profiler_report<span class="op" style="color: #5E5E5E;">/</span></span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>download: s3://sagemaker-us-east-1-215290792315/pytorch-training-2023-02-11-11-22-02-024/rule-output/ProfilerReport/profiler-output/profiler-reports/CPUBottleneck.json to profiler_report/profiler-reports/CPUBottleneck.json
download: s3://sagemaker-us-east-1-215290792315/pytorch-training-2023-02-11-11-22-02-024/rule-output/ProfilerReport/profiler-output/profiler-reports/MaxInitializationTime.json to profiler_report/profiler-reports/MaxInitializationTime.json
download: s3://sagemaker-us-east-1-215290792315/pytorch-training-2023-02-11-11-22-02-024/rule-output/ProfilerReport/profiler-output/profiler-reports/Dataloader.json to profiler_report/profiler-reports/Dataloader.json
download: s3://sagemaker-us-east-1-215290792315/pytorch-training-2023-02-11-11-22-02-024/rule-output/ProfilerReport/profiler-output/profiler-reports/OverallFrameworkMetrics.json to profiler_report/profiler-reports/OverallFrameworkMetrics.json
download: s3://sagemaker-us-east-1-215290792315/pytorch-training-2023-02-11-11-22-02-024/rule-output/ProfilerReport/profiler-output/profiler-reports/BatchSize.json to profiler_report/profiler-reports/BatchSize.json
download: s3://sagemaker-us-east-1-215290792315/pytorch-training-2023-02-11-11-22-02-024/rule-output/ProfilerReport/profiler-output/profiler-reports/OverallSystemUsage.json to profiler_report/profiler-reports/OverallSystemUsage.json
download: s3://sagemaker-us-east-1-215290792315/pytorch-training-2023-02-11-11-22-02-024/rule-output/ProfilerReport/profiler-output/profiler-reports/GPUMemoryIncrease.json to profiler_report/profiler-reports/GPUMemoryIncrease.json
download: s3://sagemaker-us-east-1-215290792315/pytorch-training-2023-02-11-11-22-02-024/rule-output/ProfilerReport/profiler-output/profiler-reports/IOBottleneck.json to profiler_report/profiler-reports/IOBottleneck.json
download: s3://sagemaker-us-east-1-215290792315/pytorch-training-2023-02-11-11-22-02-024/rule-output/ProfilerReport/profiler-output/profiler-reports/LoadBalancing.json to profiler_report/profiler-reports/LoadBalancing.json
download: s3://sagemaker-us-east-1-215290792315/pytorch-training-2023-02-11-11-22-02-024/rule-output/ProfilerReport/profiler-output/profiler-report.ipynb to profiler_report/profiler-report.ipynb
download: s3://sagemaker-us-east-1-215290792315/pytorch-training-2023-02-11-11-22-02-024/rule-output/ProfilerReport/profiler-output/profiler-reports/LowGPUUtilization.json to profiler_report/profiler-reports/LowGPUUtilization.json
download: s3://sagemaker-us-east-1-215290792315/pytorch-training-2023-02-11-11-22-02-024/rule-output/ProfilerReport/profiler-output/profiler-reports/StepOutlier.json to profiler_report/profiler-reports/StepOutlier.json
download: s3://sagemaker-us-east-1-215290792315/pytorch-training-2023-02-11-11-22-02-024/rule-output/ProfilerReport/profiler-output/profiler-report.html to profiler_report/profiler-report.html</code></pre>
</div>
</div>
<p>You can review the profiler report <a href="https://pranath.github.io/pds/profiler-report.html">here</a>.</p>
</section>
</section>
<section id="deploy-the-model" class="level2" data-number="6">
<h2 data-number="6" class="anchored" data-anchor-id="deploy-the-model"><span class="header-section-number">6</span> Deploy the model</h2>
<p>Now we will create a custom <code>SentimentPredictor</code> that encapsulates a JSONLines serializer and deserializer. To be passed into the <code>PyTorchModel</code> it needs to be wrapped as a class.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb43" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb43-1"><span class="im" style="color: #00769E;">from</span> sagemaker.predictor <span class="im" style="color: #00769E;">import</span> Predictor</span>
<span id="cb43-2"><span class="im" style="color: #00769E;">from</span> sagemaker.serializers <span class="im" style="color: #00769E;">import</span> JSONLinesSerializer</span>
<span id="cb43-3"><span class="im" style="color: #00769E;">from</span> sagemaker.deserializers <span class="im" style="color: #00769E;">import</span> JSONLinesDeserializer</span>
<span id="cb43-4"></span>
<span id="cb43-5"><span class="kw" style="color: #003B4F;">class</span> SentimentPredictor(Predictor):</span>
<span id="cb43-6">    <span class="kw" style="color: #003B4F;">def</span> <span class="fu" style="color: #4758AB;">__init__</span>(<span class="va" style="color: #111111;">self</span>, endpoint_name, sagemaker_session):</span>
<span id="cb43-7">        <span class="bu" style="color: null;">super</span>().<span class="fu" style="color: #4758AB;">__init__</span>(endpoint_name, </span>
<span id="cb43-8">                         sagemaker_session<span class="op" style="color: #5E5E5E;">=</span>sagemaker_session, </span>
<span id="cb43-9">                         serializer<span class="op" style="color: #5E5E5E;">=</span>JSONLinesSerializer(),</span>
<span id="cb43-10">                         deserializer<span class="op" style="color: #5E5E5E;">=</span>JSONLinesDeserializer())</span></code></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb44" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb44-1"><span class="im" style="color: #00769E;">import</span> time</span>
<span id="cb44-2"><span class="im" style="color: #00769E;">from</span> sagemaker.pytorch.model <span class="im" style="color: #00769E;">import</span> PyTorchModel</span>
<span id="cb44-3"></span>
<span id="cb44-4">timestamp <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">int</span>(time.time())</span>
<span id="cb44-5"></span>
<span id="cb44-6">pytorch_model_name <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">'</span><span class="sc" style="color: #5E5E5E;">{}</span><span class="st" style="color: #20794D;">-</span><span class="sc" style="color: #5E5E5E;">{}</span><span class="st" style="color: #20794D;">-</span><span class="sc" style="color: #5E5E5E;">{}</span><span class="st" style="color: #20794D;">'</span>.<span class="bu" style="color: null;">format</span>(training_job_name, <span class="st" style="color: #20794D;">'pt'</span>, timestamp)</span>
<span id="cb44-7"></span>
<span id="cb44-8">model <span class="op" style="color: #5E5E5E;">=</span> PyTorchModel(name<span class="op" style="color: #5E5E5E;">=</span>pytorch_model_name,</span>
<span id="cb44-9">                     model_data<span class="op" style="color: #5E5E5E;">=</span>estimator.model_data,</span>
<span id="cb44-10">                     predictor_cls<span class="op" style="color: #5E5E5E;">=</span>SentimentPredictor,</span>
<span id="cb44-11">                     entry_point<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'inference.py'</span>,</span>
<span id="cb44-12">                     source_dir<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'src'</span>,</span>
<span id="cb44-13">                     framework_version<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'1.6.0'</span>,</span>
<span id="cb44-14">                     py_version<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'py3'</span>,</span>
<span id="cb44-15">                     role<span class="op" style="color: #5E5E5E;">=</span>role)</span></code></pre></div>
</div>
<div class="cell" data-outputid="4922a522-8c15-428f-a648-02597f213c11">
<div class="sourceCode cell-code" id="cb45" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb45-1"><span class="im" style="color: #00769E;">import</span> time</span>
<span id="cb45-2"></span>
<span id="cb45-3">pytorch_endpoint_name <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">'</span><span class="sc" style="color: #5E5E5E;">{}</span><span class="st" style="color: #20794D;">-</span><span class="sc" style="color: #5E5E5E;">{}</span><span class="st" style="color: #20794D;">-</span><span class="sc" style="color: #5E5E5E;">{}</span><span class="st" style="color: #20794D;">'</span>.<span class="bu" style="color: null;">format</span>(training_job_name, <span class="st" style="color: #20794D;">'pt'</span>, timestamp)</span>
<span id="cb45-4"></span>
<span id="cb45-5"><span class="bu" style="color: null;">print</span>(pytorch_endpoint_name)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>pytorch-training-2023-02-11-11-22-02-024-pt-1676117278</code></pre>
</div>
</div>
<p>Now we deploy the model as an endpoint.</p>
<div class="cell" data-outputid="72355abe-ebf0-4fa7-8079-7ee6c2bdba90">
<div class="sourceCode cell-code" id="cb47" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb47-1"><span class="op" style="color: #5E5E5E;">%%</span>time</span>
<span id="cb47-2"></span>
<span id="cb47-3">predictor <span class="op" style="color: #5E5E5E;">=</span> model.deploy(initial_instance_count<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">1</span>, </span>
<span id="cb47-4">                         instance_type<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'ml.m5.large'</span>, </span>
<span id="cb47-5">                         endpoint_name<span class="op" style="color: #5E5E5E;">=</span>pytorch_endpoint_name)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>----------!CPU times: user 2min 15s, sys: 9.35 s, total: 2min 25s
Wall time: 7min 23s</code></pre>
</div>
</div>
</section>
<section id="test-model" class="level2" data-number="7">
<h2 data-number="7" class="anchored" data-anchor-id="test-model"><span class="header-section-number">7</span> Test model</h2>
<p>Here, we will pass sample strings of text to the endpoint in order to see the sentiment. We will try one example of each sentiment.</p>
<div class="cell" data-outputid="47d672de-b9cb-48f6-b13e-2c3a277ebb99">
<div class="sourceCode cell-code" id="cb49" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb49-1">inputs <span class="op" style="color: #5E5E5E;">=</span> [</span>
<span id="cb49-2">    {<span class="st" style="color: #20794D;">"features"</span>: [<span class="st" style="color: #20794D;">"I love this product!"</span>]},</span>
<span id="cb49-3">    {<span class="st" style="color: #20794D;">"features"</span>: [<span class="st" style="color: #20794D;">"OK, but not great."</span>]},</span>
<span id="cb49-4">    {<span class="st" style="color: #20794D;">"features"</span>: [<span class="st" style="color: #20794D;">"This is not the right product."</span>]},</span>
<span id="cb49-5">]</span>
<span id="cb49-6"></span>
<span id="cb49-7">predictor <span class="op" style="color: #5E5E5E;">=</span> SentimentPredictor(endpoint_name<span class="op" style="color: #5E5E5E;">=</span>pytorch_endpoint_name,</span>
<span id="cb49-8">                               sagemaker_session<span class="op" style="color: #5E5E5E;">=</span>sess)</span>
<span id="cb49-9"></span>
<span id="cb49-10">predicted_classes <span class="op" style="color: #5E5E5E;">=</span> predictor.predict(inputs)</span>
<span id="cb49-11"></span>
<span id="cb49-12"><span class="cf" style="color: #003B4F;">for</span> predicted_class <span class="kw" style="color: #003B4F;">in</span> predicted_classes:</span>
<span id="cb49-13">    <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">"Predicted class </span><span class="sc" style="color: #5E5E5E;">{}</span><span class="st" style="color: #20794D;"> with probability </span><span class="sc" style="color: #5E5E5E;">{}</span><span class="st" style="color: #20794D;">"</span>.<span class="bu" style="color: null;">format</span>(predicted_class[<span class="st" style="color: #20794D;">'predicted_label'</span>], predicted_class[<span class="st" style="color: #20794D;">'probability'</span>]))</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Predicted class 1 with probability 0.9605445861816406
Predicted class 0 with probability 0.5798221230506897
Predicted class -1 with probability 0.7667604684829712</code></pre>
</div>
</div>
</section>
<section id="acknowledgements" class="level2" data-number="8">
<h2 data-number="8" class="anchored" data-anchor-id="acknowledgements"><span class="header-section-number">8</span> Acknowledgements</h2>
<p>I’d like to express my thanks to the great <a href="https://www.deeplearning.ai/courses/practical-data-science-specialization/">Deep Learning AI Practical Data Science on AWS Specialisation Course</a> which i completed, and acknowledge the use of some images and other materials from the training course in this article.</p>


</section>

 ]]></description>
  <category>aws</category>
  <category>cloud-data-science</category>
  <category>natural-language-processing</category>
  <category>deep-learning</category>
  <guid>http://livingdatalab.com/posts/2023-02-11-train-reviews-text-classifier-with-bert-and-aws-sagemaker.html</guid>
  <pubDate>Sat, 11 Feb 2023 00:00:00 GMT</pubDate>
  <media:content url="https://github.com/pranath/blog/raw/master/images/aws2.png" medium="image" type="image/png"/>
</item>
<item>
  <title>Feature Transformation with Amazon SageMaker Processing Job and Feature Store</title>
  <dc:creator>Pranath Fernando</dc:creator>
  <link>http://livingdatalab.com/posts/2023-02-08-feature-transformation-aws-sagemaker-processing-job-feature-store.html</link>
  <description><![CDATA[ 




<section id="introduction" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="introduction"><span class="header-section-number">1</span> Introduction</h2>
<p>In <a href="../#category=aws">earlier articles we introduced AWS cloud services for data science</a>, and showed how it can help with different stages of the data science &amp; machine learning workflow.</p>
<p><img src="http://livingdatalab.com/posts/https:/github.com/pranath/blog/raw/master/images/aws_ds_workflow.png" title="The AWS Data Science Workflow" class="img-fluid"></p>
<p>In this article we will look at the <strong>Prepare &amp; Transform</strong> stage using AWS including:</p>
<ul>
<li>Feature engineering</li>
<li>Feature store</li>
</ul>
<p>Using the raw <a href="https://www.kaggle.com/nicapotato/womens-ecommerce-clothing-reviews">Women’s Clothing Reviews</a> dataset - we will prepare it to train a BERT-based natural language processing (NLP) model. The model will be used to classify customer reviews into positive (1), neutral (0) and negative (-1) sentiment.</p>
<p>We will convert the original review text into machine-readable features used by BERT. To perform the required feature transformation we will configure an Amazon SageMaker processing job, which will be running a custom Python script.</p>
</section>
<section id="the-bert-language-model" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="the-bert-language-model"><span class="header-section-number">2</span> The Bert language model</h2>
<p>BERT stands for ‘Bidirectional Encoder Representations from Transformers’. So Bert language models are based on the transformer type models first created in 2017.</p>
<p><img src="http://livingdatalab.com/posts/https:/github.com/pranath/blog/raw/master/images/aws_bert_history.png" title="The History of Language Models" class="img-fluid"></p>
<p>In a <a href="2023-02-06-creating-text-classifier-using-aws-sagemaker-blazingtext.html">previous article we used a Blazing Text Language Model</a> to create a text classifier. Blazing Text language models are in turn based on Word2Vec type language models. But how do word2vec/Blazing text language models work? essentially these models convert individual words into a series of numbers or a <em>vector</em>.</p>
<p><img src="http://livingdatalab.com/posts/https:/github.com/pranath/blog/raw/master/images/aws_blazingtext_embed.png" title="Blazing Text Embeddings" class="img-fluid"></p>
<p>I used word2vec in one of my first data science/deep learning projects back in 2019 <a href="https://docs.google.com/presentation/d/164oDiuEZFR35X9QEJN1R-rOb4sp5r32DxR4Xm6z-Qgs/edit#slide=id.p">classifying disaster text messages</a>.</p>
<p>This means with word2vec similar meaning words will have similar numbers and vector positions, this is what this language model learns. The downside of this approach though is it allows only for one sense of what a word might mean - but we know in practice the meaning of a word can be effected by the context.</p>
<p>For example, if we were trying to decide if these two phrases were positive or negative:</p>
<ul>
<li>I love the dress</li>
<li>I love the dress, but not the price</li>
</ul>
<p>A word2vec model might end up giving quite positive sentiment to both of these phrases when summing up the meaning of these words individually, yet we can see that the second phrase might have more neutral if not negative sentiment, because here ‘love’, usually positive, has been modified by the context of the words its within.</p>
<p>This is one key thing that transformer models such as BERT or GPT can do, <strong>they can take into account the context of a word, and indeed process an entire phrase in one go to give a vector for that group of words, rather than for one word at a time.</strong></p>
<p><img src="http://livingdatalab.com/posts/https:/github.com/pranath/blog/raw/master/images/aws_bert_embed.png" title="The Bert Embeddings" class="img-fluid"></p>
<p>In particular transformers use <em>attention</em> to capture the relationship and meaning between words used together. You can find out more about the differences between word2vec and transformer models <a href="https://towardsdatascience.com/word2vec-to-transformers-caf5a3daa08a">here</a>.</p>
</section>
<section id="feature-engineering-at-scale" class="level2" data-number="3">
<h2 data-number="3" class="anchored" data-anchor-id="feature-engineering-at-scale"><span class="header-section-number">3</span> Feature Engineering at Scale</h2>
<p>Amazon SageMaker processing allows you to perform data related tasks such as, preprocessing, postprocessing, and model evaluation at scale. SageMaker processing provides this capability by using a distributed cluster. By specifying some parameters, you can control how many notes and the type of the notes that make up the distributed cluster.</p>
<p><img src="http://livingdatalab.com/posts/https:/github.com/pranath/blog/raw/master/images/aws_processing.png" title="Amazon SageMaker Processing" class="img-fluid"></p>
<p>Sagemaker Feature Store is a fully managed service that provides purpose-built feature store. SageMaker Feature Store provides you with a centralized repository to securely save and serve features from.</p>
<p>Next, SageMaker Feature Store provides you with the capabilities to reuse the features, not just across a single machine learning project, but across multiple projects. A typical challenge that data scientist sees is training an inference skew that could result from discrepancies in the data used for training and the data used for inferencing. Sagemaker Feature Store helps reduce the skew by reusing the features across training and inference traces and by keeping the features consistent.</p>
<p>Finally, SageMaker Feature Store provides the capabilities to create it for the features both in real time and batch. The ability to creating for features in real time suppose use cases such as near real time ML predictions. Similarly, the ability to look up features in batch mode can be used to support use cases, such as model training.</p>
<p><img src="http://livingdatalab.com/posts/https:/github.com/pranath/blog/raw/master/images/aws_feature_store.png" title="AWS Feature Store" class="img-fluid"></p>
</section>
<section id="import-libraries-initialise" class="level2" data-number="4">
<h2 data-number="4" class="anchored" data-anchor-id="import-libraries-initialise"><span class="header-section-number">4</span> Import Libraries &amp; Initialise</h2>
<div class="cell">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;">import</span> boto3</span>
<span id="cb1-2"><span class="im" style="color: #00769E;">import</span> sagemaker</span>
<span id="cb1-3"><span class="im" style="color: #00769E;">import</span> botocore</span>
<span id="cb1-4"></span>
<span id="cb1-5">config <span class="op" style="color: #5E5E5E;">=</span> botocore.config.Config(user_agent_extra<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'dlai-pds/c2/w1'</span>)</span>
<span id="cb1-6"></span>
<span id="cb1-7"><span class="co" style="color: #5E5E5E;"># low-level service client of the boto3 session</span></span>
<span id="cb1-8">sm <span class="op" style="color: #5E5E5E;">=</span> boto3.client(service_name<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'sagemaker'</span>, </span>
<span id="cb1-9">                  config<span class="op" style="color: #5E5E5E;">=</span>config)</span>
<span id="cb1-10"></span>
<span id="cb1-11">featurestore_runtime <span class="op" style="color: #5E5E5E;">=</span> boto3.client(service_name<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'sagemaker-featurestore-runtime'</span>, </span>
<span id="cb1-12">                                    config<span class="op" style="color: #5E5E5E;">=</span>config)</span>
<span id="cb1-13"></span>
<span id="cb1-14">sess <span class="op" style="color: #5E5E5E;">=</span> sagemaker.Session(sagemaker_client<span class="op" style="color: #5E5E5E;">=</span>sm,</span>
<span id="cb1-15">                         sagemaker_featurestore_runtime_client<span class="op" style="color: #5E5E5E;">=</span>featurestore_runtime)</span>
<span id="cb1-16"></span>
<span id="cb1-17">bucket <span class="op" style="color: #5E5E5E;">=</span> sess.default_bucket()</span>
<span id="cb1-18">role <span class="op" style="color: #5E5E5E;">=</span> sagemaker.get_execution_role()</span>
<span id="cb1-19">region <span class="op" style="color: #5E5E5E;">=</span> sess.boto_region_name</span></code></pre></div>
</div>
</section>
<section id="configure-the-sagemaker-feature-store" class="level2" data-number="5">
<h2 data-number="5" class="anchored" data-anchor-id="configure-the-sagemaker-feature-store"><span class="header-section-number">5</span> Configure the SageMaker Feature Store</h2>
<section id="configure-dataset" class="level3" data-number="5.1">
<h3 data-number="5.1" class="anchored" data-anchor-id="configure-dataset"><span class="header-section-number">5.1</span> Configure dataset</h3>
<p>The raw dataset is in the public S3 bucket. Let’s start by specifying the S3 location of it:</p>
<div class="cell" data-outputid="b4ddde35-0d6b-4320-a9be-f29a22f1be3c">
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1">raw_input_data_s3_uri <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">'s3://dlai-practical-data-science/data/raw/'</span></span>
<span id="cb2-2"><span class="bu" style="color: null;">print</span>(raw_input_data_s3_uri)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>s3://dlai-practical-data-science/data/raw/</code></pre>
</div>
</div>
<p>List the files in the S3 bucket (in this case it will be just one file):</p>
<div class="cell" data-outputid="5712b73b-7dd8-47d6-b0a9-f2b69298a913">
<div class="sourceCode cell-code" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><span class="op" style="color: #5E5E5E;">!</span>aws s3 ls $raw_input_data_s3_uri</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>2021-04-30 02:21:06    8457214 womens_clothing_ecommerce_reviews.csv</code></pre>
</div>
</div>
</section>
<section id="configure-the-sagemaker-feature-store-1" class="level3" data-number="5.2">
<h3 data-number="5.2" class="anchored" data-anchor-id="configure-the-sagemaker-feature-store-1"><span class="header-section-number">5.2</span> Configure the SageMaker feature store</h3>
<p>As the result of the transformation, in addition to generating files in S3 bucket, we will also save the transformed data in the <strong>Amazon SageMaker Feature Store</strong> to be used by others in our organization, for example.</p>
<p>To configure a Feature Store we need to setup a <strong>Feature Group</strong>. This is the main resource containing all of the metadata related to the data stored in the Feature Store.</p>
<p>A Feature Group should contain a list of <strong>Feature Definitions</strong>. A Feature Definition consists of a name and the data type. The Feature Group also contains an online store configuration and an offline store configuration controlling where the data is stored. Enabling the online store allows quick access to the latest value for a record via the <a href="https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_feature_store_GetRecord.html">GetRecord API</a>. The offline store allows storage of the data in your S3 bucket. We will be using the offline store here.</p>
<p>Let’s setup the Feature Group name and the Feature Store offline prefix in S3 bucket.</p>
<div class="cell" data-outputid="fc9ed9db-1b5f-4575-f4f9-516bcb663856">
<div class="sourceCode cell-code" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><span class="im" style="color: #00769E;">import</span> time</span>
<span id="cb6-2">timestamp <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">int</span>(time.time())</span>
<span id="cb6-3"></span>
<span id="cb6-4">feature_group_name <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">'reviews-feature-group-'</span> <span class="op" style="color: #5E5E5E;">+</span> <span class="bu" style="color: null;">str</span>(timestamp)</span>
<span id="cb6-5">feature_store_offline_prefix <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">'reviews-feature-store-'</span> <span class="op" style="color: #5E5E5E;">+</span> <span class="bu" style="color: null;">str</span>(timestamp)</span>
<span id="cb6-6"></span>
<span id="cb6-7"><span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">'Feature group name: </span><span class="sc" style="color: #5E5E5E;">{}</span><span class="st" style="color: #20794D;">'</span>.<span class="bu" style="color: null;">format</span>(feature_group_name))</span>
<span id="cb6-8"><span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">'Feature store offline prefix in S3: </span><span class="sc" style="color: #5E5E5E;">{}</span><span class="st" style="color: #20794D;">'</span>.<span class="bu" style="color: null;">format</span>(feature_store_offline_prefix))</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Feature group name: reviews-feature-group-1675799708
Feature store offline prefix in S3: reviews-feature-store-1675799708</code></pre>
</div>
</div>
<p>Taking two features from the original raw dataset (<code>Review Text</code> and <code>Rating</code>), we will transform it preparing to be used for the model training and then to be saved in the Feature Store. Here we will define the related features to be stored as a list of <code>FeatureDefinition</code>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><span class="im" style="color: #00769E;">from</span> sagemaker.feature_store.feature_definition <span class="im" style="color: #00769E;">import</span> (</span>
<span id="cb8-2">    FeatureDefinition,</span>
<span id="cb8-3">    FeatureTypeEnum,</span>
<span id="cb8-4">)</span>
<span id="cb8-5"></span>
<span id="cb8-6">feature_definitions<span class="op" style="color: #5E5E5E;">=</span> [</span>
<span id="cb8-7">    <span class="co" style="color: #5E5E5E;"># unique ID of the review</span></span>
<span id="cb8-8">    FeatureDefinition(feature_name<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'review_id'</span>, feature_type<span class="op" style="color: #5E5E5E;">=</span>FeatureTypeEnum.STRING), </span>
<span id="cb8-9">    <span class="co" style="color: #5E5E5E;"># ingestion timestamp</span></span>
<span id="cb8-10">    FeatureDefinition(feature_name<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'date'</span>, feature_type<span class="op" style="color: #5E5E5E;">=</span>FeatureTypeEnum.STRING),</span>
<span id="cb8-11">    <span class="co" style="color: #5E5E5E;"># sentiment: -1 (negative), 0 (neutral) or 1 (positive). It will be found the Rating values (1, 2, 3, 4, 5)</span></span>
<span id="cb8-12">    FeatureDefinition(feature_name<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'sentiment'</span>, feature_type<span class="op" style="color: #5E5E5E;">=</span>FeatureTypeEnum.STRING), </span>
<span id="cb8-13">    <span class="co" style="color: #5E5E5E;"># label ID of the target class (sentiment)</span></span>
<span id="cb8-14">    FeatureDefinition(feature_name<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'label_id'</span>, feature_type<span class="op" style="color: #5E5E5E;">=</span>FeatureTypeEnum.STRING),</span>
<span id="cb8-15">    <span class="co" style="color: #5E5E5E;"># reviews encoded with the BERT tokenizer</span></span>
<span id="cb8-16">    FeatureDefinition(feature_name<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'input_ids'</span>, feature_type<span class="op" style="color: #5E5E5E;">=</span>FeatureTypeEnum.STRING),</span>
<span id="cb8-17">    <span class="co" style="color: #5E5E5E;"># original Review Text</span></span>
<span id="cb8-18">    FeatureDefinition(feature_name<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'review_body'</span>, feature_type<span class="op" style="color: #5E5E5E;">=</span>FeatureTypeEnum.STRING),</span>
<span id="cb8-19">    <span class="co" style="color: #5E5E5E;"># train/validation/test label</span></span>
<span id="cb8-20">    FeatureDefinition(feature_name<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'split_type'</span>, feature_type<span class="op" style="color: #5E5E5E;">=</span>FeatureTypeEnum.STRING)</span>
<span id="cb8-21">]</span></code></pre></div>
</div>
<p>Let’s create the feature group using the feature definitions defined above.</p>
<div class="cell" data-outputid="1bb637b8-7887-46dd-8634-575fc8095b69">
<div class="sourceCode cell-code" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><span class="im" style="color: #00769E;">from</span> sagemaker.feature_store.feature_group <span class="im" style="color: #00769E;">import</span> FeatureGroup</span>
<span id="cb9-2"></span>
<span id="cb9-3">feature_group <span class="op" style="color: #5E5E5E;">=</span> FeatureGroup(</span>
<span id="cb9-4">    name<span class="op" style="color: #5E5E5E;">=</span>feature_group_name, </span>
<span id="cb9-5">    feature_definitions<span class="op" style="color: #5E5E5E;">=</span>feature_definitions, </span>
<span id="cb9-6">    sagemaker_session<span class="op" style="color: #5E5E5E;">=</span>sess</span>
<span id="cb9-7">)</span>
<span id="cb9-8"></span>
<span id="cb9-9"><span class="bu" style="color: null;">print</span>(feature_group)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>FeatureGroup(name='reviews-feature-group-1675799708', sagemaker_session=&lt;sagemaker.session.Session object at 0x7f9cb912c350&gt;, feature_definitions=[FeatureDefinition(feature_name='review_id', feature_type=&lt;FeatureTypeEnum.STRING: 'String'&gt;), FeatureDefinition(feature_name='date', feature_type=&lt;FeatureTypeEnum.STRING: 'String'&gt;), FeatureDefinition(feature_name='sentiment', feature_type=&lt;FeatureTypeEnum.STRING: 'String'&gt;), FeatureDefinition(feature_name='label_id', feature_type=&lt;FeatureTypeEnum.STRING: 'String'&gt;), FeatureDefinition(feature_name='input_ids', feature_type=&lt;FeatureTypeEnum.STRING: 'String'&gt;), FeatureDefinition(feature_name='review_body', feature_type=&lt;FeatureTypeEnum.STRING: 'String'&gt;), FeatureDefinition(feature_name='split_type', feature_type=&lt;FeatureTypeEnum.STRING: 'String'&gt;)])</code></pre>
</div>
</div>
<p>We will use the defined Feature Group later in this project, the actual creation of the Feature Group will take place in the processing job. Now let’s move into the setup of the processing job to transform the dataset.</p>
</section>
</section>
<section id="transform-the-dataset" class="level2" data-number="6">
<h2 data-number="6" class="anchored" data-anchor-id="transform-the-dataset"><span class="header-section-number">6</span> Transform the dataset</h2>
<p>We will configure a SageMaker processing job to run a custom Python script to balance and transform the raw data into a format used by BERT model.</p>
<p>Let’s set the transformation parameters including the instance type, instance count, and train/validation/test split percentages. We will use a relatively small instance type for this project. Please refer to <a href="https://aws.amazon.com/sagemaker/pricing/">this</a> link for additional instance types that may work for your use case.</p>
<p>We can also choose whether you want to balance the dataset or not. In this case, we will balance the dataset to avoid class imbalance in the target variable, <code>sentiment</code>.</p>
<p>Another important parameter of the model is the <code>max_seq_length</code>, which specifies the maximum length of the classified reviews for the RoBERTa model. If the sentence is shorter than the maximum length parameter, it will be padded. In another case, when the sentence is longer, it will be truncated from the right side.</p>
<p>Since a smaller <code>max_seq_length</code> leads to faster training and lower resource utilization, you want to find the smallest power-of-2 that captures <code>100%</code> of our reviews. For this dataset, the <code>100th</code> percentile is <code>115</code>. However, it’s best to stick with powers-of-2 when using BERT. So let’s choose <code>128</code> as this is the smallest power-of-2 greater than <code>115</code>. We will see below how the shorter sentences will be padded to a maximum length.</p>
<pre><code>mean        52.512374
std         31.387048
min          1.000000
10%         10.000000
20%         22.000000
30%         32.000000
40%         41.000000
50%         51.000000
60%         61.000000
70%         73.000000
80%         88.000000
90%         97.000000
100%       115.000000
max        115.000000</code></pre>
<p><img src="http://livingdatalab.com/posts/https:/github.com/pranath/blog/raw/master/images/distribution_num_words_per_review.png" title="Histogram of text sequence lengths" class="img-fluid"></p>
<div class="cell" data-scrolled="true">
<div class="sourceCode cell-code" id="cb12" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1">processing_instance_type<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'ml.c5.xlarge'</span></span>
<span id="cb12-2">processing_instance_count<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">1</span></span>
<span id="cb12-3">train_split_percentage<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">0.90</span></span>
<span id="cb12-4">validation_split_percentage<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">0.05</span></span>
<span id="cb12-5">test_split_percentage<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">0.05</span></span>
<span id="cb12-6">balance_dataset<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span></span>
<span id="cb12-7">max_seq_length<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">128</span></span></code></pre></div>
</div>
<p>To balance and transform our data, we will use a scikit-learn-based processing job. This is essentially a generic Python processing job with scikit-learn pre-installed. We can specify the version of scikit-learn we wish to use. Also we will pass the SageMaker execution role, processing instance type and instance count.</p>
<div class="cell" data-scrolled="true">
<div class="sourceCode cell-code" id="cb13" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><span class="im" style="color: #00769E;">from</span> sagemaker.sklearn.processing <span class="im" style="color: #00769E;">import</span> SKLearnProcessor</span>
<span id="cb13-2"></span>
<span id="cb13-3">processor <span class="op" style="color: #5E5E5E;">=</span> SKLearnProcessor(</span>
<span id="cb13-4">    framework_version<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'0.23-1'</span>,</span>
<span id="cb13-5">    role<span class="op" style="color: #5E5E5E;">=</span>role,</span>
<span id="cb13-6">    instance_type<span class="op" style="color: #5E5E5E;">=</span>processing_instance_type,</span>
<span id="cb13-7">    instance_count<span class="op" style="color: #5E5E5E;">=</span>processing_instance_count,</span>
<span id="cb13-8">    env<span class="op" style="color: #5E5E5E;">=</span>{<span class="st" style="color: #20794D;">'AWS_DEFAULT_REGION'</span>: region},                             </span>
<span id="cb13-9">    max_runtime_in_seconds<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">7200</span></span>
<span id="cb13-10">)</span></code></pre></div>
</div>
<p>The processing job will be running the Python code from the file <a href="https://github.com/pranath/pds/blob/main/prepare_data.py"><code>src/prepare_data.py</code></a>.</p>
<div class="cell" data-outputid="36d16e53-c76f-4665-9a17-5cbaa581c55c">
<div class="sourceCode cell-code" id="cb14" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><span class="im" style="color: #00769E;">import</span> sys, importlib</span>
<span id="cb14-2">sys.path.append(<span class="st" style="color: #20794D;">'src/'</span>)</span>
<span id="cb14-3"></span>
<span id="cb14-4"><span class="co" style="color: #5E5E5E;"># import the `prepare_data.py` module</span></span>
<span id="cb14-5"><span class="im" style="color: #00769E;">import</span> prepare_data</span>
<span id="cb14-6"></span>
<span id="cb14-7"><span class="co" style="color: #5E5E5E;"># reload the module if it has been previously loaded </span></span>
<span id="cb14-8"><span class="cf" style="color: #003B4F;">if</span> <span class="st" style="color: #20794D;">'prepare_data'</span> <span class="kw" style="color: #003B4F;">in</span> sys.modules:</span>
<span id="cb14-9">    importlib.<span class="bu" style="color: null;">reload</span>(prepare_data)</span>
<span id="cb14-10"></span>
<span id="cb14-11">input_ids <span class="op" style="color: #5E5E5E;">=</span> prepare_data.convert_to_bert_input_ids(<span class="st" style="color: #20794D;">"this product is great!"</span>, max_seq_length)</span>
<span id="cb14-12">    </span>
<span id="cb14-13">updated_correctly <span class="op" style="color: #5E5E5E;">=</span> <span class="va" style="color: #111111;">False</span></span>
<span id="cb14-14"></span>
<span id="cb14-15"><span class="cf" style="color: #003B4F;">if</span> <span class="bu" style="color: null;">len</span>(input_ids) <span class="op" style="color: #5E5E5E;">!=</span> max_seq_length:</span>
<span id="cb14-16">    <span class="cf" style="color: #003B4F;">raise</span> <span class="pp" style="color: #AD0000;">Exception</span>(<span class="st" style="color: #20794D;">'Please check that the function </span><span class="ch" style="color: #20794D;">\'</span><span class="st" style="color: #20794D;">convert_to_bert_input_ids</span><span class="ch" style="color: #20794D;">\'</span><span class="st" style="color: #20794D;"> in the file src/prepare_data.py is complete.'</span>)</span>
<span id="cb14-17"><span class="cf" style="color: #003B4F;">else</span>:</span>
<span id="cb14-18">    <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">'##################'</span>)</span>
<span id="cb14-19">    <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">'Updated correctly!'</span>)</span>
<span id="cb14-20">    <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">'##################'</span>)</span>
<span id="cb14-21"></span>
<span id="cb14-22">    updated_correctly <span class="op" style="color: #5E5E5E;">=</span> <span class="va" style="color: #111111;">True</span></span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>##################
Updated correctly!
##################</code></pre>
</div>
</div>
<div class="cell" data-outputid="1d816a68-2ca9-4893-c5d9-b942dfe893e7">
<div class="sourceCode cell-code" id="cb16" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1">input_ids <span class="op" style="color: #5E5E5E;">=</span> prepare_data.convert_to_bert_input_ids(<span class="st" style="color: #20794D;">"this product is great!"</span>, max_seq_length)</span>
<span id="cb16-2"></span>
<span id="cb16-3"><span class="bu" style="color: null;">print</span>(input_ids)</span>
<span id="cb16-4"><span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">'Length of the sequence: </span><span class="sc" style="color: #5E5E5E;">{}</span><span class="st" style="color: #20794D;">'</span>.<span class="bu" style="color: null;">format</span>(<span class="bu" style="color: null;">len</span>(input_ids)))</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[0, 9226, 1152, 16, 372, 328, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
Length of the sequence: 128</code></pre>
</div>
</div>
<p>Now we launch the processing job with the custom script passing defined above parameters.</p>
<div class="cell" data-outputid="bcbfb17d-a9cf-4bc3-f0b6-c3ffd4bb542b">
<div class="sourceCode cell-code" id="cb18" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><span class="im" style="color: #00769E;">from</span> sagemaker.processing <span class="im" style="color: #00769E;">import</span> ProcessingInput, ProcessingOutput</span>
<span id="cb18-2"></span>
<span id="cb18-3"><span class="cf" style="color: #003B4F;">if</span> (updated_correctly):</span>
<span id="cb18-4"></span>
<span id="cb18-5">    processor.run(code<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'src/prepare_data.py'</span>,</span>
<span id="cb18-6">              inputs<span class="op" style="color: #5E5E5E;">=</span>[</span>
<span id="cb18-7">                    ProcessingInput(source<span class="op" style="color: #5E5E5E;">=</span>raw_input_data_s3_uri,</span>
<span id="cb18-8">                                    destination<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'/opt/ml/processing/input/data/'</span>,</span>
<span id="cb18-9">                                    s3_data_distribution_type<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'ShardedByS3Key'</span>)</span>
<span id="cb18-10">              ],</span>
<span id="cb18-11">              outputs<span class="op" style="color: #5E5E5E;">=</span>[</span>
<span id="cb18-12">                    ProcessingOutput(output_name<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'sentiment-train'</span>,</span>
<span id="cb18-13">                                     source<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'/opt/ml/processing/output/sentiment/train'</span>,</span>
<span id="cb18-14">                                     s3_upload_mode<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'EndOfJob'</span>),</span>
<span id="cb18-15">                    ProcessingOutput(output_name<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'sentiment-validation'</span>,</span>
<span id="cb18-16">                                     source<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'/opt/ml/processing/output/sentiment/validation'</span>,</span>
<span id="cb18-17">                                     s3_upload_mode<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'EndOfJob'</span>),</span>
<span id="cb18-18">                    ProcessingOutput(output_name<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'sentiment-test'</span>,</span>
<span id="cb18-19">                                     source<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'/opt/ml/processing/output/sentiment/test'</span>,</span>
<span id="cb18-20">                                     s3_upload_mode<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'EndOfJob'</span>)</span>
<span id="cb18-21">              ],</span>
<span id="cb18-22">              arguments<span class="op" style="color: #5E5E5E;">=</span>[<span class="st" style="color: #20794D;">'--train-split-percentage'</span>, <span class="bu" style="color: null;">str</span>(train_split_percentage),</span>
<span id="cb18-23">                         <span class="st" style="color: #20794D;">'--validation-split-percentage'</span>, <span class="bu" style="color: null;">str</span>(validation_split_percentage),</span>
<span id="cb18-24">                         <span class="st" style="color: #20794D;">'--test-split-percentage'</span>, <span class="bu" style="color: null;">str</span>(test_split_percentage),</span>
<span id="cb18-25">                         <span class="st" style="color: #20794D;">'--balance-dataset'</span>, <span class="bu" style="color: null;">str</span>(balance_dataset),</span>
<span id="cb18-26">                         <span class="st" style="color: #20794D;">'--max-seq-length'</span>, <span class="bu" style="color: null;">str</span>(max_seq_length),                         </span>
<span id="cb18-27">                         <span class="st" style="color: #20794D;">'--feature-store-offline-prefix'</span>, <span class="bu" style="color: null;">str</span>(feature_store_offline_prefix),</span>
<span id="cb18-28">                         <span class="st" style="color: #20794D;">'--feature-group-name'</span>, <span class="bu" style="color: null;">str</span>(feature_group_name)                         </span>
<span id="cb18-29">              ],</span>
<span id="cb18-30">              logs<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>,</span>
<span id="cb18-31">              wait<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">False</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Job Name:  sagemaker-scikit-learn-2023-02-07-19-57-59-405
Inputs:  [{'InputName': 'input-1', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://dlai-practical-data-science/data/raw/', 'LocalPath': '/opt/ml/processing/input/data/', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'ShardedByS3Key', 'S3CompressionType': 'None'}}, {'InputName': 'code', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-951182689916/sagemaker-scikit-learn-2023-02-07-19-57-59-405/input/code/prepare_data.py', 'LocalPath': '/opt/ml/processing/input/code', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}]
Outputs:  [{'OutputName': 'sentiment-train', 'AppManaged': False, 'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-951182689916/sagemaker-scikit-learn-2023-02-07-19-57-59-405/output/sentiment-train', 'LocalPath': '/opt/ml/processing/output/sentiment/train', 'S3UploadMode': 'EndOfJob'}}, {'OutputName': 'sentiment-validation', 'AppManaged': False, 'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-951182689916/sagemaker-scikit-learn-2023-02-07-19-57-59-405/output/sentiment-validation', 'LocalPath': '/opt/ml/processing/output/sentiment/validation', 'S3UploadMode': 'EndOfJob'}}, {'OutputName': 'sentiment-test', 'AppManaged': False, 'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-951182689916/sagemaker-scikit-learn-2023-02-07-19-57-59-405/output/sentiment-test', 'LocalPath': '/opt/ml/processing/output/sentiment/test', 'S3UploadMode': 'EndOfJob'}}]</code></pre>
</div>
</div>
<p>You can see the information about the processing jobs using the <code>describe</code> function. The result is in dictionary format. Let’s pull the processing job name:</p>
<div class="cell" data-outputid="30efa06b-9280-4261-e383-cfdb58d55f4d" data-scrolled="true">
<div class="sourceCode cell-code" id="cb20" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1">scikit_processing_job_name <span class="op" style="color: #5E5E5E;">=</span> processor.jobs[<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>].describe()[<span class="st" style="color: #20794D;">'ProcessingJobName'</span>]</span>
<span id="cb20-2"></span>
<span id="cb20-3"><span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">'Processing job name: </span><span class="sc" style="color: #5E5E5E;">{}</span><span class="st" style="color: #20794D;">'</span>.<span class="bu" style="color: null;">format</span>(scikit_processing_job_name))</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Processing job name: sagemaker-scikit-learn-2023-02-07-19-57-59-405</code></pre>
</div>
</div>
<p>Let’s pull the processing job status from the processing job description.</p>
<div class="cell" data-outputid="bbb0d2fb-094a-4cbb-ad88-fc1dc5c6a48f" data-scrolled="true">
<div class="sourceCode cell-code" id="cb22" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><span class="bu" style="color: null;">print</span>(processor.jobs[<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>].describe().keys())</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>dict_keys(['ProcessingInputs', 'ProcessingOutputConfig', 'ProcessingJobName', 'ProcessingResources', 'StoppingCondition', 'AppSpecification', 'Environment', 'RoleArn', 'ProcessingJobArn', 'ProcessingJobStatus', 'LastModifiedTime', 'CreationTime', 'ResponseMetadata'])</code></pre>
</div>
</div>
<div class="cell" data-outputid="f88ffba6-dd55-4c57-ff3e-60f28e7819ea" data-scrolled="true">
<div class="sourceCode cell-code" id="cb24" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1">scikit_processing_job_status <span class="op" style="color: #5E5E5E;">=</span> processor.jobs[<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>].describe()[<span class="st" style="color: #20794D;">'ProcessingJobStatus'</span>]</span>
<span id="cb24-2"><span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">'Processing job status: </span><span class="sc" style="color: #5E5E5E;">{}</span><span class="st" style="color: #20794D;">'</span>.<span class="bu" style="color: null;">format</span>(scikit_processing_job_status))</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Processing job status: InProgress</code></pre>
</div>
</div>
<div class="cell" data-outputid="d7e17737-e44f-439d-e860-9ad9045b906b">
<div class="sourceCode cell-code" id="cb26" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><span class="op" style="color: #5E5E5E;">%%</span>time</span>
<span id="cb26-2"></span>
<span id="cb26-3">running_processor <span class="op" style="color: #5E5E5E;">=</span> sagemaker.processing.ProcessingJob.from_processing_name(</span>
<span id="cb26-4">    processing_job_name<span class="op" style="color: #5E5E5E;">=</span>scikit_processing_job_name,</span>
<span id="cb26-5">    sagemaker_session<span class="op" style="color: #5E5E5E;">=</span>sess</span>
<span id="cb26-6">)</span>
<span id="cb26-7"></span>
<span id="cb26-8">running_processor.wait(logs<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">False</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>....................................................................................................................................!CPU times: user 647 ms, sys: 44.3 ms, total: 691 ms
Wall time: 11min 13s</code></pre>
</div>
</div>
<p>Let’s inspect the transformed and balanced data in the S3 bucket.</p>
<div class="cell" data-outputid="5bd636b5-220b-4d92-e570-f61ef08ceaef">
<div class="sourceCode cell-code" id="cb28" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1">processing_job_description <span class="op" style="color: #5E5E5E;">=</span> running_processor.describe()</span>
<span id="cb28-2"></span>
<span id="cb28-3">output_config <span class="op" style="color: #5E5E5E;">=</span> processing_job_description[<span class="st" style="color: #20794D;">'ProcessingOutputConfig'</span>]</span>
<span id="cb28-4"><span class="cf" style="color: #003B4F;">for</span> output <span class="kw" style="color: #003B4F;">in</span> output_config[<span class="st" style="color: #20794D;">'Outputs'</span>]:</span>
<span id="cb28-5">    <span class="cf" style="color: #003B4F;">if</span> output[<span class="st" style="color: #20794D;">'OutputName'</span>] <span class="op" style="color: #5E5E5E;">==</span> <span class="st" style="color: #20794D;">'sentiment-train'</span>:</span>
<span id="cb28-6">        processed_train_data_s3_uri <span class="op" style="color: #5E5E5E;">=</span> output[<span class="st" style="color: #20794D;">'S3Output'</span>][<span class="st" style="color: #20794D;">'S3Uri'</span>]</span>
<span id="cb28-7">    <span class="cf" style="color: #003B4F;">if</span> output[<span class="st" style="color: #20794D;">'OutputName'</span>] <span class="op" style="color: #5E5E5E;">==</span> <span class="st" style="color: #20794D;">'sentiment-validation'</span>:</span>
<span id="cb28-8">        processed_validation_data_s3_uri <span class="op" style="color: #5E5E5E;">=</span> output[<span class="st" style="color: #20794D;">'S3Output'</span>][<span class="st" style="color: #20794D;">'S3Uri'</span>]</span>
<span id="cb28-9">    <span class="cf" style="color: #003B4F;">if</span> output[<span class="st" style="color: #20794D;">'OutputName'</span>] <span class="op" style="color: #5E5E5E;">==</span> <span class="st" style="color: #20794D;">'sentiment-test'</span>:</span>
<span id="cb28-10">        processed_test_data_s3_uri <span class="op" style="color: #5E5E5E;">=</span> output[<span class="st" style="color: #20794D;">'S3Output'</span>][<span class="st" style="color: #20794D;">'S3Uri'</span>]</span>
<span id="cb28-11">        </span>
<span id="cb28-12"><span class="bu" style="color: null;">print</span>(processed_train_data_s3_uri)</span>
<span id="cb28-13"><span class="bu" style="color: null;">print</span>(processed_validation_data_s3_uri)</span>
<span id="cb28-14"><span class="bu" style="color: null;">print</span>(processed_test_data_s3_uri)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>s3://sagemaker-us-east-1-951182689916/sagemaker-scikit-learn-2023-02-07-19-57-59-405/output/sentiment-train
s3://sagemaker-us-east-1-951182689916/sagemaker-scikit-learn-2023-02-07-19-57-59-405/output/sentiment-validation
s3://sagemaker-us-east-1-951182689916/sagemaker-scikit-learn-2023-02-07-19-57-59-405/output/sentiment-test</code></pre>
</div>
</div>
<div class="cell" data-outputid="f11a5fe8-12f7-4997-ff23-bf263ad744f7" data-scrolled="true">
<div class="sourceCode cell-code" id="cb30" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><span class="op" style="color: #5E5E5E;">!</span>aws s3 ls $processed_train_data_s3_uri<span class="op" style="color: #5E5E5E;">/</span></span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>2023-02-07 20:10:54    4896333 part-algo-1-womens_clothing_ecommerce_reviews.tsv</code></pre>
</div>
</div>
<div class="cell" data-outputid="0e77df43-82cf-4331-fca4-260076006e8d" data-scrolled="true">
<div class="sourceCode cell-code" id="cb32" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><span class="op" style="color: #5E5E5E;">!</span>aws s3 ls $processed_validation_data_s3_uri<span class="op" style="color: #5E5E5E;">/</span></span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>2023-02-07 20:10:54     269735 part-algo-1-womens_clothing_ecommerce_reviews.tsv</code></pre>
</div>
</div>
<div class="cell" data-outputid="963692e4-adde-4975-e2a3-03af2ac7934c" data-scrolled="true">
<div class="sourceCode cell-code" id="cb34" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1"><span class="op" style="color: #5E5E5E;">!</span>aws s3 ls $processed_test_data_s3_uri<span class="op" style="color: #5E5E5E;">/</span></span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>2023-02-07 20:10:55     269933 part-algo-1-womens_clothing_ecommerce_reviews.tsv</code></pre>
</div>
</div>
<p>Now we copy the data into the folder <code>balanced</code>.</p>
<div class="cell" data-outputid="96f547ff-ca9e-4d69-b853-c28e53a957f1">
<div class="sourceCode cell-code" id="cb36" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb36-1"><span class="op" style="color: #5E5E5E;">!</span>aws s3 cp $processed_train_data_s3_uri<span class="op" style="color: #5E5E5E;">/</span>part<span class="op" style="color: #5E5E5E;">-</span>algo<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span><span class="op" style="color: #5E5E5E;">-</span>womens_clothing_ecommerce_reviews.tsv .<span class="op" style="color: #5E5E5E;">/</span>balanced<span class="op" style="color: #5E5E5E;">/</span>sentiment<span class="op" style="color: #5E5E5E;">-</span>train<span class="op" style="color: #5E5E5E;">/</span></span>
<span id="cb36-2"><span class="op" style="color: #5E5E5E;">!</span>aws s3 cp $processed_validation_data_s3_uri<span class="op" style="color: #5E5E5E;">/</span>part<span class="op" style="color: #5E5E5E;">-</span>algo<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span><span class="op" style="color: #5E5E5E;">-</span>womens_clothing_ecommerce_reviews.tsv .<span class="op" style="color: #5E5E5E;">/</span>balanced<span class="op" style="color: #5E5E5E;">/</span>sentiment<span class="op" style="color: #5E5E5E;">-</span>validation<span class="op" style="color: #5E5E5E;">/</span></span>
<span id="cb36-3"><span class="op" style="color: #5E5E5E;">!</span>aws s3 cp $processed_test_data_s3_uri<span class="op" style="color: #5E5E5E;">/</span>part<span class="op" style="color: #5E5E5E;">-</span>algo<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span><span class="op" style="color: #5E5E5E;">-</span>womens_clothing_ecommerce_reviews.tsv .<span class="op" style="color: #5E5E5E;">/</span>balanced<span class="op" style="color: #5E5E5E;">/</span>sentiment<span class="op" style="color: #5E5E5E;">-</span>test<span class="op" style="color: #5E5E5E;">/</span></span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>download: s3://sagemaker-us-east-1-951182689916/sagemaker-scikit-learn-2023-02-07-19-57-59-405/output/sentiment-train/part-algo-1-womens_clothing_ecommerce_reviews.tsv to balanced/sentiment-train/part-algo-1-womens_clothing_ecommerce_reviews.tsv
download: s3://sagemaker-us-east-1-951182689916/sagemaker-scikit-learn-2023-02-07-19-57-59-405/output/sentiment-validation/part-algo-1-womens_clothing_ecommerce_reviews.tsv to balanced/sentiment-validation/part-algo-1-womens_clothing_ecommerce_reviews.tsv
download: s3://sagemaker-us-east-1-951182689916/sagemaker-scikit-learn-2023-02-07-19-57-59-405/output/sentiment-test/part-algo-1-womens_clothing_ecommerce_reviews.tsv to balanced/sentiment-test/part-algo-1-womens_clothing_ecommerce_reviews.tsv</code></pre>
</div>
</div>
<p>Let’s review the training, validation and test data outputs:</p>
<div class="cell" data-outputid="627eb440-3ec3-4ecd-e7c0-e88c2920a4ce">
<div class="sourceCode cell-code" id="cb38" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb38-1"><span class="op" style="color: #5E5E5E;">!</span>head <span class="op" style="color: #5E5E5E;">-</span>n <span class="dv" style="color: #AD0000;">5</span> .<span class="op" style="color: #5E5E5E;">/</span>balanced<span class="op" style="color: #5E5E5E;">/</span>sentiment<span class="op" style="color: #5E5E5E;">-</span>train<span class="op" style="color: #5E5E5E;">/</span>part<span class="op" style="color: #5E5E5E;">-</span>algo<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span><span class="op" style="color: #5E5E5E;">-</span>womens_clothing_ecommerce_reviews.tsv</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>review_id   sentiment   label_id    input_ids   review_body date
15231   -1  0   [0, 100, 657, 13855, 27734, 111, 4682, 13, 42, 65, 4, 5, 10199, 16, 38596, 4, 24, 18, 227, 4136, 8, 5, 1468, 14, 51, 146, 9287, 66, 9, 4, 5, 5780, 16, 15652, 8, 5, 14893, 62, 5, 760, 32, 2422, 11962, 4, 5, 3318, 631, 14, 18, 95, 7209, 89, 116, 1437, 24, 18, 10, 3318, 631, 14, 95, 23835, 89, 4, 24, 630, 75, 1437, 356, 205, 7209, 1437, 8, 24, 630, 75, 356, 205, 3016, 4, 1437, 42, 13855, 6439, 56, 98, 203, 801, 4, 939, 437, 2299, 5779, 4, 1437, 13, 39328, 5135, 1437, 939, 524, 195, 108, 245, 113, 1437, 16157, 1437, 2631, 438, 8, 10, 650, 21, 1969, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]   "I love jumpsuits - except for this one. the fabric is blah. it's between plastic and the material that they make flags out of. the print is adorable and the buttons up the front are super cute. the tie thing that's just hanging there?  it's a tie thing that just hangs there. it doesn't  look good hanging  and it doesn't look good tied.  this jumpsuit had so much potential. i'm definitely disappointed.  for sizing reference  i am 5'5""  135  34c and a small was perfect." 2023-02-07T20:04:40Z
8389    -1  0   [0, 100, 269, 770, 7, 101, 209, 1437, 53, 51, 95, 399, 75, 356, 235, 15, 127, 195, 108, 246, 2345, 102, 35156, 5120, 4, 939, 33, 380, 35841, 8, 460, 619, 66, 9, 317, 2498, 2084, 6149, 1033, 1437, 98, 2085, 939, 437, 95, 45, 5, 235, 1002, 13, 209, 1437, 53, 51, 1415, 98, 11962, 8, 939, 770, 7, 492, 106, 10, 860, 4, 5, 13977, 21, 350, 239, 13, 127, 25896, 1437, 8, 5, 2985, 18459, 58, 350, 380, 8, 851, 162, 10, 33062, 3786, 356, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]  I really wanted to like these  but they just didn't look right on my 5'3 sorta bulky frame. i have big thighs and always feel out of place wearing leggings  so maybe i'm just not the right target for these  but they looked so cute and i wanted to give them a try. the waist was too high for my liking  and the leg openings were too big and gave me a stumpified look.  2023-02-07T20:04:40Z
17752   1   2   [0, 713, 16, 10, 1528, 5262, 299, 42514, 571, 26875, 1827, 8, 1237, 650, 4, 939, 2333, 3568, 10, 650, 50, 4761, 11, 6215, 13657, 1437, 53, 15679, 219, 939, 460, 1836, 62, 4, 939, 437, 10, 2491, 438, 1437, 8, 10, 739, 10698, 1969, 4, 5, 760, 16, 10, 828, 11708, 1437, 53, 45, 98, 203, 47, 240, 10, 740, 5602, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]   This is a true tiny top........gorgeous and runs small. i usually wear a small or medium in retailer tops  but timy i always size up. i'm a 36c  and a large fits perfect. the front is a bit sheer  but not so much you need a cami.   2023-02-07T20:04:40Z
65  1   2   [0, 100, 3584, 42, 299, 11, 41, 9876, 1001, 1400, 94, 186, 4, 5, 1318, 16, 4613, 8, 5, 2272, 1173, 2440, 3195, 16, 182, 2216, 4, 5, 3089, 11556, 34, 10, 2721, 4140, 219, 740, 7042, 1020, 459, 14, 16, 7391, 23, 5, 10762, 1437, 53, 64, 28, 2928, 30, 11803, 4, 939, 362, 29, 372, 77, 10610, 80, 430, 1319, 4, 939, 5328, 24, 19, 5, 2205, 4104, 66, 1437, 8, 24, 3723, 15390, 149, 5, 3089, 11556, 23, 5, 2576, 4, 24, 67, 1326, 372, 77, 5, 11021, 354, 4104, 16, 10610, 11, 4, 127, 129, 2813, 16, 14, 24, 74, 283, 11, 10, 4716, 1459, 1836, 25, 24, 18, 10, 2842, 380, 23, 5, 10762, 8, 5397, 3572, 2, 1, 1, 1, 1, 1]   I purchased this top in an antro store last week. the quality is wonderful and the greenish blue color is very unique. the blouse has a beautiful stretchy camsiole that is attached at the shoulders  but can be removed by snaps. i tooks great when worn two different ways. i wore it with the campole out  and it peeks through the blouse at the bottom. it also looks great when the camisole is worn in. my only wish is that it would come in a petite size as it's a touch big at the shoulders and neckli    2023-02-07T20:04:40Z</code></pre>
</div>
</div>
<div class="cell" data-outputid="fce03655-4455-476d-aeca-5e4b6e378f7a">
<div class="sourceCode cell-code" id="cb40" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb40-1"><span class="op" style="color: #5E5E5E;">!</span>head <span class="op" style="color: #5E5E5E;">-</span>n <span class="dv" style="color: #AD0000;">5</span> .<span class="op" style="color: #5E5E5E;">/</span>balanced<span class="op" style="color: #5E5E5E;">/</span>sentiment<span class="op" style="color: #5E5E5E;">-</span>validation<span class="op" style="color: #5E5E5E;">/</span>part<span class="op" style="color: #5E5E5E;">-</span>algo<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span><span class="op" style="color: #5E5E5E;">-</span>womens_clothing_ecommerce_reviews.tsv</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>review_id   sentiment   label_id    input_ids   review_body date
5506    1   2   [0, 19065, 3588, 11, 1110, 9, 1468, 1437, 1318, 1437, 5780, 734, 18891, 59, 5, 2408, 19, 5, 14187, 156, 24, 45, 173, 13, 162, 4, 939, 2740, 65, 1836, 159, 25, 5131, 30, 97, 34910, 1437, 53, 14, 399, 75, 173, 131, 89, 21, 350, 203, 10199, 13, 5, 5933, 8, 5, 14187, 156, 24, 356, 19351, 4, 939, 2740, 10, 4761, 8, 939, 113, 119, 195, 108, 245, 113, 15, 5, 5350, 11454, 526, 4, 14223, 157, 4, 939, 348, 56, 98, 203, 6620, 19, 97, 6215, 3365, 98, 939, 437, 45, 350, 5779, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1] "Great dress in terms of material  quality  print...something about the weight with the lining made it not work for me. i ordered one size down as recommended by other reviewers  but that didn't work; there was too much fabric for the length and the lining made it look heavier. i ordered a medium and i""m 5'5"" on the curvy side. oh well. i've had so much luck with other retailer orders so i'm not too disappointed." 2023-02-07T20:04:40Z
8480    0   1   [0, 713, 2170, 473, 45, 109, 42, 16576, 2427, 4, 24, 16, 12058, 4, 959, 1437, 5, 13977, 21, 98, 650, 14, 5, 16721, 1344, 11532, 88, 127, 13977, 442, 162, 206, 9, 10, 25818, 11809, 2187, 4, 9574, 1437, 24, 21, 5, 1154, 1836, 98, 939, 64, 75, 1836, 62, 4, 939, 437, 204, 108, 1225, 113, 98, 5, 5933, 21, 1969, 111, 24, 376, 7, 235, 1065, 127, 15145, 4, 939, 657, 5, 16576, 98, 203, 14, 939, 437, 2811, 11356, 366, 27345, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1] "This picture does not do this skirt justice. it is gorgeous. however  the waist was so small that the sequins dug into my waist making me think of a medieval torture device. unfortunately  it was the largest size so i can't size up. i'm 4'11"" so the length was perfect - it came to right above my knees. i love the skirt so much that i'm considering liposuction."   2023-02-07T20:04:40Z
66  0   1   [0, 100, 829, 42, 6399, 11, 127, 6097, 3023, 29, 8, 24, 10698, 6683, 4, 939, 116, 119, 45, 5373, 11, 657, 19, 24, 53, 939, 67, 218, 116, 90, 28101, 4, 5, 6399, 16, 15, 5, 7174, 526, 4, 109, 939, 240, 7, 3568, 10, 740, 5602, 12213, 24, 1437, 117, 4, 127, 2212, 16, 6538, 4, 24, 473, 8736, 162, 9, 10, 1468, 14, 115, 2179, 103, 6538, 71, 103, 3568, 8, 21, 5065, 4, 19, 14, 145, 26, 939, 116, 890, 10397, 42, 6399, 11, 2569, 514, 8, 6713, 3841, 8, 5952, 14, 40, 2097, 6538, 31, 2623, 4, 5, 5933, 16, 2051, 8, 939, 109, 101, 5, 3369, 2629, 11, 760, 116, 405, 3639, 10, 410, 14548, 2, 1, 1, 1, 1, 1, 1]   I received this shirt in my typical xs and it fits perfectly. i?m not crazy in love with it but i also don?t dislike. the shirt is on the thin side. do i need to wear a cami underneath it  no. my concern is holes. it does remind me of a material that could develop some holes after some wear and washes. with that being said i?ll wash this shirt in cold water and hang dry and hopefully that will prevent holes from developing. the length is fine and i do like the slits in front?it adds a little dim    2023-02-07T20:04:40Z
10411   -1  0   [0, 100, 33, 57, 546, 23, 42, 23204, 804, 187, 24, 78, 376, 66, 8, 939, 1747, 2740, 24, 77, 24, 21, 843, 207, 160, 4, 939, 2740, 10, 1836, 475, 4716, 1459, 1437, 16748, 77, 24, 2035, 8, 939, 1381, 24, 15, 1437, 24, 21, 182, 2233, 219, 1437, 13116, 101, 1437, 8, 222, 45, 3041, 101, 24, 1415, 15, 5, 1421, 804, 98, 939, 1051, 24, 124, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]  I have been looking at this sweater online since it first came out and i finally ordered it when it was 40% off. i ordered a size m petite  sadly when it arrived and i tried it on  it was very boxy  stiff like  and did not flow like it looked on the model online so i sent it back.   2023-02-07T20:04:40Z</code></pre>
</div>
</div>
<div class="cell" data-outputid="dfa07e96-7f91-4be6-afdc-e98a520bce67">
<div class="sourceCode cell-code" id="cb42" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb42-1"><span class="op" style="color: #5E5E5E;">!</span>head <span class="op" style="color: #5E5E5E;">-</span>n <span class="dv" style="color: #AD0000;">5</span> .<span class="op" style="color: #5E5E5E;">/</span>balanced<span class="op" style="color: #5E5E5E;">/</span>sentiment<span class="op" style="color: #5E5E5E;">-</span>test<span class="op" style="color: #5E5E5E;">/</span>part<span class="op" style="color: #5E5E5E;">-</span>algo<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span><span class="op" style="color: #5E5E5E;">-</span>womens_clothing_ecommerce_reviews.tsv</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>review_id   sentiment   label_id    input_ids   review_body date
4815    0   1   [0, 100, 300, 5, 1275, 1437, 61, 21, 765, 30145, 5202, 4, 5, 6399, 1495, 21, 98, 11962, 1437, 53, 5, 2564, 16, 182, 2233, 219, 4, 939, 300, 10, 650, 8, 24, 21, 169, 350, 1810, 4, 444, 6012, 8, 10941, 11, 5, 13977, 87, 5, 2170, 924, 4, 939, 524, 5074, 7, 671, 1437, 53, 24, 817, 162, 356, 101, 10, 3925, 4, 36, 43882, 14, 16, 43, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]  I got the red  which was short sleeved. the shirt itself was so cute  but the fit is very boxy. i got a small and it was way too wide. far wider and shorter in the waist than the picture shows. i am sad to return  but it makes me look like a square. (shape that is)   2023-02-07T20:04:40Z
1933    1   2   [0, 1708, 5, 124, 9, 24, 1437, 30, 5, 13977, 1437, 15713, 5559, 95, 10, 5262, 828, 4, 114, 939, 120, 2671, 1437, 24, 40, 28, 350, 251, 4, 53, 939, 657, 5, 16576, 1437, 24, 16, 34203, 8, 11962, 4, 45, 24, 17414, 13, 162, 190, 114, 5, 1270, 161, 24787, 4, 939, 2740, 5, 16273, 642, 8, 5, 5933, 16, 1256, 203, 25, 7092, 1437, 95, 874, 5, 4117, 11, 760, 4, 5, 13977, 16, 41783, 1437, 2671, 24, 74, 1136, 55, 15, 127, 28097, 36, 2457, 1755, 5, 350, 251, 1129, 656, 4, 36, 15314, 23246, 1437, 973, 12, 2518, 11, 13977, 1437, 765, 5856, 41137, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]   But the back of it  by the waist  bunches just a tiny bit. if i get bigger  it will be too long. but i love the skirt  it is flattering and cute. not itchy for me even if the title says wool. i ordered the 00p and the length is pretty much as pictured  just below the knee in front. the waist is snug  bigger it would fall more on my hips (hence the too long comment earlier. (115 lbs  26-27 in waist  short legs...)    2023-02-07T20:04:40Z
14029   -1  0   [0, 100, 269, 657, 5, 6184, 8, 5, 356, 15, 5, 1421, 1437, 8, 939, 802, 939, 74, 657, 24, 4, 939, 2740, 804, 1437, 98, 939, 222, 45, 860, 15, 11, 1400, 4, 77, 939, 1381, 24, 15, 1437, 24, 34, 169, 350, 203, 10199, 198, 5, 13977, 8, 16576, 4, 24, 16, 7992, 10199, 25, 157, 1437, 8, 34, 10, 14187, 1437, 8, 5, 13977, 34, 1823, 10199, 13, 5, 1521, 1437, 8, 24, 34, 12189, 1437, 98, 24, 70, 3639, 62, 7, 28, 169, 350, 35156, 4, 24, 16, 45, 34203, 23, 70, 8, 156, 162, 356, 158, 2697, 19351, 4, 939, 524, 3357, 42, 3588, 4, 5074, 1437, 142, 24, 1326, 98, 9869, 15, 5, 1421, 4, 939, 524, 2, 1, 1, 1, 1] I really love the pattern and the look on the model  and i thought i would love it. i ordered online  so i did not try on in store. when i tried it on  it has way too much fabric around the waist and skirt. it is thick fabric as well  and has a lining  and the waist has extra fabric for the design  and it has pockets  so it all adds up to be way too bulky. it is not flattering at all and made me look 10 pounds heavier. i am returning this dress. sad  because it looks so lovely on the model. i am    2023-02-07T20:04:40Z
10468   0   1   [0, 713, 6966, 18605, 16, 182, 157, 156, 8, 190, 39083, 906, 11, 621, 4, 939, 437, 195, 108, 398, 113, 8, 59, 17445, 2697, 4, 939, 2333, 3568, 10, 1836, 231, 4, 939, 3568, 10, 2631, 417, 11689, 4, 939, 303, 5, 3235, 7, 422, 10, 828, 650, 4, 939, 1835, 24, 142, 1437, 1135, 141, 203, 939, 6640, 5, 2496, 1437, 24, 95, 938, 75, 34203, 15, 127, 809, 1907, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]    "This swimsuit is very well made and even prettier in person. i'm 5'8"" and about 145 pounds. i usually wear a size 6. i wear a 34d bra. i found the suit to run a bit small. i returned it because  despite how much i liked the style  it just wasn't flattering on my body type."    2023-02-07T20:04:40Z</code></pre>
</div>
</div>
</section>
<section id="query-the-feature-store" class="level2" data-number="7">
<h2 data-number="7" class="anchored" data-anchor-id="query-the-feature-store"><span class="header-section-number">7</span> Query the Feature Store</h2>
<p>In addition to transforming the data and saving in S3 bucket, the processing job populates the feature store with the transformed and balanced data. Let’s query this data using Amazon Athena.</p>
<section id="export-training-validation-and-test-datasets-from-the-feature-store" class="level3" data-number="7.1">
<h3 data-number="7.1" class="anchored" data-anchor-id="export-training-validation-and-test-datasets-from-the-feature-store"><span class="header-section-number">7.1</span> Export training, validation, and test datasets from the Feature Store</h3>
<p>Here we will do the export only for the training dataset, as an example.</p>
<p>We will use the <code>athena_query()</code> function to create an Athena query for the defined above Feature Group. Then we can pull the table name of the Amazon Glue Data Catalog table which is auto-generated by Feature Store.</p>
<div class="cell" data-outputid="5d8077d0-a8b9-4e3a-920c-643ba37e4265">
<div class="sourceCode cell-code" id="cb44" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb44-1">feature_store_query <span class="op" style="color: #5E5E5E;">=</span> feature_group.athena_query()</span>
<span id="cb44-2"></span>
<span id="cb44-3">feature_store_table <span class="op" style="color: #5E5E5E;">=</span> feature_store_query.table_name</span>
<span id="cb44-4"></span>
<span id="cb44-5">query_string <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">"""</span></span>
<span id="cb44-6"><span class="st" style="color: #20794D;">    SELECT date,</span></span>
<span id="cb44-7"><span class="st" style="color: #20794D;">        review_id,</span></span>
<span id="cb44-8"><span class="st" style="color: #20794D;">        sentiment, </span></span>
<span id="cb44-9"><span class="st" style="color: #20794D;">        label_id,</span></span>
<span id="cb44-10"><span class="st" style="color: #20794D;">        input_ids,</span></span>
<span id="cb44-11"><span class="st" style="color: #20794D;">        review_body</span></span>
<span id="cb44-12"><span class="st" style="color: #20794D;">    FROM "</span><span class="sc" style="color: #5E5E5E;">{}</span><span class="st" style="color: #20794D;">" </span></span>
<span id="cb44-13"><span class="st" style="color: #20794D;">    WHERE split_type='train' </span></span>
<span id="cb44-14"><span class="st" style="color: #20794D;">    LIMIT 5</span></span>
<span id="cb44-15"><span class="st" style="color: #20794D;">"""</span>.<span class="bu" style="color: null;">format</span>(feature_store_table)</span>
<span id="cb44-16"></span>
<span id="cb44-17"><span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">'Glue Catalog table name: </span><span class="sc" style="color: #5E5E5E;">{}</span><span class="st" style="color: #20794D;">'</span>.<span class="bu" style="color: null;">format</span>(feature_store_table))</span>
<span id="cb44-18"><span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">'Running query: </span><span class="sc" style="color: #5E5E5E;">{}</span><span class="st" style="color: #20794D;">'</span>.<span class="bu" style="color: null;">format</span>(query_string))</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Glue Catalog table name: reviews-feature-group-1675799708-1675800251
Running query: 
    SELECT date,
        review_id,
        sentiment, 
        label_id,
        input_ids,
        review_body
    FROM "reviews-feature-group-1675799708-1675800251" 
    WHERE split_type='train' 
    LIMIT 5
</code></pre>
</div>
</div>
<p>Now we configure the S3 location for the query results. This allows us to re-use the query results for future queries if the data has not changed. We can even share this S3 location between team members to improve query performance for common queries on data that does not change often.</p>
<div class="cell" data-outputid="16e5dec6-907f-4617-c5b1-77c508a60490">
<div class="sourceCode cell-code" id="cb46" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb46-1">output_s3_uri <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">'s3://</span><span class="sc" style="color: #5E5E5E;">{}</span><span class="st" style="color: #20794D;">/query_results/</span><span class="sc" style="color: #5E5E5E;">{}</span><span class="st" style="color: #20794D;">/'</span>.<span class="bu" style="color: null;">format</span>(bucket, feature_store_offline_prefix)</span>
<span id="cb46-2"><span class="bu" style="color: null;">print</span>(output_s3_uri)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>s3://sagemaker-us-east-1-951182689916/query_results/reviews-feature-store-1675799708/</code></pre>
</div>
</div>
<p>Let’s query the feature store.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb48" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb48-1">feature_store_query.run(</span>
<span id="cb48-2">    query_string<span class="op" style="color: #5E5E5E;">=</span>query_string,</span>
<span id="cb48-3">    output_location<span class="op" style="color: #5E5E5E;">=</span>output_s3_uri </span>
<span id="cb48-4">)</span>
<span id="cb48-5"></span>
<span id="cb48-6">feature_store_query.wait()</span></code></pre></div>
</div>
<div class="cell" data-outputid="94020c99-585a-4aff-dd74-d988b35e3177">
<div class="sourceCode cell-code" id="cb49" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb49-1"><span class="im" style="color: #00769E;">import</span> pandas <span class="im" style="color: #00769E;">as</span> pd</span>
<span id="cb49-2">pd.set_option(<span class="st" style="color: #20794D;">"max_colwidth"</span>, <span class="dv" style="color: #AD0000;">100</span>)</span>
<span id="cb49-3"></span>
<span id="cb49-4">df_feature_store <span class="op" style="color: #5E5E5E;">=</span> feature_store_query.as_dataframe()</span>
<span id="cb49-5">df_feature_store</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="34">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>date</th>
      <th>review_id</th>
      <th>sentiment</th>
      <th>label_id</th>
      <th>input_ids</th>
      <th>review_body</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2023-02-07T20:04:40Z</td>
      <td>3151</td>
      <td>0</td>
      <td>1</td>
      <td>[0, 17425, 27941, 181, 267, 1318, 4, 939, 33, 10, 5342, 7174, 5120, 8, 42, 10601, 15, 162, 101, ...</td>
      <td>Definitely pj quality. i have a fairly thin frame and this hung on me like a tent. and it's very...</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2023-02-07T20:04:40Z</td>
      <td>2313</td>
      <td>0</td>
      <td>1</td>
      <td>[0, 713, 16, 10, 182, 11962, 3588, 4, 24, 21, 1969, 137, 939, 15158, 24, 4, 5, 1272, 939, 56, 71...</td>
      <td>This is a very cute dress. it was perfect before i washed it. the problems i had after washing i...</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2023-02-07T20:04:40Z</td>
      <td>10378</td>
      <td>1</td>
      <td>2</td>
      <td>[0, 100, 2162, 5, 10521, 1437, 61, 16, 10, 12058, 3195, 4, 939, 101, 5, 251, 5933, 11, 5, 3701, ...</td>
      <td>I bought the grey  which is a gorgeous color. i like the long length in the arms (though i tried...</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2023-02-07T20:04:40Z</td>
      <td>13251</td>
      <td>0</td>
      <td>1</td>
      <td>[0, 37396, 299, 804, 111, 8578, 11, 621, 4, 1237, 650, 1437, 941, 15, 2576, 23385, 1902, 4, 802,...</td>
      <td>Pretty top online - okay in person. runs small  especially on bottom hemline. thought it would h...</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2023-02-07T20:04:40Z</td>
      <td>9286</td>
      <td>-1</td>
      <td>0</td>
      <td>[0, 713, 299, 16, 2721, 804, 8, 11, 621, 4, 939, 524, 11, 117, 169, 10, 739, 455, 11464, 22101, ...</td>
      <td>This top is beautiful online and in person. i am in no way a large full figured gal  but i did o...</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
</section>
<section id="export-tsv-from-feature-store" class="level3" data-number="7.2">
<h3 data-number="7.2" class="anchored" data-anchor-id="export-tsv-from-feature-store"><span class="header-section-number">7.2</span> Export TSV from Feature Store</h3>
<p>Save the output as a TSV file:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb50" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb50-1">df_feature_store.to_csv(<span class="st" style="color: #20794D;">'./feature_store_export.tsv'</span>,</span>
<span id="cb50-2">                        sep<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'</span><span class="ch" style="color: #20794D;">\t</span><span class="st" style="color: #20794D;">'</span>,</span>
<span id="cb50-3">                        index<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">False</span>,</span>
<span id="cb50-4">                        header<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>)</span></code></pre></div>
</div>
<div class="cell" data-outputid="16035dde-6294-4b65-dbf0-bd405e1f1645">
<div class="sourceCode cell-code" id="cb51" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb51-1"><span class="op" style="color: #5E5E5E;">!</span>head <span class="op" style="color: #5E5E5E;">-</span>n <span class="dv" style="color: #AD0000;">5</span> .<span class="op" style="color: #5E5E5E;">/</span>feature_store_export.tsv</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>date    review_id   sentiment   label_id    input_ids   review_body
2023-02-07T20:04:40Z    3151    0   1   [0, 17425, 27941, 181, 267, 1318, 4, 939, 33, 10, 5342, 7174, 5120, 8, 42, 10601, 15, 162, 101, 10, 10178, 4, 8, 24, 18, 182, 7174, 1437, 98, 24, 1364, 25, 10, 6966, 1719, 1437, 53, 2299, 45, 10, 3588, 13, 932, 1493, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]    Definitely pj quality. i have a fairly thin frame and this hung on me like a tent. and it's very thin  so it works as a swim cover  but definitely not a dress for anything else.
2023-02-07T20:04:40Z    2313    0   1   [0, 713, 16, 10, 182, 11962, 3588, 4, 24, 21, 1969, 137, 939, 15158, 24, 4, 5, 1272, 939, 56, 71, 14784, 24, 21, 5, 15705, 13178, 10490, 9, 5, 3588, 28704, 5933, 11036, 150, 5, 1025, 909, 14187, 222, 45, 1437, 98, 5, 909, 14187, 3723, 15390, 66, 10, 205, 10468, 50, 80, 4, 8, 187, 5, 3588, 16, 10941, 939, 64, 75, 269, 3568, 24, 396, 634, 741, 17625, 13344, 1437, 941, 13, 5, 124, 9, 5, 3588, 187, 24, 18, 10941, 89, 8, 114, 939, 18822, 81, 47, 115, 192, 960, 4, 939, 437, 98, 5779, 11, 5, 1318, 142, 24, 16, 10, 182, 11962, 1437, 4342, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]  This is a very cute dress. it was perfect before i washed it. the problems i had after washing it was the outer cotton layer of the dress shrunk length wise while the inside black lining did not  so the black lining peeks out a good inch or two. and since the dress is shorter i can't really wear it without using biker shorts  especially for the back of the dress since it's shorter there and if i bent over you could see everything. i'm so disappointed in the quality because it is a very cute  ver
2023-02-07T20:04:40Z    10378   1   2   [0, 100, 2162, 5, 10521, 1437, 61, 16, 10, 12058, 3195, 4, 939, 101, 5, 251, 5933, 11, 5, 3701, 36, 18401, 939, 1381, 24, 15, 11, 430, 8089, 8, 5, 3124, 5933, 222, 182, 322, 3793, 8, 1256, 4, 939, 101, 5, 5933, 4, 5, 124, 473, 14902, 15673, 1437, 53, 939, 202, 101, 5, 6399, 4, 24, 18, 7082, 1437, 9881, 8, 34203, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]  I bought the grey  which is a gorgeous color. i like the long length in the arms (though i tried it on in different colors and the arm length did very). soft and pretty. i like the length. the back does wrinkle  but i still like the shirt. it's loose  casual and flattering.
2023-02-07T20:04:40Z    13251   0   1   [0, 37396, 299, 804, 111, 8578, 11, 621, 4, 1237, 650, 1437, 941, 15, 2576, 23385, 1902, 4, 802, 24, 74, 33, 10, 7021, 7, 24, 4, 24, 473, 45, 4, 55, 11708, 11, 621, 87, 939, 802, 24, 74, 28, 4, 14, 1979, 75, 912, 162, 31, 2396, 24, 600, 4, 24, 21, 5, 169, 24, 4976, 15, 127, 7050, 14, 21, 29747, 24203, 4, 1415, 101, 939, 21, 2498, 10, 741, 1452, 4, 939, 218, 75, 33, 10, 739, 7050, 1437, 95, 7735, 356, 15, 162, 4, 9327, 1437, 142, 24, 16, 41, 15652, 5780, 4, 299, 156, 13, 29284, 50, 10, 4716, 1459, 6429, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]  Pretty top online - okay in person. runs small  especially on bottom hemline. thought it would have a swing to it. it does not. more sheer in person than i thought it would be. that wouldn't stop me from keeping it though. it was the way it laid on my chest that was unflattering. looked like i was wearing a bib. i don't have a large chest  just weird look on me. unfortunate  because it is an adorable print. top made for thinner or a petite lady.</code></pre>
</div>
</div>
<p>Upload TSV to the S3 bucket:</p>
<div class="cell" data-outputid="57290246-f471-4e48-b0e5-1b2a681773b8">
<div class="sourceCode cell-code" id="cb53" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb53-1"><span class="op" style="color: #5E5E5E;">!</span>aws s3 cp .<span class="op" style="color: #5E5E5E;">/</span>feature_store_export.tsv s3:<span class="op" style="color: #5E5E5E;">//</span>$bucket<span class="op" style="color: #5E5E5E;">/</span>feature_store<span class="op" style="color: #5E5E5E;">/</span>feature_store_export.tsv</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>upload: ./feature_store_export.tsv to s3://sagemaker-us-east-1-951182689916/feature_store/feature_store_export.tsv</code></pre>
</div>
</div>
<p>Check the file in the S3 bucket:</p>
<div class="cell" data-outputid="5640ed9c-5bee-410e-c22b-c1097ba6fb6b">
<div class="sourceCode cell-code" id="cb55" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb55-1"><span class="op" style="color: #5E5E5E;">!</span>aws s3 ls <span class="op" style="color: #5E5E5E;">--</span>recursive s3:<span class="op" style="color: #5E5E5E;">//</span>$bucket<span class="op" style="color: #5E5E5E;">/</span>feature_store<span class="op" style="color: #5E5E5E;">/</span>feature_store_export.tsv</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>2023-02-07 20:11:18       4714 feature_store/feature_store_export.tsv</code></pre>
</div>
</div>
</section>
<section id="check-that-the-dataset-in-the-feature-store-is-balanced-by-sentiment" class="level3" data-number="7.3">
<h3 data-number="7.3" class="anchored" data-anchor-id="check-that-the-dataset-in-the-feature-store-is-balanced-by-sentiment"><span class="header-section-number">7.3</span> Check that the dataset in the Feature Store is balanced by sentiment</h3>
<p>Now we can setup an Athena query to check that the stored dataset is balanced by the target class <code>sentiment</code>.</p>
<p>We will rrite an SQL query to count the total number of the reviews per <code>sentiment</code> stored in the Feature Group.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb57" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb57-1">feature_store_query_2 <span class="op" style="color: #5E5E5E;">=</span> feature_group.athena_query()</span>
<span id="cb57-2"></span>
<span id="cb57-3">query_string_count_by_sentiment <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">"""</span></span>
<span id="cb57-4"><span class="st" style="color: #20794D;">SELECT sentiment, COUNT(*) AS count_reviews</span></span>
<span id="cb57-5"><span class="st" style="color: #20794D;">FROM "</span><span class="sc" style="color: #5E5E5E;">{}</span><span class="st" style="color: #20794D;">"</span></span>
<span id="cb57-6"><span class="st" style="color: #20794D;">GROUP BY sentiment</span></span>
<span id="cb57-7"><span class="st" style="color: #20794D;">"""</span>.<span class="bu" style="color: null;">format</span>(feature_store_table)</span></code></pre></div>
</div>
<p>Now we query the feature store.</p>
<div class="cell" data-outputid="d812a8f3-720c-401a-9cd5-553a467cf07f">
<div class="sourceCode cell-code" id="cb58" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb58-1">feature_store_query_2.run(</span>
<span id="cb58-2">    query_string<span class="op" style="color: #5E5E5E;">=</span>query_string_count_by_sentiment, </span>
<span id="cb58-3">    output_location<span class="op" style="color: #5E5E5E;">=</span>output_s3_uri </span>
<span id="cb58-4">)</span>
<span id="cb58-5"></span>
<span id="cb58-6">feature_store_query_2.wait()</span>
<span id="cb58-7"></span>
<span id="cb58-8">df_count_by_sentiment <span class="op" style="color: #5E5E5E;">=</span> feature_store_query_2.as_dataframe()</span>
<span id="cb58-9">df_count_by_sentiment</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="40">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>sentiment</th>
      <th>count_reviews</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>2051</td>
    </tr>
    <tr>
      <th>1</th>
      <td>-1</td>
      <td>2051</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1</td>
      <td>2051</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<p>Let’s visualize the result of the query in the bar plot, showing the count of the reviews by sentiment value.</p>
<div class="cell" data-outputid="e4ec7bc7-058d-4ec5-be1c-d4cac2bc3728">
<div class="sourceCode cell-code" id="cb59" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb59-1"><span class="op" style="color: #5E5E5E;">%</span>matplotlib inline</span>
<span id="cb59-2"><span class="im" style="color: #00769E;">import</span> seaborn <span class="im" style="color: #00769E;">as</span> sns</span>
<span id="cb59-3"></span>
<span id="cb59-4">sns.barplot(</span>
<span id="cb59-5">    data<span class="op" style="color: #5E5E5E;">=</span>df_count_by_sentiment, </span>
<span id="cb59-6">    x<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'sentiment'</span>, </span>
<span id="cb59-7">    y<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'count_reviews'</span>, </span>
<span id="cb59-8">    color<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"blue"</span></span>
<span id="cb59-9">)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="43">
<pre><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x7f9c4f4c9710&gt;</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="http://livingdatalab.com/posts/2023-02-08-feature-transformation-aws-sagemaker-processing-job-feature-store_files/figure-html/cell-36-output-2.png" class="img-fluid"></p>
</div>
</div>
</section>
</section>
<section id="acknowledgements" class="level2" data-number="8">
<h2 data-number="8" class="anchored" data-anchor-id="acknowledgements"><span class="header-section-number">8</span> Acknowledgements</h2>
<p>I’d like to express my thanks to the great <a href="https://www.deeplearning.ai/courses/practical-data-science-specialization/">Deep Learning AI Practical Data Science on AWS Specialisation Course</a> which i completed, and acknowledge the use of some images and other materials from the training course in this article.</p>


</section>

 ]]></description>
  <category>aws</category>
  <category>cloud-data-science</category>
  <category>natural-language-processing</category>
  <category>deep-learning</category>
  <guid>http://livingdatalab.com/posts/2023-02-08-feature-transformation-aws-sagemaker-processing-job-feature-store.html</guid>
  <pubDate>Wed, 08 Feb 2023 00:00:00 GMT</pubDate>
  <media:content url="https://github.com/pranath/blog/raw/master/images/aws.png" medium="image" type="image/png"/>
</item>
</channel>
</rss>
