<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>LivingDataLab</title>
<link>http://livingdatalab.com/index.html</link>
<atom:link href="http://livingdatalab.com/index.xml" rel="self" type="application/rss+xml"/>
<description>LivingDataLab AI Technical Blog</description>
<generator>quarto-1.3.450</generator>
<lastBuildDate>Wed, 08 Nov 2023 00:00:00 GMT</lastBuildDate>
<item>
  <title>Langchain and OpenAI Functions - Conversational agents</title>
  <dc:creator>Pranath Fernando</dc:creator>
  <link>http://livingdatalab.com/posts/2023-11-08-langchain-openai-functional_conversational-agents.html</link>
  <description><![CDATA[ In this post we aim to explore the advanced concept of conversational agents. Building upon our previous articles, we delve into creating a conversational future using Large Language Models (LLMs), blending tool usage with chat memory, akin to the workings of OpenAI’s ChatGPT. This article serves as a comprehensive guide to understanding and implementing these agents. ]]></description>
  <category>natural-language-processing</category>
  <category>langchain</category>
  <category>openai</category>
  <category>agents</category>
  <guid>http://livingdatalab.com/posts/2023-11-08-langchain-openai-functional_conversational-agents.html</guid>
  <pubDate>Wed, 08 Nov 2023 00:00:00 GMT</pubDate>
  <media:content url="https://github.com/pranath/blog/raw/master/images/langchain2.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Langchain and OpenAI Functions - Tools and Routing</title>
  <dc:creator>Pranath Fernando</dc:creator>
  <link>http://livingdatalab.com/posts/2023-11-07-langchain-openai-functions-tools-routing-apis.html</link>
  <description><![CDATA[ This article will delve into the mechanics of OpenAI’s functions, how to use it to select the appropriate tools for an LLM, and how to execute them efficiently. This can give you the knowledge to create your own tools tailored to specific tasks and to utilize them effectively within the OpenAI framework and Langchain to create powerful LLM based applications. ]]></description>
  <category>natural-language-processing</category>
  <category>langchain</category>
  <category>openai</category>
  <guid>http://livingdatalab.com/posts/2023-11-07-langchain-openai-functions-tools-routing-apis.html</guid>
  <pubDate>Tue, 07 Nov 2023 00:00:00 GMT</pubDate>
  <media:content url="https://github.com/pranath/blog/raw/master/images/langchain1.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Enhancing Data Structuring through Tagging and Extraction with OpenAI and LangChain</title>
  <dc:creator>Pranath Fernando</dc:creator>
  <link>http://livingdatalab.com/posts/2023-11-06-tagging-and-extraction-with-openai-and-langchain.html</link>
  <description><![CDATA[ Structured data extraction is increasingly becoming an essential tool for developers who wish to harness the power of Large Language Model capabilities. This blog post aims to provide a comprehensive understanding of how developers can use OpenAI functions for tagging and extraction, two primary use cases central to transforming unstructured text into structured, actionable data. ]]></description>
  <category>natural-language-processing</category>
  <category>langchain</category>
  <category>openai</category>
  <guid>http://livingdatalab.com/posts/2023-11-06-tagging-and-extraction-with-openai-and-langchain.html</guid>
  <pubDate>Mon, 06 Nov 2023 00:00:00 GMT</pubDate>
  <media:content url="https://github.com/pranath/blog/raw/master/images/langchain3.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>OpenAI Function Calling In LangChain</title>
  <dc:creator>Pranath Fernando</dc:creator>
  <link>http://livingdatalab.com/posts/2023-11-05-openai-function-calling-with-langchain.html</link>
  <description><![CDATA[ In our ongoing exploration of artificial intelligence tools, this article synthesizes insights from our previous articles, focusing on the integration of OpenAI functions with Langchain’s expression language. We will also delve into the utility of PyDantic, a Python library that simplifies the construction of OpenAI functions. ]]></description>
  <category>natural-language-processing</category>
  <category>langchain</category>
  <category>openai</category>
  <guid>http://livingdatalab.com/posts/2023-11-05-openai-function-calling-with-langchain.html</guid>
  <pubDate>Sun, 05 Nov 2023 00:00:00 GMT</pubDate>
  <media:content url="https://github.com/pranath/blog/raw/master/images/langchain2.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>An Introduction to LangChain Expression Language (LCEL)</title>
  <dc:creator>Pranath Fernando</dc:creator>
  <link>http://livingdatalab.com/posts/2023-11-04-an-introduction-to-langchain-expression-language.html</link>
  <description><![CDATA[ In the evolving world of large language models and AI, the need for more streamlined and efficient methods of chaining components and agents together has led to the development of LangChain, and more recently the LangChain Expression Language (LCEL). This new syntax simplifies the construction and management of these llm chains, enhancing transparency and usability, enabling the building of LLM application prototypes quicker and faster. ]]></description>
  <category>natural-language-processing</category>
  <category>deep-learning</category>
  <category>langchain</category>
  <category>openai</category>
  <guid>http://livingdatalab.com/posts/2023-11-04-an-introduction-to-langchain-expression-language.html</guid>
  <pubDate>Sat, 04 Nov 2023 00:00:00 GMT</pubDate>
  <media:content url="https://github.com/pranath/blog/raw/master/images/langchain1.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Unlocking Function Calls with OpenAI - A Step-by-Step Guide to Augmenting OpenAI Language Models</title>
  <dc:creator>Pranath Fernando</dc:creator>
  <link>http://livingdatalab.com/posts/2023-11-03-openai-function-calling-a-step-by-step-guide.html</link>
  <description><![CDATA[ OpenAI’s API comes with a range of powerful features, one of which is the ability to call functions. This capability, introduced a few months back, opens up a realm of possibilities, making interactions with the language model more dynamic and informative - allowing the model to access external knowledge and functionality. ]]></description>
  <category>natural-language-processing</category>
  <category>openai</category>
  <guid>http://livingdatalab.com/posts/2023-11-03-openai-function-calling-a-step-by-step-guide.html</guid>
  <pubDate>Fri, 03 Nov 2023 00:00:00 GMT</pubDate>
  <media:content url="https://github.com/pranath/blog/raw/master/images/ai-db1.png" medium="image" type="image/png"/>
</item>
<item>
  <title>AI and the Meta-Crisis - How AI is likely to play a major role in the multiple threats humanity faces and their possible solutions</title>
  <dc:creator>Pranath Fernando</dc:creator>
  <link>http://livingdatalab.com/posts/2023-10-15-ai-the-metacrisis-how-ai-will-play-a-major-roleiin-multiple-existential-threats-and-solutions.html</link>
  <description><![CDATA[ In an era marked by burgeoning technological capabilities, humanity finds itself on the precipice of self-induced existential calamities. The concern doesn’t merely lie in the manifest risks, but also in the inadvertent augmentation of certain risks while trying to mitigate others. This article aims to introduce concepts that help us understand these called the Meta-crisis and Third Attractor, and describe how AI plays an essential role of both of these. ]]></description>
  <category>ideas</category>
  <guid>http://livingdatalab.com/posts/2023-10-15-ai-the-metacrisis-how-ai-will-play-a-major-roleiin-multiple-existential-threats-and-solutions.html</guid>
  <pubDate>Sat, 14 Oct 2023 23:00:00 GMT</pubDate>
  <media:content url="https://github.com/pranath/blog/raw/master/images/ai-metacrisis.png" medium="image" type="image/png"/>
</item>
<item>
  <title>Using LLMs and Langchain to Ask Questions about SQL Databases</title>
  <dc:creator>Pranath Fernando</dc:creator>
  <link>http://livingdatalab.com/posts/2023-08-20-using-llms-langchain-to-ask-questions-about-sql-databases.html</link>
  <description><![CDATA[ SQL databases are frequently used to hold enterprise data. Natural language interaction with SQL databases is made feasible by LLMs such as OpenAI’s ChatGPT and GPT Models. LangChain provides SQL Chains and Agents for building and running SQL queries based on natural language prompts. These SQL Chains and Agents are compatible with any SQL dialect supported by SQLAlchemy (e.g., MySQL, PostgreSQL, Oracle SQL, Databricks, SQLite). ]]></description>
  <category>natural-language-processing</category>
  <category>agents</category>
  <category>langchain</category>
  <category>openai</category>
  <category>llm-evaluation</category>
  <guid>http://livingdatalab.com/posts/2023-08-20-using-llms-langchain-to-ask-questions-about-sql-databases.html</guid>
  <pubDate>Sat, 19 Aug 2023 23:00:00 GMT</pubDate>
  <media:content url="https://github.com/pranath/blog/raw/master/images/ai-db1.png" medium="image" type="image/png"/>
</item>
<item>
  <title>Comparing Question and Answer LLM System Outputs</title>
  <dc:creator>Pranath Fernando</dc:creator>
  <link>http://livingdatalab.com/posts/2023-08-19-comparing-question-answer-llm-system-outputs.html</link>
  <description><![CDATA[ The most frequent method for comparing two models is to run them both on the same dataset and compare the aggregate metrics. This method is valuable, but it may miss out on important information regarding the quality of the two system alternatives. In this instance, it may be useful to run direct pairwise comparisons on the responses and examine the resulting preference scores. ]]></description>
  <category>natural-language-processing</category>
  <category>deep-learning</category>
  <category>langchain</category>
  <category>openai</category>
  <category>llm-evaluation</category>
  <guid>http://livingdatalab.com/posts/2023-08-19-comparing-question-answer-llm-system-outputs.html</guid>
  <pubDate>Fri, 18 Aug 2023 23:00:00 GMT</pubDate>
  <media:content url="https://github.com/pranath/blog/raw/master/images/ai-eval4.png" medium="image" type="image/png"/>
</item>
<item>
  <title>Evaluating Question and Answer Systems with Dynamic Data</title>
  <dc:creator>Pranath Fernando</dc:creator>
  <link>http://livingdatalab.com/posts/2023-08-18-evaluating-question-answer-llm-systems-with-dynamic-data.html</link>
  <description><![CDATA[ In many real-world settings, the correct answer to a question may alter over time. For example, if you’re designing a Q&amp;A system on top of a database or that connects to an API, the underlying data may be updated regularly. In such instances, you should still measure the correctness of your system, but you should do so in a method that compensates for these changes. ]]></description>
  <category>natural-language-processing</category>
  <category>deep-learning</category>
  <category>langchain</category>
  <category>openai</category>
  <category>llm-evaluation</category>
  <guid>http://livingdatalab.com/posts/2023-08-18-evaluating-question-answer-llm-systems-with-dynamic-data.html</guid>
  <pubDate>Thu, 17 Aug 2023 23:00:00 GMT</pubDate>
  <media:content url="https://github.com/pranath/blog/raw/master/images/ai-eval3.png" medium="image" type="image/png"/>
</item>
<item>
  <title>Measuring the Accuracy of an LLM based Question and Answering System</title>
  <dc:creator>Pranath Fernando</dc:creator>
  <link>http://livingdatalab.com/posts/2023-08-17-measuring-accuracy-of-a-question-answering-system.html</link>
  <description><![CDATA[ Evaluating a question and response system can help you improve its system architecture as well as the prompt and model quality. We tend to improve what we can measure, therefore verifying for correctness is a key focus. One difficulty in gauging accuracy is that the responses are unstructured text. A Q&amp;A system can generate lengthy responses, rendering typical metrics like BLEU or ROUGE unreliable. In this case, employing a well-labeled dataset and llm-assisted assessors can help you rate the response quality of your system. This supplemented any human review and other measurements you may have already implemented. ]]></description>
  <category>natural-language-processing</category>
  <category>deep-learning</category>
  <category>langchain</category>
  <category>openai</category>
  <category>llm-evaluation</category>
  <guid>http://livingdatalab.com/posts/2023-08-17-measuring-accuracy-of-a-question-answering-system.html</guid>
  <pubDate>Wed, 16 Aug 2023 23:00:00 GMT</pubDate>
  <media:content url="https://github.com/pranath/blog/raw/master/images/ai-eval2.png" medium="image" type="image/png"/>
</item>
<item>
  <title>Langsmith for LLM Application Evaluation &amp; Monitoring</title>
  <dc:creator>Pranath Fernando</dc:creator>
  <link>http://livingdatalab.com/posts/2023-08-16-langsmith-for-llm-application-evaluation.html</link>
  <description><![CDATA[ LangChain simplifies the development of LLM apps and Agents. However, getting LLM applications into production can be tricky. To produce a high-quality result, you will most likely need to heavily customise and iterate on your prompts, chains, and other components. ]]></description>
  <category>natural-language-processing</category>
  <category>deep-learning</category>
  <category>langchain</category>
  <category>openai</category>
  <category>llm-evaluation</category>
  <guid>http://livingdatalab.com/posts/2023-08-16-langsmith-for-llm-application-evaluation.html</guid>
  <pubDate>Tue, 15 Aug 2023 23:00:00 GMT</pubDate>
  <media:content url="https://github.com/pranath/blog/raw/master/images/ai-eval1.png" medium="image" type="image/png"/>
</item>
<item>
  <title>Guarding Against Undesirable LLM Outputs with the Self-Critique Chain</title>
  <dc:creator>Pranath Fernando</dc:creator>
  <link>http://livingdatalab.com/posts/2023-08-15-guarding-against-bad-outputs-with-self-critque-chain.html</link>
  <description><![CDATA[ Large language models (LLMs) can produce unpleasant results on occasion. Some well-known examples of this behaviour include hazardous or hallucinatory content. It is critical to use a technique to ensure that the model’s answers are appropriate in a production setting. Fortunately, these foundational models have the necessary knowledge to correct themselves with a gentle push in the proper direction. ]]></description>
  <category>natural-language-processing</category>
  <category>deep-learning</category>
  <category>langchain</category>
  <category>activeloop</category>
  <category>openai</category>
  <guid>http://livingdatalab.com/posts/2023-08-15-guarding-against-bad-outputs-with-self-critque-chain.html</guid>
  <pubDate>Mon, 14 Aug 2023 23:00:00 GMT</pubDate>
  <media:content url="https://github.com/pranath/blog/raw/master/images/langchain-deeplake2.png" medium="image" type="image/png"/>
</item>
<item>
  <title>Creating a Voice Assistant for your Knowledge Base</title>
  <dc:creator>Pranath Fernando</dc:creator>
  <link>http://livingdatalab.com/posts/2023-08-14-voice-assistant-for-your-knowledge-base.html</link>
  <description><![CDATA[ Here we plan to build a voice assistant for a knowledge base. This post will explain how to create your own voice assistant using cutting-edge artificial intelligence tools. OpenAI’s Whisper, a sophisticated automatic speech recognition (ASR) algorithm, is used by the voice assistant. Whisper efficiently converts our vocal inputs to text. After we’ve transcribed our speech inputs into text, we’ll focus on creating voice outputs. We use Eleven Labs to accomplish this, which allows the voice assistant to reply to users in an engaging and natural manner. ]]></description>
  <category>natural-language-processing</category>
  <category>deep-learning</category>
  <category>langchain</category>
  <category>activeloop</category>
  <category>openai</category>
  <guid>http://livingdatalab.com/posts/2023-08-14-voice-assistant-for-your-knowledge-base.html</guid>
  <pubDate>Sun, 13 Aug 2023 23:00:00 GMT</pubDate>
  <media:content url="https://github.com/pranath/blog/raw/master/images/langchain-deeplake1.png" medium="image" type="image/png"/>
</item>
<item>
  <title>A YouTube Video Summarizer Using Whisper and LangChain</title>
  <dc:creator>Pranath Fernando</dc:creator>
  <link>http://livingdatalab.com/posts/2023-08-13-a-youtube-summariser-using-whisper-and-langchain.html</link>
  <description><![CDATA[ We recently discussed LangChain’s strong feature called chains, which allows for the building of an end-to-end pipeline for leveraging language models. To create a user-friendly interface, chains incorporate many components such as models, prompts, memory, parsing output, and debugging. We also went over the process of creating custom pipelines by inheriting the Chain class and looked at the LLMChain as an example. That article laid the groundwork for subsequent posts, in which we will apply these concepts to a hands-on project of summarising a YouTube video. ]]></description>
  <category>natural-language-processing</category>
  <category>deep-learning</category>
  <category>langchain</category>
  <category>activeloop</category>
  <category>openai</category>
  <guid>http://livingdatalab.com/posts/2023-08-13-a-youtube-summariser-using-whisper-and-langchain.html</guid>
  <pubDate>Sat, 12 Aug 2023 23:00:00 GMT</pubDate>
  <media:content url="https://github.com/pranath/blog/raw/master/images/langchain-deeplake4.png" medium="image" type="image/png"/>
</item>
<item>
  <title>Chains and why they are used in Langchain</title>
  <dc:creator>Pranath Fernando</dc:creator>
  <link>http://livingdatalab.com/posts/2023-08-12-chains-and-why-they-are-used-in-langchain.html</link>
  <description><![CDATA[ Because it allows for natural language querying, prompting is regarded the most effective means of communicating with language models. We talked over prompting tactics and briefly used chains earlier. The chains will be explained in greater depth in this lesson. ]]></description>
  <category>natural-language-processing</category>
  <category>deep-learning</category>
  <category>langchain</category>
  <category>activeloop</category>
  <category>openai</category>
  <guid>http://livingdatalab.com/posts/2023-08-12-chains-and-why-they-are-used-in-langchain.html</guid>
  <pubDate>Fri, 11 Aug 2023 23:00:00 GMT</pubDate>
  <media:content url="https://github.com/pranath/blog/raw/master/images/langchain-deeplake3.png" medium="image" type="image/png"/>
</item>
<item>
  <title>Building a Customer Support Question Answering Chatbot</title>
  <dc:creator>Pranath Fernando</dc:creator>
  <link>http://livingdatalab.com/posts/2023-08-11-building-a-customer-support-chatbot.html</link>
  <description><![CDATA[ Large language models like GPT-4 and ChatGPT have emerged as key advancements in the IT world as we observe faster technological growth. These cutting-edge models exhibit outstanding skill in content creation. They do, however, face some difficulties, including as biases and hallucinations. Despite these drawbacks, LLMs have the power to completely change the way chatbot development is done. ]]></description>
  <category>natural-language-processing</category>
  <category>deep-learning</category>
  <category>langchain</category>
  <category>activeloop</category>
  <category>openai</category>
  <category>retrievers</category>
  <category>vectordb</category>
  <guid>http://livingdatalab.com/posts/2023-08-11-building-a-customer-support-chatbot.html</guid>
  <pubDate>Thu, 10 Aug 2023 23:00:00 GMT</pubDate>
  <media:content url="https://github.com/pranath/blog/raw/master/images/langchain-deeplake2.png" medium="image" type="image/png"/>
</item>
<item>
  <title>Exploring Embeddings for Large Language Models</title>
  <dc:creator>Pranath Fernando</dc:creator>
  <link>http://livingdatalab.com/posts/2023-08-10-exploring-embeddings-for-large-language-models.html</link>
  <description><![CDATA[ The most fascinating and useful components of machine learning are vector embeddings, which are essential to many natural language processing, recommendation, and search algorithms. You have dealt with embedding-using systems if you have used voice assistants, recommendation engines, or translators. ]]></description>
  <category>natural-language-processing</category>
  <category>deep-learning</category>
  <category>langchain</category>
  <category>activeloop</category>
  <category>openai</category>
  <category>retrievers</category>
  <category>vectordb</category>
  <guid>http://livingdatalab.com/posts/2023-08-10-exploring-embeddings-for-large-language-models.html</guid>
  <pubDate>Wed, 09 Aug 2023 23:00:00 GMT</pubDate>
  <media:content url="https://github.com/pranath/blog/raw/master/images/langchain-deeplake2.png" medium="image" type="image/png"/>
</item>
<item>
  <title>Text Splitters for Retrieval and Large Language Models</title>
  <dc:creator>Pranath Fernando</dc:creator>
  <link>http://livingdatalab.com/posts/2023-08-09-text-splitters-for-retrieval-and-large-language-models.html</link>
  <description><![CDATA[ Large Language Models are known for producing text that looks and reads like human beings, but they may also “hallucinate” and produce information that is both accurate and illogical. It’s interesting to note that this inclination can be helpful while undertaking creative work because it produces a variety of original and inventive thoughts, opening up fresh viewpoints and promoting the creative process. This presents a problem, though, in circumstances where accuracy is crucial, including code reviews, duties involving insurance, or answers to research-related questions. ]]></description>
  <category>natural-language-processing</category>
  <category>deep-learning</category>
  <category>langchain</category>
  <category>activeloop</category>
  <category>openai</category>
  <category>retrievers</category>
  <guid>http://livingdatalab.com/posts/2023-08-09-text-splitters-for-retrieval-and-large-language-models.html</guid>
  <pubDate>Tue, 08 Aug 2023 23:00:00 GMT</pubDate>
  <media:content url="https://github.com/pranath/blog/raw/master/images/langchain-deeplake1.png" medium="image" type="image/png"/>
</item>
<item>
  <title>Streamlined Data Ingestion for LLMs</title>
  <dc:creator>Pranath Fernando</dc:creator>
  <link>http://livingdatalab.com/posts/2023-08-08-streamlined-data-ingestion-for-llms.html</link>
  <description><![CDATA[ The LangChain library provides a number of assistance classes that are intended to make it easier to load and extract data from various sources. These classes simplify managing various data formats, regardless of whether the information came from a PDF file or online content. ]]></description>
  <category>natural-language-processing</category>
  <category>deep-learning</category>
  <category>langchain</category>
  <category>activeloop</category>
  <category>openai</category>
  <category>retrievers</category>
  <guid>http://livingdatalab.com/posts/2023-08-08-streamlined-data-ingestion-for-llms.html</guid>
  <pubDate>Mon, 07 Aug 2023 23:00:00 GMT</pubDate>
  <media:content url="https://github.com/pranath/blog/raw/master/images/langchain-deeplake4.png" medium="image" type="image/png"/>
</item>
</channel>
</rss>
