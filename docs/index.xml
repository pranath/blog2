<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>LivingDataLab</title>
<link>http://livingdatalab.com/index.html</link>
<atom:link href="http://livingdatalab.com/index.xml" rel="self" type="application/rss+xml"/>
<description>LivingDataLab Data Science &amp; AI Blog</description>
<generator>quarto-1.3.450</generator>
<lastBuildDate>Fri, 18 Aug 2023 23:00:00 GMT</lastBuildDate>
<item>
  <title>Comparing Question and Answer LLM System Outputs</title>
  <dc:creator>Pranath Fernando</dc:creator>
  <link>http://livingdatalab.com/posts/2023-08-19-comparing-question-answer-llm-system-outputs.html</link>
  <description><![CDATA[ The most frequent method for comparing two models is to run them both on the same dataset and compare the aggregate metrics. This method is valuable, but it may miss out on important information regarding the quality of the two system alternatives. In this instance, it may be useful to run direct pairwise comparisons on the responses and examine the resulting preference scores. ]]></description>
  <category>natural-language-processing</category>
  <category>deep-learning</category>
  <category>langchain</category>
  <category>openai</category>
  <category>llm-evaluation</category>
  <guid>http://livingdatalab.com/posts/2023-08-19-comparing-question-answer-llm-system-outputs.html</guid>
  <pubDate>Fri, 18 Aug 2023 23:00:00 GMT</pubDate>
  <media:content url="https://github.com/pranath/blog/raw/master/images/ai-eval4.png" medium="image" type="image/png"/>
</item>
<item>
  <title>Evaluating Question and Answer Systems with Dynamic Data</title>
  <dc:creator>Pranath Fernando</dc:creator>
  <link>http://livingdatalab.com/posts/2023-08-18-evaluating-question-answer-llm-systems-with-dynamic-data.html</link>
  <description><![CDATA[ In many real-world settings, the correct answer to a question may alter over time. For example, if you’re designing a Q&amp;A system on top of a database or that connects to an API, the underlying data may be updated regularly. In such instances, you should still measure the correctness of your system, but you should do so in a method that compensates for these changes. ]]></description>
  <category>natural-language-processing</category>
  <category>deep-learning</category>
  <category>langchain</category>
  <category>openai</category>
  <category>llm-evaluation</category>
  <guid>http://livingdatalab.com/posts/2023-08-18-evaluating-question-answer-llm-systems-with-dynamic-data.html</guid>
  <pubDate>Thu, 17 Aug 2023 23:00:00 GMT</pubDate>
  <media:content url="https://github.com/pranath/blog/raw/master/images/ai-eval3.png" medium="image" type="image/png"/>
</item>
<item>
  <title>Measuring the Accuracy of an LLM based Question and Answering System</title>
  <dc:creator>Pranath Fernando</dc:creator>
  <link>http://livingdatalab.com/posts/2023-08-17-measuring-accuracy-of-a-question-answering-system.html</link>
  <description><![CDATA[ Evaluating a question and response system can help you improve its system architecture as well as the prompt and model quality. We tend to improve what we can measure, therefore verifying for correctness is a key focus. One difficulty in gauging accuracy is that the responses are unstructured text. A Q&amp;A system can generate lengthy responses, rendering typical metrics like BLEU or ROUGE unreliable. In this case, employing a well-labeled dataset and llm-assisted assessors can help you rate the response quality of your system. This supplemented any human review and other measurements you may have already implemented. ]]></description>
  <category>natural-language-processing</category>
  <category>deep-learning</category>
  <category>langchain</category>
  <category>openai</category>
  <category>llm-evaluation</category>
  <guid>http://livingdatalab.com/posts/2023-08-17-measuring-accuracy-of-a-question-answering-system.html</guid>
  <pubDate>Wed, 16 Aug 2023 23:00:00 GMT</pubDate>
  <media:content url="https://github.com/pranath/blog/raw/master/images/ai-eval2.png" medium="image" type="image/png"/>
</item>
<item>
  <title>Langsmith for LLM Application Evaluation &amp; Monitoring</title>
  <dc:creator>Pranath Fernando</dc:creator>
  <link>http://livingdatalab.com/posts/2023-08-16-langsmith-for-llm-application-evaluation.html</link>
  <description><![CDATA[ LangChain simplifies the development of LLM apps and Agents. However, getting LLM applications into production can be tricky. To produce a high-quality result, you will most likely need to heavily customise and iterate on your prompts, chains, and other components. ]]></description>
  <category>natural-language-processing</category>
  <category>deep-learning</category>
  <category>langchain</category>
  <category>openai</category>
  <category>llm-evaluation</category>
  <guid>http://livingdatalab.com/posts/2023-08-16-langsmith-for-llm-application-evaluation.html</guid>
  <pubDate>Tue, 15 Aug 2023 23:00:00 GMT</pubDate>
  <media:content url="https://github.com/pranath/blog/raw/master/images/ai-eval1.png" medium="image" type="image/png"/>
</item>
<item>
  <title>Guarding Against Undesirable LLM Outputs with the Self-Critique Chain</title>
  <dc:creator>Pranath Fernando</dc:creator>
  <link>http://livingdatalab.com/posts/2023-08-15-guarding-against-bad-outputs-with-self-critque-chain.html</link>
  <description><![CDATA[ Large language models (LLMs) can produce unpleasant results on occasion. Some well-known examples of this behaviour include hazardous or hallucinatory content. It is critical to use a technique to ensure that the model’s answers are appropriate in a production setting. Fortunately, these foundational models have the necessary knowledge to correct themselves with a gentle push in the proper direction. ]]></description>
  <category>natural-language-processing</category>
  <category>deep-learning</category>
  <category>langchain</category>
  <category>activeloop</category>
  <category>openai</category>
  <guid>http://livingdatalab.com/posts/2023-08-15-guarding-against-bad-outputs-with-self-critque-chain.html</guid>
  <pubDate>Mon, 14 Aug 2023 23:00:00 GMT</pubDate>
  <media:content url="https://github.com/pranath/blog/raw/master/images/langchain-deeplake2.png" medium="image" type="image/png"/>
</item>
<item>
  <title>Creating a Voice Assistant for your Knowledge Base</title>
  <dc:creator>Pranath Fernando</dc:creator>
  <link>http://livingdatalab.com/posts/2023-08-14-voice-assistant-for-your-knowledge-base.html</link>
  <description><![CDATA[ Here we plan to build a voice assistant for a knowledge base. This post will explain how to create your own voice assistant using cutting-edge artificial intelligence tools. OpenAI’s Whisper, a sophisticated automatic speech recognition (ASR) algorithm, is used by the voice assistant. Whisper efficiently converts our vocal inputs to text. After we’ve transcribed our speech inputs into text, we’ll focus on creating voice outputs. We use Eleven Labs to accomplish this, which allows the voice assistant to reply to users in an engaging and natural manner. ]]></description>
  <category>natural-language-processing</category>
  <category>deep-learning</category>
  <category>langchain</category>
  <category>activeloop</category>
  <category>openai</category>
  <guid>http://livingdatalab.com/posts/2023-08-14-voice-assistant-for-your-knowledge-base.html</guid>
  <pubDate>Sun, 13 Aug 2023 23:00:00 GMT</pubDate>
  <media:content url="https://github.com/pranath/blog/raw/master/images/langchain-deeplake1.png" medium="image" type="image/png"/>
</item>
<item>
  <title>A YouTube Video Summarizer Using Whisper and LangChain</title>
  <dc:creator>Pranath Fernando</dc:creator>
  <link>http://livingdatalab.com/posts/2023-08-13-a-youtube-summariser-using-whisper-and-langchain.html</link>
  <description><![CDATA[ We recently discussed LangChain’s strong feature called chains, which allows for the building of an end-to-end pipeline for leveraging language models. To create a user-friendly interface, chains incorporate many components such as models, prompts, memory, parsing output, and debugging. We also went over the process of creating custom pipelines by inheriting the Chain class and looked at the LLMChain as an example. That article laid the groundwork for subsequent posts, in which we will apply these concepts to a hands-on project of summarising a YouTube video. ]]></description>
  <category>natural-language-processing</category>
  <category>deep-learning</category>
  <category>langchain</category>
  <category>activeloop</category>
  <category>openai</category>
  <guid>http://livingdatalab.com/posts/2023-08-13-a-youtube-summariser-using-whisper-and-langchain.html</guid>
  <pubDate>Sat, 12 Aug 2023 23:00:00 GMT</pubDate>
  <media:content url="https://github.com/pranath/blog/raw/master/images/langchain-deeplake4.png" medium="image" type="image/png"/>
</item>
<item>
  <title>Chains and why they are used in Langchain</title>
  <dc:creator>Pranath Fernando</dc:creator>
  <link>http://livingdatalab.com/posts/2023-08-12-chains-and-why-they-are-used-in-langchain.html</link>
  <description><![CDATA[ Because it allows for natural language querying, prompting is regarded the most effective means of communicating with language models. We talked over prompting tactics and briefly used chains earlier. The chains will be explained in greater depth in this lesson. ]]></description>
  <category>natural-language-processing</category>
  <category>deep-learning</category>
  <category>langchain</category>
  <category>activeloop</category>
  <category>openai</category>
  <guid>http://livingdatalab.com/posts/2023-08-12-chains-and-why-they-are-used-in-langchain.html</guid>
  <pubDate>Fri, 11 Aug 2023 23:00:00 GMT</pubDate>
  <media:content url="https://github.com/pranath/blog/raw/master/images/langchain-deeplake3.png" medium="image" type="image/png"/>
</item>
<item>
  <title>Building a Customer Support Question Answering Chatbot</title>
  <dc:creator>Pranath Fernando</dc:creator>
  <link>http://livingdatalab.com/posts/2023-08-11-building-a-customer-support-chatbot.html</link>
  <description><![CDATA[ Large language models like GPT-4 and ChatGPT have emerged as key advancements in the IT world as we observe faster technological growth. These cutting-edge models exhibit outstanding skill in content creation. They do, however, face some difficulties, including as biases and hallucinations. Despite these drawbacks, LLMs have the power to completely change the way chatbot development is done. ]]></description>
  <category>natural-language-processing</category>
  <category>deep-learning</category>
  <category>langchain</category>
  <category>activeloop</category>
  <category>openai</category>
  <category>retrievers</category>
  <category>vectordb</category>
  <guid>http://livingdatalab.com/posts/2023-08-11-building-a-customer-support-chatbot.html</guid>
  <pubDate>Thu, 10 Aug 2023 23:00:00 GMT</pubDate>
  <media:content url="https://github.com/pranath/blog/raw/master/images/langchain-deeplake2.png" medium="image" type="image/png"/>
</item>
<item>
  <title>Exploring Embeddings for Large Language Models</title>
  <dc:creator>Pranath Fernando</dc:creator>
  <link>http://livingdatalab.com/posts/2023-08-10-exploring-embeddings-for-large-language-models.html</link>
  <description><![CDATA[ The most fascinating and useful components of machine learning are vector embeddings, which are essential to many natural language processing, recommendation, and search algorithms. You have dealt with embedding-using systems if you have used voice assistants, recommendation engines, or translators. ]]></description>
  <category>natural-language-processing</category>
  <category>deep-learning</category>
  <category>langchain</category>
  <category>activeloop</category>
  <category>openai</category>
  <category>retrievers</category>
  <category>vectordb</category>
  <guid>http://livingdatalab.com/posts/2023-08-10-exploring-embeddings-for-large-language-models.html</guid>
  <pubDate>Wed, 09 Aug 2023 23:00:00 GMT</pubDate>
  <media:content url="https://github.com/pranath/blog/raw/master/images/langchain-deeplake2.png" medium="image" type="image/png"/>
</item>
<item>
  <title>Text Splitters for Retrieval and Large Language Models</title>
  <dc:creator>Pranath Fernando</dc:creator>
  <link>http://livingdatalab.com/posts/2023-08-09-text-splitters-for-retrieval-and-large-language-models.html</link>
  <description><![CDATA[ Large Language Models are known for producing text that looks and reads like human beings, but they may also “hallucinate” and produce information that is both accurate and illogical. It’s interesting to note that this inclination can be helpful while undertaking creative work because it produces a variety of original and inventive thoughts, opening up fresh viewpoints and promoting the creative process. This presents a problem, though, in circumstances where accuracy is crucial, including code reviews, duties involving insurance, or answers to research-related questions. ]]></description>
  <category>natural-language-processing</category>
  <category>deep-learning</category>
  <category>langchain</category>
  <category>activeloop</category>
  <category>openai</category>
  <category>retrievers</category>
  <guid>http://livingdatalab.com/posts/2023-08-09-text-splitters-for-retrieval-and-large-language-models.html</guid>
  <pubDate>Tue, 08 Aug 2023 23:00:00 GMT</pubDate>
  <media:content url="https://github.com/pranath/blog/raw/master/images/langchain-deeplake1.png" medium="image" type="image/png"/>
</item>
<item>
  <title>Streamlined Data Ingestion for LLMs</title>
  <dc:creator>Pranath Fernando</dc:creator>
  <link>http://livingdatalab.com/posts/2023-08-08-streamlined-data-ingestion-for-llms.html</link>
  <description><![CDATA[ The LangChain library provides a number of assistance classes that are intended to make it easier to load and extract data from various sources. These classes simplify managing various data formats, regardless of whether the information came from a PDF file or online content. ]]></description>
  <category>natural-language-processing</category>
  <category>deep-learning</category>
  <category>langchain</category>
  <category>activeloop</category>
  <category>openai</category>
  <category>retrievers</category>
  <guid>http://livingdatalab.com/posts/2023-08-08-streamlined-data-ingestion-for-llms.html</guid>
  <pubDate>Mon, 07 Aug 2023 23:00:00 GMT</pubDate>
  <media:content url="https://github.com/pranath/blog/raw/master/images/langchain-deeplake4.png" medium="image" type="image/png"/>
</item>
<item>
  <title>Exploring The Role of LangChain’s Indexes and Retrievers</title>
  <dc:creator>Pranath Fernando</dc:creator>
  <link>http://livingdatalab.com/posts/2023-08-07-langchain-indexes-and-retreievers.html</link>
  <description><![CDATA[ In LangChain, retrievers and indexes are essential for organising documents and obtaining relevant data for LLMs. With an emphasis on the function of indexes and retrievers, we will examine some of the benefits and drawbacks of employing document-based LLMs (i.e., LLMs that incorporate pertinent documents inside their prompts). ]]></description>
  <category>natural-language-processing</category>
  <category>deep-learning</category>
  <category>langchain</category>
  <category>activeloop</category>
  <category>openai</category>
  <category>retrievers</category>
  <guid>http://livingdatalab.com/posts/2023-08-07-langchain-indexes-and-retreievers.html</guid>
  <pubDate>Sun, 06 Aug 2023 23:00:00 GMT</pubDate>
  <media:content url="https://github.com/pranath/blog/raw/master/images/langchain-deeplake3.png" medium="image" type="image/png"/>
</item>
<item>
  <title>Creating Knowledge Graphs from Textual Data and LLM’s</title>
  <dc:creator>Pranath Fernando</dc:creator>
  <link>http://livingdatalab.com/posts/2023-08-06-creating-knowledge-graphs-from-text-data-with-llms.html</link>
  <description><![CDATA[ Understanding the connections between various types of information is essential in today’s data-driven environment. Unstructured text may now be transformed into a structured network of items and their relationships using knowledge graphs, which have evolved as a potent tool for visualising and exploring these connections. We will walk you through a straightforward method for converting textual data into a knowledge graph, making complex content more approachable and understandable. ]]></description>
  <category>natural-language-processing</category>
  <category>deep-learning</category>
  <category>langchain</category>
  <category>activeloop</category>
  <category>openai</category>
  <category>prompt-engineering</category>
  <category>network-analysis</category>
  <guid>http://livingdatalab.com/posts/2023-08-06-creating-knowledge-graphs-from-text-data-with-llms.html</guid>
  <pubDate>Sat, 05 Aug 2023 23:00:00 GMT</pubDate>
  <media:content url="https://github.com/pranath/blog/raw/master/images/langchain-deeplake2.png" medium="image" type="image/png"/>
</item>
<item>
  <title>An Improved News Articles Summarizer</title>
  <dc:creator>Pranath Fernando</dc:creator>
  <link>http://livingdatalab.com/posts/2023-08-05-an-improved-news-articles-summariser.html</link>
  <description><![CDATA[ This article aims to improve our earlier News Article Summarizer implementation. Our goal is to improve our tool’s ability to extract the most important information from lengthy news items and display it in an easy-to-read, bulleted list format. With this improvement, consumers will be able to quickly and clearly understand the essential ideas of an article, saving time and improving the reading experience. ]]></description>
  <category>natural-language-processing</category>
  <category>deep-learning</category>
  <category>langchain</category>
  <category>activeloop</category>
  <category>openai</category>
  <category>prompt-engineering</category>
  <guid>http://livingdatalab.com/posts/2023-08-05-an-improved-news-articles-summariser.html</guid>
  <pubDate>Fri, 04 Aug 2023 23:00:00 GMT</pubDate>
  <media:content url="https://github.com/pranath/blog/raw/master/images/langchain-deeplake1.png" medium="image" type="image/png"/>
</item>
<item>
  <title>Managing Large Language Model Outputs with Parsers</title>
  <dc:creator>Pranath Fernando</dc:creator>
  <link>http://livingdatalab.com/posts/2023-08-04-managing-llm-outputs-with-parsers.html</link>
  <description><![CDATA[ In a production setting, a predictable data structure is always desired even when language models can only produce textual outputs. Imagine, for instance, that you are developing a thesaurus application and want to provide a list of potential synonyms depending on the context. The LLMs are strong enough to produce a lot of proposals quickly. ]]></description>
  <category>natural-language-processing</category>
  <category>deep-learning</category>
  <category>langchain</category>
  <category>activeloop</category>
  <category>openai</category>
  <category>prompt-engineering</category>
  <guid>http://livingdatalab.com/posts/2023-08-04-managing-llm-outputs-with-parsers.html</guid>
  <pubDate>Thu, 03 Aug 2023 23:00:00 GMT</pubDate>
  <media:content url="https://github.com/pranath/blog/raw/master/images/langchain-deeplake4.png" medium="image" type="image/png"/>
</item>
<item>
  <title>Getting the Best of Few Shot Prompts and Example Selectors for LLMs</title>
  <dc:creator>Pranath Fernando</dc:creator>
  <link>http://livingdatalab.com/posts/2023-08-03-getting-the-best-of-few-shot-prompts-and-example-selectors.html</link>
  <description><![CDATA[ In this article, we’ll examine how example selectors and few-shot prompts might improve LangChain’s language model performance. There are several ways to implement Few-shot prompting and Example selection in LangChain. To help you get the most of your language model, we’ll go through three different strategies and weigh their benefits and drawbacks. ]]></description>
  <category>natural-language-processing</category>
  <category>deep-learning</category>
  <category>langchain</category>
  <category>activeloop</category>
  <category>openai</category>
  <category>prompt-engineering</category>
  <guid>http://livingdatalab.com/posts/2023-08-03-getting-the-best-of-few-shot-prompts-and-example-selectors.html</guid>
  <pubDate>Wed, 02 Aug 2023 23:00:00 GMT</pubDate>
  <media:content url="https://github.com/pranath/blog/raw/master/images/langchain-deeplake3.png" medium="image" type="image/png"/>
</item>
<item>
  <title>Using Prompt Templates with Large Language Models</title>
  <dc:creator>Pranath Fernando</dc:creator>
  <link>http://livingdatalab.com/posts/2023-08-02-using-prompt-templates-for-llms.html</link>
  <description><![CDATA[ We can do a variety of jobs thanks to large language models. These models work on the simple premise that they take a text input sequence and produce a text output sequence. The prompt or input text is the most important element in this process. ]]></description>
  <category>natural-language-processing</category>
  <category>deep-learning</category>
  <category>langchain</category>
  <category>activeloop</category>
  <category>openai</category>
  <category>prompt-engineering</category>
  <guid>http://livingdatalab.com/posts/2023-08-02-using-prompt-templates-for-llms.html</guid>
  <pubDate>Tue, 01 Aug 2023 23:00:00 GMT</pubDate>
  <media:content url="https://github.com/pranath/blog/raw/master/images/langchain-deeplake2.png" medium="image" type="image/png"/>
</item>
<item>
  <title>Prompt Engineering Tips and Tricks for Large Language Models</title>
  <dc:creator>Pranath Fernando</dc:creator>
  <link>http://livingdatalab.com/posts/2023-08-01-prompt-engineering-tips-and-tricks.html</link>
  <description><![CDATA[ In the relatively young field of prompt engineering, prompts are created and improved in order to make efficient use of language models for a variety of applications and research areas. It is necessary for many NLP tasks and aids in a better understanding of the strengths and weaknesses of LLMs. To assist you better comprehend the subtleties of prompt engineering, we will use real-world examples to contrast good and terrible prompts. ]]></description>
  <category>natural-language-processing</category>
  <category>deep-learning</category>
  <category>langchain</category>
  <category>activeloop</category>
  <category>openai</category>
  <category>prompt-engineering</category>
  <guid>http://livingdatalab.com/posts/2023-08-01-prompt-engineering-tips-and-tricks.html</guid>
  <pubDate>Mon, 31 Jul 2023 23:00:00 GMT</pubDate>
  <media:content url="https://github.com/pranath/blog/raw/master/images/langchain-deeplake1.png" medium="image" type="image/png"/>
</item>
<item>
  <title>Popular Large Language Models Compared</title>
  <dc:creator>Pranath Fernando</dc:creator>
  <link>http://livingdatalab.com/posts/2023-07-31-popular-large-language-models-compared.html</link>
  <description><![CDATA[ We will examine the integration of various LLM models in LangChain in this article. We will look at and contrast the aspects of the platforms that enable these LLM types. Some of the most well-liked pre-trained models that are publicly accessible are already supported by LangChain. We have previously covered a number of alternatives in earlier posts, including ChatGPT, GPT-4, GPT-3, and GPT4ALL. ]]></description>
  <category>natural-language-processing</category>
  <category>deep-learning</category>
  <category>langchain</category>
  <category>activeloop</category>
  <guid>http://livingdatalab.com/posts/2023-07-31-popular-large-language-models-compared.html</guid>
  <pubDate>Sun, 30 Jul 2023 23:00:00 GMT</pubDate>
  <media:content url="https://github.com/pranath/blog/raw/master/images/langchain-deeplake4.png" medium="image" type="image/png"/>
</item>
</channel>
</rss>
