{
 "cells": [
  {
   "cell_type": "raw",
   "id": "62461473-aa19-4091-a988-9876b755f753",
   "metadata": {},
   "source": [
    "---\n",
    "date: '2023-08-07'\n",
    "categories:\n",
    " - natural-language-processing\n",
    " - deep-learning\n",
    " - langchain\n",
    " - activeloop\n",
    " - openai\n",
    " - retrievers\n",
    "title: Exploring The Role of LangChain's Indexes and Retrievers\n",
    "description: With an emphasis on the function of indexes and retrievers - here we will examine some of the benefits and drawbacks of employing document-based LLMs that use these\n",
    "image: https://github.com/pranath/blog/raw/master/images/langchain-deeplake3.png\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f853bd9-e8ca-4877-9a08-4ea3e8968778",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In LangChain, retrievers and indexes are essential for organising documents and obtaining relevant data for LLMs.  With an emphasis on the function of indexes and retrievers, we will examine some of the benefits and drawbacks of employing document-based LLMs (i.e., LLMs that incorporate pertinent documents inside their prompts).\n",
    "\n",
    "A retriever uses the index to find and return relevant documents in answer to user queries. An index is a potent data structure that painstakingly organises and saves documents to facilitate efficient searching. The main index types in LangChain are based on vector databases, with embeddings-based indexes being the most common.\n",
    "\n",
    "## Import Libs & Setup\n",
    "\n",
    "Here, we load a text file using the TextLoader class. Keep in mind to use the following command to install the necessary packages: pip install deeplake openai tiktoken langchain==0.0.208."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03c4a373-af1e-4275-852f-03ab676a2f27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain==0.0.208 in /Users/pranathfernando/opt/anaconda3/lib/python3.9/site-packages (0.0.208)\n",
      "Requirement already satisfied: deeplake in /Users/pranathfernando/opt/anaconda3/lib/python3.9/site-packages (3.6.17)\n",
      "Requirement already satisfied: openai in /Users/pranathfernando/opt/anaconda3/lib/python3.9/site-packages (0.27.7)\n",
      "Requirement already satisfied: tiktoken in /Users/pranathfernando/opt/anaconda3/lib/python3.9/site-packages (0.4.0)\n",
      "Requirement already satisfied: langchainplus-sdk>=0.0.13 in /Users/pranathfernando/opt/anaconda3/lib/python3.9/site-packages (from langchain==0.0.208) (0.0.20)\n",
      "Requirement already satisfied: pydantic<2,>=1 in /Users/pranathfernando/opt/anaconda3/lib/python3.9/site-packages (from langchain==0.0.208) (1.10.8)\n",
      "Requirement already satisfied: PyYAML>=5.4.1 in /Users/pranathfernando/opt/anaconda3/lib/python3.9/site-packages (from langchain==0.0.208) (6.0)\n",
      "Requirement already satisfied: numpy<2,>=1 in /Users/pranathfernando/opt/anaconda3/lib/python3.9/site-packages (from langchain==0.0.208) (1.23.5)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /Users/pranathfernando/opt/anaconda3/lib/python3.9/site-packages (from langchain==0.0.208) (8.2.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/pranathfernando/opt/anaconda3/lib/python3.9/site-packages (from langchain==0.0.208) (3.8.4)\n",
      "Requirement already satisfied: openapi-schema-pydantic<2.0,>=1.2 in /Users/pranathfernando/opt/anaconda3/lib/python3.9/site-packages (from langchain==0.0.208) (1.2.4)\n",
      "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /Users/pranathfernando/opt/anaconda3/lib/python3.9/site-packages (from langchain==0.0.208) (2.8.4)\n",
      "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in /Users/pranathfernando/opt/anaconda3/lib/python3.9/site-packages (from langchain==0.0.208) (0.5.7)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/pranathfernando/opt/anaconda3/lib/python3.9/site-packages (from langchain==0.0.208) (2.28.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/pranathfernando/opt/anaconda3/lib/python3.9/site-packages (from langchain==0.0.208) (1.4.39)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /Users/pranathfernando/opt/anaconda3/lib/python3.9/site-packages (from langchain==0.0.208) (4.0.2)\n",
      "Requirement already satisfied: nest-asyncio in /Users/pranathfernando/opt/anaconda3/lib/python3.9/site-packages (from deeplake) (1.5.5)\n",
      "Requirement already satisfied: pyjwt in /Users/pranathfernando/opt/anaconda3/lib/python3.9/site-packages (from deeplake) (2.4.0)\n",
      "Requirement already satisfied: numcodecs in /Users/pranathfernando/opt/anaconda3/lib/python3.9/site-packages (from deeplake) (0.11.0)\n",
      "Requirement already satisfied: aioboto3>=10.4.0 in /Users/pranathfernando/opt/anaconda3/lib/python3.9/site-packages (from deeplake) (11.2.0)\n",
      "Requirement already satisfied: pathos in /Users/pranathfernando/opt/anaconda3/lib/python3.9/site-packages (from deeplake) (0.3.1)\n",
      "Requirement already satisfied: pillow in /Users/pranathfernando/opt/anaconda3/lib/python3.9/site-packages (from deeplake) (9.2.0)\n",
      "Requirement already satisfied: click in /Users/pranathfernando/opt/anaconda3/lib/python3.9/site-packages (from deeplake) (8.0.4)\n",
      "Requirement already satisfied: tqdm in /Users/pranathfernando/opt/anaconda3/lib/python3.9/site-packages (from deeplake) (4.65.0)\n",
      "Requirement already satisfied: humbug>=0.3.1 in /Users/pranathfernando/opt/anaconda3/lib/python3.9/site-packages (from deeplake) (0.3.2)\n",
      "Requirement already satisfied: boto3 in /Users/pranathfernando/opt/anaconda3/lib/python3.9/site-packages (from deeplake) (1.26.76)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/pranathfernando/opt/anaconda3/lib/python3.9/site-packages (from tiktoken) (2022.7.9)\n",
      "Requirement already satisfied: aiobotocore[boto3]==2.5.0 in /Users/pranathfernando/opt/anaconda3/lib/python3.9/site-packages (from aioboto3>=10.4.0->deeplake) (2.5.0)\n",
      "Requirement already satisfied: aioitertools>=0.5.1 in /Users/pranathfernando/opt/anaconda3/lib/python3.9/site-packages (from aiobotocore[boto3]==2.5.0->aioboto3>=10.4.0->deeplake) (0.11.0)\n",
      "Requirement already satisfied: wrapt>=1.10.10 in /Users/pranathfernando/opt/anaconda3/lib/python3.9/site-packages (from aiobotocore[boto3]==2.5.0->aioboto3>=10.4.0->deeplake) (1.14.1)\n",
      "Requirement already satisfied: botocore<1.29.77,>=1.29.76 in /Users/pranathfernando/opt/anaconda3/lib/python3.9/site-packages (from aiobotocore[boto3]==2.5.0->aioboto3>=10.4.0->deeplake) (1.29.76)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/pranathfernando/opt/anaconda3/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.208) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/pranathfernando/opt/anaconda3/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.208) (1.3.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/pranathfernando/opt/anaconda3/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.208) (21.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/pranathfernando/opt/anaconda3/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.208) (6.0.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/pranathfernando/opt/anaconda3/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.208) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /Users/pranathfernando/opt/anaconda3/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.208) (2.0.4)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /Users/pranathfernando/opt/anaconda3/lib/python3.9/site-packages (from boto3->deeplake) (0.10.0)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /Users/pranathfernando/opt/anaconda3/lib/python3.9/site-packages (from boto3->deeplake) (0.6.0)\n",
      "Requirement already satisfied: typing-inspect>=0.4.0 in /Users/pranathfernando/opt/anaconda3/lib/python3.9/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.208) (0.9.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.3.0 in /Users/pranathfernando/opt/anaconda3/lib/python3.9/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.208) (3.19.0)\n",
      "Requirement already satisfied: marshmallow-enum<2.0.0,>=1.5.1 in /Users/pranathfernando/opt/anaconda3/lib/python3.9/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.208) (1.5.1)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /Users/pranathfernando/opt/anaconda3/lib/python3.9/site-packages (from pydantic<2,>=1->langchain==0.0.208) (4.6.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/pranathfernando/opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2->langchain==0.0.208) (2023.5.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/pranathfernando/opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2->langchain==0.0.208) (1.26.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/pranathfernando/opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2->langchain==0.0.208) (3.3)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /Users/pranathfernando/opt/anaconda3/lib/python3.9/site-packages (from SQLAlchemy<3,>=1.4->langchain==0.0.208) (1.1.1)\n",
      "Requirement already satisfied: entrypoints in /Users/pranathfernando/opt/anaconda3/lib/python3.9/site-packages (from numcodecs->deeplake) (0.4)\n",
      "Requirement already satisfied: ppft>=1.7.6.7 in /Users/pranathfernando/opt/anaconda3/lib/python3.9/site-packages (from pathos->deeplake) (1.7.6.7)\n",
      "Requirement already satisfied: multiprocess>=0.70.15 in /Users/pranathfernando/opt/anaconda3/lib/python3.9/site-packages (from pathos->deeplake) (0.70.15)\n",
      "Requirement already satisfied: dill>=0.3.7 in /Users/pranathfernando/opt/anaconda3/lib/python3.9/site-packages (from pathos->deeplake) (0.3.7)\n",
      "Requirement already satisfied: pox>=0.3.3 in /Users/pranathfernando/opt/anaconda3/lib/python3.9/site-packages (from pathos->deeplake) (0.3.3)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /Users/pranathfernando/opt/anaconda3/lib/python3.9/site-packages (from botocore<1.29.77,>=1.29.76->aiobotocore[boto3]==2.5.0->aioboto3>=10.4.0->deeplake) (2.8.2)\n",
      "Requirement already satisfied: packaging>=17.0 in /Users/pranathfernando/opt/anaconda3/lib/python3.9/site-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.208) (21.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/pranathfernando/opt/anaconda3/lib/python3.9/site-packages (from typing-inspect>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.208) (0.4.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/pranathfernando/opt/anaconda3/lib/python3.9/site-packages (from packaging>=17.0->marshmallow<4.0.0,>=3.3.0->dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.208) (3.0.9)\n",
      "Requirement already satisfied: six>=1.5 in /Users/pranathfernando/opt/anaconda3/lib/python3.9/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.29.77,>=1.29.76->aiobotocore[boto3]==2.5.0->aioboto3>=10.4.0->deeplake) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "#| include: false\n",
    "!pip install langchain==0.0.208 deeplake openai tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3dbcf910-89bc-4599-8128-0db07168828a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "import os\n",
    "import openai\n",
    "import sys\n",
    "sys.path.append('../..')\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "openai.api_key  = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8d9171-08ca-4dea-81e1-a2bb669fda52",
   "metadata": {},
   "source": [
    "## Retrievers\n",
    "\n",
    "Retrievers concentrate on removing pertinent documents to combine with language model suggestions. A retriever exposes a method called get_relevant_documents that takes a query string as input and returns a list of documents that are connected to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a94bc523-5cea-4264-924b-11d1862221cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "# text to write to a local file\n",
    "# taken from https://www.theverge.com/2023/3/14/23639313/google-ai-language-model-palm-api-challenge-openai\n",
    "text = \"\"\"Google opens up its AI language model PaLM to challenge OpenAI and GPT-3\n",
    "Google is offering developers access to one of its most advanced AI language models: PaLM.\n",
    "The search giant is launching an API for PaLM alongside a number of AI enterprise tools\n",
    "it says will help businesses “generate text, images, code, videos, audio, and more from\n",
    "simple natural language prompts.”\n",
    "\n",
    "PaLM is a large language model, or LLM, similar to the GPT series created by OpenAI or\n",
    "Meta’s LLaMA family of models. Google first announced PaLM in April 2022. Like other LLMs,\n",
    "PaLM is a flexible system that can potentially carry out all sorts of text generation and\n",
    "editing tasks. You could train PaLM to be a conversational chatbot like ChatGPT, for\n",
    "example, or you could use it for tasks like summarizing text or even writing code.\n",
    "(It’s similar to features Google also announced today for its Workspace apps like Google\n",
    "Docs and Gmail.)\n",
    "\"\"\"\n",
    "\n",
    "# write text to local file\n",
    "with open(\"docs/my_file.txt\", \"w\") as file:\n",
    "    file.write(text)\n",
    "\n",
    "# use TextLoader to load text from local file\n",
    "loader = TextLoader(\"docs/my_file.txt\")\n",
    "docs_from_file = loader.load()\n",
    "\n",
    "print(len(docs_from_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a6537f9-10c4-44bd-ac95-b063647dd1ed",
   "metadata": {},
   "source": [
    "Then, we use CharacterTextSplitter to split the docs into texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6042f94b-b547-4aef-8452-e64cc2e1abd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 373, which is longer than the specified 200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "# create a text splitter\n",
    "text_splitter = CharacterTextSplitter(chunk_size=200, chunk_overlap=20)\n",
    "\n",
    "# split documents into chunks\n",
    "docs = text_splitter.split_documents(docs_from_file)\n",
    "\n",
    "print(len(docs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74ff8c2-171b-4944-843a-9ff7859bdc60",
   "metadata": {},
   "source": [
    "These embeddings allow us to effectively search for documents or portions of documents that relate to our query by examining their semantic similarities. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d63336ee-f04a-4244-9b59-3ab9aeadf5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "# Before executing the following code, make sure to have\n",
    "# your OpenAI key saved in the “OPENAI_API_KEY” environment variable.\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c27220-b818-4658-b5ea-c24e1be64c9e",
   "metadata": {},
   "source": [
    "## DeepLake Vector Store\n",
    "\n",
    "We'll employ the Deep Lake vector store with our embeddings in place.\n",
    "\n",
    "Deep Lake provides several advantages over the typical vector store:\n",
    "\n",
    "- It’s multimodal, which means that it can be used to store items of diverse modalities, such as texts, images, audio, and video, along with their vector representations.\n",
    "- It’s serverless, which means that we can create and manage cloud datasets without the need to create and managing a database instance. This aspect gives a great speedup to new projects.\n",
    "- It’s possible to easily create a streaming data loader out of the data loaded into a Deep Lake dataset, which is convenient for fine-tuning machine learning models using common frameworks like PyTorch and TensorFlow.\n",
    "- Data can be queried and visualized easily from the web.\n",
    "\n",
    "Deep Lake is highly suited to serve as the serverless memory that LLM chains and agents need for a variety of tasks, such as storing pertinent documents for question-answering or images to manage some guided image-generation tasks, thanks to its nature. Here is a diagram that illustrates this feature.\n",
    "\n",
    "<img src=\"https://github.com/pranath/blog/raw/master/images/deeplake-2.png\" width=\"800\"/>\n",
    "\n",
    "Let’s create an instance of a Deep Lake dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "639927f9-cc2e-446f-a46f-7f99ce94dcdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your Deep Lake dataset has been successfully created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset(path='hub://pranath/langchain_course_indexers_retrievers', tensors=['embedding', 'id', 'metadata', 'text'])\n",
      "\n",
      "  tensor      htype      shape     dtype  compression\n",
      "  -------    -------    -------   -------  ------- \n",
      " embedding  embedding  (2, 1536)  float32   None   \n",
      "    id        text      (2, 1)      str     None   \n",
      " metadata     json      (2, 1)      str     None   \n",
      "   text       text      (2, 1)      str     None   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['bd8b9dd6-39c8-11ee-8a93-acde48001122',\n",
       " 'bd8b9f52-39c8-11ee-8a93-acde48001122']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.vectorstores import DeepLake\n",
    "\n",
    "# Before executing the following code, make sure to have your\n",
    "# Activeloop key saved in the “ACTIVELOOP_TOKEN” environment variable.\n",
    "\n",
    "# create Deep Lake dataset\n",
    "# TODO: use your organization id here. (by default, org id is your username)\n",
    "my_activeloop_org_id = \"pranath\"\n",
    "my_activeloop_dataset_name = \"langchain_course_indexers_retrievers\"\n",
    "dataset_path = f\"hub://{my_activeloop_org_id}/{my_activeloop_dataset_name}\"\n",
    "db = DeepLake(dataset_path=dataset_path, embedding_function=embeddings)\n",
    "\n",
    "# add documents to our Deep Lake dataset\n",
    "db.add_documents(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "768d2cbb-8ecc-44a6-b723-778fda3f9c4c",
   "metadata": {},
   "source": [
    "In this example, we are expanding the dataset using text documents. Deep Lake is multimodal, therefore we might have specified an image embedder model in addition to adding photos to it. This could be helpful when looking for images that match a text search query or when using an image as a query.\n",
    "\n",
    "The ability to store larger datasets in local memory becomes more difficult. Given that we are only uploading two documents in this instance, we might have easily used a nearby vector store. However, thousands or millions of documents might be used in a normal production situation and accessible from many programmes, necessitating the requirement for a centralised cloud dataset.\n",
    "\n",
    "We then make a retriever."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ac173c3-d35c-4b0d-aaec-85d982c54d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create retriever from db\n",
    "retriever = db.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e910fb45-5d4f-42f2-aea4-71f13798fce3",
   "metadata": {},
   "source": [
    "Once we have the retriever, we can start with question-answering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "415f73b2-988f-4589-b1bb-99b67d7eb419",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "# create a retrieval chain\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "\tllm=OpenAI(model=\"text-davinci-003\"),\n",
    "\tchain_type=\"stuff\",\n",
    "\tretriever=retriever\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c5a886-2c89-4316-9532-6281659531c7",
   "metadata": {},
   "source": [
    "We can query our document that is an about specific topic that can be found in the documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1dd7b9dd-966d-45b4-8ff7-53d4a3cc8bb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Google is offering developers access to its advanced AI language model, PaLM, via an API, along with a number of AI enterprise tools that can generate text, images, code, videos, audio, and more from simple natural language prompts. PaLM is a large language model, similar to the GPT series created by OpenAI, which Google hopes will help businesses carry out text generation and editing tasks.\n"
     ]
    }
   ],
   "source": [
    "query = \"How Google plans to challenge OpenAI?\"\n",
    "response = qa_chain.run(query)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18fc031c-63f8-484f-bc36-a66c1068b918",
   "metadata": {},
   "source": [
    "## What occurred behind the scenes?\n",
    "\n",
    "In the beginning, we used a \"stuff chain\" (see CombineDocuments Chains). One method of providing information to the LLM is stuffing. We \"stuff\" all the information into the LLM's prompt using this method. However, because the majority of LLMs have a context length restriction, this approach is only useful with shorter documents.\n",
    "\n",
    "The embeddings are also used in a similarity search to find papers that match and can be used as context for the LLM. Even though it might not seem extremely beneficial with only one document, since we \"chunked\" our text, we are actually working with numerous documents. We may still stay inside the permitted context size by pre-selecting the most appropriate documents based on semantic similarity and provide the model with useful knowledge through the prompt.\n",
    "\n",
    "Thus, via this investigation, we have learned how crucial indexes and retrievers are in enhancing the efficiency of large language models while processing document-based data. \n",
    "\n",
    "By transforming documents and user queries into numerical vectors (embeddings) and storing them in specialised databases like Deep Lake, which serves as our vector store database, the system becomes more effective at discovering and presenting pertinent information.\n",
    "\n",
    "The usefulness of this strategy in improving the general language understanding capabilities of LLMs is demonstrated by the retriever's ability to locate documents in the embedding space that are closely connected to a user's query.\n",
    "\n",
    "## A Potential Problem\n",
    "\n",
    "The disadvantage of this approach is that when storing data, you might not know how to find the appropriate papers. In the Q&A example, we divided the content into equal halves so that when a user asks a question, both helpful and pointless text will appear.\n",
    "\n",
    "It is bad to include irrelevant information in the LLM prompt because:\n",
    "\n",
    "1. It may cause the LLM to lose sight of important information.\n",
    "2. It takes up valuable space that may be used for information that is more pertinent.\n",
    "\n",
    "## Possible Solution\n",
    "\n",
    "To solve this problem, a DocumentCompressor abstraction has been developed, enabling the use of compress_documents on the obtained documents.\n",
    "\n",
    "In LangChain, the ContextualCompressionRetriever is a wrapper for another retriever. The base retriever's retrieved documents are automatically compressed using a DocumentCompressor and a base retriever. This means that, in response to a certain query, only the most pertinent portions of the documents are delivered.\n",
    "\n",
    "The LLMChainExtractor is a well-liked compressor option that employs an LLMChain to extract only the statements pertinent to the query from the documents. Utilising a ContextualCompressionRetriever and wrapping the base retriever with an LLMChainExtractor helps to improve the retrieval process. The LLMChainExtractor loops through the documents that were initially returned and only extracts the information that is pertinent to the query. \n",
    "\n",
    "Here is an illustration of how to utilise LLMChainExtractor with ContextualCompressionRetriever:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e6a1b866-8b2b-417e-ac3a-fb44f8de5774",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import LLMChainExtractor\n",
    "\n",
    "# create GPT3 wrapper\n",
    "llm = OpenAI(model=\"text-davinci-003\", temperature=0)\n",
    "\n",
    "# create compressor for the retriever\n",
    "compressor = LLMChainExtractor.from_llm(llm)\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "\tbase_compressor=compressor,\n",
    "\tbase_retriever=retriever\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6da886-e895-4db4-a3cc-6e99fc946767",
   "metadata": {},
   "source": [
    "Once we have created the compression_retriever, we can use it to retrieve the compressed relevant documents to a query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "67580a53-dd89-4182-8024-387240123eb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pranathfernando/opt/anaconda3/lib/python3.9/site-packages/langchain/chains/llm.py:275: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google is offering developers access to one of its most advanced AI language models: PaLM. The search giant is launching an API for PaLM alongside a number of AI enterprise tools it says will help businesses “generate text, images, code, videos, audio, and more from simple natural language prompts.”\n"
     ]
    }
   ],
   "source": [
    "# retrieving compressed documents\n",
    "retrieved_docs = compression_retriever.get_relevant_documents(\n",
    "\t\"How Google plans to challenge OpenAI?\"\n",
    ")\n",
    "print(retrieved_docs[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d928f0d-f5e8-42ee-beb8-ad8a2303ed1d",
   "metadata": {},
   "source": [
    "Compressors are designed to make it simple to communicate to the LLM only the pertinent data. By doing this, you may also provide the LLM with more information because, during the first retrieval stage, you can concentrate on recall (by, for example, increasing the amount of documents returned) and leave precision to the compressors:\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "For working with unstructured data and language models, LangChain's indexes and retrievers provide modular, adaptable, and configurable solutions. They primarily concentrate on vector databases, while they offer only a limited amount of support for structured data.\n",
    "\n",
    "Further Reading:\n",
    "\n",
    "[https://python.langchain.com/docs/modules/data_connection/retrievers/contextual_compression/](https://python.langchain.com/docs/modules/data_connection/retrievers/contextual_compression/)\n",
    "\n",
    "[https://blog.langchain.dev/improving-document-retrieval-with-contextual-compression/](https://blog.langchain.dev/improving-document-retrieval-with-contextual-compression/)\n",
    "\n",
    "## Acknowledgements\n",
    "\n",
    "I'd like to express my thanks to the wonderful [LangChain & Vector Databases in Production Course](https://learn.activeloop.ai/courses/langchain) by Activeloop - which i completed, and acknowledge the use of some images and other materials from the course in this article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5266fc17-a486-4d64-bd8d-d10622673580",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
