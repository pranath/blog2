{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "aliases:\n",
    "- /2023/02/12/building-aws-sagemaker-pipeline-train-deploy-bert-text-classifier\n",
    "date: '2023-02-12'\n",
    "categories:\n",
    " - aws\n",
    " - cloud-data-science\n",
    " - natural-language-processing\n",
    " - deep-learning\n",
    "description: In this project we train and deploy a BERT Based text classifier using\n",
    "  AWS Sagemaker pipelines, and describe how this can help with MLOPS to provide the\n",
    "  most efficient path to production for training deploying and maintaining machine\n",
    "  learning models at scale in production.\n",
    "output-file: 2023-02-12-building-aws-sagemaker-pipeline-train-deploy-bert-text-classifier.html\n",
    "title: Building an AWS SageMaker Pipeline for a BERT Based text classifier\n",
    "image: https://github.com/pranath/blog/raw/master/images/aws3.png\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "djTjLcJqBHIO"
   },
   "source": [
    "## Introduction\n",
    "\n",
    "\n",
    "In [earlier articles we introduced AWS cloud services for data science](/#category=aws), and showed how it can help with different stages of the data science & machine learning workflow.\n",
    "\n",
    "![](https://github.com/pranath/blog/raw/master/images/aws_ds_workflow.png \"The AWS Data Science Workflow\")\n",
    "\n",
    "In this project will look at the deploy and manage phase for the workflow using **AWS Sagemaker Pipelines**, which will actually involve all previous phases.\n",
    "\n",
    "In particular we will do the following:\n",
    "\n",
    "* Define and run a pipeline using a directed acyclic graph (DAG) with specific pipeline parameters and model hyper-parameters\n",
    "* Define a processing step that cleans, balances, transforms, and splits our dataset into train, validation, and test dataset\n",
    "* Define a training step that trains a model using the train and validation datasets\n",
    "* Define a processing step that evaluates the trained model's performance on the test dataset\n",
    "* Define a register model step that creates a model package from the trained model\n",
    "* Define a conditional step that checks the model's performance and conditionally registers the model for deployment\n",
    "\n",
    "Using the raw [Women's Clothing Reviews](https://www.kaggle.com/nicapotato/womens-ecommerce-clothing-reviews) dataset - we will prepare it to train a deep learning BERT-based natural language processing (NLP) model. The model will be used to classify customer reviews into positive (1), neutral (0) and negative (-1) sentiment.\n",
    "\n",
    "## What are MLOPS ?\n",
    "\n",
    "MLOPS stands for Machine Learning Operations - but what does that mean? \n",
    "\n",
    "MLOps builds on DevOps practices that encompass people, process, and technology. However, MLOps also includes considerations and practices that are really unique to machine learning workloads. All of these practices aim to be able to deliver machine learning workloads quickly to production while still maintaining high quality consistency and ensuring end-to-end traceability.\n",
    "\n",
    "![](https://github.com/pranath/blog/raw/master/images/aws_path_mlmodels.png \"Consideratons\")\n",
    "\n",
    "It's important to consider that the machine learning development life cycle is very different than the software development life cycle for a variety of reasons. \n",
    "\n",
    "![](https://github.com/pranath/blog/raw/master/images/aws_path_mlmodels2.png \"Challenges\")\n",
    "\n",
    "First, the model development life cycle is difficult to plan for from a project management perspective. It typically includes longer experimentation cycles than you would see in a standard agile software development process. Also the development of machine learning models includes data tasks like feature engineering and data preparation. You also have data processing code, as well as new inputs and artifacts to consider for versioning. You also have additional pipeline task as well. When you start to look at automating the machine learning workflow, the inputs and artifacts that are generated across these tasks result in multiple disparate pipelines with dependencies that can be a bit more challenging, stitched together than a typical software development workflow. \n",
    "\n",
    "![](https://github.com/pranath/blog/raw/master/images/aws_opml.png \"Goals\")\n",
    "\n",
    "Second, some models exist by themselves where you might be manually reading prediction requests and getting responses through a batch process or even within your notebook on an ad hoc basis. This is especially true in research environments. However, in many cases, a model is typically a small part of an overall solution that incorporates machine-learning. While that model is still a very key component to that solution, most often there is a need for other components that need to be built or integrated. As an example, consider your product review use case and your model that is predicting the classes of sentiment for a product review. That model itself will be able to classify the sentiment related to a product, but you also need to consider how that prediction will actually be used and potentially integrated into other existing applications. For this, there may be additional tasks like creating a rest API as a common interface for other applications to integrate with your model or even building applications that can respond to those reviews. This could mean creating automation to initiate back-end processes that allow for customer support engineers to quickly react and respond to any negative reviews. \n",
    "\n",
    "![](https://github.com/pranath/blog/raw/master/images/aws_opml2.png \"Path to production\")\n",
    "\n",
    "A third consideration is that where typically multiple personas span the machine learning development lifecycle, and all are really needed to ultimately be able to build, deploy, integrate, and operate a machine learning workload. This can create challenges as these personas often have competing priorities and needs. There may also be skill gaps in building an operating machine learning workloads. As an example, a data scientist may not have a traditional IT background. While they may be very comfortable in creating a model that meets the performance objectives that have been identified for your particular machine learning use case, they may not know how to host that model in a way that it can be consumed by other applications or other systems. In this case, there may be a need to have a deployment engineer that is also engaged to help in building out the infrastructure and the resources that are needed to operate and host that model.\n",
    "\n",
    "![](https://github.com/pranath/blog/raw/master/images/aws_opml3.png \"Accelerating the path to production\")\n",
    "\n",
    "Also, you might need to integrate that hosted model with another application. In this case, you're likely to depend on a software engineer to perform that integration. If there isn't a cross-functional team with the same project goals in place, competing priorities and skill gaps across these personas make it really difficult to provide that path to production for your model. \n",
    "\n",
    "![](https://github.com/pranath/blog/raw/master/images/aws_opml4.png \"Improving the Quality of Deployed Models\")\n",
    "\n",
    "Finally, many teams have processes in place supporting different regulatory or even internal corporate requirements. This means that when you're creating your machine learning pipeline, sometimes you also need to be able to ensure that traditional practices can be included inside the steps of your pipeline. Something like change management as an example here. This may mean that within your pipeline, you're going to automatically open a change ticket anytime a new model gets deployed to production. Or maybe it's a manual approval that's required before your model can deploy to production. All of these processes may need to be incorporated inside your machine learning pipeline. \n",
    "\n",
    "![](https://github.com/pranath/blog/raw/master/images/aws_opml5.png \"Key Considerations\")\n",
    "\n",
    "**MLOps aims to provide the most efficient path to production by reducing manual hand-offs between the steps in your workflow, increasing automation within those steps in your workflow, and then going a step further to orchestrate the steps across your workflow.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ugysMiEiBHIR"
   },
   "source": [
    "## AWS Pipelines Terminology\n",
    "\n",
    "This project focuses on the following features of Amazon SageMaker Pipelines:\n",
    "\n",
    "* **Pipelines** - a directed acyclic graph (DAG) of steps and conditions to orchestrate SageMaker jobs and resource creation\n",
    "* **Processing job steps** - a simplified, managed experience on SageMaker to run data processing workloads, such as feature engineering, data validation, model evaluation, and model explainability\n",
    "* **Training job steps** - an iterative process that teaches a model to make predictions on new data by presenting examples from a training dataset\n",
    "* **Conditional step execution** - provides conditional execution of branches in a pipeline\n",
    "* **Registering models** - register a model in a model registry to create a deployable models in Amazon SageMaker\n",
    "* **Parameterized pipeline executions** - allows pipeline executions to vary by supplied parameters\n",
    "* **Model endpoint** - hosts the model as a REST endpoint to serve predictions from new data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c06lVZu7BHIS"
   },
   "source": [
    "## Creating a BERT Pipeline\n",
    "\n",
    "The pipeline that we will create follows a typical machine learning application pattern of pre-processing, training, evaluation, and model registration.\n",
    "\n",
    "In the processing step, we will perform feature engineering to transform the `review_body` text into BERT embeddings using the pre-trained BERT model and split the dataset into train, validation and test files. The transformed dataset is stored in a feature store. To optimize for Tensorflow training, the transformed dataset files are saved using the TFRecord format in Amazon S3.\n",
    "\n",
    "In the training step, we will fine-tune the BERT model to the customer reviews dataset and add a new classification layer to predict the `sentiment` for a given `review_body`.\n",
    "\n",
    "In the evaluation step, we will take the trained model and a test dataset as input, and produce a JSON file containing classification evaluation metrics.\n",
    "\n",
    "In the condition step, we will register the trained model if the accuracy of the model, as determined by our evaluation step, exceeds a given threshold value. \n",
    "\n",
    "![](https://github.com/pranath/blog/raw/master/images/bert_sagemaker_pipeline.png \"BERT Sagemaker Pipelines\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7QiHC7YFBHIT"
   },
   "source": [
    "First, let's install the required modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ba98ycxfBHIT",
    "outputId": "033ebc50-8831-4fd9-f9af-a30ec409e8f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyring is skipped due to an exception: 'keyring.backends'\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "#| include: false\n",
    "# please ignore warning messages during the installation\n",
    "!pip install --disable-pip-version-check -q sagemaker==2.35.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QoUaqYB9BHIV"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sagemaker\n",
    "import logging\n",
    "import boto3\n",
    "import sagemaker\n",
    "import pandas as pd\n",
    "import json\n",
    "import botocore\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "config = botocore.config.Config(user_agent_extra='dlai-pds/c2/w3')\n",
    "\n",
    "# low-level service client of the boto3 session\n",
    "sm = boto3.client(service_name='sagemaker', \n",
    "                  config=config)\n",
    "\n",
    "sm_runtime = boto3.client('sagemaker-runtime',\n",
    "                          config=config)\n",
    "\n",
    "sess = sagemaker.Session(sagemaker_client=sm,\n",
    "                         sagemaker_runtime_client=sm_runtime)\n",
    "\n",
    "bucket = sess.default_bucket()\n",
    "role = sagemaker.get_execution_role()\n",
    "region = sess.boto_region_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bIvIRsDCBHIW"
   },
   "source": [
    "Let's setup the pipeline name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nW6UeJxTBHIX"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "timestamp = int(time.time())\n",
    "\n",
    "pipeline_name = 'BERT-pipeline-{}'.format(timestamp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R1E3kyWvBHIX"
   },
   "source": [
    "## Configure the dataset and processing step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RCrv9gALBHIX"
   },
   "source": [
    "### Configure S3 path for raw input data\n",
    "\n",
    "The raw dataset is in the public S3 bucket. Let's start by specifying the S3 location of it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F9eTtX0zBHIY",
    "outputId": "bf6a9f74-3ac8-41f3-9687-cd1b46820068"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://dlai-practical-data-science/data/raw/\n"
     ]
    }
   ],
   "source": [
    "raw_input_data_s3_uri = 's3://dlai-practical-data-science/data/raw/'\n",
    "print(raw_input_data_s3_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "apFyIwvfBHIY"
   },
   "source": [
    "List the files in the S3 bucket (in this case it will be just one file):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nkOllshqBHIZ",
    "outputId": "704edfd2-2e74-445d-fd0a-d261ce456342"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-30 02:21:06    8457214 womens_clothing_ecommerce_reviews.csv\n"
     ]
    }
   ],
   "source": [
    "!aws s3 ls $raw_input_data_s3_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jv2TXJg8BHIZ"
   },
   "source": [
    "### Configure processing step\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H_-ajAxMBHIZ"
   },
   "source": [
    "For the pipeline workflow we will need to create workflow parameters of a specific type: integer, string, or float."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pe5uFGOGBHIZ"
   },
   "outputs": [],
   "source": [
    "from sagemaker.workflow.parameters import (\n",
    "    ParameterInteger,\n",
    "    ParameterString,\n",
    "    ParameterFloat,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "emFdbS6JBHIa"
   },
   "source": [
    "Now set the parameters for the processing step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XRQqkBu4BHIa"
   },
   "outputs": [],
   "source": [
    "processing_instance_type = ParameterString(\n",
    "    name=\"ProcessingInstanceType\",\n",
    "    default_value=\"ml.c5.2xlarge\"\n",
    ")\n",
    "\n",
    "processing_instance_count = ParameterInteger(\n",
    "    name=\"ProcessingInstanceCount\",\n",
    "    default_value=1\n",
    ")\n",
    "\n",
    "train_split_percentage = ParameterFloat(\n",
    "    name=\"TrainSplitPercentage\",\n",
    "    default_value=0.90,\n",
    ")\n",
    "\n",
    "validation_split_percentage = ParameterFloat(\n",
    "    name=\"ValidationSplitPercentage\",\n",
    "    default_value=0.05,\n",
    ")\n",
    "\n",
    "test_split_percentage = ParameterFloat(\n",
    "    name=\"TestSplitPercentage\",\n",
    "    default_value=0.05,\n",
    ")\n",
    "\n",
    "balance_dataset = ParameterString(\n",
    "    name=\"BalanceDataset\",\n",
    "    default_value=\"True\",\n",
    ")\n",
    "\n",
    "max_seq_length = ParameterInteger(\n",
    "    name=\"MaxSeqLength\",\n",
    "    default_value=128,\n",
    ")\n",
    "\n",
    "feature_store_offline_prefix = ParameterString(\n",
    "    name=\"FeatureStoreOfflinePrefix\",\n",
    "    default_value=\"reviews-feature-store-\" + str(timestamp),\n",
    ")\n",
    "\n",
    "feature_group_name = ParameterString(\n",
    "    name=\"FeatureGroupName\",\n",
    "    default_value=\"reviews-feature-group-\" + str(timestamp)\n",
    ")\n",
    "\n",
    "input_data = ParameterString(\n",
    "    name=\"InputData\",\n",
    "    default_value=raw_input_data_s3_uri,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AMNaW0M-BHIa"
   },
   "source": [
    "Setting up scikit-learn-based processor, pass the SageMaker execution role, processing instance type and instance count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4F8218vOBHIb"
   },
   "outputs": [],
   "source": [
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "\n",
    "processor = SKLearnProcessor(\n",
    "    framework_version='0.23-1',\n",
    "    role=role,\n",
    "    instance_type=processing_instance_type,\n",
    "    instance_count=processing_instance_count,\n",
    "    env={'AWS_DEFAULT_REGION': region},                             \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PX8Hs51UBHIb"
   },
   "source": [
    "Now we will use the processor instance to construct a `ProcessingStep`, along with the input and output channels and the code that will be executed when the pipeline invokes pipeline execution. This is very similar to a processor instance's `run` method, for those familiar with the existing Python SDK.\n",
    "\n",
    "Note the `\"sentiment-train\"`, `\"sentiment-validation\"` and `\"sentiment-test\"` named channels specified in the output configuration for the processing job. Such step `Properties` can be used in subsequent steps and will resolve to their runtime values at execution. In particular, we will call out this usage defining the training step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wH12ZA6BBHIb",
    "outputId": "cccebd03-d359-47d4-cb04-6cb53cde120a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProcessingStep(name='Processing', step_type=<StepTypeEnum.PROCESSING: 'Processing'>)\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker.workflow.steps import ProcessingStep\n",
    "\n",
    "processing_inputs=[\n",
    "    ProcessingInput(\n",
    "        input_name='raw-input-data',\n",
    "        source=input_data,\n",
    "        destination='/opt/ml/processing/input/data/',\n",
    "        s3_data_distribution_type='ShardedByS3Key'\n",
    "    )\n",
    "]\n",
    "\n",
    "processing_outputs=[\n",
    "    ProcessingOutput(output_name='sentiment-train',\n",
    "                     source='/opt/ml/processing/output/sentiment/train',\n",
    "                     s3_upload_mode='EndOfJob'),\n",
    "    ProcessingOutput(output_name='sentiment-validation',\n",
    "                     source='/opt/ml/processing/output/sentiment/validation',\n",
    "                     s3_upload_mode='EndOfJob'),\n",
    "    ProcessingOutput(output_name='sentiment-test',\n",
    "                     source='/opt/ml/processing/output/sentiment/test',\n",
    "                     s3_upload_mode='EndOfJob')\n",
    "]        \n",
    "\n",
    "processing_step = ProcessingStep(\n",
    "    name='Processing', \n",
    "    code='src/prepare_data.py',\n",
    "    processor=processor,\n",
    "    inputs=processing_inputs,\n",
    "    outputs=processing_outputs,\n",
    "    job_arguments=['--train-split-percentage', str(train_split_percentage.default_value),                   \n",
    "                   '--validation-split-percentage', str(validation_split_percentage.default_value),\n",
    "                   '--test-split-percentage', str(test_split_percentage.default_value),\n",
    "                   '--balance-dataset', str(balance_dataset.default_value),\n",
    "                   '--max-seq-length', str(max_seq_length.default_value),                   \n",
    "                   '--feature-store-offline-prefix', str(feature_store_offline_prefix.default_value),\n",
    "                   '--feature-group-name', str(feature_group_name.default_value)\n",
    "                  ]\n",
    ")        \n",
    "\n",
    "print(processing_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cpA7iezkBHIc"
   },
   "source": [
    "Now we can call out the properties of the processing job as an object using the command `processing_step.properties`. To print out and explore the attributes use `__dict__` method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3rsHtNInBHIc",
    "outputId": "24eec809-fdf8-45c0-dc04-721ac29153c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"AppSpecification\": \"<sagemaker.workflow.properties.Properties object at 0x7fcdf5298a10>\",\n",
      "    \"AutoMLJobArn\": \"<sagemaker.workflow.properties.Properties object at 0x7fcdf5431d10>\",\n",
      "    \"CreationTime\": \"<sagemaker.workflow.properties.Properties object at 0x7fcdf5431950>\",\n",
      "    \"Environment\": \"<sagemaker.workflow.properties.Properties object at 0x7fcdf5298690>\",\n",
      "    \"ExitMessage\": \"<sagemaker.workflow.properties.Properties object at 0x7fcdf5431d50>\",\n",
      "    \"ExperimentConfig\": \"<sagemaker.workflow.properties.Properties object at 0x7fcdf52a0b10>\",\n",
      "    \"FailureReason\": \"<sagemaker.workflow.properties.Properties object at 0x7fcdf5431750>\",\n",
      "    \"LastModifiedTime\": \"<sagemaker.workflow.properties.Properties object at 0x7fcdf5431a10>\",\n",
      "    \"MonitoringScheduleArn\": \"<sagemaker.workflow.properties.Properties object at 0x7fcdf5431190>\",\n",
      "    \"NetworkConfig\": \"<sagemaker.workflow.properties.Properties object at 0x7fcdf5298b90>\",\n",
      "    \"ProcessingEndTime\": \"<sagemaker.workflow.properties.Properties object at 0x7fcdf5431610>\",\n",
      "    \"ProcessingInputs\": \"<sagemaker.workflow.properties.PropertiesList object at 0x7fcdf5298350>\",\n",
      "    \"ProcessingJobArn\": \"<sagemaker.workflow.properties.Properties object at 0x7fcdf5431410>\",\n",
      "    \"ProcessingJobName\": \"<sagemaker.workflow.properties.Properties object at 0x7fcdf5298590>\",\n",
      "    \"ProcessingJobStatus\": \"<sagemaker.workflow.properties.Properties object at 0x7fcdf5431310>\",\n",
      "    \"ProcessingOutputConfig\": \"<sagemaker.workflow.properties.Properties object at 0x7fcdf5298510>\",\n",
      "    \"ProcessingResources\": \"<sagemaker.workflow.properties.Properties object at 0x7fcdf52984d0>\",\n",
      "    \"ProcessingStartTime\": \"<sagemaker.workflow.properties.Properties object at 0x7fcdf5431ed0>\",\n",
      "    \"RoleArn\": \"<sagemaker.workflow.properties.Properties object at 0x7fcdf5298650>\",\n",
      "    \"StoppingCondition\": \"<sagemaker.workflow.properties.Properties object at 0x7fcdf5298a50>\",\n",
      "    \"TrainingJobArn\": \"<sagemaker.workflow.properties.Properties object at 0x7fcdf5431bd0>\",\n",
      "    \"_path\": \"Steps.Processing\",\n",
      "    \"_shape_name\": \"DescribeProcessingJobResponse\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# print out the list of the processing job properties\n",
    "print(json.dumps(\n",
    "    processing_step.properties.__dict__,\n",
    "    indent=4, sort_keys=True, default=str\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oLYvfBobBHId"
   },
   "source": [
    "Pull the channel `sentiment-train` from the output configuration of the processing job. Print out the attributes of the resulting object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CphNG82ZBHId",
    "outputId": "1a5369ca-8996-42cc-a2d7-6db70c5aede9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"AppManaged\": \"<sagemaker.workflow.properties.Properties object at 0x7fcdf543c490>\",\n",
      "    \"FeatureStoreOutput\": \"<sagemaker.workflow.properties.Properties object at 0x7fcdf54d4510>\",\n",
      "    \"OutputName\": \"<sagemaker.workflow.properties.Properties object at 0x7fcdf5384650>\",\n",
      "    \"S3Output\": \"<sagemaker.workflow.properties.Properties object at 0x7fcdf53845d0>\",\n",
      "    \"_path\": \"Steps.Processing.ProcessingOutputConfig.Outputs['sentiment-train']\",\n",
      "    \"_shape_name\": \"ProcessingOutput\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(\n",
    "    processing_step.properties.ProcessingOutputConfig.Outputs['sentiment-train'].__dict__, \n",
    "    indent=4, sort_keys=True, default=str\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "spd1C4foBHId"
   },
   "source": [
    "Now we can pull and print out attributes of the S3 output path related to the `sentiment-train` output channel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xK353bizBHIe",
    "outputId": "dfa191f0-ccff-4e84-c304-4a64f757b7f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"__str__\": \"S3Uri\",\n",
      "    \"_path\": \"Steps.Processing.ProcessingOutputConfig.Outputs['sentiment-train'].S3Output.S3Uri\",\n",
      "    \"_shape_name\": \"S3Uri\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(\n",
    "    processing_step.properties.ProcessingOutputConfig.Outputs['sentiment-train'].S3Output.S3Uri.__dict__,\n",
    "    indent=4, sort_keys=True, default=str\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gZeXdiitBHIe"
   },
   "source": [
    "Let's pull and print out attributes of the S3 output path object related to the `sentiment-test` output channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6eV-KypeBHIe",
    "outputId": "da8c78c7-73fc-49b9-ae1b-de5351dd2c23"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"__str__\": \"S3Uri\",\n",
      "    \"_path\": \"Steps.Processing.ProcessingOutputConfig.Outputs['sentiment-test'].S3Output.S3Uri\",\n",
      "    \"_shape_name\": \"S3Uri\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(\n",
    "    processing_step.properties.ProcessingOutputConfig.Outputs['sentiment-test'].S3Output.S3Uri.__dict__, \n",
    "    indent=4, sort_keys=True, default=str\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OFv2nkhGBHIf"
   },
   "source": [
    "These objects can be passed into the next steps of the workflow. Also, we can pull the arguments of the processing step with the corresponding function. The result is in the dictionary format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ABgNRnf4BHIf",
    "outputId": "1cad757e-7257-4de9-9839-87e1064dbb23"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['ProcessingResources', 'AppSpecification', 'RoleArn', 'ProcessingInputs', 'ProcessingOutputConfig', 'Environment'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processing_step.arguments.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Uz-X8cRBHIg"
   },
   "source": [
    "Let's pull and review processing inputs from the arguments of the processing step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tFQy_vU8BHIg",
    "outputId": "d923a819-de37-4576-ce4a-f121a31e5b25"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'InputName': 'raw-input-data',\n",
       "  'AppManaged': False,\n",
       "  'S3Input': {'S3Uri': ParameterString(name='InputData', parameter_type=<ParameterTypeEnum.STRING: 'String'>, default_value='s3://dlai-practical-data-science/data/raw/'),\n",
       "   'LocalPath': '/opt/ml/processing/input/data/',\n",
       "   'S3DataType': 'S3Prefix',\n",
       "   'S3InputMode': 'File',\n",
       "   'S3DataDistributionType': 'ShardedByS3Key',\n",
       "   'S3CompressionType': 'None'}},\n",
       " {'InputName': 'code',\n",
       "  'AppManaged': False,\n",
       "  'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-912822595625/sagemaker-scikit-learn-2023-02-12-13-32-22-918/input/code/prepare_data.py',\n",
       "   'LocalPath': '/opt/ml/processing/input/code',\n",
       "   'S3DataType': 'S3Prefix',\n",
       "   'S3InputMode': 'File',\n",
       "   'S3DataDistributionType': 'FullyReplicated',\n",
       "   'S3CompressionType': 'None'}}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processing_step.arguments['ProcessingInputs']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d6_rFbMEBHIg"
   },
   "source": [
    "Let's now pull and review configuration of the processing outputs from the arguments of the processing step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9bfGa9BLBHIh",
    "outputId": "b1a5bc56-0416-441d-a771-8e40ca39c1ec"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Outputs': [{'OutputName': 'sentiment-train',\n",
       "   'AppManaged': False,\n",
       "   'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-912822595625/sagemaker-scikit-learn-2023-02-12-13-32-20-378/output/sentiment-train',\n",
       "    'LocalPath': '/opt/ml/processing/output/sentiment/train',\n",
       "    'S3UploadMode': 'EndOfJob'}},\n",
       "  {'OutputName': 'sentiment-validation',\n",
       "   'AppManaged': False,\n",
       "   'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-912822595625/sagemaker-scikit-learn-2023-02-12-13-32-20-378/output/sentiment-validation',\n",
       "    'LocalPath': '/opt/ml/processing/output/sentiment/validation',\n",
       "    'S3UploadMode': 'EndOfJob'}},\n",
       "  {'OutputName': 'sentiment-test',\n",
       "   'AppManaged': False,\n",
       "   'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-912822595625/sagemaker-scikit-learn-2023-02-12-13-32-20-378/output/sentiment-test',\n",
       "    'LocalPath': '/opt/ml/processing/output/sentiment/test',\n",
       "    'S3UploadMode': 'EndOfJob'}}]}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processing_step.arguments['ProcessingOutputConfig'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SnZSb9u2BHIh"
   },
   "source": [
    "## Configure training step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_5InFOkeBHIh"
   },
   "source": [
    "### Define parameters\n",
    "\n",
    "Setup the parameters for the workflow. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TZ31iuvCBHIi"
   },
   "outputs": [],
   "source": [
    "freeze_bert_layer = ParameterString(\n",
    "    name=\"FreezeBertLayer\",\n",
    "    default_value=\"False\",\n",
    ")\n",
    "\n",
    "epochs = ParameterInteger(\n",
    "    name=\"Epochs\",\n",
    "    default_value=3\n",
    ")\n",
    "    \n",
    "learning_rate = ParameterFloat(\n",
    "    name=\"LearningRate\",\n",
    "    default_value=0.00001\n",
    ") \n",
    "    \n",
    "train_batch_size = ParameterInteger(\n",
    "    name=\"TrainBatchSize\",\n",
    "    default_value=64\n",
    ")\n",
    "\n",
    "train_steps_per_epoch = ParameterInteger(\n",
    "    name=\"TrainStepsPerEpoch\",\n",
    "    default_value=50\n",
    ")\n",
    "\n",
    "validation_batch_size = ParameterInteger(\n",
    "    name=\"ValidationBatchSize\",\n",
    "    default_value=64\n",
    ")\n",
    "\n",
    "validation_steps_per_epoch = ParameterInteger(\n",
    "    name=\"ValidationStepsPerEpoch\",\n",
    "    default_value=50\n",
    ")\n",
    "\n",
    "seed = ParameterInteger(\n",
    "    name=\"Seed\",\n",
    "    default_value=42\n",
    ")\n",
    "\n",
    "run_validation = ParameterString(\n",
    "    name=\"RunValidation\",\n",
    "    default_value=\"True\",\n",
    ")\n",
    "\n",
    "train_instance_count = ParameterInteger(\n",
    "    name=\"TrainInstanceCount\",\n",
    "    default_value=1\n",
    ")\n",
    "\n",
    "train_instance_type = ParameterString(\n",
    "    name=\"TrainInstanceType\",\n",
    "    default_value=\"ml.c5.9xlarge\"\n",
    ")\n",
    "\n",
    "train_volume_size = ParameterInteger(\n",
    "    name=\"TrainVolumeSize\",\n",
    "    default_value=256\n",
    ") \n",
    "\n",
    "input_mode = ParameterString(\n",
    "    name=\"InputMode\",\n",
    "    default_value=\"File\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "faEmAm1SBHIi"
   },
   "source": [
    "### Configure hyper-parameters\n",
    "\n",
    "Setup the dictionary that will be passed into the hyperparameters argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1xHO0LcNBHIi"
   },
   "outputs": [],
   "source": [
    "hyperparameters={\n",
    "    'max_seq_length': max_seq_length,\n",
    "    'freeze_bert_layer': freeze_bert_layer,\n",
    "    'epochs': epochs,\n",
    "    'learning_rate': learning_rate,\n",
    "    'train_batch_size': train_batch_size,\n",
    "    'train_steps_per_epoch': train_steps_per_epoch,\n",
    "    'validation_batch_size': validation_batch_size,\n",
    "    'validation_steps_per_epoch': validation_steps_per_epoch,\n",
    "    'seed': seed,\n",
    "    'run_validation': run_validation\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cSyqYCgaBHIj"
   },
   "source": [
    "### Configure model-evaluation metrics\n",
    "\n",
    "Choose loss and accuracy as the evaluation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R0jnoG1JBHIj"
   },
   "outputs": [],
   "source": [
    "metric_definitions = [\n",
    "     {'Name': 'validation:loss', 'Regex': 'val_loss: ([0-9.]+)'},\n",
    "     {'Name': 'validation:accuracy', 'Regex': 'val_acc: ([0-9.]+)'},\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z1G3dFw4BHIk"
   },
   "source": [
    "### Configure the `PyTorchEstimator`\n",
    "\n",
    "Let's configure an estimator and the input dataset. A typical training script loads data from the input channels, configures training with hyperparameters, trains a model, and saves a model to `model_dir` so that it can be hosted later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LYO3f15kBHIk"
   },
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorch as PyTorchEstimator\n",
    "\n",
    "estimator = PyTorchEstimator(\n",
    "    entry_point='train.py',\n",
    "    source_dir='src',\n",
    "    role=role,\n",
    "    instance_count=train_instance_count,\n",
    "    instance_type=train_instance_type,\n",
    "    volume_size=train_volume_size,\n",
    "    py_version='py3',\n",
    "    framework_version='1.6.0',\n",
    "    hyperparameters=hyperparameters,\n",
    "    metric_definitions=metric_definitions,\n",
    "    input_mode=input_mode\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dv4tnI4VBHIk"
   },
   "source": [
    "### Setup pipeline step caching\n",
    "\n",
    "Step signature caching allows SageMaker Pipelines, before executing a step, to find a previous execution of a step that was called using the same arguments. Cache hit gets created if the previous execution is found. Then during execution instead of recomputing the step, pipelines propagates the values from the cache hit.\n",
    "\n",
    "Timeout period is defined using [ISO 8601](https://en.wikipedia.org/wiki/ISO_8601#Durations) format, it can contain a year, month, week, day, hour, and minute value. \n",
    "\n",
    "More details on SageMaker Pipeline step caching can be found [here](https://docs.aws.amazon.com/sagemaker/latest/dg/pipelines-caching.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nxCJHLEUBHIk"
   },
   "outputs": [],
   "source": [
    "from sagemaker.workflow.steps import CacheConfig\n",
    "\n",
    "cache_config = CacheConfig(enable_caching=True, expire_after=\"PT1H\") # PT1H represents `one hour`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XEUNx5bSBHIk"
   },
   "source": [
    "### Configure the `TrainingStep`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ca7E6Ct8BHIl"
   },
   "source": [
    "Now we configure the `TrainingStep` calling the outputs of the processing step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ltaXifx_BHIl",
    "outputId": "1cb4774c-ee9a-4e9d-c088-b062621abaa9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrainingStep(name='Train', step_type=<StepTypeEnum.TRAINING: 'Training'>)\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.workflow.steps import TrainingStep\n",
    "\n",
    "training_step = TrainingStep(\n",
    "    name='Train',\n",
    "    estimator=estimator,\n",
    "    inputs={\n",
    "        'train': TrainingInput(\n",
    "            s3_data=processing_step.properties.ProcessingOutputConfig.Outputs[\n",
    "                'sentiment-train'\n",
    "            ].S3Output.S3Uri,\n",
    "            content_type='text/csv'\n",
    "        ),\n",
    "        'validation': TrainingInput(\n",
    "            s3_data=processing_step.properties.ProcessingOutputConfig.Outputs[\n",
    "                'sentiment-validation'\n",
    "            ].S3Output.S3Uri,\n",
    "            content_type='text/csv'\n",
    "        )\n",
    "    },\n",
    "    cache_config=cache_config\n",
    ")\n",
    "\n",
    "print(training_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pGSJ73e5BHIl"
   },
   "source": [
    "We will use the `__dict__` method to print out attributes of the training step properties. Briefly review the result. The attributes match the object model of the [DescribeTrainingJob](https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_DescribeTrainingJob.html) response object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cWmxU0eSBHIl",
    "outputId": "593d96f5-84ad-46e2-c89e-c2d19fe5f68a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_path': 'Steps.Train',\n",
       " '_shape_name': 'DescribeTrainingJobResponse',\n",
       " 'TrainingJobName': <sagemaker.workflow.properties.Properties at 0x7fcdf5101310>,\n",
       " 'TrainingJobArn': <sagemaker.workflow.properties.Properties at 0x7fcdf5101350>,\n",
       " 'TuningJobArn': <sagemaker.workflow.properties.Properties at 0x7fcdf5101390>,\n",
       " 'LabelingJobArn': <sagemaker.workflow.properties.Properties at 0x7fcdf51013d0>,\n",
       " 'AutoMLJobArn': <sagemaker.workflow.properties.Properties at 0x7fcdf5101210>,\n",
       " 'ModelArtifacts': <sagemaker.workflow.properties.Properties at 0x7fcdf5101250>,\n",
       " 'TrainingJobStatus': <sagemaker.workflow.properties.Properties at 0x7fcdf51012d0>,\n",
       " 'SecondaryStatus': <sagemaker.workflow.properties.Properties at 0x7fcdf5101110>,\n",
       " 'FailureReason': <sagemaker.workflow.properties.Properties at 0x7fcdf5101150>,\n",
       " 'HyperParameters': <sagemaker.workflow.properties.Properties at 0x7fcdf5101190>,\n",
       " 'AlgorithmSpecification': <sagemaker.workflow.properties.Properties at 0x7fcdf51011d0>,\n",
       " 'RoleArn': <sagemaker.workflow.properties.Properties at 0x7fcdf5101850>,\n",
       " 'InputDataConfig': <sagemaker.workflow.properties.PropertiesList at 0x7fcdf5101750>,\n",
       " 'OutputDataConfig': <sagemaker.workflow.properties.Properties at 0x7fcdf5101490>,\n",
       " 'ResourceConfig': <sagemaker.workflow.properties.Properties at 0x7fcdf51015d0>,\n",
       " 'VpcConfig': <sagemaker.workflow.properties.Properties at 0x7fcdf5424e10>,\n",
       " 'StoppingCondition': <sagemaker.workflow.properties.Properties at 0x7fcdf5424350>,\n",
       " 'CreationTime': <sagemaker.workflow.properties.Properties at 0x7fcdf5424910>,\n",
       " 'TrainingStartTime': <sagemaker.workflow.properties.Properties at 0x7fcdf5424750>,\n",
       " 'TrainingEndTime': <sagemaker.workflow.properties.Properties at 0x7fcdf5424950>,\n",
       " 'LastModifiedTime': <sagemaker.workflow.properties.Properties at 0x7fcdf5424550>,\n",
       " 'SecondaryStatusTransitions': <sagemaker.workflow.properties.PropertiesList at 0x7fcdf5424a10>,\n",
       " 'FinalMetricDataList': <sagemaker.workflow.properties.PropertiesList at 0x7fcdf5424590>,\n",
       " 'EnableNetworkIsolation': <sagemaker.workflow.properties.Properties at 0x7fcdf5424e50>,\n",
       " 'EnableInterContainerTrafficEncryption': <sagemaker.workflow.properties.Properties at 0x7fcdf5424690>,\n",
       " 'EnableManagedSpotTraining': <sagemaker.workflow.properties.Properties at 0x7fcdf5424150>,\n",
       " 'CheckpointConfig': <sagemaker.workflow.properties.Properties at 0x7fcdf5424fd0>,\n",
       " 'TrainingTimeInSeconds': <sagemaker.workflow.properties.Properties at 0x7fcdf5424490>,\n",
       " 'BillableTimeInSeconds': <sagemaker.workflow.properties.Properties at 0x7fcdf5424ad0>,\n",
       " 'DebugHookConfig': <sagemaker.workflow.properties.Properties at 0x7fcdf54246d0>,\n",
       " 'ExperimentConfig': <sagemaker.workflow.properties.Properties at 0x7fcdf53a7d50>,\n",
       " 'DebugRuleConfigurations': <sagemaker.workflow.properties.PropertiesList at 0x7fcdf53a7890>,\n",
       " 'TensorBoardOutputConfig': <sagemaker.workflow.properties.Properties at 0x7fcdf53a7e50>,\n",
       " 'DebugRuleEvaluationStatuses': <sagemaker.workflow.properties.PropertiesList at 0x7fcdf53a7dd0>,\n",
       " 'ProfilerConfig': <sagemaker.workflow.properties.Properties at 0x7fcdf53a7d90>,\n",
       " 'ProfilerRuleConfigurations': <sagemaker.workflow.properties.PropertiesList at 0x7fcdf53a79d0>,\n",
       " 'ProfilerRuleEvaluationStatuses': <sagemaker.workflow.properties.PropertiesList at 0x7fcdf53a7410>,\n",
       " 'ProfilingStatus': <sagemaker.workflow.properties.Properties at 0x7fcdf53a7ad0>,\n",
       " 'RetryStrategy': <sagemaker.workflow.properties.Properties at 0x7fcdf53a7a10>,\n",
       " 'Environment': <sagemaker.workflow.properties.Properties at 0x7fcdf53a7950>,\n",
       " 'WarmPoolStatus': <sagemaker.workflow.properties.Properties at 0x7fcdf53a7f10>}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_step.properties.__dict__ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ityDTb6oBHIm"
   },
   "source": [
    "## Configure model-evaluation step\n",
    "\n",
    "First, we will develop an evaluation script that will be specified in the model evaluation processing step. The evaluation script users the trained model and the test dataset to produce a JSON file with classification evaluation metrics such as accuracy.\n",
    "\n",
    "The evaluation script performs the following steps:\n",
    "* loads in the model\n",
    "* reads in the test data\n",
    "* issues a bunch of predictions against the test data\n",
    "* builds a classification report, including accuracy\n",
    "* saves the evaluation report to the evaluation directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "21Vj546HBHIm"
   },
   "source": [
    "Create an instance of the `SKLearnProcessor` to run our evaluation script as a scikit-learn-based SageMaker processing job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r3wu1RSRBHIm",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "\n",
    "evaluation_processor = SKLearnProcessor(\n",
    "    framework_version='0.23-1',\n",
    "    role=role,\n",
    "    instance_type=processing_instance_type,\n",
    "    instance_count=processing_instance_count,\n",
    "    env={'AWS_DEFAULT_REGION': region},\n",
    "    max_runtime_in_seconds=7200\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rlQtQi15BHIm"
   },
   "source": [
    "Setup the output `PropertyFile`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fIRENkXzBHIn"
   },
   "outputs": [],
   "source": [
    "from sagemaker.workflow.properties import PropertyFile\n",
    "\n",
    "evaluation_report = PropertyFile(\n",
    "    name='EvaluationReport',\n",
    "    output_name='metrics',\n",
    "    path='evaluation.json'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HB8MDlW-BHIn"
   },
   "source": [
    "Now we use the processor instance to construct a `ProcessingStep`, along with the input and output channels and the code that will be executed when the pipeline invokes pipeline execution. This is very similar to a processor instance's `run` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZV-FObtoBHIn"
   },
   "outputs": [],
   "source": [
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "\n",
    "evaluation_step = ProcessingStep(\n",
    "    name='EvaluateModel',\n",
    "    processor=evaluation_processor,\n",
    "    code='src/evaluate_model_metrics.py',\n",
    "    inputs=[\n",
    "        ProcessingInput(\n",
    "            source=training_step.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "            destination='/opt/ml/processing/input/model'\n",
    "        ),\n",
    "        ProcessingInput(\n",
    "            source=processing_step.properties.ProcessingOutputConfig.Outputs['sentiment-test'].S3Output.S3Uri,\n",
    "            destination='/opt/ml/processing/input/data'\n",
    "        )\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(output_name='metrics', \n",
    "                         s3_upload_mode='EndOfJob',\n",
    "                         source='/opt/ml/processing/output/metrics/'),\n",
    "    ],\n",
    "    job_arguments=[\n",
    "        '--max-seq-length', str(max_seq_length.default_value),\n",
    "    ],\n",
    "    property_files=[evaluation_report],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "71ldnRsDBHIo"
   },
   "source": [
    "## Configure and register model step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pwLj5skPBHIo"
   },
   "source": [
    "### Configure the model for deployment\n",
    "\n",
    "We will now use the estimator instance that was used for the training step to construct an instance of `RegisterModel`. The result of executing `RegisterModel` in a pipeline is a model package. A model package is a reusable model artifacts abstraction that packages all ingredients necessary for inference. Primarily, it consists of an inference specification that defines the inference image to use along with an optional model weights location.\n",
    "\n",
    "A model package group is a collection of model packages. You can create a model package group for a specific ML business problem, and you can keep adding versions/model packages into it. Typically, customers are expected to create a ModelPackageGroup for a SageMaker workflow pipeline so that they can keep adding versions/model packages to the group for every workflow pipeline run.\n",
    "\n",
    "The construction of `RegisterModel` is very similar to an estimator instance's `register` method, for those familiar with the existing Python SDK.\n",
    "\n",
    "In particular, we will pass in the `S3ModelArtifacts` from the `training_step` properties.\n",
    "\n",
    "Of note, here we will be provided a specific model package group name which will be used in the Model Registry and Continuous Integration/Continuous Deployment (CI/CD) work later on. Let's setup the variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GFFBWBGFBHIo"
   },
   "outputs": [],
   "source": [
    "model_approval_status = ParameterString(\n",
    "    name=\"ModelApprovalStatus\",\n",
    "    default_value=\"PendingManualApproval\"\n",
    ")\n",
    "\n",
    "deploy_instance_type = ParameterString(\n",
    "    name=\"DeployInstanceType\",\n",
    "    default_value=\"ml.m5.large\"\n",
    ")\n",
    "\n",
    "deploy_instance_count = ParameterInteger(\n",
    "    name=\"DeployInstanceCount\",\n",
    "    default_value=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DM5_yOm4BHIo",
    "outputId": "801217b4-4c41-46bd-c1e7-e3eecf95cb47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT-Reviews-1676208665\n"
     ]
    }
   ],
   "source": [
    "model_package_group_name = f\"BERT-Reviews-{timestamp}\"\n",
    "\n",
    "print(model_package_group_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XlO9pPJABHIp"
   },
   "source": [
    "Configure the `ModelMetrics` to be stored as metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uf2V7CCYBHIp",
    "outputId": "686e843f-9bf2-49ea-c0cb-e530838f774a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<sagemaker.model_metrics.ModelMetrics object at 0x7fcdf40cd5d0>\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.model_metrics import MetricsSource, ModelMetrics \n",
    "\n",
    "model_metrics = ModelMetrics(\n",
    "    model_statistics=MetricsSource(\n",
    "        s3_uri=\"{}/evaluation.json\".format(\n",
    "            evaluation_step.arguments[\"ProcessingOutputConfig\"][\"Outputs\"][0][\"S3Output\"][\"S3Uri\"]\n",
    "        ),\n",
    "        content_type=\"application/json\"\n",
    "    )\n",
    ")\n",
    "\n",
    "print(model_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7s6DJHptBHIp"
   },
   "source": [
    "Define deployment image for inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bplsIqRCBHIp",
    "outputId": "c9e17fee-616b-4f13-8431-c3eab06105c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "763104351884.dkr.ecr.us-east-1.amazonaws.com/pytorch-inference:1.6.0-cpu-py36\n"
     ]
    }
   ],
   "source": [
    "inference_image_uri = sagemaker.image_uris.retrieve(\n",
    "    framework=\"pytorch\",\n",
    "    region=region,\n",
    "    version=\"1.6.0\",\n",
    "    py_version=\"py36\",\n",
    "    instance_type=deploy_instance_type,\n",
    "    image_scope=\"inference\"\n",
    ")\n",
    "print(inference_image_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eGVFeds8BHIq"
   },
   "source": [
    "### Register the model for deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LL1VZpNHBHIq"
   },
   "source": [
    "Let's now configure the register model step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ceJ_1mlzBHIq"
   },
   "outputs": [],
   "source": [
    "from sagemaker.workflow.step_collections import RegisterModel\n",
    "\n",
    "register_step = RegisterModel(\n",
    "    name=\"RegisterModel\",\n",
    "    estimator=estimator,\n",
    "    image_uri=inference_image_uri, \n",
    "    model_data=training_step.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "    content_types=[\"application/jsonlines\"],\n",
    "    response_types=[\"application/jsonlines\"],\n",
    "    inference_instances=[deploy_instance_type],\n",
    "    transform_instances=[deploy_instance_type], \n",
    "    model_package_group_name=model_package_group_name,\n",
    "    approval_status=model_approval_status,\n",
    "    model_metrics=model_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fbEvkKoTBHIq"
   },
   "source": [
    "## Create model for deployment step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "93KZInoABHIr"
   },
   "source": [
    "Let's configure the model for deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4Ztpq_xZBHIr"
   },
   "outputs": [],
   "source": [
    "from sagemaker.model import Model\n",
    "\n",
    "model_name = 'bert-model-{}'.format(timestamp)\n",
    "\n",
    "model = Model(\n",
    "    name=model_name,\n",
    "    image_uri=inference_image_uri, \n",
    "    model_data=training_step.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "    sagemaker_session=sess,\n",
    "    role=role,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9GAtdBV_BHIr"
   },
   "source": [
    "Now we configure create model input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DUBelM8OBHIr"
   },
   "outputs": [],
   "source": [
    "from sagemaker.inputs import CreateModelInput\n",
    "\n",
    "create_inputs = CreateModelInput(\n",
    "    instance_type=deploy_instance_type, \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wcan3YUPBHIs"
   },
   "source": [
    "Lastly we configure the create model step for the workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YiuY7q1EBHIs"
   },
   "outputs": [],
   "source": [
    "from sagemaker.workflow.steps import CreateModelStep\n",
    "\n",
    "create_step = CreateModelStep(\n",
    "    name=\"CreateModel\",\n",
    "    model=model, \n",
    "    inputs=create_inputs, \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pZyBUg0yBHIs"
   },
   "source": [
    "## Check accuracy condition step\n",
    "\n",
    "Finally, we would like to only register this model if the accuracy of the model, as determined by our evaluation step `evaluation_step`, exceeded some value. A `ConditionStep` allows for pipelines to support conditional execution in the pipeline DAG based on conditions of step properties. \n",
    "\n",
    "Below, we will:\n",
    "\n",
    "* define a minimum accuracy value as a parameter\n",
    "* define a `ConditionGreaterThan` on the accuracy value found in the output of the evaluation step, `evaluation_step`.\n",
    "* use the condition in the list of conditions in a `ConditionStep`\n",
    "* pass the `RegisterModel` step collection into the `if_steps` of the `ConditionStep`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5FiDhieJBHIs"
   },
   "outputs": [],
   "source": [
    "min_accuracy_value = ParameterFloat(\n",
    "    name=\"MinAccuracyValue\",\n",
    "    default_value=0.33 # random choice from three classes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NA326TEXBHIt"
   },
   "outputs": [],
   "source": [
    "from sagemaker.workflow.conditions import ConditionGreaterThanOrEqualTo\n",
    "from sagemaker.workflow.condition_step import (\n",
    "    ConditionStep,\n",
    "    JsonGet,\n",
    ")\n",
    "\n",
    "minimum_accuracy_condition = ConditionGreaterThanOrEqualTo(\n",
    "    left=JsonGet(\n",
    "        step=evaluation_step,\n",
    "        property_file=evaluation_report,\n",
    "        json_path=\"metrics.accuracy.value\",\n",
    "    ),\n",
    "    right=min_accuracy_value # minimum accuracy threshold\n",
    ")\n",
    "\n",
    "minimum_accuracy_condition_step = ConditionStep(\n",
    "    name=\"AccuracyCondition\",\n",
    "    conditions=[minimum_accuracy_condition],\n",
    "    if_steps=[register_step, create_step], # successfully exceeded or equaled the minimum accuracy, continue with model registration\n",
    "    else_steps=[], # did not exceed the minimum accuracy, the model will not be registered\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pjk6iN3lBHIt"
   },
   "source": [
    "## Create pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0NOv_nVnBHIt"
   },
   "source": [
    "### Define a pipeline of parameters, steps, and conditions\n",
    "\n",
    "Let's tie it all up into a workflow pipeline so we can execute it, and even schedule it.\n",
    "\n",
    "A pipeline requires a `name`, `parameters`, and `steps`. Names must be unique within an `(account, region)` pair so you can append the timestamp to the name to reduce the chance of name conflict.\n",
    "\n",
    "Note:\n",
    "\n",
    "* All the parameters used in the definitions must be present.\n",
    "* Steps passed into the pipeline need not be in the order of execution. The SageMaker workflow service will resolve the _data dependency_ DAG as steps the execution complete.\n",
    "* Steps must be unique to either pipeline step list or a single condition step if/else list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qNNRd6mCBHIu"
   },
   "outputs": [],
   "source": [
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    name=pipeline_name,\n",
    "    parameters=[\n",
    "        input_data,\n",
    "        processing_instance_count,\n",
    "        processing_instance_type,\n",
    "        max_seq_length,\n",
    "        balance_dataset,\n",
    "        train_split_percentage,\n",
    "        validation_split_percentage,\n",
    "        test_split_percentage,\n",
    "        feature_store_offline_prefix,\n",
    "        feature_group_name,\n",
    "        epochs,\n",
    "        learning_rate,\n",
    "        train_batch_size,\n",
    "        train_steps_per_epoch,\n",
    "        validation_batch_size,\n",
    "        validation_steps_per_epoch,\n",
    "        freeze_bert_layer,\n",
    "        seed,\n",
    "        train_instance_count,\n",
    "        train_instance_type,\n",
    "        train_volume_size,        \n",
    "        input_mode,\n",
    "        run_validation,\n",
    "        min_accuracy_value,\n",
    "        model_approval_status,\n",
    "        deploy_instance_type,\n",
    "        deploy_instance_count\n",
    "    ],\n",
    "    steps=[processing_step, training_step, evaluation_step, minimum_accuracy_condition_step],\n",
    "    sagemaker_session=sess,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ofm2lQs9BHIu"
   },
   "source": [
    "Let's examine the JSON of the pipeline definition that meets the SageMaker Workflow Pipeline DSL specification.\n",
    "\n",
    "By examining the definition, you are also confirming that the pipeline was well-defined, and that the parameters and step properties resolve correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XFFw5oBQBHIu",
    "outputId": "27f05fa4-8980-4dbb-b3e9-52ba548492b0",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Metadata': {},\n",
      " 'Parameters': [{'DefaultValue': 's3://dlai-practical-data-science/data/raw/',\n",
      "                 'Name': 'InputData',\n",
      "                 'Type': 'String'},\n",
      "                {'DefaultValue': 1,\n",
      "                 'Name': 'ProcessingInstanceCount',\n",
      "                 'Type': 'Integer'},\n",
      "                {'DefaultValue': 'ml.c5.2xlarge',\n",
      "                 'Name': 'ProcessingInstanceType',\n",
      "                 'Type': 'String'},\n",
      "                {'DefaultValue': 128,\n",
      "                 'Name': 'MaxSeqLength',\n",
      "                 'Type': 'Integer'},\n",
      "                {'DefaultValue': 'True',\n",
      "                 'Name': 'BalanceDataset',\n",
      "                 'Type': 'String'},\n",
      "                {'DefaultValue': 0.9,\n",
      "                 'Name': 'TrainSplitPercentage',\n",
      "                 'Type': 'Float'},\n",
      "                {'DefaultValue': 0.05,\n",
      "                 'Name': 'ValidationSplitPercentage',\n",
      "                 'Type': 'Float'},\n",
      "                {'DefaultValue': 0.05,\n",
      "                 'Name': 'TestSplitPercentage',\n",
      "                 'Type': 'Float'},\n",
      "                {'DefaultValue': 'reviews-feature-store-1676208665',\n",
      "                 'Name': 'FeatureStoreOfflinePrefix',\n",
      "                 'Type': 'String'},\n",
      "                {'DefaultValue': 'reviews-feature-group-1676208665',\n",
      "                 'Name': 'FeatureGroupName',\n",
      "                 'Type': 'String'},\n",
      "                {'DefaultValue': 3, 'Name': 'Epochs', 'Type': 'Integer'},\n",
      "                {'DefaultValue': 1e-05,\n",
      "                 'Name': 'LearningRate',\n",
      "                 'Type': 'Float'},\n",
      "                {'DefaultValue': 64,\n",
      "                 'Name': 'TrainBatchSize',\n",
      "                 'Type': 'Integer'},\n",
      "                {'DefaultValue': 50,\n",
      "                 'Name': 'TrainStepsPerEpoch',\n",
      "                 'Type': 'Integer'},\n",
      "                {'DefaultValue': 64,\n",
      "                 'Name': 'ValidationBatchSize',\n",
      "                 'Type': 'Integer'},\n",
      "                {'DefaultValue': 50,\n",
      "                 'Name': 'ValidationStepsPerEpoch',\n",
      "                 'Type': 'Integer'},\n",
      "                {'DefaultValue': 'False',\n",
      "                 'Name': 'FreezeBertLayer',\n",
      "                 'Type': 'String'},\n",
      "                {'DefaultValue': 42, 'Name': 'Seed', 'Type': 'Integer'},\n",
      "                {'DefaultValue': 1,\n",
      "                 'Name': 'TrainInstanceCount',\n",
      "                 'Type': 'Integer'},\n",
      "                {'DefaultValue': 'ml.c5.9xlarge',\n",
      "                 'Name': 'TrainInstanceType',\n",
      "                 'Type': 'String'},\n",
      "                {'DefaultValue': 256,\n",
      "                 'Name': 'TrainVolumeSize',\n",
      "                 'Type': 'Integer'},\n",
      "                {'DefaultValue': 'File', 'Name': 'InputMode', 'Type': 'String'},\n",
      "                {'DefaultValue': 'True',\n",
      "                 'Name': 'RunValidation',\n",
      "                 'Type': 'String'},\n",
      "                {'DefaultValue': 0.33,\n",
      "                 'Name': 'MinAccuracyValue',\n",
      "                 'Type': 'Float'},\n",
      "                {'DefaultValue': 'PendingManualApproval',\n",
      "                 'Name': 'ModelApprovalStatus',\n",
      "                 'Type': 'String'},\n",
      "                {'DefaultValue': 'ml.m5.large',\n",
      "                 'Name': 'DeployInstanceType',\n",
      "                 'Type': 'String'},\n",
      "                {'DefaultValue': 1,\n",
      "                 'Name': 'DeployInstanceCount',\n",
      "                 'Type': 'Integer'}],\n",
      " 'Steps': [{'Arguments': {'AppSpecification': {'ContainerArguments': ['--train-split-percentage',\n",
      "                                                                      '0.9',\n",
      "                                                                      '--validation-split-percentage',\n",
      "                                                                      '0.05',\n",
      "                                                                      '--test-split-percentage',\n",
      "                                                                      '0.05',\n",
      "                                                                      '--balance-dataset',\n",
      "                                                                      'True',\n",
      "                                                                      '--max-seq-length',\n",
      "                                                                      '128',\n",
      "                                                                      '--feature-store-offline-prefix',\n",
      "                                                                      'reviews-feature-store-1676208665',\n",
      "                                                                      '--feature-group-name',\n",
      "                                                                      'reviews-feature-group-1676208665'],\n",
      "                                               'ContainerEntrypoint': ['python3',\n",
      "                                                                       '/opt/ml/processing/input/code/prepare_data.py'],\n",
      "                                               'ImageUri': '683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-scikit-learn:0.23-1-cpu-py3'},\n",
      "                          'Environment': {'AWS_DEFAULT_REGION': 'us-east-1'},\n",
      "                          'ProcessingInputs': [{'AppManaged': False,\n",
      "                                                'InputName': 'raw-input-data',\n",
      "                                                'S3Input': {'LocalPath': '/opt/ml/processing/input/data/',\n",
      "                                                            'S3CompressionType': 'None',\n",
      "                                                            'S3DataDistributionType': 'ShardedByS3Key',\n",
      "                                                            'S3DataType': 'S3Prefix',\n",
      "                                                            'S3InputMode': 'File',\n",
      "                                                            'S3Uri': {'Get': 'Parameters.InputData'}}},\n",
      "                                               {'AppManaged': False,\n",
      "                                                'InputName': 'code',\n",
      "                                                'S3Input': {'LocalPath': '/opt/ml/processing/input/code',\n",
      "                                                            'S3CompressionType': 'None',\n",
      "                                                            'S3DataDistributionType': 'FullyReplicated',\n",
      "                                                            'S3DataType': 'S3Prefix',\n",
      "                                                            'S3InputMode': 'File',\n",
      "                                                            'S3Uri': 's3://sagemaker-us-east-1-912822595625/sagemaker-scikit-learn-2023-02-12-13-37-28-563/input/code/prepare_data.py'}}],\n",
      "                          'ProcessingOutputConfig': {'Outputs': [{'AppManaged': False,\n",
      "                                                                  'OutputName': 'sentiment-train',\n",
      "                                                                  'S3Output': {'LocalPath': '/opt/ml/processing/output/sentiment/train',\n",
      "                                                                               'S3UploadMode': 'EndOfJob',\n",
      "                                                                               'S3Uri': 's3://sagemaker-us-east-1-912822595625/sagemaker-scikit-learn-2023-02-12-13-32-20-378/output/sentiment-train'}},\n",
      "                                                                 {'AppManaged': False,\n",
      "                                                                  'OutputName': 'sentiment-validation',\n",
      "                                                                  'S3Output': {'LocalPath': '/opt/ml/processing/output/sentiment/validation',\n",
      "                                                                               'S3UploadMode': 'EndOfJob',\n",
      "                                                                               'S3Uri': 's3://sagemaker-us-east-1-912822595625/sagemaker-scikit-learn-2023-02-12-13-32-20-378/output/sentiment-validation'}},\n",
      "                                                                 {'AppManaged': False,\n",
      "                                                                  'OutputName': 'sentiment-test',\n",
      "                                                                  'S3Output': {'LocalPath': '/opt/ml/processing/output/sentiment/test',\n",
      "                                                                               'S3UploadMode': 'EndOfJob',\n",
      "                                                                               'S3Uri': 's3://sagemaker-us-east-1-912822595625/sagemaker-scikit-learn-2023-02-12-13-32-20-378/output/sentiment-test'}}]},\n",
      "                          'ProcessingResources': {'ClusterConfig': {'InstanceCount': {'Get': 'Parameters.ProcessingInstanceCount'},\n",
      "                                                                    'InstanceType': {'Get': 'Parameters.ProcessingInstanceType'},\n",
      "                                                                    'VolumeSizeInGB': 30}},\n",
      "                          'RoleArn': 'arn:aws:iam::912822595625:role/sagemaker-studio-vpc-firewall-us-east-1-sagemaker-execution-role'},\n",
      "            'Name': 'Processing',\n",
      "            'Type': 'Processing'},\n",
      "           {'Arguments': {'AlgorithmSpecification': {'EnableSageMakerMetricsTimeSeries': True,\n",
      "                                                     'MetricDefinitions': [{'Name': 'validation:loss',\n",
      "                                                                            'Regex': 'val_loss: '\n",
      "                                                                                     '([0-9.]+)'},\n",
      "                                                                           {'Name': 'validation:accuracy',\n",
      "                                                                            'Regex': 'val_acc: '\n",
      "                                                                                     '([0-9.]+)'}],\n",
      "                                                     'TrainingImage': '763104351884.dkr.ecr.us-east-1.amazonaws.com/pytorch-training:1.6.0-cpu-py3',\n",
      "                                                     'TrainingInputMode': {'Get': 'Parameters.InputMode'}},\n",
      "                          'DebugHookConfig': {'CollectionConfigurations': [],\n",
      "                                              'S3OutputPath': 's3://sagemaker-us-east-1-912822595625/'},\n",
      "                          'HyperParameters': {'epochs': '3',\n",
      "                                              'freeze_bert_layer': '\"False\"',\n",
      "                                              'learning_rate': '1e-05',\n",
      "                                              'max_seq_length': '128',\n",
      "                                              'run_validation': '\"True\"',\n",
      "                                              'sagemaker_container_log_level': '20',\n",
      "                                              'sagemaker_job_name': '\"pytorch-training-2023-02-12-13-37-28-707\"',\n",
      "                                              'sagemaker_program': '\"train.py\"',\n",
      "                                              'sagemaker_region': '\"us-east-1\"',\n",
      "                                              'sagemaker_submit_directory': '\"s3://sagemaker-us-east-1-912822595625/pytorch-training-2023-02-12-13-37-28-707/source/sourcedir.tar.gz\"',\n",
      "                                              'seed': '42',\n",
      "                                              'train_batch_size': '64',\n",
      "                                              'train_steps_per_epoch': '50',\n",
      "                                              'validation_batch_size': '64',\n",
      "                                              'validation_steps_per_epoch': '50'},\n",
      "                          'InputDataConfig': [{'ChannelName': 'train',\n",
      "                                               'ContentType': 'text/csv',\n",
      "                                               'DataSource': {'S3DataSource': {'S3DataDistributionType': 'FullyReplicated',\n",
      "                                                                               'S3DataType': 'S3Prefix',\n",
      "                                                                               'S3Uri': {'Get': \"Steps.Processing.ProcessingOutputConfig.Outputs['sentiment-train'].S3Output.S3Uri\"}}}},\n",
      "                                              {'ChannelName': 'validation',\n",
      "                                               'ContentType': 'text/csv',\n",
      "                                               'DataSource': {'S3DataSource': {'S3DataDistributionType': 'FullyReplicated',\n",
      "                                                                               'S3DataType': 'S3Prefix',\n",
      "                                                                               'S3Uri': {'Get': \"Steps.Processing.ProcessingOutputConfig.Outputs['sentiment-validation'].S3Output.S3Uri\"}}}}],\n",
      "                          'OutputDataConfig': {'S3OutputPath': 's3://sagemaker-us-east-1-912822595625/'},\n",
      "                          'ProfilerConfig': {'S3OutputPath': 's3://sagemaker-us-east-1-912822595625/'},\n",
      "                          'ProfilerRuleConfigurations': [{'RuleConfigurationName': 'ProfilerReport-1676209048',\n",
      "                                                          'RuleEvaluatorImage': '503895931360.dkr.ecr.us-east-1.amazonaws.com/sagemaker-debugger-rules:latest',\n",
      "                                                          'RuleParameters': {'rule_to_invoke': 'ProfilerReport'}}],\n",
      "                          'ResourceConfig': {'InstanceCount': {'Get': 'Parameters.TrainInstanceCount'},\n",
      "                                             'InstanceType': {'Get': 'Parameters.TrainInstanceType'},\n",
      "                                             'VolumeSizeInGB': {'Get': 'Parameters.TrainVolumeSize'}},\n",
      "                          'RoleArn': 'arn:aws:iam::912822595625:role/sagemaker-studio-vpc-firewall-us-east-1-sagemaker-execution-role',\n",
      "                          'StoppingCondition': {'MaxRuntimeInSeconds': 86400}},\n",
      "            'CacheConfig': {'Enabled': True, 'ExpireAfter': 'PT1H'},\n",
      "            'Name': 'Train',\n",
      "            'Type': 'Training'},\n",
      "           {'Arguments': {'AppSpecification': {'ContainerArguments': ['--max-seq-length',\n",
      "                                                                      '128'],\n",
      "                                               'ContainerEntrypoint': ['python3',\n",
      "                                                                       '/opt/ml/processing/input/code/evaluate_model_metrics.py'],\n",
      "                                               'ImageUri': '683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-scikit-learn:0.23-1-cpu-py3'},\n",
      "                          'Environment': {'AWS_DEFAULT_REGION': 'us-east-1'},\n",
      "                          'ProcessingInputs': [{'AppManaged': False,\n",
      "                                                'InputName': 'input-1',\n",
      "                                                'S3Input': {'LocalPath': '/opt/ml/processing/input/model',\n",
      "                                                            'S3CompressionType': 'None',\n",
      "                                                            'S3DataDistributionType': 'FullyReplicated',\n",
      "                                                            'S3DataType': 'S3Prefix',\n",
      "                                                            'S3InputMode': 'File',\n",
      "                                                            'S3Uri': {'Get': 'Steps.Train.ModelArtifacts.S3ModelArtifacts'}}},\n",
      "                                               {'AppManaged': False,\n",
      "                                                'InputName': 'input-2',\n",
      "                                                'S3Input': {'LocalPath': '/opt/ml/processing/input/data',\n",
      "                                                            'S3CompressionType': 'None',\n",
      "                                                            'S3DataDistributionType': 'FullyReplicated',\n",
      "                                                            'S3DataType': 'S3Prefix',\n",
      "                                                            'S3InputMode': 'File',\n",
      "                                                            'S3Uri': {'Get': \"Steps.Processing.ProcessingOutputConfig.Outputs['sentiment-test'].S3Output.S3Uri\"}}},\n",
      "                                               {'AppManaged': False,\n",
      "                                                'InputName': 'code',\n",
      "                                                'S3Input': {'LocalPath': '/opt/ml/processing/input/code',\n",
      "                                                            'S3CompressionType': 'None',\n",
      "                                                            'S3DataDistributionType': 'FullyReplicated',\n",
      "                                                            'S3DataType': 'S3Prefix',\n",
      "                                                            'S3InputMode': 'File',\n",
      "                                                            'S3Uri': 's3://sagemaker-us-east-1-912822595625/sagemaker-scikit-learn-2023-02-12-13-37-29-187/input/code/evaluate_model_metrics.py'}}],\n",
      "                          'ProcessingOutputConfig': {'Outputs': [{'AppManaged': False,\n",
      "                                                                  'OutputName': 'metrics',\n",
      "                                                                  'S3Output': {'LocalPath': '/opt/ml/processing/output/metrics/',\n",
      "                                                                               'S3UploadMode': 'EndOfJob',\n",
      "                                                                               'S3Uri': 's3://sagemaker-us-east-1-912822595625/sagemaker-scikit-learn-2023-02-12-13-35-32-414/output/metrics'}}]},\n",
      "                          'ProcessingResources': {'ClusterConfig': {'InstanceCount': {'Get': 'Parameters.ProcessingInstanceCount'},\n",
      "                                                                    'InstanceType': {'Get': 'Parameters.ProcessingInstanceType'},\n",
      "                                                                    'VolumeSizeInGB': 30}},\n",
      "                          'RoleArn': 'arn:aws:iam::912822595625:role/sagemaker-studio-vpc-firewall-us-east-1-sagemaker-execution-role',\n",
      "                          'StoppingCondition': {'MaxRuntimeInSeconds': 7200}},\n",
      "            'Name': 'EvaluateModel',\n",
      "            'PropertyFiles': [{'FilePath': 'evaluation.json',\n",
      "                               'OutputName': 'metrics',\n",
      "                               'PropertyFileName': 'EvaluationReport'}],\n",
      "            'Type': 'Processing'},\n",
      "           {'Arguments': {'Conditions': [{'LeftValue': {'Std:JsonGet': {'Path': 'metrics.accuracy.value',\n",
      "                                                                        'PropertyFile': {'Get': 'Steps.EvaluateModel.PropertyFiles.EvaluationReport'}}},\n",
      "                                          'RightValue': {'Get': 'Parameters.MinAccuracyValue'},\n",
      "                                          'Type': 'GreaterThanOrEqualTo'}],\n",
      "                          'ElseSteps': [],\n",
      "                          'IfSteps': [{'Arguments': {'InferenceSpecification': {'Containers': [{'Image': '763104351884.dkr.ecr.us-east-1.amazonaws.com/pytorch-inference:1.6.0-cpu-py36',\n",
      "                                                                                                'ModelDataUrl': {'Get': 'Steps.Train.ModelArtifacts.S3ModelArtifacts'}}],\n",
      "                                                                                'SupportedContentTypes': ['application/jsonlines'],\n",
      "                                                                                'SupportedRealtimeInferenceInstanceTypes': [{'Get': 'Parameters.DeployInstanceType'}],\n",
      "                                                                                'SupportedResponseMIMETypes': ['application/jsonlines'],\n",
      "                                                                                'SupportedTransformInstanceTypes': [{'Get': 'Parameters.DeployInstanceType'}]},\n",
      "                                                     'ModelApprovalStatus': {'Get': 'Parameters.ModelApprovalStatus'},\n",
      "                                                     'ModelMetrics': {'ModelQuality': {'Statistics': {'ContentType': 'application/json',\n",
      "                                                                                                      'S3Uri': 's3://sagemaker-us-east-1-912822595625/sagemaker-scikit-learn-2023-02-12-13-35-32-414/output/metrics/evaluation.json'}}},\n",
      "                                                     'ModelPackageGroupName': 'BERT-Reviews-1676208665'},\n",
      "                                       'Name': 'RegisterModel',\n",
      "                                       'Type': 'RegisterModel'},\n",
      "                                      {'Arguments': {'ExecutionRoleArn': 'arn:aws:iam::912822595625:role/sagemaker-studio-vpc-firewall-us-east-1-sagemaker-execution-role',\n",
      "                                                     'PrimaryContainer': {'Environment': {},\n",
      "                                                                          'Image': '763104351884.dkr.ecr.us-east-1.amazonaws.com/pytorch-inference:1.6.0-cpu-py36',\n",
      "                                                                          'ModelDataUrl': {'Get': 'Steps.Train.ModelArtifacts.S3ModelArtifacts'}}},\n",
      "                                       'Name': 'CreateModel',\n",
      "                                       'Type': 'Model'}]},\n",
      "            'Name': 'AccuracyCondition',\n",
      "            'Type': 'Condition'}],\n",
      " 'Version': '2020-12-01'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pprint import pprint\n",
    "\n",
    "definition = json.loads(pipeline.definition())\n",
    "\n",
    "pprint(definition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VvMf5N3tBHIu"
   },
   "source": [
    "Now we create a pipeline using the `create` method and then print the Amazon Resource Name (ARN) of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "srmBq-_oBHIv",
    "outputId": "8c60e97f-d45b-4ea1-be6e-ee42b7c36822"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:sagemaker:us-east-1:912822595625:pipeline/bert-pipeline-1676208665\n"
     ]
    }
   ],
   "source": [
    "response = pipeline.create(role_arn=role)\n",
    "\n",
    "pipeline_arn = response[\"PipelineArn\"]\n",
    "print(pipeline_arn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z8m29XjPBHIv"
   },
   "source": [
    "### Start Pipeline\n",
    "Let's submit our pipeline definition to the Amazon SageMaker Pipeline service. The role passed in will be used by the service to create all the jobs defined in the steps. We will start the pipeline using the parameters passed into the `start()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6LfhkqL3BHIv",
    "outputId": "fed7b243-649f-4834-c4ee-42c21e3ce00d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:sagemaker:us-east-1:912822595625:pipeline/bert-pipeline-1676208665/execution/h4inlmq7fqwk\n"
     ]
    }
   ],
   "source": [
    "execution = pipeline.start(\n",
    "    parameters=dict(\n",
    "        InputData=raw_input_data_s3_uri,\n",
    "        ProcessingInstanceCount=1,\n",
    "        ProcessingInstanceType='ml.c5.2xlarge',\n",
    "        MaxSeqLength=128,\n",
    "        BalanceDataset='True',\n",
    "        TrainSplitPercentage=0.9,\n",
    "        ValidationSplitPercentage=0.05,\n",
    "        TestSplitPercentage=0.05,\n",
    "        FeatureStoreOfflinePrefix='reviews-feature-store-'+str(timestamp),\n",
    "        FeatureGroupName='reviews-feature-group-'+str(timestamp),\n",
    "        Epochs=3,\n",
    "        LearningRate=0.000012,\n",
    "        TrainBatchSize=64,\n",
    "        TrainStepsPerEpoch=50,\n",
    "        ValidationBatchSize=64,\n",
    "        ValidationStepsPerEpoch=64,\n",
    "        FreezeBertLayer='False',\n",
    "        Seed=42,         \n",
    "        TrainInstanceCount=1,\n",
    "        TrainInstanceType='ml.c5.9xlarge',\n",
    "        TrainVolumeSize=256,\n",
    "        InputMode='File',\n",
    "        RunValidation='True',\n",
    "        MinAccuracyValue=0.01,\n",
    "        ModelApprovalStatus='PendingManualApproval', \n",
    "        DeployInstanceType='ml.m5.large',\n",
    "        DeployInstanceCount=1 \n",
    "    )\n",
    ")\n",
    "\n",
    "print(execution.arn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q8OY9HSlBHIw"
   },
   "source": [
    "### Wait for pipeline execution\n",
    "\n",
    "Now we can describe execution instance and list the steps in the execution to find out more about the execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BKW5JXMGBHIw",
    "outputId": "efe604fa-ddc1-4e23-ad4d-203a0aaadfe2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'CreatedBy': {'DomainId': 'd-h9yolcap5nrc',\n",
      "               'UserProfileArn': 'arn:aws:sagemaker:us-east-1:912822595625:user-profile/d-h9yolcap5nrc/sagemaker-user-profile-us-east-1',\n",
      "               'UserProfileName': 'sagemaker-user-profile-us-east-1'},\n",
      " 'CreationTime': datetime.datetime(2023, 2, 12, 13, 37, 41, 761000, tzinfo=tzlocal()),\n",
      " 'LastModifiedBy': {'DomainId': 'd-h9yolcap5nrc',\n",
      "                    'UserProfileArn': 'arn:aws:sagemaker:us-east-1:912822595625:user-profile/d-h9yolcap5nrc/sagemaker-user-profile-us-east-1',\n",
      "                    'UserProfileName': 'sagemaker-user-profile-us-east-1'},\n",
      " 'LastModifiedTime': datetime.datetime(2023, 2, 12, 13, 37, 41, 761000, tzinfo=tzlocal()),\n",
      " 'PipelineArn': 'arn:aws:sagemaker:us-east-1:912822595625:pipeline/bert-pipeline-1676208665',\n",
      " 'PipelineExecutionArn': 'arn:aws:sagemaker:us-east-1:912822595625:pipeline/bert-pipeline-1676208665/execution/h4inlmq7fqwk',\n",
      " 'PipelineExecutionDisplayName': 'execution-1676209061894',\n",
      " 'PipelineExecutionStatus': 'Executing',\n",
      " 'ResponseMetadata': {'HTTPHeaders': {'content-length': '815',\n",
      "                                      'content-type': 'application/x-amz-json-1.1',\n",
      "                                      'date': 'Sun, 12 Feb 2023 13:37:46 GMT',\n",
      "                                      'x-amzn-requestid': '5d8ec01a-6a95-4737-802b-82302f7ab368'},\n",
      "                      'HTTPStatusCode': 200,\n",
      "                      'RequestId': '5d8ec01a-6a95-4737-802b-82302f7ab368',\n",
      "                      'RetryAttempts': 0}}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "execution_run = execution.describe()\n",
    "pprint(execution_run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7wy0TvxXBHIw"
   },
   "source": [
    "Print the execution display name and its ARN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nr5XDggsBHIw",
    "outputId": "4da59038-01c5-44fb-8b66-b757f6202406"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "execution-1676209061894\n"
     ]
    }
   ],
   "source": [
    "execution_run_name = execution_run['PipelineExecutionDisplayName']\n",
    "print(execution_run_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KC8m3mpIBHIx",
    "outputId": "20e767dc-cde1-493c-b769-fd94a2e32c90"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:sagemaker:us-east-1:912822595625:pipeline/bert-pipeline-1676208665/execution/h4inlmq7fqwk\n"
     ]
    }
   ],
   "source": [
    "pipeline_execution_arn = execution_run['PipelineExecutionArn']\n",
    "print(pipeline_execution_arn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8gy3inJ6BHIx"
   },
   "source": [
    "### Describe completed pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NaQR1pPMBHIx"
   },
   "source": [
    "We will wait for the first step to start running and print the information about it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PUyjssNdBHIx",
    "outputId": "c02195a7-bafb-4e5d-a1e6-91b1d30d3723"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'StepName': 'Processing',\n",
       "  'StartTime': datetime.datetime(2023, 2, 12, 13, 37, 42, 570000, tzinfo=tzlocal()),\n",
       "  'StepStatus': 'Executing',\n",
       "  'AttemptCount': 0,\n",
       "  'Metadata': {'ProcessingJob': {'Arn': 'arn:aws:sagemaker:us-east-1:912822595625:processing-job/pipelines-h4inlmq7fqwk-processing-mwnbfz07z3'}}}]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "time.sleep(30)\n",
    "\n",
    "execution.list_steps()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "inTpM-Z_BHIy"
   },
   "source": [
    "### Wait for the pipeline to complete\n",
    "\n",
    "To get the information about the pipeline execution we can use a low-level service client of the boto3 session. It is also useful for other operations that you will see below.\n",
    "\n",
    "In the code below we will be observing the pipeline execution summary and waiting for the execution status to change from `Executing` to `Succeeded`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KpVVsNkoBHIy",
    "outputId": "380b6722-6362-4805-8654-9e398e28f874"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing\n",
      "Please wait...\n",
      "Please wait...\n",
      "Please wait...\n",
      "Please wait...\n",
      "Please wait...\n",
      "Please wait...\n",
      "Please wait...\n",
      "Please wait...\n",
      "Please wait...\n",
      "Please wait...\n",
      "Please wait...\n",
      "Please wait...\n",
      "Please wait...\n",
      "Please wait...\n",
      "Please wait...\n",
      "Please wait...\n",
      "Please wait...\n",
      "Please wait...\n",
      "Please wait...\n",
      "[{'PipelineExecutionArn': 'arn:aws:sagemaker:us-east-1:912822595625:pipeline/bert-pipeline-1676208665/execution/h4inlmq7fqwk',\n",
      "  'PipelineExecutionDisplayName': 'execution-1676209061894',\n",
      "  'PipelineExecutionStatus': 'Succeeded',\n",
      "  'StartTime': datetime.datetime(2023, 2, 12, 13, 37, 41, 761000, tzinfo=tzlocal())}]\n",
      "CPU times: user 14.7 s, sys: 641 ms, total: 15.4 s\n",
      "Wall time: 32min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import time\n",
    "from pprint import pprint\n",
    "\n",
    "sm = boto3.Session().client(service_name='sagemaker', region_name=region)\n",
    "\n",
    "executions_response = sm.list_pipeline_executions(PipelineName=pipeline_name)['PipelineExecutionSummaries']\n",
    "pipeline_execution_status = executions_response[0]['PipelineExecutionStatus']\n",
    "print(pipeline_execution_status)\n",
    "\n",
    "while pipeline_execution_status=='Executing':\n",
    "    try:\n",
    "        executions_response = sm.list_pipeline_executions(PipelineName=pipeline_name)['PipelineExecutionSummaries']\n",
    "        pipeline_execution_status = executions_response[0]['PipelineExecutionStatus']\n",
    "    except Exception as e:\n",
    "        print('Please wait...')\n",
    "        time.sleep(30)    \n",
    "    \n",
    "pprint(executions_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VwtX_xDuBHIz"
   },
   "source": [
    "We can list the execution steps to check out the status and artifacts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8Rk4DTDIBHIz",
    "outputId": "35bed80d-fa02-4dbf-8dd7-1c049f4f2b14"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succeeded\n"
     ]
    }
   ],
   "source": [
    "pipeline_execution_status = executions_response[0]['PipelineExecutionStatus']\n",
    "print(pipeline_execution_status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pLpFwoweBHIz",
    "outputId": "ae57cfe1-cc01-4d7f-9509-0a123e8f5fc5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:sagemaker:us-east-1:912822595625:pipeline/bert-pipeline-1676208665/execution/h4inlmq7fqwk\n"
     ]
    }
   ],
   "source": [
    "pipeline_execution_arn = executions_response[0]['PipelineExecutionArn']\n",
    "print(pipeline_execution_arn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uPKwtjmPBHI0"
   },
   "source": [
    "## Evaluate the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3ixhm99xBHI0"
   },
   "source": [
    "### Describe evaluation metrics\n",
    "\n",
    "Now we examine the resulting model evaluation after the pipeline completes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zeWAijEoBHI0",
    "outputId": "71c01fc4-2b17-4b05-830c-b54ed89c1e7a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transform output s3://sagemaker-us-east-1-912822595625/sagemaker-scikit-learn-2023-02-12-13-32-20-378/output/sentiment-train\n"
     ]
    }
   ],
   "source": [
    "processing_job_name = None\n",
    "\n",
    "# pull the processing step name\n",
    "for execution_step in reversed(execution.list_steps()):\n",
    "    if execution_step['StepName'] == 'Processing':\n",
    "        processing_job_name=execution_step['Metadata']['ProcessingJob']['Arn'].split('/')[-1]\n",
    "\n",
    "# get the description of the processing job\n",
    "describe_transform_processing_job_response = sm.describe_processing_job(ProcessingJobName=processing_job_name)\n",
    "\n",
    "# get the output S3 path\n",
    "transform_output_s3_uri = describe_transform_processing_job_response['ProcessingOutputConfig']['Outputs'][0]['S3Output']['S3Uri']\n",
    "print('Transform output {}'.format(transform_output_s3_uri))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l8lq35mzBHI0",
    "outputId": "9e51d7c5-bbd5-4397-e79b-4a8112a8674d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-02-12 13:48:45    4882265 sagemaker-scikit-learn-2023-02-12-13-32-20-378/output/sentiment-train/part-algo-1-womens_clothing_ecommerce_reviews.tsv\n"
     ]
    }
   ],
   "source": [
    "# list the files in the resulting output S3 path\n",
    "!aws s3 ls --recursive $transform_output_s3_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WNv0tDr4BHI0"
   },
   "source": [
    "Let's pull the name of the model-evaluation step and then get the S3 path of the evaluation metrics, which will contain the evaluation report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ak2MO_6RBHI1",
    "outputId": "89be571d-1417-4fff-ed89-7429df045686"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation output s3://sagemaker-us-east-1-912822595625/sagemaker-scikit-learn-2023-02-12-13-35-32-414/output/metrics\n"
     ]
    }
   ],
   "source": [
    "processing_job_name = None\n",
    "\n",
    "for execution_step in reversed(execution.list_steps()):\n",
    "    if execution_step['StepName'] == 'EvaluateModel': \n",
    "        processing_job_name=execution_step['Metadata']['ProcessingJob']['Arn'].split('/')[-1]\n",
    "\n",
    "describe_evaluation_processing_job_response = sm.describe_processing_job(ProcessingJobName=processing_job_name)\n",
    "\n",
    "evaluation_metrics_s3_uri = describe_evaluation_processing_job_response['ProcessingOutputConfig']['Outputs'][0]['S3Output']['S3Uri']\n",
    "print('Evaluation output {}'.format(evaluation_metrics_s3_uri))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q_xFe8rIBHI1"
   },
   "source": [
    "### Review the evaluation report\n",
    "\n",
    "Download the evaluation report and print the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hmeIQa0hBHI1",
    "outputId": "7b1c79b8-2c63-4392-d604-57888208403b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'metrics': {'accuracy': {'value': 0.7313915857605178}}}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "evaluation_json = sagemaker.s3.S3Downloader.read_file(\"{}/evaluation.json\".format(\n",
    "    evaluation_metrics_s3_uri\n",
    "))\n",
    "\n",
    "pprint(json.loads(evaluation_json))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J0EvhR2FBHI1"
   },
   "source": [
    "### List pipeline artifacts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "acn14f7YBHI2"
   },
   "source": [
    "Now let's find and print the ARN and job name of the training job. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W7VUeKbkBHI2",
    "outputId": "7ab73b20-8c68-4d38-b603-d2bea3a64094"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'AttemptCount': 0,\n",
      " 'EndTime': datetime.datetime(2023, 2, 12, 14, 4, 49, 838000, tzinfo=tzlocal()),\n",
      " 'Metadata': {'TrainingJob': {'Arn': 'arn:aws:sagemaker:us-east-1:912822595625:training-job/pipelines-h4inlmq7fqwk-Train-nYXyWGwBe5'}},\n",
      " 'StartTime': datetime.datetime(2023, 2, 12, 13, 48, 54, 641000, tzinfo=tzlocal()),\n",
      " 'StepName': 'Train',\n",
      " 'StepStatus': 'Succeeded'}\n",
      "Training job ARN: arn:aws:sagemaker:us-east-1:912822595625:training-job/pipelines-h4inlmq7fqwk-Train-nYXyWGwBe5\n",
      "Training job Name: pipelines-h4inlmq7fqwk-Train-nYXyWGwBe5\n"
     ]
    }
   ],
   "source": [
    "training_job_arn=None\n",
    "\n",
    "for execution_step in execution.list_steps():\n",
    "    if execution_step['StepName'] == 'Train':\n",
    "        training_job_arn = execution_step['Metadata']['TrainingJob']['Arn']        \n",
    "        pprint(execution_step)\n",
    "        break\n",
    "print('Training job ARN: {}'.format(training_job_arn))\n",
    "        \n",
    "training_job_name = training_job_arn.split('/')[-1]\n",
    "print('Training job Name: {}'.format(training_job_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RHuOvxk9BHI2"
   },
   "source": [
    "Using similar approach we can find and print the pipeline artifacts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RrlIcq7gBHI2"
   },
   "outputs": [],
   "source": [
    "processing_job_name=None\n",
    "training_job_name=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0KAU6dWzBHI2",
    "outputId": "0cf68005-c1d1-4277-9e23-ea043e62f970"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'AttemptCount': 0,\n",
      " 'EndTime': datetime.datetime(2023, 2, 12, 13, 48, 53, 920000, tzinfo=tzlocal()),\n",
      " 'Metadata': {'ProcessingJob': {'Arn': 'arn:aws:sagemaker:us-east-1:912822595625:processing-job/pipelines-h4inlmq7fqwk-processing-mwnbfz07z3'}},\n",
      " 'StartTime': datetime.datetime(2023, 2, 12, 13, 37, 42, 570000, tzinfo=tzlocal()),\n",
      " 'StepName': 'Processing',\n",
      " 'StepStatus': 'Succeeded'}\n",
      "Processing job name: pipelines-h4inlmq7fqwk-processing-mwnbfz07z3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name/Source</th>\n",
       "      <th>Direction</th>\n",
       "      <th>Type</th>\n",
       "      <th>Association Type</th>\n",
       "      <th>Lineage Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>s3://...-13-37-36-257/input/code/prepare_data.py</td>\n",
       "      <td>Input</td>\n",
       "      <td>DataSet</td>\n",
       "      <td>ContributedTo</td>\n",
       "      <td>artifact</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>s3://dlai-practical-data-science/data/raw/</td>\n",
       "      <td>Input</td>\n",
       "      <td>DataSet</td>\n",
       "      <td>ContributedTo</td>\n",
       "      <td>artifact</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>68331...om/sagemaker-scikit-learn:0.23-1-cpu-py3</td>\n",
       "      <td>Input</td>\n",
       "      <td>Image</td>\n",
       "      <td>ContributedTo</td>\n",
       "      <td>artifact</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>s3://...02-12-13-32-20-378/output/sentiment-test</td>\n",
       "      <td>Output</td>\n",
       "      <td>DataSet</td>\n",
       "      <td>Produced</td>\n",
       "      <td>artifact</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>s3://...13-32-20-378/output/sentiment-validation</td>\n",
       "      <td>Output</td>\n",
       "      <td>DataSet</td>\n",
       "      <td>Produced</td>\n",
       "      <td>artifact</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>s3://...2-12-13-32-20-378/output/sentiment-train</td>\n",
       "      <td>Output</td>\n",
       "      <td>DataSet</td>\n",
       "      <td>Produced</td>\n",
       "      <td>artifact</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Name/Source Direction     Type  \\\n",
       "0  s3://...-13-37-36-257/input/code/prepare_data.py     Input  DataSet   \n",
       "1        s3://dlai-practical-data-science/data/raw/     Input  DataSet   \n",
       "2  68331...om/sagemaker-scikit-learn:0.23-1-cpu-py3     Input    Image   \n",
       "3  s3://...02-12-13-32-20-378/output/sentiment-test    Output  DataSet   \n",
       "4  s3://...13-32-20-378/output/sentiment-validation    Output  DataSet   \n",
       "5  s3://...2-12-13-32-20-378/output/sentiment-train    Output  DataSet   \n",
       "\n",
       "  Association Type Lineage Type  \n",
       "0    ContributedTo     artifact  \n",
       "1    ContributedTo     artifact  \n",
       "2    ContributedTo     artifact  \n",
       "3         Produced     artifact  \n",
       "4         Produced     artifact  \n",
       "5         Produced     artifact  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'AttemptCount': 0,\n",
      " 'EndTime': datetime.datetime(2023, 2, 12, 14, 4, 49, 838000, tzinfo=tzlocal()),\n",
      " 'Metadata': {'TrainingJob': {'Arn': 'arn:aws:sagemaker:us-east-1:912822595625:training-job/pipelines-h4inlmq7fqwk-Train-nYXyWGwBe5'}},\n",
      " 'StartTime': datetime.datetime(2023, 2, 12, 13, 48, 54, 641000, tzinfo=tzlocal()),\n",
      " 'StepName': 'Train',\n",
      " 'StepStatus': 'Succeeded'}\n",
      "Training job name: pipelines-h4inlmq7fqwk-Train-nYXyWGwBe5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name/Source</th>\n",
       "      <th>Direction</th>\n",
       "      <th>Type</th>\n",
       "      <th>Association Type</th>\n",
       "      <th>Lineage Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>s3://...13-32-20-378/output/sentiment-validation</td>\n",
       "      <td>Input</td>\n",
       "      <td>DataSet</td>\n",
       "      <td>ContributedTo</td>\n",
       "      <td>artifact</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>s3://...2-12-13-32-20-378/output/sentiment-train</td>\n",
       "      <td>Input</td>\n",
       "      <td>DataSet</td>\n",
       "      <td>ContributedTo</td>\n",
       "      <td>artifact</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>76310...onaws.com/pytorch-training:1.6.0-cpu-py3</td>\n",
       "      <td>Input</td>\n",
       "      <td>Image</td>\n",
       "      <td>ContributedTo</td>\n",
       "      <td>artifact</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>s3://...qwk-Train-nYXyWGwBe5/output/model.tar.gz</td>\n",
       "      <td>Output</td>\n",
       "      <td>Model</td>\n",
       "      <td>Produced</td>\n",
       "      <td>artifact</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Name/Source Direction     Type  \\\n",
       "0  s3://...13-32-20-378/output/sentiment-validation     Input  DataSet   \n",
       "1  s3://...2-12-13-32-20-378/output/sentiment-train     Input  DataSet   \n",
       "2  76310...onaws.com/pytorch-training:1.6.0-cpu-py3     Input    Image   \n",
       "3  s3://...qwk-Train-nYXyWGwBe5/output/model.tar.gz    Output    Model   \n",
       "\n",
       "  Association Type Lineage Type  \n",
       "0    ContributedTo     artifact  \n",
       "1    ContributedTo     artifact  \n",
       "2    ContributedTo     artifact  \n",
       "3         Produced     artifact  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'AttemptCount': 0,\n",
      " 'EndTime': datetime.datetime(2023, 2, 12, 14, 10, 48, 729000, tzinfo=tzlocal()),\n",
      " 'Metadata': {'ProcessingJob': {'Arn': 'arn:aws:sagemaker:us-east-1:912822595625:processing-job/pipelines-h4inlmq7fqwk-evaluatemodel-uqvunnu2ks'}},\n",
      " 'StartTime': datetime.datetime(2023, 2, 12, 14, 4, 50, 615000, tzinfo=tzlocal()),\n",
      " 'StepName': 'EvaluateModel',\n",
      " 'StepStatus': 'Succeeded'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name/Source</th>\n",
       "      <th>Direction</th>\n",
       "      <th>Type</th>\n",
       "      <th>Association Type</th>\n",
       "      <th>Lineage Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>s3://...640/input/code/evaluate_model_metrics.py</td>\n",
       "      <td>Input</td>\n",
       "      <td>DataSet</td>\n",
       "      <td>ContributedTo</td>\n",
       "      <td>artifact</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>s3://...02-12-13-32-20-378/output/sentiment-test</td>\n",
       "      <td>Input</td>\n",
       "      <td>DataSet</td>\n",
       "      <td>ContributedTo</td>\n",
       "      <td>artifact</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>s3://...qwk-Train-nYXyWGwBe5/output/model.tar.gz</td>\n",
       "      <td>Input</td>\n",
       "      <td>Model</td>\n",
       "      <td>ContributedTo</td>\n",
       "      <td>artifact</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>68331...om/sagemaker-scikit-learn:0.23-1-cpu-py3</td>\n",
       "      <td>Input</td>\n",
       "      <td>Image</td>\n",
       "      <td>ContributedTo</td>\n",
       "      <td>artifact</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>s3://...n-2023-02-12-13-35-32-414/output/metrics</td>\n",
       "      <td>Output</td>\n",
       "      <td>DataSet</td>\n",
       "      <td>Produced</td>\n",
       "      <td>artifact</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Name/Source Direction     Type  \\\n",
       "0  s3://...640/input/code/evaluate_model_metrics.py     Input  DataSet   \n",
       "1  s3://...02-12-13-32-20-378/output/sentiment-test     Input  DataSet   \n",
       "2  s3://...qwk-Train-nYXyWGwBe5/output/model.tar.gz     Input    Model   \n",
       "3  68331...om/sagemaker-scikit-learn:0.23-1-cpu-py3     Input    Image   \n",
       "4  s3://...n-2023-02-12-13-35-32-414/output/metrics    Output  DataSet   \n",
       "\n",
       "  Association Type Lineage Type  \n",
       "0    ContributedTo     artifact  \n",
       "1    ContributedTo     artifact  \n",
       "2    ContributedTo     artifact  \n",
       "3    ContributedTo     artifact  \n",
       "4         Produced     artifact  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'AttemptCount': 0,\n",
      " 'EndTime': datetime.datetime(2023, 2, 12, 14, 10, 50, 320000, tzinfo=tzlocal()),\n",
      " 'Metadata': {'Condition': {'Outcome': 'True'}},\n",
      " 'StartTime': datetime.datetime(2023, 2, 12, 14, 10, 49, 585000, tzinfo=tzlocal()),\n",
      " 'StepName': 'AccuracyCondition',\n",
      " 'StepStatus': 'Succeeded'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'AttemptCount': 0,\n",
      " 'EndTime': datetime.datetime(2023, 2, 12, 14, 10, 52, 545000, tzinfo=tzlocal()),\n",
      " 'Metadata': {'Model': {'Arn': 'arn:aws:sagemaker:us-east-1:912822595625:model/pipelines-h4inlmq7fqwk-createmodel-tu0lobcfq6'}},\n",
      " 'StartTime': datetime.datetime(2023, 2, 12, 14, 10, 51, 78000, tzinfo=tzlocal()),\n",
      " 'StepName': 'CreateModel',\n",
      " 'StepStatus': 'Succeeded'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'AttemptCount': 0,\n",
      " 'EndTime': datetime.datetime(2023, 2, 12, 14, 10, 52, 324000, tzinfo=tzlocal()),\n",
      " 'Metadata': {'RegisterModel': {'Arn': 'arn:aws:sagemaker:us-east-1:912822595625:model-package/bert-reviews-1676208665/1'}},\n",
      " 'StartTime': datetime.datetime(2023, 2, 12, 14, 10, 51, 78000, tzinfo=tzlocal()),\n",
      " 'StepName': 'RegisterModel',\n",
      " 'StepStatus': 'Succeeded'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name/Source</th>\n",
       "      <th>Direction</th>\n",
       "      <th>Type</th>\n",
       "      <th>Association Type</th>\n",
       "      <th>Lineage Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>s3://...qwk-Train-nYXyWGwBe5/output/model.tar.gz</td>\n",
       "      <td>Input</td>\n",
       "      <td>Model</td>\n",
       "      <td>ContributedTo</td>\n",
       "      <td>artifact</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>76310...aws.com/pytorch-inference:1.6.0-cpu-py36</td>\n",
       "      <td>Input</td>\n",
       "      <td>Image</td>\n",
       "      <td>ContributedTo</td>\n",
       "      <td>artifact</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bert-reviews-1676208665-1-PendingManualApprova...</td>\n",
       "      <td>Input</td>\n",
       "      <td>Approval</td>\n",
       "      <td>ContributedTo</td>\n",
       "      <td>action</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BERT-Reviews-1676208665-1676211052-aws-model-p...</td>\n",
       "      <td>Output</td>\n",
       "      <td>ModelGroup</td>\n",
       "      <td>AssociatedWith</td>\n",
       "      <td>context</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Name/Source Direction        Type  \\\n",
       "0   s3://...qwk-Train-nYXyWGwBe5/output/model.tar.gz     Input       Model   \n",
       "1   76310...aws.com/pytorch-inference:1.6.0-cpu-py36     Input       Image   \n",
       "2  bert-reviews-1676208665-1-PendingManualApprova...     Input    Approval   \n",
       "3  BERT-Reviews-1676208665-1676211052-aws-model-p...    Output  ModelGroup   \n",
       "\n",
       "  Association Type Lineage Type  \n",
       "0    ContributedTo     artifact  \n",
       "1    ContributedTo     artifact  \n",
       "2    ContributedTo       action  \n",
       "3   AssociatedWith      context  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "from sagemaker.lineage.visualizer import LineageTableVisualizer\n",
    "\n",
    "viz = LineageTableVisualizer(sagemaker.session.Session())\n",
    "\n",
    "for execution_step in reversed(execution.list_steps()):\n",
    "    pprint(execution_step)\n",
    "    if execution_step['StepName'] == 'Processing':\n",
    "        processing_job_name=execution_step['Metadata']['ProcessingJob']['Arn'].split('/')[-1]\n",
    "        print('Processing job name: {}'.format(processing_job_name))\n",
    "        display(viz.show(processing_job_name=processing_job_name))\n",
    "    elif execution_step['StepName'] == 'Train':\n",
    "        training_job_name=execution_step['Metadata']['TrainingJob']['Arn'].split('/')[-1]\n",
    "        print('Training job name: {}'.format(training_job_name))\n",
    "        display(viz.show(training_job_name=training_job_name))\n",
    "    else:\n",
    "        display(viz.show(pipeline_execution_step=execution_step))\n",
    "        time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-eTg30QFBHI3"
   },
   "source": [
    "## Deploy and test the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OwxTMNiIBHI3"
   },
   "source": [
    "### Approve trained model\n",
    "\n",
    "The pipeline created a model package version within the specified model package group and an approval status of `PendingManualApproval`.  This requires a separate step to manually approve the model before deploying to production.\n",
    "\n",
    "We can approve the model using the SageMaker Studio UI or programmatically as shown below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mhXqTGkUBHI3"
   },
   "source": [
    "Get the model package ARN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OsJZc_1MBHI3",
    "outputId": "b5a1f02f-625f-43b6-9c17-18972e1ca6b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:sagemaker:us-east-1:912822595625:model-package/bert-reviews-1676208665/1\n"
     ]
    }
   ],
   "source": [
    "for execution_step in execution.list_steps():\n",
    "    if execution_step['StepName'] == 'RegisterModel':\n",
    "        model_package_arn = execution_step['Metadata']['RegisterModel']['Arn']\n",
    "        break\n",
    "print(model_package_arn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SuTv1zmsBHI4"
   },
   "source": [
    "Update the model package with the `Approved` status to prepare for deployment.\n",
    "\n",
    "The model must be `Approved` before it can be deployed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IDt2bD1YBHI4",
    "outputId": "49ae389d-3b0b-4529-b77c-09f035f94b9c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ModelPackageArn': 'arn:aws:sagemaker:us-east-1:912822595625:model-package/bert-reviews-1676208665/1',\n",
      " 'ResponseMetadata': {'HTTPHeaders': {'content-length': '102',\n",
      "                                      'content-type': 'application/x-amz-json-1.1',\n",
      "                                      'date': 'Sun, 12 Feb 2023 14:15:24 GMT',\n",
      "                                      'x-amzn-requestid': '95e70fcf-b3f0-4925-be40-73450c40a5ec'},\n",
      "                      'HTTPStatusCode': 200,\n",
      "                      'RequestId': '95e70fcf-b3f0-4925-be40-73450c40a5ec',\n",
      "                      'RetryAttempts': 0}}\n"
     ]
    }
   ],
   "source": [
    "model_package_update_response = sm.update_model_package(\n",
    "    ModelPackageArn=model_package_arn,\n",
    "    ModelApprovalStatus=\"Approved\",\n",
    ")\n",
    "\n",
    "pprint(model_package_update_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DAs_SqumBHI4"
   },
   "source": [
    "### Deploy model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wmDohf_9BHI4"
   },
   "source": [
    "Get the model ARN and the model name from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wihJIt0TBHI5",
    "outputId": "4a79b3a9-63ca-4182-dfed-063d0827cb1b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RegisterModel\n",
      "CreateModel\n",
      "arn:aws:sagemaker:us-east-1:912822595625:model/pipelines-h4inlmq7fqwk-createmodel-tu0lobcfq6\n",
      "pipelines-h4inlmq7fqwk-createmodel-tu0lobcfq6\n"
     ]
    }
   ],
   "source": [
    "for execution_step in execution.list_steps():\n",
    "    print(execution_step['StepName'])\n",
    "    if execution_step['StepName'] == 'CreateModel':\n",
    "        model_arn = execution_step['Metadata']['Model']['Arn']\n",
    "        break\n",
    "print(model_arn)\n",
    "\n",
    "model_name = model_arn.split('/')[-1]\n",
    "print(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sJ1_bTGkBHI5"
   },
   "source": [
    "### Create endpoint from registry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V30YzA4CBHI5"
   },
   "source": [
    "Configure the endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r49pBBRBBHI5",
    "outputId": "8d65d1cc-8ed2-4682-8eae-52ad417070e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert-model-epc-1676208665\n"
     ]
    }
   ],
   "source": [
    "endpoint_config_name = 'bert-model-epc-{}'.format(timestamp)\n",
    "print(endpoint_config_name)\n",
    "\n",
    "create_endpoint_config_response = sm.create_endpoint_config(\n",
    "    EndpointConfigName = endpoint_config_name,\n",
    "    ProductionVariants=[{\n",
    "        'InstanceType':'ml.m5.xlarge',\n",
    "        'InitialVariantWeight':1,\n",
    "        'InitialInstanceCount':1,\n",
    "        'ModelName': model_name,\n",
    "        'VariantName':'AllTraffic'}])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Z9lwvrZBHI6"
   },
   "source": [
    "Create the endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EjdYbyYDBHI6",
    "outputId": "8e6c05ae-6a88-4e71-fc09-307995983c70"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EndpointName=bert-model-ep-1676208665\n",
      "arn:aws:sagemaker:us-east-1:912822595625:endpoint/bert-model-ep-1676208665\n"
     ]
    }
   ],
   "source": [
    "pipeline_endpoint_name = 'bert-model-ep-{}'.format(timestamp)\n",
    "print(\"EndpointName={}\".format(pipeline_endpoint_name))\n",
    "\n",
    "create_endpoint_response = sm.create_endpoint(\n",
    "    EndpointName=pipeline_endpoint_name,\n",
    "    EndpointConfigName=endpoint_config_name)\n",
    "print(create_endpoint_response['EndpointArn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "39Pr28rdBHI6",
    "outputId": "816fc01f-bff8-404c-fe80-f4d416405b6a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for endpoint to be in `InService`...\n",
      "Endpoint deployed.\n",
      "CPU times: user 109 ms, sys: 30.6 ms, total: 140 ms\n",
      "Wall time: 4min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "while True:\n",
    "    try: \n",
    "        waiter = sm.get_waiter('endpoint_in_service')\n",
    "        print('Waiting for endpoint to be in `InService`...')\n",
    "        waiter.wait(EndpointName=pipeline_endpoint_name)\n",
    "        break;\n",
    "    except:\n",
    "        print('Waiting for endpoint...')\n",
    "        endpoint_status = sm.describe_endpoint(EndpointName=pipeline_endpoint_name)['EndpointStatus']\n",
    "        print('Endpoint status: {}'.format(endpoint_status))\n",
    "        if endpoint_status == 'Failed':\n",
    "            break\n",
    "        time.sleep(30)\n",
    "        \n",
    "print('Endpoint deployed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1L5IoaftBHI7"
   },
   "source": [
    "### Test model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SG1NucM-BHI7"
   },
   "source": [
    "Let's predict the `sentiment` with `review_body` samples and review the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5KI1G_VOBHI7",
    "outputId": "09f68f38-d201-44c0-a111-5ff2b2b7da19"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class 1 with probability 0.9203698635101318\n",
      "Predicted class 0 with probability 0.44024962186813354\n",
      "Predicted class -1 with probability 0.778016209602356\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.predictor import Predictor\n",
    "from sagemaker.serializers import JSONLinesSerializer\n",
    "from sagemaker.deserializers import JSONLinesDeserializer\n",
    "\n",
    "inputs = [\n",
    "    {\"features\": [\"I love this product!\"]},\n",
    "    {\"features\": [\"OK, but not great.\"]},\n",
    "    {\"features\": [\"This is not the right product.\"]},\n",
    "]\n",
    "\n",
    "predictor = Predictor(\n",
    "    endpoint_name=pipeline_endpoint_name,\n",
    "    serializer=JSONLinesSerializer(),\n",
    "    deserializer=JSONLinesDeserializer(),\n",
    "    sagemaker_session=sess\n",
    ")\n",
    "\n",
    "predicted_classes = predictor.predict(inputs)\n",
    "\n",
    "for predicted_class in predicted_classes:\n",
    "    print(\"Predicted class {} with probability {}\".format(predicted_class['predicted_label'], predicted_class['probability']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7cgoyu8CBHI7"
   },
   "source": [
    "### SageMaker Studio extensions\n",
    "\n",
    "SageMaker Studio provides a rich set of features to visually inspect SageMaker resources including pipelines, training jobs, and endpoints.\n",
    "\n",
    "![](https://github.com/pranath/blog/raw/master/images/sm_studio_extensions_pipelines.png \"Sagemaker Studio Extensions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C0VZ52bwBHI8"
   },
   "source": [
    "## Acknowledgements\n",
    "\n",
    "I'd like to express my thanks to the great [Deep Learning AI Practical Data Science on AWS Specialisation Course](https://www.deeplearning.ai/courses/practical-data-science-specialization/) which i completed, and acknowledge the use of some images and other materials from the training course in this article."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
