{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "date: '2023-05-06'\n",
    "categories:\n",
    " - natural-language-processing\n",
    " - deep-learning\n",
    " - openai\n",
    " - prompt-engineering\n",
    "title: Expanding & Customising Text using Large Language Models \n",
    "description: We will use ChatGPT to generate customer service emails that are tailored to each customer's review.\n",
    "image: https://github.com/pranath/blog/raw/master/images/chatgpt3.jpg\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Large language models such as [ChatGPT](https://openai.com/blog/chatgpt) can generate text responses based on a given prompt or input. Writing prompts allow users to guide the language model's output by providing a specific context or topic for the response. This feature has many practical applications, such as generating creative writing prompts, assisting in content creation, and even aiding in customer service chatbots. \n",
    "\n",
    "For example, a writing prompt such as \"Write a short story about a time traveler who goes back to the medieval period\" could lead the language model to generate a variety of unique and creative responses. Additionally, prompts can be used to generate more specific and relevant responses for tasks such as language translation or summarization. In these cases, the prompt would provide information about the desired output, such as the language to be translated or the key points to be included in the summary. Overall, prompts provide a way to harness the power of large language models for a wide range of practical applications.\n",
    "\n",
    "However, creating effective prompts for large language models remains a significant challenge, as even prompts that seem similar can produce vastly different outputs. \n",
    "\n",
    "In my previous article, we looked at [how to use Large Language Models for text transformation](2023-05-05-large-language-models-for-text-transformation.html).\n",
    "\n",
    "In this article, we will look at how to use ChatGPT to generate customer service emails that are tailored to each customer's review.\n",
    "\n",
    "\n",
    "## Setup\n",
    "\n",
    "### Load the API key and relevant Python libaries.\n",
    "\n",
    "First we need to load certain python libs and connect the OpenAi api.\n",
    "\n",
    "The OpenAi api library needs to be configured with an account's secret key, which is available on the [website](https://platform.openai.com/account/api-keys). \n",
    "\n",
    "You can either set it as the `OPENAI_API_KEY` environment variable before using the library:\n",
    " ```\n",
    " !export OPENAI_API_KEY='sk-...'\n",
    " ```\n",
    "\n",
    "Or, set `openai.api_key` to its value:\n",
    "\n",
    "```\n",
    "import openai\n",
    "openai.api_key = \"sk-...\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "openai.api_key  = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper function\n",
    "\n",
    "We will use OpenAI's `gpt-3.5-turbo` model and the [chat completions endpoint](https://platform.openai.com/docs/guides/chat). \n",
    "\n",
    "This helper function will make it easier to use prompts and look at the generated outputs:\n",
    "\n",
    "We'll simply define this helper function to make it easier to use prompts and examine outputs that are generated. *GetCompletion* is a function that just accepts a prompt and returns the completion for that prompt. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(prompt, model=\"gpt-3.5-turbo\",temperature=0): # Andrew mentioned that the prompt/ completion paradigm is preferable for this class\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature, # this is the degree of randomness of the model's output\n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expanding Text\n",
    "\n",
    "Expanding is taking a little text, such as a list of instructions or a subject matter, and having the large language model produce a larger text, such as an email or an essay on the subject. There are many fantastic applications for this, such as when you collaborate on ideas using a sizable language model. \n",
    "But we must also accept that there are potentially problematic use cases for this, such as if someone were to use it to produce a lot of spam or an essay. \n",
    "Therefore, we should use these large language model capabilities responsibly and to benefit people.\n",
    "\n",
    "I will give an example of how a language model can be used to create a customised email depending on some data. The email will come from an AI bot, which is crucial for transparency, as we have indicated.\n",
    "We're also going to employ temperature, another one of the model's input parameters, which lets you alter the level of exploration and variation in the model answers.\n",
    "\n",
    "## Customize the automated reply to a customer email\n",
    "\n",
    "We will now create a customised email for a customer based on a review and the sentiment of the review using the language model. In a [previous article we extracted the sentiment using prompts](2023-05-04-inferring-with-text-prompts-for-large-language-models.html) so we know it can do this already.\n",
    "\n",
    "So based on the sentiment, we'll modify the response. As a customer care AI assistant, your duty is to write an email thanking the client for their review. The customer's email address is delimited by three backticks, therefore follow these instructions to send the email. It will respond to the review, whether it's positive or indifferent. If the response is unfavourable, apologise and advise them to contact customer service.\n",
    "\n",
    "So, our instruction will read: ensure that you include precise information from the evaluation, write in a clear and professional manner, and sign the email as an AI customer agent. It's crucial to maintain this level of transparency and inform the user that the content they are viewing was produced by AI when employing a language model to generate text that will be displayed to them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# given the sentiment from the lesson on \"inferring\",\n",
    "# and the original customer message, customize the email\n",
    "sentiment = \"negative\"\n",
    "\n",
    "# review for a blender\n",
    "review = f\"\"\"\n",
    "So, they still had the 17 piece system on seasonal \\\n",
    "sale for around $49 in the month of November, about \\\n",
    "half off, but for some reason (call it price gouging) \\\n",
    "around the second week of December the prices all went \\\n",
    "up to about anywhere from between $70-$89 for the same \\\n",
    "system. And the 11 piece system went up around $10 or \\\n",
    "so in price also from the earlier sale price of $29. \\\n",
    "So it looks okay, but if you look at the base, the part \\\n",
    "where the blade locks into place doesnâ€™t look as good \\\n",
    "as in previous editions from a few years ago, but I \\\n",
    "plan to be very gentle with it (example, I crush \\\n",
    "very hard items like beans, ice, rice, etc. in the \\ \n",
    "blender first then pulverize them in the serving size \\\n",
    "I want in the blender then switch to the whipping \\\n",
    "blade for a finer flour, and use the cross cutting blade \\\n",
    "first when making smoothies, then use the flat blade \\\n",
    "if I need them finer/less pulpy). Special tip when making \\\n",
    "smoothies, finely cut and freeze the fruits and \\\n",
    "vegetables (if using spinach-lightly stew soften the \\ \n",
    "spinach then freeze until ready for use-and if making \\\n",
    "sorbet, use a small to medium sized food processor) \\ \n",
    "that you plan to use that way you can avoid adding so \\\n",
    "much ice if at all-when making your smoothie. \\\n",
    "After about a year, the motor was making a funny noise. \\\n",
    "I called customer service but the warranty expired \\\n",
    "already, so I had to buy another one. FYI: The overall \\\n",
    "quality has gone done in these types of products, so \\\n",
    "they are kind of counting on brand recognition and \\\n",
    "consumer loyalty to maintain sales. Got it in about \\\n",
    "two days.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "You are a customer service AI assistant.\n",
    "Your task is to send an email reply to a valued customer.\n",
    "Given the customer email delimited by ```, \\\n",
    "Generate a reply to thank the customer for their review.\n",
    "If the sentiment is positive or neutral, thank them for \\\n",
    "their review.\n",
    "If the sentiment is negative, apologize and suggest that \\\n",
    "they can reach out to customer service. \n",
    "Make sure to use specific details from the review.\n",
    "Write in a concise and professional tone.\n",
    "Sign the email as `AI customer agent`.\n",
    "Customer review: ```{review}```\n",
    "Review sentiment: {sentiment}\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {.callout-tip}\n",
    "### Output\n",
    "Dear valued customer,\n",
    "\n",
    "Thank you for taking the time to leave a review about our product. We are sorry to hear that you experienced a price increase and that the quality of the product did not meet your expectations. We apologize for any inconvenience this may have caused you.\n",
    "\n",
    "If you have any further concerns or questions, please do not hesitate to reach out to our customer service team. They will be more than happy to assist you in any way they can.\n",
    "\n",
    "Thank you again for your feedback. We appreciate your business and hope to have the opportunity to serve you better in the future.\n",
    "\n",
    "Best regards,\n",
    "\n",
    "AI customer agent\n",
    ":::\n",
    "\n",
    "This email is the reply to the customer. It sort of responds to the specifics the client brought up in their review. \n",
    "And, sort of following our instructions, advises them to contact customer support because this is simply an AI customer service representative. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change temperature to get a different reply\n",
    "\n",
    "The next step will include using the temperature language model parameter, which will let us alter the model's response variety. You can think of temperature as the model's level of exploration or randomness.\n",
    "\n",
    "So, for this particular phrase, my favourite food is the kind of most likely next word that the model predicts is pizza and the kind of next to most likely it suggests are sushi and tacos. As a result, at a temperature of zero, the model will always select the next word that is most likely to be chosen, in this case pizza. At a higher temperature, however, it will also select one of the less likely words, and at an even higher temperature, it may select tacos, which only has a 5% chance of being selected. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/pranath/blog/raw/master/images/chatgpt-temperature.png\"/>\n",
    "\n",
    "In general, it's best to use temperature zero when developing apps that require some sort of predictable reaction. \n",
    "\n",
    "We've been using temperature zero in most of these examples, and its best to stick with this approach if you want to design a dependable system that operates according to plan. You could use a higher temperature if you're trying to get the model to be in a more inventive way and want a wider range of possible outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "You are a customer service AI assistant.\n",
    "Your task is to send an email reply to a valued customer.\n",
    "Given the customer email delimited by ```, \\\n",
    "Generate a reply to thank the customer for their review.\n",
    "If the sentiment is positive or neutral, thank them for \\\n",
    "their review.\n",
    "If the sentiment is negative, apologize and suggest that \\\n",
    "they can reach out to customer service. \n",
    "Make sure to use specific details from the review.\n",
    "Write in a concise and professional tone.\n",
    "Sign the email as `AI customer agent`.\n",
    "Customer review: ```{review}```\n",
    "Review sentiment: {sentiment}\n",
    "\"\"\"\n",
    "response = get_completion(prompt, temperature=0.7)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {.callout-tip}\n",
    "### Output\n",
    "Dear Valued Customer,\n",
    "\n",
    "Thank you for taking the time to leave a review regarding our product. We sincerely apologize for any inconvenience you may have experienced with the recent price increase and the quality of the product. We understand that you had some concerns with the base of the system and that the motor made a funny noise after a year of use. We would like to assure you that your feedback is important to us, and we will do our best to improve the quality of our products.\n",
    "\n",
    "We recommend that you reach out to our customer service department if you encounter any issues with our products in the future. Our team is always happy to assist you and answer any questions you may have. We are committed to providing the best possible service to our customers.\n",
    "\n",
    "Thank you again for your review. We appreciate your business and hope to have the opportunity to serve you again in the future.\n",
    "\n",
    "Sincerely,\n",
    "\n",
    "AI customer agent\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In summary, the model's outputs are somewhat more random as the temperature rises. \n",
    "You might almost argue that the assistant becomes more distracted but also perhaps more creative as the temperature rises. \n",
    "\n",
    "## Acknowledgements\n",
    "\n",
    "I'd like to express my thanks to the wonderful [ChatGPT Prompt Engineering for Developers Course](https://www.deeplearning.ai/short-courses/chatgpt-prompt-engineering-for-developers/) by DeepLearning.ai and OpenAI - which i completed, and acknowledge the use of some images and other materials from the course in this article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
