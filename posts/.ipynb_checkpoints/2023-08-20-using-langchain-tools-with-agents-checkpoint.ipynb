{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "date: '2023-08-20'\n",
    "categories:\n",
    " - natural-language-processing\n",
    " - deep-learning\n",
    " - langchain\n",
    " - activeloop\n",
    " - openai\n",
    "title: Using Langchain Tools with Agents\n",
    "description: Tools are modular, reusable components meticulously designed to accomplish specific tasks or provide answers to distinct types of questions. In this post, we will explore the various Tools in LangChain, uncovering their unique capabilities.\n",
    "image: https://github.com/pranath/blog/raw/master/images/langchain-deeplake3.png\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Tools are modular, reusable components meticulously designed to accomplish specific tasks or provide answers to distinct types of questions. By integrating these tools seamlessly into the system, users can effortlessly tap into a diverse range of functionalities and information sources to tackle challenges and generate meaningful responses. In this post, we will explore the various Tools in LangChain, uncovering their unique capabilities.\n",
    "\n",
    "A few notable examples of tools in LangChain, without getting into technical details, are:\n",
    "\n",
    "- Google Search: This tool uses the Google Search API to fetch relevant information from the web, which can be used to answer queries related to current events, facts, or any topic where a quick search can provide accurate results.\n",
    "- Requests: This tool employs the popular Python library \"requests\" to interact with web services, access APIs, or obtain data from different online sources. It can be particularly useful for gathering structured data or specific information from a web service.\n",
    "- Python REPL: The Python REPL (Read-Eval-Print Loop) tool allows users to execute Python code on-the-fly to perform calculations, manipulate data, or test algorithms. It serves as an interactive programming environment within the LangChain system.\n",
    "- Wikipedia: The Wikipedia tool leverages the Wikipedia API to search and retrieve relevant articles, summaries, or specific information from the vast repository of knowledge on the Wikipedia platform.\n",
    "- Wolfram Alpha: With this tool, users can tap into the powerful computational knowledge engine of Wolfram Alpha to answer complex questions, perform advanced calculations, or generate visual representations of data.\n",
    "\n",
    "## LangChain Agents and Toolkits\n",
    "\n",
    "An Agent in LangChain is a bot that responds to questions using natural language instructions and can use tools. It is also used to determine which actions to do and in what order based on user input. A tool (such as a search engine or a calculator) can be used and its output processed, or a response can be returned to the user. When utilised appropriately, agents are extremely powerful since they may call chains dynamically based on user input.\n",
    "\n",
    "An agent has access to a set of tools and may choose which ones to employ based on user input. Tools are functions that carry out certain tasks. To build an agent in LangChain, use the initialize_agent function in conjunction with the load_tools method to prepare the tools that the agent can utilise. \n",
    "\n",
    "For example, the following code can be used to develop a simple agent. When necessary, it can use the SerpApi service to retrieve Google search results or the Python requests wrapper. Remember to use the following command to install the necessary packages: Install langchain==0.0.208 deeplake openai tiktoken with pip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jTC0DUiGPKT-",
    "outputId": "a2edb221-6b44-4f5a-ffc2-a5be462182a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
     ]
    }
   ],
   "source": [
    "#| include: false\n",
    "!pip install -q langchain==0.0.208 openai tiktoken newspaper3k python-dotenv wikipedia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google-Search\n",
    "\n",
    "LLMs have knowledge only up to the point where they were trained, leaving them clueless of any information beyond that point. The incorporation of search engines as tools within the LangChain system provides a substantial benefit. The LangChain library includes a Google Search API wrapper for use in your project. This wrapper can be used as a standalone utility or as a tool within an agent.\n",
    "\n",
    "First, ensure you have a Google Search API API Key and Custom Search Engine ID. If you don't currently have a Custom Search Engine ID, [this tutorial](https://help.elfsight.com/article/331-how-to-get-search-engine-id) can help you create one.\n",
    "\n",
    "Also, getting Google Search API is straightforward. If you have Google Cloud Platform access, you’d just go to the [credentials page](https://support.google.com/googleapi/answer/6158862?hl=en) and click Create credentials > API key.\n",
    "\n",
    "Set them as environment variables, as seen below. Then, using GoogleSearchAPIWrapper, you can get the top k search results for a query. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RQlwrwiHSs1n",
    "outputId": "1056a176-1875-4c61-f242-8b6e2e6a7d53"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "!echo \"OPENAI_API_KEY='<OPENAI_API_KEY>'\" > .env\n",
    "!echo \"GOOGLE_CSE_ID='<GOOGLE_CSE_ID>'\" >> .env\n",
    "!echo \"GOOGLE_API_KEY='<GOOGLE_API_KEY>'\" >> .env\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_dJLxlVgVHwO"
   },
   "outputs": [],
   "source": [
    "#| include: false\n",
    "# from langchain import OpenAI\n",
    "# from langchain.agents import load_tools\n",
    "# from langchain.agents import load_tools\n",
    "# from langchain.agents import initialize_agent\n",
    "# from langchain.agents import AgentType\n",
    "\n",
    "# llm = OpenAI(model_name=\"text-davinci-003\", temperature=0)\n",
    "\n",
    "# tools = load_tools(['serpapi', 'requests_all'], llm=llm)\n",
    "# agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ryC3AD9SVXqG",
    "outputId": "e9798244-5e57-42c2-b472-56bbbb9696c2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'Madrid | History, Population, Climate, & Facts | Britannica',\n",
       "  'link': 'https://www.britannica.com/place/Madrid',\n",
       "  'snippet': \"May 23, 2023 ... Madrid, city, capital of Spain and of Madrid provincia (province). Spain's arts and financial centre, the city proper and province form a\\xa0...\"},\n",
       " {'title': 'Madrid - Eurocities',\n",
       "  'link': 'https://eurocities.eu/cities/madrid/',\n",
       "  'snippet': 'As the Spanish capital, Madrid is home to embassies and international organisations, major companies and financial institutions. It ranks first in Spain for the\\xa0...'},\n",
       " {'title': 'Madrid - Wikipedia',\n",
       "  'link': 'https://en.wikipedia.org/wiki/Madrid',\n",
       "  'snippet': 'Madrid is the capital and most populous city of Spain. The city has almost 3.6 million inhabitants and a metropolitan area population of approximately 6.7\\xa0...'}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# As a standalone utility:\n",
    "from langchain. utilities import GoogleSearchAPIWrapper\n",
    "\n",
    "search = GoogleSearchAPIWrapper()\n",
    "search.results(\"What is the capital of Spain?\", 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the LangChain library, using the available tools requires some necessary steps to be taken. First, you need to initialize an agent, which is the central manager for effectively using these tools. Then, we need to define the language model that we want the agent to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jrx3zf9JY5jl"
   },
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "\n",
    "llm = OpenAI(model_name=\"text-davinci-003\", temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now start an agent and load the google-search tool for it to use. The agent will load the search results and present them to the llm in order for it to respond to our enquiry. The ZERO_SHOT_REACT_DESCRIPTION type allows you to select any of the tools defined to offer context for the model based on their description. (You can employ many agent kinds; [learn more]()https://python.langchain.com/docs/modules/agents/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3urfg-RTZw0R",
    "outputId": "d3873496-6d48-4179-d166-1dc03f0b94e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I should research this online.\n",
      "Action: Google Search\n",
      "Action Input: National drink in Spain\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mSangría is Spain's national drink, so of course it belongs on this list! Spain is famous for it's wine, which is the base of this drink. Although there is nothing officially considered the national alcoholic drink of Spain, many people would say is the Spanish sherry wine (also known as vino de ... Apr 20, 2021 ... Spanish horchata is a very popular sweet, creamy drink made by mixing the milky juice of tiger nuts with white sugar. The drink must be ... \"Very Old Rare Sherry\", Pedro Ximenez by Garvey. Jerez de la Frontera (Andalusia, Spain), aged 30 years. Sherry is a national liquor of Spain. Nov 27, 2012 ... The fervor with which Spaniards drink gin & tonics is, to say the ... gin tonic is the national drink (and that ampersands are expendable). Jul 25, 2022 ... Orujo is an ancient Spanish pomace brandy that is enjoyed throughout the country, but it is usually associated with northern Spain—namely ... Even out of the country, people recognize the sherry wine as a very typical drink from Spain. Of course, when talking about the Spanish national drink, we could ... Horchata. A cooling creamy drink for summer, horchata (or orxata as it is also spelled in Valencian and Catalan) can be found in specialised ... Feb 22, 2023 ... Undoubtedly, sangria is one of the typical drinks of Spain. For some, it is even considered the national drink of Spain. Jul 10, 2022 ... But it couldn´t be another way, as wine is the national drink of Spain. You could probably not know that Spain is the second largest wine ...\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
      "Final Answer: The national drink of Spain is Sherry wine.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What is the national drink in Spain?',\n",
       " 'output': 'The national drink of Spain is Sherry wine.'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.agents import initialize_agent, load_tools\n",
    "\n",
    "tools = load_tools([\"google-search\"])\n",
    "\n",
    "agent = initialize_agent(\n",
    "    tools,\n",
    "    llm,\n",
    "    agent=\"zero-shot-react-description\",\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "agent(\"What is the national drink in Spain?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requests\n",
    "\n",
    "The internet is a vast repository of knowledge that Large Language Models cannot directly access. To promote seamless interaction between LLMs and this abundance of information, LangChain provides a handy wrapper built around the Python Requests module. This wrapper accepts a URL as an input and receives data from the supplied URL effectively, allowing LLMs to easily obtain and process web-based content.\n",
    "\n",
    "In this example, we'll use mockapi.io to create a bogus RESTful backend. Follow these steps to do it:\n",
    "\n",
    "1. Go to [mockapi.io](https://mockapi.io/) and sign up for a free account.\n",
    "2. After signing up, log in to your account.\n",
    "3. Click on \"New Project\" (the \"+\" icon) and give your project a name. You don't need to fill in any optional fields.\n",
    "4. Once the project is created, click on it to view your unique API endpoint.\n",
    "5. Click on \"New Resource\" to create a new resource for your API. For example, if you want to create an endpoint for users, you can name the resource \"users.”\n",
    "6. Define the schema for your resource. For instance, if you want each user to have an id, name, and email, you can use the following schema:\n",
    "\n",
    "{\n",
    "    \"id\": \"integer\",\n",
    "    \"name\": \"string\",\n",
    "    \"email\": \"string\"\n",
    "}\n",
    "\n",
    "Click on the \"Create\" button to create the resource with the defined schema.\n",
    "\n",
    "This fake backend will have an endpoint to retrieve information about fake users stored in the backend. A dictionary will represent each user. For instance:\n",
    "\n",
    "{\n",
    "    \"id\": \"1\",\n",
    "    \"name\": \"John Doe\",\n",
    "    \"email\": \"john.doe@example.com\"\n",
    "}\n",
    "\n",
    "Let's interact with our phoney RESTful backend using the LangChain tools. First, import the relevant libraries and configure the agent with the appropriate tools. Then, instruct the agent to make an HTTP request to \"https://644696c1ee791e1e2903b0bb.mockapi.io/user\": this is the address of our particular mockapi instance, where you should discover 30 users. Replace the address with \"https://YOUR-MOCKAPI-SERVER-ID>.mockapi.io/user\" if you wish to test your mockapi instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wlxCyLWpZ1b6"
   },
   "outputs": [],
   "source": [
    "from langchain.agents import AgentType\n",
    "\n",
    "tools = load_tools([\"requests_all\"], llm=llm)\n",
    "agent = initialize_agent(\n",
    "    tools,\n",
    "    llm,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V5HZBqSHZ9wH",
    "outputId": "f9309eea-a788-4edd-e22f-9293275f5aba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to get the list of users from the URL\n",
      "Action: requests_get\n",
      "Action Input: https://644696c1ee791e1e2903b0bb.mockapi.io/user\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m[{\"createdAt\":\"2023-04-24T07:55:47.634Z\",\"name\":\"Mr. Kelly Balistreri\",\"avatar\":\"https://cloudflare-ipfs.com/ipfs/Qmd3W5DuhgHirLHGVixi6V76LhCkZUz6pnFt5AJBiyvHye/avatar/1244.jpg\",\"id\":\"1\"},{\"createdAt\":\"2023-04-24T03:54:44.108Z\",\"name\":\"Bradley Cronin\",\"avatar\":\"https://cloudflare-ipfs.com/ipfs/Qmd3W5DuhgHirLHGVixi6V76LhCkZUz6pnFt5AJBiyvHye/avatar/615.jpg\",\"id\":\"2\"},{\"createdAt\":\"2023-04-24T14:32:29.991Z\",\"name\":\"Jennifer Block Sr.\",\"avatar\":\"https://cloudflare-ipfs.com/ipfs/Qmd3W5DuhgHirLHGVixi6V76LhCkZUz6pnFt5AJBiyvHye/avatar/105.jpg\",\"id\":\"3\"},{\"createdAt\":\"2023-04-23T23:30:05.868Z\",\"name\":\"Nathaniel Toy V\",\"avatar\":\"https://cloudflare-ipfs.com/ipfs/Qmd3W5DuhgHirLHGVixi6V76LhCkZUz6pnFt5AJBiyvHye/avatar/533.jpg\",\"id\":\"4\"},{\"createdAt\":\"2023-04-24T03:01:15.797Z\",\"name\":\"Regina Veum\",\"avatar\":\"https://cloudflare-ipfs.com/ipfs/Qmd3W5DuhgHirLHGVixi6V76LhCkZUz6pnFt5AJBiyvHye/avatar/1047.jpg\",\"id\":\"5\"},{\"createdAt\":\"2023-04-23T18:38:07.884Z\",\"name\":\"Miss Jaime Aufderhar\",\"avatar\":\"https://cloudflare-ipfs.com/ipfs/Qmd3W5DuhgHirLHGVixi6V76LhCkZUz6pnFt5AJBiyvHye/avatar/979.jpg\",\"id\":\"6\"},{\"createdAt\":\"2023-04-24T14:23:26.777Z\",\"name\":\"Ginger Rolfson I\",\"avatar\":\"https://cloudflare-ipfs.com/ipfs/Qmd3W5DuhgHirLHGVixi6V76LhCkZUz6pnFt5AJBiyvHye/avatar/311.jpg\",\"id\":\"7\"},{\"createdAt\":\"2023-04-24T02:10:57.769Z\",\"name\":\"Kelli Braun\",\"avatar\":\"https://cloudflare-ipfs.com/ipfs/Qmd3W5DuhgHirLHGVixi6V76LhCkZUz6pnFt5AJBiyvHye/avatar/24.jpg\",\"id\":\"8\"},{\"createdAt\":\"2023-04-24T14:31:17.436Z\",\"name\":\"Mrs. Ralph Bergstrom\",\"avatar\":\"https://cloudflare-ipfs.com/ipfs/Qmd3W5DuhgHirLHGVixi6V76LhCkZUz6pnFt5AJBiyvHye/avatar/1219.jpg\",\"id\":\"9\"},{\"createdAt\":\"2023-04-23T16:19:28.348Z\",\"name\":\"Joshua Tromp IV\",\"avatar\":\"https://cloudflare-ipfs.com/ipfs/Qmd3W5DuhgHirLHGVixi6V76LhCkZUz6pnFt5AJBiyvHye/avatar/1242.jpg\",\"id\":\"10\"},{\"createdAt\":\"2023-04-24T02:22:40.398Z\",\"name\":\"Mrs. Alexandra Lueilwitz\",\"avatar\":\"https://cloudflare-ipfs.com/ipfs/Qmd3W5DuhgHirLHGVixi6V76LhCkZUz6pnFt5AJBiyvHye/avatar/778.jpg\",\"id\":\"11\"},{\"createdAt\":\"2023-04-24T07:45:30.139Z\",\"name\":\"Reginald Parisian\",\"avatar\":\"https://cloudflare-ipfs.com/ipfs/Qmd3W5DuhgHirLHGVixi6V76LhCkZUz6pnFt5AJBiyvHye/avatar/634.jpg\",\"id\":\"12\"},{\"createdAt\":\"2023-04-24T07:54:38.530Z\",\"name\":\"Leon Hayes\",\"avatar\":\"https://cloudflare-ipfs.com/ipfs/Qmd3W5DuhgHirLHGVixi6V76LhCkZUz6pnFt5AJBiyvHye/avatar/846.jpg\",\"id\":\"13\"},{\"createdAt\":\"2023-04-23T21:42:33.334Z\",\"name\":\"Earl Runolfsson Jr.\",\"avatar\":\"https://cloudflare-ipfs.com/ipfs/Qmd3W5DuhgHirLHGVixi6V76LhCkZUz6pnFt5AJBiyvHye/avatar/919.jpg\",\"id\":\"14\"},{\"createdAt\":\"2023-04-23T16:24:07.464Z\",\"name\":\"Mrs. Rosalie Goldner\",\"avatar\":\"https://cloudflare-ipfs.com/ipfs/Qmd3W5DuhgHirLHGVixi6V76LhCkZUz6pnFt5AJBiyvHye/avatar/1109.jpg\",\"id\":\"15\"},{\"createdAt\":\"2023-04-23T22:34:57.525Z\",\"name\":\"Cindy Koelpin\",\"avatar\":\"https://cloudflare-ipfs.com/ipfs/Qmd3W5DuhgHirLHGVixi6V76LhCkZUz6pnFt5AJBiyvHye/avatar/406.jpg\",\"id\":\"16\"},{\"createdAt\":\"2023-04-24T10:48:48.113Z\",\"name\":\"Woodrow Williamson\",\"avatar\":\"https://cloudflare-ipfs.com/ipfs/Qmd3W5DuhgHirLHGVixi6V76LhCkZUz6pnFt5AJBiyvHye/avatar/712.jpg\",\"id\":\"17\"},{\"createdAt\":\"2023-04-24T00:57:43.603Z\",\"name\":\"Kristi Satterfield\",\"avatar\":\"https://cloudflare-ipfs.com/ipfs/Qmd3W5DuhgHirLHGVixi6V76LhCkZUz6pnFt5AJBiyvHye/avatar/315.jpg\",\"id\":\"18\"},{\"createdAt\":\"2023-04-23T20:26:12.239Z\",\"name\":\"Miss Jill Brakus\",\"avatar\":\"https://cloudflare-ipfs.com/ipfs/Qmd3W5DuhgHirLHGVixi6V76LhCkZUz6pnFt5AJBiyvHye/avatar/1099.jpg\",\"id\":\"19\"},{\"createdAt\":\"2023-04-24T11:59:15.215Z\",\"name\":\"Christy Monahan\",\"avatar\":\"https://cloudflare-ipfs.com/ipfs/Qmd3W5DuhgHirLHGVixi6V76LhCkZUz6pnFt5AJBiyvHye/avatar/452.jpg\",\"id\":\"20\"},{\"createdAt\":\"2023-04-24T09:22:44.409Z\",\"name\":\"Latoya Hammes\",\"avatar\":\"https://cloudflare-ipfs.com/ipfs/Qmd3W5DuhgHirLHGVixi6V76LhCkZUz6pnFt5AJBiyvHye/avatar/747.jpg\",\"id\":\"21\"},{\"createdAt\":\"2023-04-23T19:27:58.947Z\",\"name\":\"Pat McGlynn\",\"avatar\":\"https://cloudflare-ipfs.com/ipfs/Qmd3W5DuhgHirLHGVixi6V76LhCkZUz6pnFt5AJBiyvHye/avatar/1133.jpg\",\"id\":\"22\"},{\"createdAt\":\"2023-04-23T16:44:33.052Z\",\"name\":\"Elizabeth Zboncak\",\"avatar\":\"https://cloudflare-ipfs.com/ipfs/Qmd3W5DuhgHirLHGVixi6V76LhCkZUz6pnFt5AJBiyvHye/avatar/569.jpg\",\"id\":\"23\"},{\"createdAt\":\"2023-04-24T10:05:19.598Z\",\"name\":\"Ms. Constance Hackett Jr.\",\"avatar\":\"https://cloudflare-ipfs.com/ipfs/Qmd3W5DuhgHirLHGVixi6V76LhCkZUz6pnFt5AJBiyvHye/avatar/1059.jpg\",\"id\":\"24\"},{\"createdAt\":\"2023-04-24T07:55:11.013Z\",\"name\":\"Irvin Cummerata\",\"avatar\":\"https://cloudflare-ipfs.com/ipfs/Qmd3W5DuhgHirLHGVixi6V76LhCkZUz6pnFt5AJBiyvHye/avatar/708.jpg\",\"id\":\"25\"},{\"createdAt\":\"2023-04-24T02:09:34.331Z\",\"name\":\"Jan Stanton\",\"avatar\":\"https://cloudflare-ipfs.com/ipfs/Qmd3W5DuhgHirLHGVixi6V76LhCkZUz6pnFt5AJBiyvHye/avatar/987.jpg\",\"id\":\"26\"},{\"createdAt\":\"2023-04-24T04:20:43.153Z\",\"name\":\"Mable Kuphal\",\"avatar\":\"https://cloudflare-ipfs.com/ipfs/Qmd3W5DuhgHirLHGVixi6V76LhCkZUz6pnFt5AJBiyvHye/avatar/444.jpg\",\"id\":\"27\"},{\"createdAt\":\"2023-04-24T06:10:38.771Z\",\"name\":\"Paula Kshlerin\",\"avatar\":\"https://cloudflare-ipfs.com/ipfs/Qmd3W5DuhgHirLHGVixi6V76LhCkZUz6pnFt5AJBiyvHye/avatar/1145.jpg\",\"id\":\"28\"},{\"createdAt\":\"2023-04-24T03:15:33.343Z\",\"name\":\"Roberto Blanda\",\"avatar\":\"https://cloudflare-ipfs.com/ipfs/Qmd3W5DuhgHirLHGVixi6V76LhCkZUz6pnFt5AJBiyvHye/avatar/575.jpg\",\"id\":\"29\"},{\"createdAt\":\"2023-04-23T18:20:58.632Z\",\"name\":\"Mr. Lisa Erdman\",\"avatar\":\"https://cloudflare-ipfs.com/ipfs/Qmd3W5DuhgHirLHGVixi6V76LhCkZUz6pnFt5AJBiyvHye/avatar/1172.jpg\",\"id\":\"30\"}]\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the list of users and can count them\n",
      "Final Answer: There are 30 users in the list.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "response = agent.run(\"Get the list of users at https://644696c1ee791e1e2903b0bb.mockapi.io/user and tell me the total number of users\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen in this example, the agent processes the given prompt after being initialised with the Request tool and the OpenAI language model. It indicates the need to retrieve data from the specified URL via a GET request, which is handled by the request tool. The agent analyses the number of users and returns the result after retrieving the user data, completing the task.\n",
    "\n",
    "## Python REPL \n",
    "\n",
    "The Python REPL tool, which allows you to execute Python code generated by the language model, is another tool feature of LangChain. Because LLMs are not adept at solving algorithmic and math problems, this can be useful for complex calculations where the language model creates code to determine the answer. \n",
    "\n",
    "Here's an example of how to use the Python-REPL tool:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dqrnMEfKaTBy"
   },
   "outputs": [],
   "source": [
    "tools = load_tools([\"python_repl\"], llm=llm)\n",
    "agent = initialize_agent(\n",
    "    tools,\n",
    "    llm,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 663
    },
    "id": "fUJP2Of0abql",
    "outputId": "e72e3c24-b30b-4537-c23c-064b38a2c43e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to generate a list of random strings, sort them, and then print the result\n",
      "Action: Python REPL\n",
      "Action Input: \n",
      "import random\n",
      "\n",
      "my_list = []\n",
      "for i in range(30):\n",
      "    my_list.append(''.join(random.choices(string.ascii_lowercase, k=4)))\n",
      "\n",
      "my_list.sort()\n",
      "print(my_list)\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mNameError(\"name 'string' is not defined\")\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to import the string module\n",
      "Action: Python REPL\n",
      "Action Input: \n",
      "import random\n",
      "import string\n",
      "\n",
      "my_list = []\n",
      "for i in range(30):\n",
      "    my_list.append(''.join(random.choices(string.ascii_lowercase, k=4)))\n",
      "\n",
      "my_list.sort()\n",
      "print(my_list)\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m['aojl', 'biyx', 'bkjq', 'bttr', 'cuef', 'culv', 'czzv', 'djwy', 'eflj', 'ekpr', 'enhg', 'epdq', 'epel', 'hxkp', 'jbrk', 'lbaw', 'mdho', 'nrmc', 'nuqk', 'nybt', 'ptdx', 'smkx', 'sosm', 'srjl', 'swnl', 'uuub', 'vgpw', 'ycli', 'zfln', 'zhsz']\n",
      "\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: ['aojl', 'biyx', 'bkjq', 'bttr', 'cuef', 'culv', 'czzv', 'djwy', 'eflj', 'ekpr', 'enhg', 'epdq', 'epel', 'hxkp', 'jbrk', 'lbaw', 'mdho', 'nrmc', 'nuqk', 'nybt', 'ptdx', 'smkx', 'sosm', 'srjl', 'swnl', 'uuub', 'vgpw', 'ycli', 'zfln', 'zhsz']\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"['aojl', 'biyx', 'bkjq', 'bttr', 'cuef', 'culv', 'czzv', 'djwy', 'eflj', 'ekpr', 'enhg', 'epdq', 'epel', 'hxkp', 'jbrk', 'lbaw', 'mdho', 'nrmc', 'nuqk', 'nybt', 'ptdx', 'smkx', 'sosm', 'srjl', 'swnl', 'uuub', 'vgpw', 'ycli', 'zfln', 'zhsz']\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\"Create a list of random strings containing 4 letters, list should contain 30 examples, and sort the list alphabetically\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wikipedia\n",
    "\n",
    "The LangChain Wikipedia API tool is a sophisticated tool that allows language models to interface with the Wikipedia API to retrieve information and use it to answer questions. You must use the pip install Wikipedia command to install the Wikipedia python package. The codes have been tested with the 1.4.0 version. Use the most recent version of the libraries, though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 250
    },
    "id": "xNJfO4wmacy2",
    "outputId": "e1318fb3-585a-43e4-c79b-9232a6b45a4e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m He is a famous prophet\n",
      "Action: Python REPL\n",
      "Action Input: print(\"Nostradamus is known for his prophecies\")\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mNostradamus is known for his prophecies\n",
      "\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: Nostradamus is known for his prophecies\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Nostradamus is known for his prophecies'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent = initialize_agent(\n",
    "    tools,\n",
    "    llm,\n",
    "    agent=\"zero-shot-react-description\",\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "tools = load_tools([\"wikipedia\"])\n",
    "\n",
    "agent.run(\"What is Nostradamus know for\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s1kBKj-Gaihq"
   },
   "source": [
    "## Wolfram-Alpha\n",
    "\n",
    "In LangChain, you can integrate Wolfram Alpha by using the WolframAlphaAPIWrapper utility. First, you need to set up a [Wolfram Alpha developer account](https://products.wolframalpha.com/api) and get your APP ID. \n",
    "\n",
    "Then, install the Wolfram Alpha Python library with pip install Wolframalpha.\n",
    "After that, you can set the Wolfram Alpha APP ID as an environment variable in your code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"WOLFRAM_ALPHA_APPID\"] = \"your_app_id\"\n",
    "\n",
    "from langchain. utilities.wolfram_alpha import WolframAlphaAPIWrapper\n",
    "\n",
    "wolfram = WolframAlphaAPIWrapper()\n",
    "result = wolfram.run(\"What is 2x+5 = -3x + 7?\")\n",
    "print(result)  # Output: 'x = 2/5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizing the WolframAlphaAPIWrapper from the LangChain library, this code solves the algebraic equation. Let’s observe the WolframAlpha as a tool:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = load_tools([\"wolfram-alpha\"])\n",
    "\n",
    "agent = initialize_agent(\n",
    "    tools,\n",
    "    llm,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True  \n",
    ")\n",
    "\n",
    "print( agent.run(\"How many days until the next Solar eclipse\") )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Showcase of Resourceful Collaboration\n",
    "\n",
    "Agents are able to use a variety of technologies to deliver complete and accurate solutions to complex enquiries. By incorporating resources such as Wikipedia and Wolfram-Alpha, these agents are more suited to provide well-rounded solutions. Here's an illustration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = load_tools([\"wolfram-alpha\", \"wikipedia\"], llm=llm)\n",
    "\n",
    "agent = initialize_agent(\n",
    "\t\ttools,\n",
    "\t\tllm,\n",
    "\t\tagent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "\t\tverbose=True\n",
    "\t)\n",
    "\n",
    "agent.run(\"Who is Olivia Wilde's boyfriend? What is his current age raised to the 0.23 power?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "LangChain agents successfully integrate many tools, such as Wikipedia and Wolfram-Alpha, to produce a smooth knowledge integration experience. The agents are able to deliver clear, precise, and detailed responses to more complicated issues by combining the strengths of various resources.\n",
    "\n",
    "Defining bespoke tools entails developing new classes, functions, or modules within your language processing pipeline to serve special objectives. These custom tools can augment or modify the LangChain library's existing language processing capabilities, or they can construct totally new functions tailored to your individual needs. \n",
    "\n",
    "## Acknowledgements\n",
    "\n",
    "I'd like to express my thanks to the wonderful [LangChain & Vector Databases in Production Course](https://learn.activeloop.ai/courses/langchain) by Activeloop - which i completed, and acknowledge the use of some images and other materials from the course in this article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
