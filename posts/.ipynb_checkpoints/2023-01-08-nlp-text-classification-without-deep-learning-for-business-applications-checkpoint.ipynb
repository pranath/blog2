{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "aliases:\n",
    "- /pycaret/natural-language-processing/2023/01/08/nlp-text-classification-without-deep-learning-for-business-applications\n",
    "categories:\n",
    "- pycaret\n",
    "- natural-language-processing\n",
    "date: '2023-01-08'\n",
    "description: Deep Learning and AI is powering some of the most recent amazing advances\n",
    "  in text & natural language processing (NLP) applications, such as GPT-3, Chat-GPT\n",
    "  and Dall-E but these often require specialist resources such as deep learning. With\n",
    "  Machine Learning (ML) its possible to create useful NLP applications for businesses\n",
    "  without using AI and Deep Learning.\n",
    "image: https://github.com/pranath/blog/raw/master/images/nlp-text-classification.png\n",
    "output-file: 2023-01-08-nlp-text-classification-without-deep-learning-for-business-applications.html\n",
    "title: NLP and Text Classification Without Deep Learning for Business Applications\n",
    "toc: true\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sjzav_2YAVcX"
   },
   "source": [
    "## Introduction\n",
    "\n",
    "Deep Learning and AI is powering some of the most recent amazing advances in text & natural language processing (NLP) applications, such as GPT-3, Chat-GPT and Dall-E, but these often require specialist resources such as GPU servers that many businesses new to this technology don't have or can't yet justify these resources. With traditional Machine Learning (ML) its possible to create useful NLP applications such as text classification without using AI and Deep Learning, and in this article we will look at some examples of how these can provide useful business applications.\n",
    "\n",
    "## Business Applications of NLP\n",
    "\n",
    "NLP (Natural Language Processing) is a branch of Artificial Intelligence (AI) and Data Science that is having a huge effect on all areas of society, including business.\n",
    "\n",
    "**In essence, Natural language processing helps computers communicate with humans in their own language and scales other language-related tasks. For example, NLP makes it possible for computers to read text, hear speech, interpret it, measure sentiment and determine which parts are important.**\n",
    "\n",
    "A recent article by the [Harvard Business Review](https://hbr.org/2022/04/the-power-of-natural-language-processing) highlighted some of the huge potential NLP has for businesses.\n",
    "\n",
    "> Until recently, the conventional wisdom was that while AI was better than humans at data-driven decision making tasks, it was still inferior to humans for cognitive and creative ones. But in the past two years language-based AI has advanced by leaps and bounds, changing common notions of what this technology can do. The most visible advances have been in what’s called “natural language processing” (NLP), the branch of AI focused on how computers can process language like humans do. It has been used to write an article for The Guardian, and AI-authored blog posts have gone viral — feats that weren’t possible a few years ago. AI even excels at cognitive tasks like programming where it is able to generate programs for simple video games from human instructions.\n",
    "\n",
    "A recent article on LinkedIn highlighted some of the [top business applications of NLP](https://www.linkedin.com/pulse/top-natural-language-processing-applications-business-mori-/?trk=pulse-article_more-articles_related-content-card) these include:\n",
    "\n",
    "### Market Intelligence \n",
    "Marketers can utilize natural language processing to understand their clients better and use those insights to develop more effective tactics. They can analyze subjects and keywords and make effective use of unstructured data thanks to the power of NLP. It can also determine your consumers pain points and maintain track of your competition.\n",
    "\n",
    "### Sentiment Analysis\n",
    "Companies can regularly use sentiment analysis to acquire a better knowledge of their business. Humans can be sarcastic and sardonic during conversations. You may keep an eye on social media mentions and use real-time sentiment analysis to intervene before things get out of hand. Your company may sense the pulse of its customers with this NLP application. It also allows you to evaluate how your clients reacted to your most recent digital marketing campaign.\n",
    "\n",
    "### Text Classification\n",
    "Text classification, is a text analysis task that also includes sentiment analysis, involves automatically understanding, processing, and categorizing unstructured text. \n",
    "\n",
    "Let’s say you want to analyze hundreds of open-ended responses to your recent NPS survey. Doing it manually would take you a lot of time and end up being too expensive. But what if you could train a natural language processing model to automatically tag your data in just seconds, using predefined categories and applying your own criteria.\n",
    "\n",
    "### Topic Modelling\n",
    "Topic modeling is an approach that can scan a series of documents, find word and phrase patterns within them, and automatically cluster word groupings and related expressions that best represent the set. \n",
    "\n",
    "Topic Modeling doesn't require a preexisting list of tags or training data that has been previously categorized by humans, it can 'discover' what seem the most appropriate categories for a given set of documents for itself, based on which documents seem the most similar or different.\n",
    "\n",
    "### Recruiting And Hiring\n",
    "We can all agree that picking the right staff is one of the most important duties performed by the HR department. However, HR has so much data in the current situation that sifting resumes and shortlisting prospects become overwhelming.\n",
    "\n",
    "Natural Language Processing can help to make this work more accessible. HR experts can use information extraction and named entity recognition to extract information from candidates, such as their names, talents, locations, and educational histories. This enables unbiased resume filtering and the selection of the best candidate for the job.\n",
    "\n",
    "### Text Summarization\n",
    "This NLP application extracts the most crucial information from a text and summarises it. The primary purpose is to speed up sifting through massive volumes of data in news articles, legal documents, and scientific studies. Text summarization can be done in two ways: extraction-based summarization, which selects crucial words and provides a summary without adding further information, and abstraction-based summarization, which paraphrases the original content to produce new terms.\n",
    "\n",
    "### Survey Analysis \n",
    "Surveys are an essential tool for businesses to use in evaluating their performance. Survey analysis is crucial in finding defects and supporting companies in improving their goods, whether gathering input on a new product launch or analyzing how effectively a company’s customer service is doing.\n",
    "When many clients complete these surveys, the issue emerges, resulting in massive data. The human brain is unable to comprehend everything. At this time, natural language processing is introduced. These methods help organisations get accurate information about their consumers’ opinions and improve their performance.\n",
    "\n",
    "## Machine Learning vs Deep Learning for NLP and Business\n",
    "\n",
    "The most powerful and useful applications of NLP use [Deep Learning and AI](https://www.ibm.com/topics/deep-learning) which is a sub-branch of Machine Learning. All the the most recent and most powerful applications of NLP such as GPT-3, Chat-GPT and Dall-E all use Deep Learning. Many would argue [Deep Learning is perfect for NLP](https://www.kdnuggets.com/2018/04/why-deep-learning-perfect-nlp-natural-language-processing.html).\n",
    "\n",
    "In fact, [most of my own recent projects in NLP](https://livingdatalab.com/categories/#natural-language-processing) over the last few years have almost exclusively used Deep Learning.\n",
    "\n",
    "However before Deep Learning and AI existed and was developed recently, NLP still existed for many years and has its [origins in work in the 1950's](https://www.exxactcorp.com/blog/Deep-Learning/deep-learning-in-natural-language-processing-history-and-achievements). It just used different methods and techniques, that while not as powerful as Deep Learning and AI, still provided useful business applications and benefits at the time they were developed and used. These include the use of traddtional machine learning for NLP. \n",
    "\n",
    "In a recent article i covered in more detail the differences between [tradditonal machine learning and deep learning](https://livingdatalab.com/fastai/fastai-2022/deep-learning/mathematics/2022/12/17/machine-learning-to-deep-learning-from-scratch.html).\n",
    "\n",
    "Also, Deep Learning requires the use of specialist resources - namely [GPU servers](https://towardsdatascience.com/what-is-a-gpu-and-do-you-need-one-in-deep-learning-718b9597aa0d). Many businesses starting to explore the potental benefit of Data, Data Science, Machine Learning and AI don't always have the rescources or infrastructure setup to develop this technology. \n",
    "\n",
    "Furthermore, some businesses may feel much more cautious to adopt this technology and the associated cost of resources, and may need a more gradual approach that takes them on a journey as much about education, learning what this technology can do to help solve business problems, as much as gradually using more and more advanced technology.\n",
    "\n",
    "Some businesses, especially older & established businesses with exisiting business practices, may need to learn slowly how to walk first before running with the most advanced technology!\n",
    "\n",
    "With this in mind, it's good to know it is actually possible to develop useful and valuable NLP business applications - without the use of Deep Learning and the specialist resources that requires. While you might not get the best or near state of the art results for your solution, businesses can still gain huge value and benefit by using these slightly older methods compared to none at all.\n",
    "\n",
    "## Pycaret and NLP\n",
    "\n",
    "NLP often requires a significant amount of code and steps to solve business problems. [Pycaret](https://pycaret.org/) is a low code machine learning library, that allows you to perform common tasks in Data Science and Machine Learning with very little code, and has been listed in a recent article by Forbes as [*one of the 10 Best Examples Of Low-Code And No-Code AI*](https://www.forbes.com/sites/bernardmarr/2022/12/12/the-10-best-examples-of-low-code-and-no-code-ai/?sh=29f5099274b5)\n",
    "\n",
    "I've been using Pycaret myself professionally in my role as a Data Scientist as well as for [personal projects](https://livingdatalab.com/categories/#pycaret) for over a year now and have found it incredibily useful to enable me to work much more quickly and efficiently. I've also written about how Pycaret is actually a [Data Science Power Tool](https://livingdatalab.com/python-power-tools/pycaret/2021/12/04/python-power-tools-pycaret.html).\n",
    "\n",
    "In this project I will be using Pycaret for the NLP tasks we will be doing to solve certain business problems using machine learning.\n",
    "\n",
    "## Text Classification Without Deep Learning\n",
    "\n",
    "Remembering our common uses of NLP, we are going to solve 2 different business problems to illustrate these methods:\n",
    "\n",
    "- **Topic Modelling**: We will use this method to try to discover what the hidden categories are for a dataset from *kiva - a crowdfunder for loans* which includes text data of each loan application. Or put another way - what kind of hidden topics would best describe peoples loan applications? For most busineses, it might be really useful to understand using customer text, such as customer contact form text etc, and discover what kind of topics customers were talking about without us knowing or assuming we know what they are before hand.\n",
    "- **Sentiment Analysis & Classification**: We will use this method to learn to predict the sentiment of *amazon customer product reviews* using the review text, and each of the positive or negative labels they have been assigned in the dataset. In other words, given a customer review text - to predict if this is a positive or negative review. This could be very useful for a business to understand if a product or service was succesful or not, by analysing thousands or even millions of customer reviews automatically and efficiently.\n",
    "\n",
    "Note, with Topic Modelling we are actually trying to discover new categories for a given set of texts, wheras with Sentiment Analysis & Classification we are using an exisiting category. These are known as *unsupervised machine learning* and *supervised machine learning* respectively. In both cases, we produce something called a *model* which is something that we can then use on new text to predict what category that text is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-01-08T16:42:08.577935Z",
     "iopub.status.busy": "2023-01-08T16:42:08.577510Z",
     "iopub.status.idle": "2023-01-08T16:42:33.418383Z",
     "shell.execute_reply": "2023-01-08T16:42:33.417132Z",
     "shell.execute_reply.started": "2023-01-08T16:42:08.577899Z"
    },
    "id": "qS-m3GDQCfp8",
    "outputId": "5c7d9e88-c46a-43d5-dca1-4e2f923950d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pycaret-ts-alpha\n",
      "  Downloading pycaret_ts_alpha-3.0.0.dev1649017462-py3-none-any.whl (468 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.1/468.1 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: plotly>=5.0.0 in /opt/conda/lib/python3.7/site-packages (from pycaret-ts-alpha) (5.11.0)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in /opt/conda/lib/python3.7/site-packages (from pycaret-ts-alpha) (3.5.3)\n",
      "Requirement already satisfied: joblib~=1.0.1 in /opt/conda/lib/python3.7/site-packages (from pycaret-ts-alpha) (1.0.1)\n",
      "Collecting pyod>=0.9.8\n",
      "  Downloading pyod-1.0.7.tar.gz (147 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.7/147.7 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting pmdarima>=1.8.0\n",
      "  Downloading pmdarima-2.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl (1.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numba~=0.55.0 in /opt/conda/lib/python3.7/site-packages (from pycaret-ts-alpha) (0.55.2)\n",
      "Collecting sktime==0.10.1\n",
      "  Downloading sktime-0.10.1-py3-none-any.whl (6.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m39.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: ipython>=5.5.0 in /opt/conda/lib/python3.7/site-packages (from pycaret-ts-alpha) (7.33.0)\n",
      "Requirement already satisfied: yellowbrick>=1.4 in /opt/conda/lib/python3.7/site-packages (from pycaret-ts-alpha) (1.5)\n",
      "Requirement already satisfied: lightgbm>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from pycaret-ts-alpha) (3.3.2)\n",
      "Requirement already satisfied: imbalanced-learn>=0.8.1 in /opt/conda/lib/python3.7/site-packages (from pycaret-ts-alpha) (0.10.1)\n",
      "Requirement already satisfied: scipy~=1.7.3 in /opt/conda/lib/python3.7/site-packages (from pycaret-ts-alpha) (1.7.3)\n",
      "Requirement already satisfied: pandas<1.5.0,>=1.3.0 in /opt/conda/lib/python3.7/site-packages (from pycaret-ts-alpha) (1.3.5)\n",
      "Requirement already satisfied: scikit-plot>=0.3.7 in /opt/conda/lib/python3.7/site-packages (from pycaret-ts-alpha) (0.3.7)\n",
      "Collecting tbats>=1.1.0\n",
      "  Downloading tbats-1.1.2-py3-none-any.whl (43 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.8/43.8 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: category-encoders>=2.4.0 in /opt/conda/lib/python3.7/site-packages (from pycaret-ts-alpha) (2.5.1.post0)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in /opt/conda/lib/python3.7/site-packages (from pycaret-ts-alpha) (1.0.2)\n",
      "Collecting kaleido>=0.2.1\n",
      "  Downloading kaleido-0.2.1-py2.py3-none-manylinux1_x86_64.whl (79.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.9/79.9 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy~=1.21 in /opt/conda/lib/python3.7/site-packages (from pycaret-ts-alpha) (1.21.6)\n",
      "Requirement already satisfied: statsmodels>=0.12.1 in /opt/conda/lib/python3.7/site-packages (from pycaret-ts-alpha) (0.13.2)\n",
      "Collecting deprecated>=1.2.13\n",
      "  Downloading Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB)\n",
      "Requirement already satisfied: patsy>=0.5.1 in /opt/conda/lib/python3.7/site-packages (from category-encoders>=2.4.0->pycaret-ts-alpha) (0.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from imbalanced-learn>=0.8.1->pycaret-ts-alpha) (3.1.0)\n",
      "Collecting imbalanced-learn>=0.8.1\n",
      "  Downloading imbalanced_learn-0.10.0-py3-none-any.whl (225 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m225.4/225.4 kB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading imbalanced_learn-0.9.1-py3-none-any.whl (199 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.3/199.3 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading imbalanced_learn-0.9.0-py3-none-any.whl (199 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.1/199.1 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pickleshare in /opt/conda/lib/python3.7/site-packages (from ipython>=5.5.0->pycaret-ts-alpha) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from ipython>=5.5.0->pycaret-ts-alpha) (3.0.30)\n",
      "Requirement already satisfied: setuptools>=18.5 in /opt/conda/lib/python3.7/site-packages (from ipython>=5.5.0->pycaret-ts-alpha) (59.8.0)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.7/site-packages (from ipython>=5.5.0->pycaret-ts-alpha) (4.8.0)\n",
      "Requirement already satisfied: backcall in /opt/conda/lib/python3.7/site-packages (from ipython>=5.5.0->pycaret-ts-alpha) (0.2.0)\n",
      "Requirement already satisfied: matplotlib-inline in /opt/conda/lib/python3.7/site-packages (from ipython>=5.5.0->pycaret-ts-alpha) (0.1.3)\n",
      "Requirement already satisfied: traitlets>=4.2 in /opt/conda/lib/python3.7/site-packages (from ipython>=5.5.0->pycaret-ts-alpha) (5.3.0)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.7/site-packages (from ipython>=5.5.0->pycaret-ts-alpha) (0.18.1)\n",
      "Requirement already satisfied: pygments in /opt/conda/lib/python3.7/site-packages (from ipython>=5.5.0->pycaret-ts-alpha) (2.12.0)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.7/site-packages (from ipython>=5.5.0->pycaret-ts-alpha) (5.1.1)\n",
      "Requirement already satisfied: wheel in /opt/conda/lib/python3.7/site-packages (from lightgbm>=3.0.0->pycaret-ts-alpha) (0.37.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=3.3.0->pycaret-ts-alpha) (4.33.3)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=3.3.0->pycaret-ts-alpha) (9.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=3.3.0->pycaret-ts-alpha) (0.11.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=3.3.0->pycaret-ts-alpha) (2.8.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=3.3.0->pycaret-ts-alpha) (22.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=3.3.0->pycaret-ts-alpha) (3.0.9)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=3.3.0->pycaret-ts-alpha) (1.4.3)\n",
      "Requirement already satisfied: llvmlite<0.39,>=0.38.0rc1 in /opt/conda/lib/python3.7/site-packages (from numba~=0.55.0->pycaret-ts-alpha) (0.38.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas<1.5.0,>=1.3.0->pycaret-ts-alpha) (2022.1)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /opt/conda/lib/python3.7/site-packages (from plotly>=5.0.0->pycaret-ts-alpha) (8.0.1)\n",
      "Requirement already satisfied: Cython!=0.29.18,!=0.29.31,>=0.29 in /opt/conda/lib/python3.7/site-packages (from pmdarima>=1.8.0->pycaret-ts-alpha) (0.29.32)\n",
      "Requirement already satisfied: urllib3 in /opt/conda/lib/python3.7/site-packages (from pmdarima>=1.8.0->pycaret-ts-alpha) (1.26.13)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from pyod>=0.9.8->pycaret-ts-alpha) (1.15.0)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /opt/conda/lib/python3.7/site-packages (from deprecated>=1.2.13->sktime==0.10.1->pycaret-ts-alpha) (1.12.1)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /opt/conda/lib/python3.7/site-packages (from jedi>=0.16->ipython>=5.5.0->pycaret-ts-alpha) (0.8.3)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib>=3.3.0->pycaret-ts-alpha) (4.1.1)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.7/site-packages (from pexpect>4.3->ipython>=5.5.0->pycaret-ts-alpha) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.7/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=5.5.0->pycaret-ts-alpha) (0.2.5)\n",
      "Building wheels for collected packages: pyod\n",
      "  Building wheel for pyod (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pyod: filename=pyod-1.0.7-py3-none-any.whl size=181102 sha256=2b69b0a75333960c178775f382a58b0d2ef091f596321c5eb136bf230980795a\n",
      "  Stored in directory: /root/.cache/pip/wheels/a4/97/94/6574311546af4d192630d77eacb23eb1b2b9e5b1a87ebea4c7\n",
      "Successfully built pyod\n",
      "Installing collected packages: kaleido, deprecated, imbalanced-learn, sktime, pyod, pmdarima, tbats, pycaret-ts-alpha\n",
      "  Attempting uninstall: imbalanced-learn\n",
      "    Found existing installation: imbalanced-learn 0.10.1\n",
      "    Uninstalling imbalanced-learn-0.10.1:\n",
      "      Successfully uninstalled imbalanced-learn-0.10.1\n",
      "Successfully installed deprecated-1.2.13 imbalanced-learn-0.9.0 kaleido-0.2.1 pmdarima-2.0.2 pycaret-ts-alpha-3.0.0.dev1649017462 pyod-1.0.7 sktime-0.10.1 tbats-1.1.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "#| include: false\n",
    "# Use this version of pycaret to enable plotting of charts\n",
    "!pip install pycaret-ts-alpha \n",
    "from pycaret.datasets import get_data\n",
    "from pycaret.nlp import *\n",
    "import pandas as pd\n",
    "pd.set_option('max_colwidth', 800)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E52X1AqxEmM0"
   },
   "source": [
    "### Topic modelling - Discovering hidden categories in Kiva loan applications\n",
    "\n",
    "Pycaret comes with some ready to use datasets such as Kiva. [Kiva](https://www.kiva.org/) is a non-profit that allows individuals to lend money to low-income entrepreneurs and students around the world. The kiva dataset is data on individual loan applications which include the text of the application. Lets load and view the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-08T15:33:21.611024Z",
     "iopub.status.busy": "2023-01-08T15:33:21.610589Z",
     "iopub.status.idle": "2023-01-08T15:33:22.057337Z",
     "shell.execute_reply": "2023-01-08T15:33:22.056117Z",
     "shell.execute_reply.started": "2023-01-08T15:33:21.610989Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>en</th>\n",
       "      <th>gender</th>\n",
       "      <th>loan_amount</th>\n",
       "      <th>nonpayment</th>\n",
       "      <th>sector</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dominican Republic</td>\n",
       "      <td>\"Banco Esperanza\" is a group of 10 women looking to receive a small loan. Each of them has taken out a very small loan already, so this would be their second. With this loan the group is going to try and expand their small businesses and start generating more income. &lt;P&gt;\\n\\nEduviges is the group representative and leader of the group. Eduviges has a lot on the line because she has 6 children that she has to take care of. She told me that those children are the reason she wants to be successful. She wants to be able to provide a different life for them and show them that they can be successful as well. &lt;P&gt;\\n\\nEduviges has a very small business selling shoes and Avon products. She plans to expand using this loan and dreams of success. The whole group is ready for this new challenge and a...</td>\n",
       "      <td>F</td>\n",
       "      <td>1225</td>\n",
       "      <td>partner</td>\n",
       "      <td>Retail</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dominican Republic</td>\n",
       "      <td>\"Caminemos Hacia Adelante\" or \"Walking Forward\" is a group of ten entrepreneurs seeking their second loan from Esperanza International. The groups past loan has been successfully repaid and the group hopes to use additional loan funds for further business expansion. \\n\\nEstella is one of the coordinators for this group in Santiago. Estella sells undergarments to her community and neighboring communities.  Estella used her first loan, which has now been completely repaid, to buy additional products and Estela was able to increase the return on her business by adding inventory.  Estella wants to use her second loan to buy more undergarments to sell to her customers.  \\n\\nEstella lives with her mother and sister and dreams of improving the house they live in and plans to use her business ...</td>\n",
       "      <td>F</td>\n",
       "      <td>1975</td>\n",
       "      <td>lender</td>\n",
       "      <td>Clothing</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dominican Republic</td>\n",
       "      <td>\"Creciendo Por La Union\" is a group of 10 people hoping to start their own businesses. This group is looking to receive loans to either start a small business or to try and increase their business. Everyone in this group is living in extreme poverty, and they see this as a chance to improve their lives and the lives of their families. \\n\\n\"Dalina\" is the group representative and was chosen because she is a very hardworking women. She is a young mother of two children, and she realized that she wanted a better life for her and her family. She is hoping to start a small business of selling clothes to people in her barrio. She hopes to someday have a thriving business and be able to provide for her family. On behalf of Dalina, the rest of the group, and Esperanza International: Thank you ...</td>\n",
       "      <td>F</td>\n",
       "      <td>2175</td>\n",
       "      <td>partner</td>\n",
       "      <td>Clothing</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dominican Republic</td>\n",
       "      <td>\"Cristo Vive\" (\"Christ lives\" is a group of 10 women who are looking to receive their first loans. This is a very young group of women, and they all want to start changing their lives right away. Riquena is the group representative and leader of this group, and she is only 18 years old. She is also married, but has no children. She told me that once she has kids she wants to be able to provide them with a good life, and that is the main reason she is trying to start her own business. She plans on selling used clothes in her area, and hopes to one day have a big clothing store, and also design clothes. She is a very motivated person, and you can see it when you speak with her. She speaks Spanish and Creole fluently, and is studying English. This whole group is ready for this next step, ...</td>\n",
       "      <td>F</td>\n",
       "      <td>1425</td>\n",
       "      <td>partner</td>\n",
       "      <td>Clothing</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dominican Republic</td>\n",
       "      <td>\"Cristo Vive\" is a large group of 35 people, 20 of which are hoping to take out a loan. For many of them this is their second loan, and a loan they hope to use to increase their business. The business range from clothing sales to salons. Miline is the chosen group representative due to her hard work and dedication. Miline is a hardworking mother of 5 very young children, the oldest being only 10 years old. She took her first loan and started a small business of selling chicken and other types of food. With this next loan she feels like she can increase her business greatly and start making money to support her family. Her dream is to have her own store someday, and be able to provide her family with comfortable life. On behalf of Miline, the group, and Esperanza International, thank yo...</td>\n",
       "      <td>F</td>\n",
       "      <td>4025</td>\n",
       "      <td>partner</td>\n",
       "      <td>Food</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              country  \\\n",
       "0  Dominican Republic   \n",
       "1  Dominican Republic   \n",
       "2  Dominican Republic   \n",
       "3  Dominican Republic   \n",
       "4  Dominican Republic   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                en  \\\n",
       "0  \"Banco Esperanza\" is a group of 10 women looking to receive a small loan. Each of them has taken out a very small loan already, so this would be their second. With this loan the group is going to try and expand their small businesses and start generating more income. <P>\\n\\nEduviges is the group representative and leader of the group. Eduviges has a lot on the line because she has 6 children that she has to take care of. She told me that those children are the reason she wants to be successful. She wants to be able to provide a different life for them and show them that they can be successful as well. <P>\\n\\nEduviges has a very small business selling shoes and Avon products. She plans to expand using this loan and dreams of success. The whole group is ready for this new challenge and a...   \n",
       "1  \"Caminemos Hacia Adelante\" or \"Walking Forward\" is a group of ten entrepreneurs seeking their second loan from Esperanza International. The groups past loan has been successfully repaid and the group hopes to use additional loan funds for further business expansion. \\n\\nEstella is one of the coordinators for this group in Santiago. Estella sells undergarments to her community and neighboring communities.  Estella used her first loan, which has now been completely repaid, to buy additional products and Estela was able to increase the return on her business by adding inventory.  Estella wants to use her second loan to buy more undergarments to sell to her customers.  \\n\\nEstella lives with her mother and sister and dreams of improving the house they live in and plans to use her business ...   \n",
       "2  \"Creciendo Por La Union\" is a group of 10 people hoping to start their own businesses. This group is looking to receive loans to either start a small business or to try and increase their business. Everyone in this group is living in extreme poverty, and they see this as a chance to improve their lives and the lives of their families. \\n\\n\"Dalina\" is the group representative and was chosen because she is a very hardworking women. She is a young mother of two children, and she realized that she wanted a better life for her and her family. She is hoping to start a small business of selling clothes to people in her barrio. She hopes to someday have a thriving business and be able to provide for her family. On behalf of Dalina, the rest of the group, and Esperanza International: Thank you ...   \n",
       "3  \"Cristo Vive\" (\"Christ lives\" is a group of 10 women who are looking to receive their first loans. This is a very young group of women, and they all want to start changing their lives right away. Riquena is the group representative and leader of this group, and she is only 18 years old. She is also married, but has no children. She told me that once she has kids she wants to be able to provide them with a good life, and that is the main reason she is trying to start her own business. She plans on selling used clothes in her area, and hopes to one day have a big clothing store, and also design clothes. She is a very motivated person, and you can see it when you speak with her. She speaks Spanish and Creole fluently, and is studying English. This whole group is ready for this next step, ...   \n",
       "4  \"Cristo Vive\" is a large group of 35 people, 20 of which are hoping to take out a loan. For many of them this is their second loan, and a loan they hope to use to increase their business. The business range from clothing sales to salons. Miline is the chosen group representative due to her hard work and dedication. Miline is a hardworking mother of 5 very young children, the oldest being only 10 years old. She took her first loan and started a small business of selling chicken and other types of food. With this next loan she feels like she can increase her business greatly and start making money to support her family. Her dream is to have her own store someday, and be able to provide her family with comfortable life. On behalf of Miline, the group, and Esperanza International, thank yo...   \n",
       "\n",
       "  gender  loan_amount nonpayment    sector  status  \n",
       "0      F         1225    partner    Retail       0  \n",
       "1      F         1975     lender  Clothing       0  \n",
       "2      F         2175    partner  Clothing       0  \n",
       "3      F         1425    partner  Clothing       0  \n",
       "4      F         4025    partner      Food       0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "kiva = get_data('kiva')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check how big the dataset is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-08T15:33:22.060642Z",
     "iopub.status.busy": "2023-01-08T15:33:22.059916Z",
     "iopub.status.idle": "2023-01-08T15:33:22.068810Z",
     "shell.execute_reply": "2023-01-08T15:33:22.067492Z",
     "shell.execute_reply.started": "2023-01-08T15:33:22.060596Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6818"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kiva.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have around 7,000 loan applications. Lets now process and prepare the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 227,
     "referenced_widgets": [
      "54031f3d3e58425c8111f92251763f0f",
      "87dff002b24f47e095d409ccc1d67270",
      "8e53cef91b144386aed6eb17fbbf4429"
     ]
    },
    "execution": {
     "iopub.execute_input": "2023-01-08T15:33:22.070091Z",
     "iopub.status.busy": "2023-01-08T15:33:22.069772Z",
     "iopub.status.idle": "2023-01-08T15:34:37.361427Z",
     "shell.execute_reply": "2023-01-08T15:34:37.360224Z",
     "shell.execute_reply.started": "2023-01-08T15:33:22.070063Z"
    },
    "id": "MafPcPh-K81B",
    "outputId": "f751d97a-f74f-4fa6-dd65-c07ecb41ce45"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_3bf27_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"col_heading level0 col0\" >Description</th>\n",
       "      <th class=\"col_heading level0 col1\" >Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_3bf27_row0_col0\" class=\"data row0 col0\" >session_id</td>\n",
       "      <td id=\"T_3bf27_row0_col1\" class=\"data row0 col1\" >2214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_3bf27_row1_col0\" class=\"data row1 col0\" >Documents</td>\n",
       "      <td id=\"T_3bf27_row1_col1\" class=\"data row1 col1\" >6818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_3bf27_row2_col0\" class=\"data row2 col0\" >Vocab Size</td>\n",
       "      <td id=\"T_3bf27_row2_col1\" class=\"data row2 col1\" >12383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_3bf27_row3_col0\" class=\"data row3 col0\" >Custom Stopwords</td>\n",
       "      <td id=\"T_3bf27_row3_col1\" class=\"data row3 col1\" >False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f1394b4f190>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 14s, sys: 295 ms, total: 1min 15s\n",
      "Wall time: 1min 15s\n"
     ]
    }
   ],
   "source": [
    "%time experiment1 = setup(data=kiva, target='en')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x3fIaOqkOfYS"
   },
   "source": [
    "This single line of code has actually performed a large number of tasks that would normally take many lines of code, but in Pycaret is a single line of code. You can find out more about what this line does for NLP text pre-processing [here](https://www.pycaret.org/tutorials/html/NLP101.html).\n",
    "\n",
    "Now our data is prepared, lets create our topic model.\n",
    "\n",
    "For topic modelling we will be using the [Latent Dirichlet Allocation (LDA)](https://towardsdatascience.com/topic-modeling-and-latent-dirichlet-allocation-in-python-9bf156893c24) technique. I've written previously about the mathemetics behind two other techniques called [Non-negative Matrix Factorization (NMF)](https://livingdatalab.com/mathematics/linear-algebra/natural-language-processing/2021/12/28/topic-modelling-nmf.html) and [Singular Value Decomposition (SVD)](https://livingdatalab.com/mathematics/linear-algebra/natural-language-processing/2021/12/27/topic-modelling-svd.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 332,
     "referenced_widgets": [
      "eb5912f2b5744dc78e24e155e63a4a8b",
      "49e1bb466033406e930431fc51b62d12",
      "c031bb3be83c4cc4a053b215c2a9ec30"
     ]
    },
    "execution": {
     "iopub.execute_input": "2023-01-08T15:34:37.364649Z",
     "iopub.status.busy": "2023-01-08T15:34:37.364275Z",
     "iopub.status.idle": "2023-01-08T15:35:02.931381Z",
     "shell.execute_reply": "2023-01-08T15:35:02.930269Z",
     "shell.execute_reply.started": "2023-01-08T15:34:37.364617Z"
    },
    "id": "8BkcRDDfP6cy",
    "outputId": "9efbead8-b90a-48e4-cdde-043ab517081d"
   },
   "outputs": [],
   "source": [
    "lda_topic_model = create_model('lda', num_topics=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wx4eqUrUQOtS"
   },
   "source": [
    "So we now have our topic model. Notice we have set 'num_topics=4' - this means the model tries to discover the 4 topics that seem most relevant to the loan applications. We could set this to a different number if we wanted to.\n",
    "\n",
    "Now we have discovered our 4 topics for the loan applications and trained a model to recognise them, we can use this model to predict each of these 4 topics for all our applications using the *assign_model()* function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241,
     "referenced_widgets": [
      "1b039c053bdc4f528de7123df5b9a19a",
      "d4bd5eb1e58947588d31f5cfb195eb4c",
      "5e6ce698b5464b4c834bd8aadf3937d2"
     ]
    },
    "execution": {
     "iopub.execute_input": "2023-01-08T15:35:02.934066Z",
     "iopub.status.busy": "2023-01-08T15:35:02.933287Z",
     "iopub.status.idle": "2023-01-08T15:35:08.418751Z",
     "shell.execute_reply": "2023-01-08T15:35:08.417600Z",
     "shell.execute_reply.started": "2023-01-08T15:35:02.934020Z"
    },
    "id": "G6FZybwoRLfe",
    "outputId": "a7db2f7d-5ba8-4281-d835-e2dc3810f92d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>en</th>\n",
       "      <th>gender</th>\n",
       "      <th>loan_amount</th>\n",
       "      <th>nonpayment</th>\n",
       "      <th>sector</th>\n",
       "      <th>status</th>\n",
       "      <th>Topic_0</th>\n",
       "      <th>Topic_1</th>\n",
       "      <th>Topic_2</th>\n",
       "      <th>Topic_3</th>\n",
       "      <th>Dominant_Topic</th>\n",
       "      <th>Perc_Dominant_Topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dominican Republic</td>\n",
       "      <td>group woman look receive small loan take small loan already second loan group go try expand small business start generate income group representative leader group eduvige lot line child tell child reason want successful want able provide different life show successful well eduvige small business selling shoe avon product plan expand use loan dream success whole group ready new challenge road better live behalf eduvige thank support</td>\n",
       "      <td>F</td>\n",
       "      <td>1225</td>\n",
       "      <td>partner</td>\n",
       "      <td>Retail</td>\n",
       "      <td>0</td>\n",
       "      <td>0.410590</td>\n",
       "      <td>0.044232</td>\n",
       "      <td>0.001707</td>\n",
       "      <td>0.543472</td>\n",
       "      <td>Topic 3</td>\n",
       "      <td>0.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dominican Republic</td>\n",
       "      <td>caminemos walk forward group entrepreneur seek second loan esperanza_international group loan successfully_repaid group hope use additional loan fund business expansion coordinator group sell undergarment community neighboring community use first loan completely repay buy additional product estela able increase return business add inventory estella want use second loan buy undergarment sell customer live mother sister dream improve house live plan use business profit member art juice ice_cream fry food cake sale behalf esperanza group business entrepreneur like thank support</td>\n",
       "      <td>F</td>\n",
       "      <td>1975</td>\n",
       "      <td>lender</td>\n",
       "      <td>Clothing</td>\n",
       "      <td>0</td>\n",
       "      <td>0.608610</td>\n",
       "      <td>0.084845</td>\n",
       "      <td>0.001478</td>\n",
       "      <td>0.305067</td>\n",
       "      <td>Topic 0</td>\n",
       "      <td>0.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dominican Republic</td>\n",
       "      <td>por la_union group people hope start business group look receive loan start small business try increase business group poverty see chance improve life live family representative choose hardworke woman young mother child realize want well life family hope start small business sell clothe people barrio hope someday thrive business able provide family behalf thank support</td>\n",
       "      <td>F</td>\n",
       "      <td>2175</td>\n",
       "      <td>partner</td>\n",
       "      <td>Clothing</td>\n",
       "      <td>0</td>\n",
       "      <td>0.486984</td>\n",
       "      <td>0.012169</td>\n",
       "      <td>0.002022</td>\n",
       "      <td>0.498825</td>\n",
       "      <td>Topic 3</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dominican Republic</td>\n",
       "      <td>vive live group woman look receive first loan young group woman want start change life right away riquena group representative leader group year old also marry child tell kid want able provide good life main reason try start business plan sell use clothe area hope day big clothing store also design clothe motivated person see speak speak spanish creole fluently study english whole group ready next step excited_opportunity behalf thank support</td>\n",
       "      <td>F</td>\n",
       "      <td>1425</td>\n",
       "      <td>partner</td>\n",
       "      <td>Clothing</td>\n",
       "      <td>0</td>\n",
       "      <td>0.289351</td>\n",
       "      <td>0.071750</td>\n",
       "      <td>0.001620</td>\n",
       "      <td>0.637279</td>\n",
       "      <td>Topic 3</td>\n",
       "      <td>0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dominican Republic</td>\n",
       "      <td>cristo vive large group people hope take loan many second loan hope use increase business business range clothing sale salon miline choose group representative due hard work dedication miline hardworke mother young child old year old take first loan start small business sell chicken type food next loan feel increase business greatly start make money support family dream store someday able provide family comfortable life behalf miline thank support</td>\n",
       "      <td>F</td>\n",
       "      <td>4025</td>\n",
       "      <td>partner</td>\n",
       "      <td>Food</td>\n",
       "      <td>0</td>\n",
       "      <td>0.562529</td>\n",
       "      <td>0.032050</td>\n",
       "      <td>0.001672</td>\n",
       "      <td>0.403749</td>\n",
       "      <td>Topic 0</td>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              country  \\\n",
       "0  Dominican Republic   \n",
       "1  Dominican Republic   \n",
       "2  Dominican Republic   \n",
       "3  Dominican Republic   \n",
       "4  Dominican Republic   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      en  \\\n",
       "0                                                                                                                                                    group woman look receive small loan take small loan already second loan group go try expand small business start generate income group representative leader group eduvige lot line child tell child reason want successful want able provide different life show successful well eduvige small business selling shoe avon product plan expand use loan dream success whole group ready new challenge road better live behalf eduvige thank support   \n",
       "1  caminemos walk forward group entrepreneur seek second loan esperanza_international group loan successfully_repaid group hope use additional loan fund business expansion coordinator group sell undergarment community neighboring community use first loan completely repay buy additional product estela able increase return business add inventory estella want use second loan buy undergarment sell customer live mother sister dream improve house live plan use business profit member art juice ice_cream fry food cake sale behalf esperanza group business entrepreneur like thank support   \n",
       "2                                                                                                                                                                                                                    por la_union group people hope start business group look receive loan start small business try increase business group poverty see chance improve life live family representative choose hardworke woman young mother child realize want well life family hope start small business sell clothe people barrio hope someday thrive business able provide family behalf thank support   \n",
       "3                                                                                                                                         vive live group woman look receive first loan young group woman want start change life right away riquena group representative leader group year old also marry child tell kid want able provide good life main reason try start business plan sell use clothe area hope day big clothing store also design clothe motivated person see speak speak spanish creole fluently study english whole group ready next step excited_opportunity behalf thank support   \n",
       "4                                                                                                                                    cristo vive large group people hope take loan many second loan hope use increase business business range clothing sale salon miline choose group representative due hard work dedication miline hardworke mother young child old year old take first loan start small business sell chicken type food next loan feel increase business greatly start make money support family dream store someday able provide family comfortable life behalf miline thank support   \n",
       "\n",
       "  gender  loan_amount nonpayment    sector  status   Topic_0   Topic_1  \\\n",
       "0      F         1225    partner    Retail       0  0.410590  0.044232   \n",
       "1      F         1975     lender  Clothing       0  0.608610  0.084845   \n",
       "2      F         2175    partner  Clothing       0  0.486984  0.012169   \n",
       "3      F         1425    partner  Clothing       0  0.289351  0.071750   \n",
       "4      F         4025    partner      Food       0  0.562529  0.032050   \n",
       "\n",
       "    Topic_2   Topic_3 Dominant_Topic  Perc_Dominant_Topic  \n",
       "0  0.001707  0.543472        Topic 3                 0.54  \n",
       "1  0.001478  0.305067        Topic 0                 0.61  \n",
       "2  0.002022  0.498825        Topic 3                 0.50  \n",
       "3  0.001620  0.637279        Topic 3                 0.64  \n",
       "4  0.001672  0.403749        Topic 0                 0.56  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_results = assign_model(lda_topic_model)\n",
    "lda_results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "07BJZpBgRpDM"
   },
   "source": [
    "We can see the topic model has given us several new things. Firstly, for each loan application it has given us a measure of how much of each of the 4 topics that loan application scores for - which would be a value between 0 and 1. Secondly, for each loan application *Dominant_Topic* tells us which is the most important topic. Finally, *Perc_Dominant_Topic* tells hows how highly that loan application scores for its dominant topic.\n",
    "\n",
    "Lets have a look at how many loan applications are within each of the 4 topics, Pycaret makes this very easy using the *plot_model()* function.\n",
    "\n",
    "**plot_model(lda_topic_model, plot = 'topic_distribution')**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 924
    },
    "execution": {
     "iopub.execute_input": "2023-01-08T15:35:08.420694Z",
     "iopub.status.busy": "2023-01-08T15:35:08.420341Z",
     "iopub.status.idle": "2023-01-08T15:35:14.630324Z",
     "shell.execute_reply": "2023-01-08T15:35:14.629039Z",
     "shell.execute_reply.started": "2023-01-08T15:35:08.420646Z"
    },
    "id": "OXD8LzllJiKS",
    "outputId": "afb7fc22-f6f7-49ca-a245-907144bf8e10"
   },
   "source": [
    "![](https://github.com/pranath/blog/raw/master/images/topic1.png \"Topic Distribution\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we can see that topic 0 covers most of the loan applications, and the other topics much less, with topic 1 having very few examples.\n",
    "\n",
    "#### What are topics actually about ? Word counts\n",
    "\n",
    "How can we find out what these hidden topics are about? We can look at the top 100 words in the text of each topic to give us some idea.\n",
    "\n",
    "Again, Pycaret makes this very easy again using the *plot_model()* function.\n",
    "\n",
    "**plot_model(lda_topic_model, plot = 'frequency', topic_num = 'Topic 0')**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 907
    },
    "execution": {
     "iopub.execute_input": "2023-01-08T15:35:14.632305Z",
     "iopub.status.busy": "2023-01-08T15:35:14.631974Z",
     "iopub.status.idle": "2023-01-08T15:35:21.033377Z",
     "shell.execute_reply": "2023-01-08T15:35:21.032256Z",
     "shell.execute_reply.started": "2023-01-08T15:35:14.632276Z"
    },
    "id": "x29zIrgqJvsG",
    "outputId": "5a1f47a5-1382-4f76-f3ac-e526babef5f8"
   },
   "source": [
    "![](https://github.com/pranath/blog/raw/master/images/topic2.png \"Topic 0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we can see for topic 0 the top 4 words are:\n",
    "\n",
    "- Business\n",
    "- Year\n",
    "- Child\n",
    "- Old\n",
    "\n",
    "You could imagine perhaps the loan applications for this topic might emphasise for example how these loans would have a benefit in a specific year, or would benefit perhaps both older and younger people in the community?\n",
    "\n",
    "Lets have a look at topic 1.\n",
    "\n",
    "**plot_model(lda_topic_model, plot = 'frequency', topic_num = 'Topic 1')**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-08T15:35:21.035193Z",
     "iopub.status.busy": "2023-01-08T15:35:21.034761Z",
     "iopub.status.idle": "2023-01-08T15:35:27.003396Z",
     "shell.execute_reply": "2023-01-08T15:35:27.002271Z",
     "shell.execute_reply.started": "2023-01-08T15:35:21.035161Z"
    }
   },
   "source": [
    "![](https://github.com/pranath/blog/raw/master/images/topic3.png \"Topic 1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we can see for topic 1 the top 4 words are:\n",
    "\n",
    "- Year\n",
    "- Loan\n",
    "- Community\n",
    "- Clinic\n",
    "\n",
    "Perhaps applications under this topic tend to emphasise how the loan might benefit the local community, including healthcare services specifically?\n",
    "\n",
    "Lets examine topic 2.\n",
    "\n",
    "**plot_model(lda_topic_model, plot = 'frequency', topic_num = 'Topic 2')**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-08T15:35:27.005410Z",
     "iopub.status.busy": "2023-01-08T15:35:27.004972Z",
     "iopub.status.idle": "2023-01-08T15:35:32.876180Z",
     "shell.execute_reply": "2023-01-08T15:35:32.868770Z",
     "shell.execute_reply.started": "2023-01-08T15:35:27.005378Z"
    }
   },
   "source": [
    "![](https://github.com/pranath/blog/raw/master/images/topic4.png \"Topic 2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we can see for topic 2 the top 4 words are:\n",
    "\n",
    "- Rice\n",
    "- Farmer\n",
    "- Use\n",
    "- Sector\n",
    "\n",
    "For this topic it might be the case that these loan applications could be for projects more relating to agriculture and food production.\n",
    "\n",
    "Finally lets explore topic 3.\n",
    "\n",
    "**plot_model(lda_topic_model, plot = 'frequency', topic_num = 'Topic 3')**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-08T15:54:29.929034Z",
     "iopub.status.busy": "2023-01-08T15:54:29.928571Z",
     "iopub.status.idle": "2023-01-08T15:54:36.362017Z",
     "shell.execute_reply": "2023-01-08T15:54:36.358465Z",
     "shell.execute_reply.started": "2023-01-08T15:54:29.928988Z"
    }
   },
   "source": [
    "![](https://github.com/pranath/blog/raw/master/images/topic5.png \"Topic 3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The top 4 words for topic 3 are:\n",
    "\n",
    "- Loan\n",
    "- Child\n",
    "- School\n",
    "- Sell\n",
    "\n",
    "You could imagine that perhaps loans under this topic might be related to education and schools, and perhaps also the buying and selling of products for schools or children.\n",
    "\n",
    "So this have given us some good indications as to what the different hidden topics might be about regarding these loan applications. \n",
    "\n",
    "#### How similar or different are topics? Dimensionality Reduction\n",
    "\n",
    "Another thing we can do is look at these loan applicaton texts spatially. We can convert these texts into numbers that represent these texts in terms of their meaning, then plot these numbers as points in 3D space. Each point will then represent an individual loan application, and points that are closer will be applications that are more similar, and points further away applications more different.\n",
    "\n",
    "This general approach of reducing data down into simplified numbers is called *Dimenstionality Reduction* and you can find more about these methods in an [earlier project i did on this](https://github.com/pranath/high_dim_data_vis). We will use a method for this called TSNE.\n",
    "\n",
    "Again Pycaret makes this very easy to do using the *plot_model()* function.\n",
    "\n",
    "**plot_model(lda_topic_model, plot = 'tsne')**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.status.idle": "2023-01-08T15:37:15.023159Z",
     "shell.execute_reply": "2023-01-08T15:37:15.021941Z",
     "shell.execute_reply.started": "2023-01-08T15:35:38.753769Z"
    }
   },
   "source": [
    "![](https://github.com/pranath/blog/raw/master/images/topic6.png \"TSNE Plot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can tell a few things from this view of the loan applications and topics:\n",
    "\n",
    "- All topics seem to be fairly distinct with little overlap\n",
    "- Topic 0, 1 & 3 seem to meet at the edges suggesting there are a few cases that could be in either topic\n",
    "- Topic 2 seems to be the most unique, its the most separated from the others spatially\n",
    "\n",
    "This seems to confirm what we found when we looked at the top words from each topic, topic 2 was about farming and agriculture which really was much more unique compared to the other topics, which had a little more overlap between them.\n",
    "\n",
    "So we can see that topic modelling can be a very useful technique for businesses to provide insight on a group of text that we may know nothing about. It can help us discover hidden categories among these texts, how many are under each of these categories, how closely related or distinct these categories are - and much more. This could easily be applied to customer queries, survey responses, transcripts of customer conversations or emails, and more - to help businesses gain useful insights from their textual data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VjSDDsHgJQ3c"
   },
   "source": [
    "### Sentiment Analysis & Classification - Predict if Amazon product reviews are positive or negative\n",
    "\n",
    "Pycaret also comes with a dataset of amazon product reviews, lets load these and have a look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-08T17:56:25.732262Z",
     "iopub.status.busy": "2023-01-08T17:56:25.731826Z",
     "iopub.status.idle": "2023-01-08T17:56:37.474854Z",
     "shell.execute_reply": "2023-01-08T17:56:37.473715Z",
     "shell.execute_reply.started": "2023-01-08T17:56:25.732227Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pycaret-ts-alpha in /opt/conda/lib/python3.7/site-packages (3.0.0.dev1649017462)\n",
      "Requirement already satisfied: pyod>=0.9.8 in /opt/conda/lib/python3.7/site-packages (from pycaret-ts-alpha) (1.0.7)\n",
      "Requirement already satisfied: scipy~=1.7.3 in /opt/conda/lib/python3.7/site-packages (from pycaret-ts-alpha) (1.7.3)\n",
      "Requirement already satisfied: statsmodels>=0.12.1 in /opt/conda/lib/python3.7/site-packages (from pycaret-ts-alpha) (0.13.2)\n",
      "Requirement already satisfied: sktime==0.10.1 in /opt/conda/lib/python3.7/site-packages (from pycaret-ts-alpha) (0.10.1)\n",
      "Requirement already satisfied: pandas<1.5.0,>=1.3.0 in /opt/conda/lib/python3.7/site-packages (from pycaret-ts-alpha) (1.3.5)\n",
      "Requirement already satisfied: joblib~=1.0.1 in /opt/conda/lib/python3.7/site-packages (from pycaret-ts-alpha) (1.0.1)\n",
      "Requirement already satisfied: pmdarima>=1.8.0 in /opt/conda/lib/python3.7/site-packages (from pycaret-ts-alpha) (2.0.2)\n",
      "Requirement already satisfied: category-encoders>=2.4.0 in /opt/conda/lib/python3.7/site-packages (from pycaret-ts-alpha) (2.5.1.post0)\n",
      "Requirement already satisfied: yellowbrick>=1.4 in /opt/conda/lib/python3.7/site-packages (from pycaret-ts-alpha) (1.5)\n",
      "Requirement already satisfied: scikit-plot>=0.3.7 in /opt/conda/lib/python3.7/site-packages (from pycaret-ts-alpha) (0.3.7)\n",
      "Requirement already satisfied: numba~=0.55.0 in /opt/conda/lib/python3.7/site-packages (from pycaret-ts-alpha) (0.55.2)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in /opt/conda/lib/python3.7/site-packages (from pycaret-ts-alpha) (3.5.3)\n",
      "Requirement already satisfied: numpy~=1.21 in /opt/conda/lib/python3.7/site-packages (from pycaret-ts-alpha) (1.21.6)\n",
      "Requirement already satisfied: kaleido>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from pycaret-ts-alpha) (0.2.1)\n",
      "Requirement already satisfied: imbalanced-learn>=0.8.1 in /opt/conda/lib/python3.7/site-packages (from pycaret-ts-alpha) (0.9.0)\n",
      "Requirement already satisfied: lightgbm>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from pycaret-ts-alpha) (3.3.2)\n",
      "Requirement already satisfied: tbats>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from pycaret-ts-alpha) (1.1.2)\n",
      "Requirement already satisfied: ipython>=5.5.0 in /opt/conda/lib/python3.7/site-packages (from pycaret-ts-alpha) (7.33.0)\n",
      "Requirement already satisfied: plotly>=5.0.0 in /opt/conda/lib/python3.7/site-packages (from pycaret-ts-alpha) (5.11.0)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in /opt/conda/lib/python3.7/site-packages (from pycaret-ts-alpha) (1.0.2)\n",
      "Requirement already satisfied: deprecated>=1.2.13 in /opt/conda/lib/python3.7/site-packages (from sktime==0.10.1->pycaret-ts-alpha) (1.2.13)\n",
      "Requirement already satisfied: patsy>=0.5.1 in /opt/conda/lib/python3.7/site-packages (from category-encoders>=2.4.0->pycaret-ts-alpha) (0.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from imbalanced-learn>=0.8.1->pycaret-ts-alpha) (3.1.0)\n",
      "Requirement already satisfied: backcall in /opt/conda/lib/python3.7/site-packages (from ipython>=5.5.0->pycaret-ts-alpha) (0.2.0)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.7/site-packages (from ipython>=5.5.0->pycaret-ts-alpha) (5.1.1)\n",
      "Requirement already satisfied: setuptools>=18.5 in /opt/conda/lib/python3.7/site-packages (from ipython>=5.5.0->pycaret-ts-alpha) (59.8.0)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.7/site-packages (from ipython>=5.5.0->pycaret-ts-alpha) (4.8.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from ipython>=5.5.0->pycaret-ts-alpha) (3.0.30)\n",
      "Requirement already satisfied: traitlets>=4.2 in /opt/conda/lib/python3.7/site-packages (from ipython>=5.5.0->pycaret-ts-alpha) (5.3.0)\n",
      "Requirement already satisfied: pygments in /opt/conda/lib/python3.7/site-packages (from ipython>=5.5.0->pycaret-ts-alpha) (2.12.0)\n",
      "Requirement already satisfied: matplotlib-inline in /opt/conda/lib/python3.7/site-packages (from ipython>=5.5.0->pycaret-ts-alpha) (0.1.3)\n",
      "Requirement already satisfied: pickleshare in /opt/conda/lib/python3.7/site-packages (from ipython>=5.5.0->pycaret-ts-alpha) (0.7.5)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.7/site-packages (from ipython>=5.5.0->pycaret-ts-alpha) (0.18.1)\n",
      "Requirement already satisfied: wheel in /opt/conda/lib/python3.7/site-packages (from lightgbm>=3.0.0->pycaret-ts-alpha) (0.37.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=3.3.0->pycaret-ts-alpha) (0.11.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=3.3.0->pycaret-ts-alpha) (9.1.1)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=3.3.0->pycaret-ts-alpha) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=3.3.0->pycaret-ts-alpha) (2.8.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=3.3.0->pycaret-ts-alpha) (4.33.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=3.3.0->pycaret-ts-alpha) (1.4.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=3.3.0->pycaret-ts-alpha) (22.0)\n",
      "Requirement already satisfied: llvmlite<0.39,>=0.38.0rc1 in /opt/conda/lib/python3.7/site-packages (from numba~=0.55.0->pycaret-ts-alpha) (0.38.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas<1.5.0,>=1.3.0->pycaret-ts-alpha) (2022.1)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /opt/conda/lib/python3.7/site-packages (from plotly>=5.0.0->pycaret-ts-alpha) (8.0.1)\n",
      "Requirement already satisfied: urllib3 in /opt/conda/lib/python3.7/site-packages (from pmdarima>=1.8.0->pycaret-ts-alpha) (1.26.13)\n",
      "Requirement already satisfied: Cython!=0.29.18,!=0.29.31,>=0.29 in /opt/conda/lib/python3.7/site-packages (from pmdarima>=1.8.0->pycaret-ts-alpha) (0.29.32)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from pyod>=0.9.8->pycaret-ts-alpha) (1.15.0)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /opt/conda/lib/python3.7/site-packages (from deprecated>=1.2.13->sktime==0.10.1->pycaret-ts-alpha) (1.12.1)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /opt/conda/lib/python3.7/site-packages (from jedi>=0.16->ipython>=5.5.0->pycaret-ts-alpha) (0.8.3)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib>=3.3.0->pycaret-ts-alpha) (4.1.1)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.7/site-packages (from pexpect>4.3->ipython>=5.5.0->pycaret-ts-alpha) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.7/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=5.5.0->pycaret-ts-alpha) (0.2.5)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "#| include: false\n",
    "!pip install pycaret-ts-alpha \n",
    "from pycaret.datasets import get_data\n",
    "from pycaret.nlp import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('max_colwidth', 800)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def split_data(df):\n",
    "    train = df.sample(frac=0.999)\n",
    "    test = df.drop(train.index)\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-08T17:06:06.979447Z",
     "iopub.status.busy": "2023-01-08T17:06:06.978990Z",
     "iopub.status.idle": "2023-01-08T17:06:09.022516Z",
     "shell.execute_reply": "2023-01-08T17:06:09.021589Z",
     "shell.execute_reply.started": "2023-01-08T17:06:06.979403Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>Positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This is a one of the best apps acording to a bunch of people and I agree it has bombs eggs pigs TNT king pigs and realustic stuff</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This is a pretty good version of the game for being free. There are LOTS of different levels to play. My kids enjoy it a lot too.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>this is a really cool game. there are a bunch of levels and you can find golden eggs. super fun.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This is a silly game and can be frustrating, but lots of fun and definitely recommend just as a fun time.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This is a terrific game on any pad. Hrs of fun.  My grandkids love it. Great entertainment when waiting in long lines</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                          reviewText  \\\n",
       "0  This is a one of the best apps acording to a bunch of people and I agree it has bombs eggs pigs TNT king pigs and realustic stuff   \n",
       "1  This is a pretty good version of the game for being free. There are LOTS of different levels to play. My kids enjoy it a lot too.   \n",
       "2                                   this is a really cool game. there are a bunch of levels and you can find golden eggs. super fun.   \n",
       "3                          This is a silly game and can be frustrating, but lots of fun and definitely recommend just as a fun time.   \n",
       "4              This is a terrific game on any pad. Hrs of fun.  My grandkids love it. Great entertainment when waiting in long lines   \n",
       "\n",
       "   Positive  \n",
       "0         1  \n",
       "1         1  \n",
       "2         1  \n",
       "3         1  \n",
       "4         1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "amazon_reviews = get_data('amazon')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we can see we have just a column for the text of the review, and another called 'Positive' which is a label to indicate if the review was positive or not i.e. 1 or 0. Let's see how many reviews we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-01-08T17:05:24.234589Z",
     "iopub.status.idle": "2023-01-08T17:05:24.235182Z",
     "shell.execute_reply": "2023-01-08T17:05:24.235012Z",
     "shell.execute_reply.started": "2023-01-08T17:05:24.234992Z"
    }
   },
   "outputs": [],
   "source": [
    "amazon_reviews.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have around 20,000 reviews. Lets get a count of how many positive and negative reviews we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-08T17:06:09.024391Z",
     "iopub.status.busy": "2023-01-08T17:06:09.023802Z",
     "iopub.status.idle": "2023-01-08T17:06:09.038302Z",
     "shell.execute_reply": "2023-01-08T17:06:09.037200Z",
     "shell.execute_reply.started": "2023-01-08T17:06:09.024355Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    15233\n",
       "0     4767\n",
       "Name: Positive, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon_reviews['Positive'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So around 75% of the reviews are positive, and 25% negative reviews.\n",
    "\n",
    "To create a classification model, we will first need to create some *features*. These are essentially numbers that represent something we are trying to predict, so given we are trying to predict if a review is positive or negative, these features need to represent something about the text that will help us predict that.\n",
    "\n",
    "There are many methods of turning text into numeric features, but we are actually going to use *topic modelling* to create some topics to describe our text, and use these as features to help our classfier model to predict positive or negative sentiment.\n",
    "\n",
    "Lets set up and process our review data for topic modelling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-08T17:06:09.040940Z",
     "iopub.status.busy": "2023-01-08T17:06:09.040532Z",
     "iopub.status.idle": "2023-01-08T17:07:44.670621Z",
     "shell.execute_reply": "2023-01-08T17:07:44.669515Z",
     "shell.execute_reply.started": "2023-01-08T17:06:09.040906Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_0c790_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"col_heading level0 col0\" >Description</th>\n",
       "      <th class=\"col_heading level0 col1\" >Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_0c790_row0_col0\" class=\"data row0 col0\" >session_id</td>\n",
       "      <td id=\"T_0c790_row0_col1\" class=\"data row0 col1\" >497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_0c790_row1_col0\" class=\"data row1 col0\" >Documents</td>\n",
       "      <td id=\"T_0c790_row1_col1\" class=\"data row1 col1\" >20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_0c790_row2_col0\" class=\"data row2 col0\" >Vocab Size</td>\n",
       "      <td id=\"T_0c790_row2_col1\" class=\"data row2 col1\" >12771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_0c790_row3_col0\" class=\"data row3 col0\" >Custom Stopwords</td>\n",
       "      <td id=\"T_0c790_row3_col1\" class=\"data row3 col1\" >False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f4914ee0f50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 28s, sys: 1.51 s, total: 1min 30s\n",
      "Wall time: 1min 35s\n"
     ]
    }
   ],
   "source": [
    "%time experiment2 = setup(data=amazon_reviews, target='reviewText')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before we will create a topic model to create some new categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-08T17:07:44.673166Z",
     "iopub.status.busy": "2023-01-08T17:07:44.672559Z",
     "iopub.status.idle": "2023-01-08T17:08:25.969094Z",
     "shell.execute_reply": "2023-01-08T17:08:25.967875Z",
     "shell.execute_reply.started": "2023-01-08T17:07:44.673134Z"
    }
   },
   "outputs": [],
   "source": [
    "lda_topic_model2 = create_model('lda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now predict these categories for our reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-08T17:08:25.972672Z",
     "iopub.status.busy": "2023-01-08T17:08:25.971176Z",
     "iopub.status.idle": "2023-01-08T17:08:40.643167Z",
     "shell.execute_reply": "2023-01-08T17:08:40.642050Z",
     "shell.execute_reply.started": "2023-01-08T17:08:25.972602Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>Positive</th>\n",
       "      <th>Topic_0</th>\n",
       "      <th>Topic_1</th>\n",
       "      <th>Topic_2</th>\n",
       "      <th>Topic_3</th>\n",
       "      <th>Dominant_Topic</th>\n",
       "      <th>Perc_Dominant_Topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>good app acorde bunch people agree bomb egg pig king pig realustic stuff</td>\n",
       "      <td>1</td>\n",
       "      <td>0.081603</td>\n",
       "      <td>0.309925</td>\n",
       "      <td>0.227132</td>\n",
       "      <td>0.381340</td>\n",
       "      <td>Topic 3</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pretty good version game free lot different level play kid enjoy lot</td>\n",
       "      <td>1</td>\n",
       "      <td>0.070119</td>\n",
       "      <td>0.200039</td>\n",
       "      <td>0.249249</td>\n",
       "      <td>0.480594</td>\n",
       "      <td>Topic 3</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>really cool game bunch level find golden egg super fun</td>\n",
       "      <td>1</td>\n",
       "      <td>0.116654</td>\n",
       "      <td>0.263965</td>\n",
       "      <td>0.197222</td>\n",
       "      <td>0.422159</td>\n",
       "      <td>Topic 3</td>\n",
       "      <td>0.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>silly game frustrating lot fun definitely recommend fun time</td>\n",
       "      <td>1</td>\n",
       "      <td>0.077698</td>\n",
       "      <td>0.148072</td>\n",
       "      <td>0.309584</td>\n",
       "      <td>0.464646</td>\n",
       "      <td>Topic 3</td>\n",
       "      <td>0.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>terrific game pad fun grandkid love great entertainment wait long line</td>\n",
       "      <td>1</td>\n",
       "      <td>0.072539</td>\n",
       "      <td>0.138212</td>\n",
       "      <td>0.424701</td>\n",
       "      <td>0.364547</td>\n",
       "      <td>Topic 2</td>\n",
       "      <td>0.42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                 reviewText  \\\n",
       "0  good app acorde bunch people agree bomb egg pig king pig realustic stuff   \n",
       "1      pretty good version game free lot different level play kid enjoy lot   \n",
       "2                    really cool game bunch level find golden egg super fun   \n",
       "3              silly game frustrating lot fun definitely recommend fun time   \n",
       "4    terrific game pad fun grandkid love great entertainment wait long line   \n",
       "\n",
       "   Positive   Topic_0   Topic_1   Topic_2   Topic_3 Dominant_Topic  \\\n",
       "0         1  0.081603  0.309925  0.227132  0.381340        Topic 3   \n",
       "1         1  0.070119  0.200039  0.249249  0.480594        Topic 3   \n",
       "2         1  0.116654  0.263965  0.197222  0.422159        Topic 3   \n",
       "3         1  0.077698  0.148072  0.309584  0.464646        Topic 3   \n",
       "4         1  0.072539  0.138212  0.424701  0.364547        Topic 2   \n",
       "\n",
       "   Perc_Dominant_Topic  \n",
       "0                 0.38  \n",
       "1                 0.48  \n",
       "2                 0.42  \n",
       "3                 0.46  \n",
       "4                 0.42  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_results = assign_model(lda_topic_model2)\n",
    "lda_results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So our data is almost ready. Our classification model does'nt need the text data now as we have represented the text using values for our new categories created by our topic model. We also don't need the Dominant or Perc topic fields, so lets drop these columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-08T17:12:03.209740Z",
     "iopub.status.busy": "2023-01-08T17:12:03.209315Z",
     "iopub.status.idle": "2023-01-08T17:12:03.230596Z",
     "shell.execute_reply": "2023-01-08T17:12:03.229345Z",
     "shell.execute_reply.started": "2023-01-08T17:12:03.209707Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Positive</th>\n",
       "      <th>Topic_0</th>\n",
       "      <th>Topic_1</th>\n",
       "      <th>Topic_2</th>\n",
       "      <th>Topic_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.081603</td>\n",
       "      <td>0.309925</td>\n",
       "      <td>0.227132</td>\n",
       "      <td>0.381340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.070119</td>\n",
       "      <td>0.200039</td>\n",
       "      <td>0.249249</td>\n",
       "      <td>0.480594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.116654</td>\n",
       "      <td>0.263965</td>\n",
       "      <td>0.197222</td>\n",
       "      <td>0.422159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.077698</td>\n",
       "      <td>0.148072</td>\n",
       "      <td>0.309584</td>\n",
       "      <td>0.464646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.072539</td>\n",
       "      <td>0.138212</td>\n",
       "      <td>0.424701</td>\n",
       "      <td>0.364547</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Positive   Topic_0   Topic_1   Topic_2   Topic_3\n",
       "0         1  0.081603  0.309925  0.227132  0.381340\n",
       "1         1  0.070119  0.200039  0.249249  0.480594\n",
       "2         1  0.116654  0.263965  0.197222  0.422159\n",
       "3         1  0.077698  0.148072  0.309584  0.464646\n",
       "4         1  0.072539  0.138212  0.424701  0.364547"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_results.drop(['reviewText', 'Dominant_Topic', 'Perc_Dominant_Topic'], axis=1, inplace=True)\n",
    "lda_results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's common practice when training classification models to split the data, some to train the model on, and some to test the model later. Let's split this data of 20,000 reviews, to give is a small test data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-08T17:56:37.477660Z",
     "iopub.status.busy": "2023-01-08T17:56:37.477287Z",
     "iopub.status.idle": "2023-01-08T17:56:37.492476Z",
     "shell.execute_reply": "2023-01-08T17:56:37.491561Z",
     "shell.execute_reply.started": "2023-01-08T17:56:37.477611Z"
    }
   },
   "outputs": [],
   "source": [
    "train, test = split_data(lda_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-08T17:27:31.371159Z",
     "iopub.status.busy": "2023-01-08T17:27:31.370152Z",
     "iopub.status.idle": "2023-01-08T17:27:31.376312Z",
     "shell.execute_reply": "2023-01-08T17:27:31.375120Z",
     "shell.execute_reply.started": "2023-01-08T17:27:31.371106Z"
    }
   },
   "outputs": [],
   "source": [
    "#| include: false\n",
    "from pycaret.classification import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now set the data up, this time to prepare it for classification model training using our training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-08T17:27:31.377794Z",
     "iopub.status.busy": "2023-01-08T17:27:31.377437Z",
     "iopub.status.idle": "2023-01-08T17:27:31.656789Z",
     "shell.execute_reply": "2023-01-08T17:27:31.655560Z",
     "shell.execute_reply.started": "2023-01-08T17:27:31.377762Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_e05ea_row7_col1 {\n",
       "  background-color: lightgreen;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_e05ea_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >Description</th>\n",
       "      <th class=\"col_heading level0 col1\" >Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_e05ea_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_e05ea_row0_col0\" class=\"data row0 col0\" >Session id</td>\n",
       "      <td id=\"T_e05ea_row0_col1\" class=\"data row0 col1\" >227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e05ea_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_e05ea_row1_col0\" class=\"data row1 col0\" >Target</td>\n",
       "      <td id=\"T_e05ea_row1_col1\" class=\"data row1 col1\" >Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e05ea_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_e05ea_row2_col0\" class=\"data row2 col0\" >Target type</td>\n",
       "      <td id=\"T_e05ea_row2_col1\" class=\"data row2 col1\" >classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e05ea_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_e05ea_row3_col0\" class=\"data row3 col0\" >Data shape</td>\n",
       "      <td id=\"T_e05ea_row3_col1\" class=\"data row3 col1\" >(19980, 5)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e05ea_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_e05ea_row4_col0\" class=\"data row4 col0\" >Train data shape</td>\n",
       "      <td id=\"T_e05ea_row4_col1\" class=\"data row4 col1\" >(13985, 5)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e05ea_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_e05ea_row5_col0\" class=\"data row5 col0\" >Test data shape</td>\n",
       "      <td id=\"T_e05ea_row5_col1\" class=\"data row5 col1\" >(5995, 5)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e05ea_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_e05ea_row6_col0\" class=\"data row6 col0\" >Numeric features</td>\n",
       "      <td id=\"T_e05ea_row6_col1\" class=\"data row6 col1\" >4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e05ea_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_e05ea_row7_col0\" class=\"data row7 col0\" >Preprocess</td>\n",
       "      <td id=\"T_e05ea_row7_col1\" class=\"data row7 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e05ea_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_e05ea_row8_col0\" class=\"data row8 col0\" >Imputation type</td>\n",
       "      <td id=\"T_e05ea_row8_col1\" class=\"data row8 col1\" >simple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e05ea_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_e05ea_row9_col0\" class=\"data row9 col0\" >Numeric imputation</td>\n",
       "      <td id=\"T_e05ea_row9_col1\" class=\"data row9 col1\" >mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e05ea_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_e05ea_row10_col0\" class=\"data row10 col0\" >Categorical imputation</td>\n",
       "      <td id=\"T_e05ea_row10_col1\" class=\"data row10 col1\" >constant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e05ea_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_e05ea_row11_col0\" class=\"data row11 col0\" >Fold Generator</td>\n",
       "      <td id=\"T_e05ea_row11_col1\" class=\"data row11 col1\" >StratifiedKFold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e05ea_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_e05ea_row12_col0\" class=\"data row12 col0\" >Fold Number</td>\n",
       "      <td id=\"T_e05ea_row12_col1\" class=\"data row12 col1\" >10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e05ea_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_e05ea_row13_col0\" class=\"data row13 col0\" >CPU Jobs</td>\n",
       "      <td id=\"T_e05ea_row13_col1\" class=\"data row13 col1\" >-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e05ea_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_e05ea_row14_col0\" class=\"data row14 col0\" >Log Experiment</td>\n",
       "      <td id=\"T_e05ea_row14_col1\" class=\"data row14 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e05ea_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_e05ea_row15_col0\" class=\"data row15 col0\" >Experiment Name</td>\n",
       "      <td id=\"T_e05ea_row15_col1\" class=\"data row15 col1\" >clf-default-name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e05ea_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_e05ea_row16_col0\" class=\"data row16 col0\" >USI</td>\n",
       "      <td id=\"T_e05ea_row16_col1\" class=\"data row16 col1\" >22b0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f491a486b50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 259 ms, sys: 8.99 ms, total: 267 ms\n",
      "Wall time: 269 ms\n"
     ]
    }
   ],
   "source": [
    "%time experiment3 = setup(data=train, target='Positive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now train a range of different models to predict the positive or negative sentiment, and choose the best one.\n",
    "\n",
    "Again Pycaret makes this very easy to do something that would normally take many lines of code to do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-08T17:44:55.545898Z",
     "iopub.status.busy": "2023-01-08T17:44:55.545417Z",
     "iopub.status.idle": "2023-01-08T17:46:54.662918Z",
     "shell.execute_reply": "2023-01-08T17:46:54.661520Z",
     "shell.execute_reply.started": "2023-01-08T17:44:55.545850Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_62f96_ th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_62f96_row0_col0, #T_62f96_row0_col2, #T_62f96_row0_col4, #T_62f96_row0_col6, #T_62f96_row0_col7, #T_62f96_row1_col0, #T_62f96_row1_col1, #T_62f96_row1_col2, #T_62f96_row1_col3, #T_62f96_row1_col4, #T_62f96_row1_col5, #T_62f96_row1_col6, #T_62f96_row1_col7, #T_62f96_row2_col0, #T_62f96_row2_col1, #T_62f96_row2_col2, #T_62f96_row2_col3, #T_62f96_row2_col4, #T_62f96_row2_col5, #T_62f96_row2_col6, #T_62f96_row2_col7, #T_62f96_row3_col0, #T_62f96_row3_col1, #T_62f96_row3_col2, #T_62f96_row3_col3, #T_62f96_row3_col4, #T_62f96_row3_col5, #T_62f96_row3_col6, #T_62f96_row3_col7, #T_62f96_row4_col0, #T_62f96_row4_col1, #T_62f96_row4_col3, #T_62f96_row4_col4, #T_62f96_row4_col5, #T_62f96_row4_col6, #T_62f96_row4_col7, #T_62f96_row5_col0, #T_62f96_row5_col1, #T_62f96_row5_col2, #T_62f96_row5_col3, #T_62f96_row5_col4, #T_62f96_row5_col5, #T_62f96_row5_col6, #T_62f96_row5_col7, #T_62f96_row6_col0, #T_62f96_row6_col1, #T_62f96_row6_col2, #T_62f96_row6_col3, #T_62f96_row6_col4, #T_62f96_row6_col5, #T_62f96_row6_col6, #T_62f96_row6_col7, #T_62f96_row7_col0, #T_62f96_row7_col1, #T_62f96_row7_col2, #T_62f96_row7_col3, #T_62f96_row7_col4, #T_62f96_row7_col5, #T_62f96_row7_col6, #T_62f96_row7_col7, #T_62f96_row8_col0, #T_62f96_row8_col1, #T_62f96_row8_col2, #T_62f96_row8_col3, #T_62f96_row8_col4, #T_62f96_row8_col5, #T_62f96_row8_col6, #T_62f96_row9_col0, #T_62f96_row9_col1, #T_62f96_row9_col2, #T_62f96_row9_col3, #T_62f96_row9_col4, #T_62f96_row9_col5, #T_62f96_row9_col6, #T_62f96_row9_col7, #T_62f96_row10_col0, #T_62f96_row10_col1, #T_62f96_row10_col2, #T_62f96_row10_col3, #T_62f96_row10_col4, #T_62f96_row10_col5, #T_62f96_row10_col6, #T_62f96_row10_col7, #T_62f96_row11_col0, #T_62f96_row11_col1, #T_62f96_row11_col2, #T_62f96_row11_col3, #T_62f96_row11_col4, #T_62f96_row11_col5, #T_62f96_row11_col7, #T_62f96_row12_col0, #T_62f96_row12_col1, #T_62f96_row12_col2, #T_62f96_row12_col3, #T_62f96_row12_col4, #T_62f96_row12_col5, #T_62f96_row12_col6, #T_62f96_row12_col7, #T_62f96_row13_col0, #T_62f96_row13_col1, #T_62f96_row13_col2, #T_62f96_row13_col3, #T_62f96_row13_col4, #T_62f96_row13_col5, #T_62f96_row13_col6, #T_62f96_row13_col7, #T_62f96_row14_col0, #T_62f96_row14_col1, #T_62f96_row14_col2, #T_62f96_row14_col3, #T_62f96_row14_col5, #T_62f96_row14_col6, #T_62f96_row14_col7 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_62f96_row0_col1, #T_62f96_row0_col3, #T_62f96_row0_col5, #T_62f96_row4_col2, #T_62f96_row8_col7, #T_62f96_row11_col6, #T_62f96_row14_col4 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "}\n",
       "#T_62f96_row0_col8, #T_62f96_row1_col8, #T_62f96_row3_col8, #T_62f96_row4_col8, #T_62f96_row5_col8, #T_62f96_row6_col8, #T_62f96_row7_col8, #T_62f96_row8_col8, #T_62f96_row9_col8, #T_62f96_row10_col8, #T_62f96_row11_col8, #T_62f96_row12_col8, #T_62f96_row13_col8, #T_62f96_row14_col8 {\n",
       "  text-align: left;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "#T_62f96_row2_col8 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_62f96_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th class=\"col_heading level0 col1\" >Accuracy</th>\n",
       "      <th class=\"col_heading level0 col2\" >AUC</th>\n",
       "      <th class=\"col_heading level0 col3\" >Recall</th>\n",
       "      <th class=\"col_heading level0 col4\" >Prec.</th>\n",
       "      <th class=\"col_heading level0 col5\" >F1</th>\n",
       "      <th class=\"col_heading level0 col6\" >Kappa</th>\n",
       "      <th class=\"col_heading level0 col7\" >MCC</th>\n",
       "      <th class=\"col_heading level0 col8\" >TT (Sec)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_62f96_level0_row0\" class=\"row_heading level0 row0\" >svm</th>\n",
       "      <td id=\"T_62f96_row0_col0\" class=\"data row0 col0\" >SVM - Linear Kernel</td>\n",
       "      <td id=\"T_62f96_row0_col1\" class=\"data row0 col1\" >0.7618</td>\n",
       "      <td id=\"T_62f96_row0_col2\" class=\"data row0 col2\" >0.0000</td>\n",
       "      <td id=\"T_62f96_row0_col3\" class=\"data row0 col3\" >1.0000</td>\n",
       "      <td id=\"T_62f96_row0_col4\" class=\"data row0 col4\" >0.7618</td>\n",
       "      <td id=\"T_62f96_row0_col5\" class=\"data row0 col5\" >0.8648</td>\n",
       "      <td id=\"T_62f96_row0_col6\" class=\"data row0 col6\" >0.0000</td>\n",
       "      <td id=\"T_62f96_row0_col7\" class=\"data row0 col7\" >0.0000</td>\n",
       "      <td id=\"T_62f96_row0_col8\" class=\"data row0 col8\" >0.0220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_62f96_level0_row1\" class=\"row_heading level0 row1\" >lr</th>\n",
       "      <td id=\"T_62f96_row1_col0\" class=\"data row1 col0\" >Logistic Regression</td>\n",
       "      <td id=\"T_62f96_row1_col1\" class=\"data row1 col1\" >0.7617</td>\n",
       "      <td id=\"T_62f96_row1_col2\" class=\"data row1 col2\" >0.6472</td>\n",
       "      <td id=\"T_62f96_row1_col3\" class=\"data row1 col3\" >0.9981</td>\n",
       "      <td id=\"T_62f96_row1_col4\" class=\"data row1 col4\" >0.7625</td>\n",
       "      <td id=\"T_62f96_row1_col5\" class=\"data row1 col5\" >0.8645</td>\n",
       "      <td id=\"T_62f96_row1_col6\" class=\"data row1 col6\" >0.0053</td>\n",
       "      <td id=\"T_62f96_row1_col7\" class=\"data row1 col7\" >0.0294</td>\n",
       "      <td id=\"T_62f96_row1_col8\" class=\"data row1 col8\" >0.0290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_62f96_level0_row2\" class=\"row_heading level0 row2\" >ridge</th>\n",
       "      <td id=\"T_62f96_row2_col0\" class=\"data row2 col0\" >Ridge Classifier</td>\n",
       "      <td id=\"T_62f96_row2_col1\" class=\"data row2 col1\" >0.7617</td>\n",
       "      <td id=\"T_62f96_row2_col2\" class=\"data row2 col2\" >0.0000</td>\n",
       "      <td id=\"T_62f96_row2_col3\" class=\"data row2 col3\" >0.9992</td>\n",
       "      <td id=\"T_62f96_row2_col4\" class=\"data row2 col4\" >0.7620</td>\n",
       "      <td id=\"T_62f96_row2_col5\" class=\"data row2 col5\" >0.8646</td>\n",
       "      <td id=\"T_62f96_row2_col6\" class=\"data row2 col6\" >0.0019</td>\n",
       "      <td id=\"T_62f96_row2_col7\" class=\"data row2 col7\" >0.0150</td>\n",
       "      <td id=\"T_62f96_row2_col8\" class=\"data row2 col8\" >0.0160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_62f96_level0_row3\" class=\"row_heading level0 row3\" >lda</th>\n",
       "      <td id=\"T_62f96_row3_col0\" class=\"data row3 col0\" >Linear Discriminant Analysis</td>\n",
       "      <td id=\"T_62f96_row3_col1\" class=\"data row3 col1\" >0.7616</td>\n",
       "      <td id=\"T_62f96_row3_col2\" class=\"data row3 col2\" >0.6474</td>\n",
       "      <td id=\"T_62f96_row3_col3\" class=\"data row3 col3\" >0.9948</td>\n",
       "      <td id=\"T_62f96_row3_col4\" class=\"data row3 col4\" >0.7637</td>\n",
       "      <td id=\"T_62f96_row3_col5\" class=\"data row3 col5\" >0.8641</td>\n",
       "      <td id=\"T_62f96_row3_col6\" class=\"data row3 col6\" >0.0156</td>\n",
       "      <td id=\"T_62f96_row3_col7\" class=\"data row3 col7\" >0.0512</td>\n",
       "      <td id=\"T_62f96_row3_col8\" class=\"data row3 col8\" >0.0210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_62f96_level0_row4\" class=\"row_heading level0 row4\" >gbc</th>\n",
       "      <td id=\"T_62f96_row4_col0\" class=\"data row4 col0\" >Gradient Boosting Classifier</td>\n",
       "      <td id=\"T_62f96_row4_col1\" class=\"data row4 col1\" >0.7610</td>\n",
       "      <td id=\"T_62f96_row4_col2\" class=\"data row4 col2\" >0.6559</td>\n",
       "      <td id=\"T_62f96_row4_col3\" class=\"data row4 col3\" >0.9965</td>\n",
       "      <td id=\"T_62f96_row4_col4\" class=\"data row4 col4\" >0.7626</td>\n",
       "      <td id=\"T_62f96_row4_col5\" class=\"data row4 col5\" >0.8640</td>\n",
       "      <td id=\"T_62f96_row4_col6\" class=\"data row4 col6\" >0.0065</td>\n",
       "      <td id=\"T_62f96_row4_col7\" class=\"data row4 col7\" >0.0282</td>\n",
       "      <td id=\"T_62f96_row4_col8\" class=\"data row4 col8\" >0.8190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_62f96_level0_row5\" class=\"row_heading level0 row5\" >ada</th>\n",
       "      <td id=\"T_62f96_row5_col0\" class=\"data row5 col0\" >Ada Boost Classifier</td>\n",
       "      <td id=\"T_62f96_row5_col1\" class=\"data row5 col1\" >0.7602</td>\n",
       "      <td id=\"T_62f96_row5_col2\" class=\"data row5 col2\" >0.6476</td>\n",
       "      <td id=\"T_62f96_row5_col3\" class=\"data row5 col3\" >0.9937</td>\n",
       "      <td id=\"T_62f96_row5_col4\" class=\"data row5 col4\" >0.7631</td>\n",
       "      <td id=\"T_62f96_row5_col5\" class=\"data row5 col5\" >0.8633</td>\n",
       "      <td id=\"T_62f96_row5_col6\" class=\"data row5 col6\" >0.0103</td>\n",
       "      <td id=\"T_62f96_row5_col7\" class=\"data row5 col7\" >0.0318</td>\n",
       "      <td id=\"T_62f96_row5_col8\" class=\"data row5 col8\" >0.2600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_62f96_level0_row6\" class=\"row_heading level0 row6\" >catboost</th>\n",
       "      <td id=\"T_62f96_row6_col0\" class=\"data row6 col0\" >CatBoost Classifier</td>\n",
       "      <td id=\"T_62f96_row6_col1\" class=\"data row6 col1\" >0.7600</td>\n",
       "      <td id=\"T_62f96_row6_col2\" class=\"data row6 col2\" >0.6468</td>\n",
       "      <td id=\"T_62f96_row6_col3\" class=\"data row6 col3\" >0.9868</td>\n",
       "      <td id=\"T_62f96_row6_col4\" class=\"data row6 col4\" >0.7658</td>\n",
       "      <td id=\"T_62f96_row6_col5\" class=\"data row6 col5\" >0.8624</td>\n",
       "      <td id=\"T_62f96_row6_col6\" class=\"data row6 col6\" >0.0316</td>\n",
       "      <td id=\"T_62f96_row6_col7\" class=\"data row6 col7\" >0.0690</td>\n",
       "      <td id=\"T_62f96_row6_col8\" class=\"data row6 col8\" >6.6620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_62f96_level0_row7\" class=\"row_heading level0 row7\" >lightgbm</th>\n",
       "      <td id=\"T_62f96_row7_col0\" class=\"data row7 col0\" >Light Gradient Boosting Machine</td>\n",
       "      <td id=\"T_62f96_row7_col1\" class=\"data row7 col1\" >0.7583</td>\n",
       "      <td id=\"T_62f96_row7_col2\" class=\"data row7 col2\" >0.6380</td>\n",
       "      <td id=\"T_62f96_row7_col3\" class=\"data row7 col3\" >0.9829</td>\n",
       "      <td id=\"T_62f96_row7_col4\" class=\"data row7 col4\" >0.7661</td>\n",
       "      <td id=\"T_62f96_row7_col5\" class=\"data row7 col5\" >0.8610</td>\n",
       "      <td id=\"T_62f96_row7_col6\" class=\"data row7 col6\" >0.0332</td>\n",
       "      <td id=\"T_62f96_row7_col7\" class=\"data row7 col7\" >0.0675</td>\n",
       "      <td id=\"T_62f96_row7_col8\" class=\"data row7 col8\" >0.1940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_62f96_level0_row8\" class=\"row_heading level0 row8\" >nb</th>\n",
       "      <td id=\"T_62f96_row8_col0\" class=\"data row8 col0\" >Naive Bayes</td>\n",
       "      <td id=\"T_62f96_row8_col1\" class=\"data row8 col1\" >0.7540</td>\n",
       "      <td id=\"T_62f96_row8_col2\" class=\"data row8 col2\" >0.6470</td>\n",
       "      <td id=\"T_62f96_row8_col3\" class=\"data row8 col3\" >0.9608</td>\n",
       "      <td id=\"T_62f96_row8_col4\" class=\"data row8 col4\" >0.7720</td>\n",
       "      <td id=\"T_62f96_row8_col5\" class=\"data row8 col5\" >0.8561</td>\n",
       "      <td id=\"T_62f96_row8_col6\" class=\"data row8 col6\" >0.0727</td>\n",
       "      <td id=\"T_62f96_row8_col7\" class=\"data row8 col7\" >0.1019</td>\n",
       "      <td id=\"T_62f96_row8_col8\" class=\"data row8 col8\" >0.0250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_62f96_level0_row9\" class=\"row_heading level0 row9\" >xgboost</th>\n",
       "      <td id=\"T_62f96_row9_col0\" class=\"data row9 col0\" >Extreme Gradient Boosting</td>\n",
       "      <td id=\"T_62f96_row9_col1\" class=\"data row9 col1\" >0.7495</td>\n",
       "      <td id=\"T_62f96_row9_col2\" class=\"data row9 col2\" >0.6231</td>\n",
       "      <td id=\"T_62f96_row9_col3\" class=\"data row9 col3\" >0.9590</td>\n",
       "      <td id=\"T_62f96_row9_col4\" class=\"data row9 col4\" >0.7692</td>\n",
       "      <td id=\"T_62f96_row9_col5\" class=\"data row9 col5\" >0.8537</td>\n",
       "      <td id=\"T_62f96_row9_col6\" class=\"data row9 col6\" >0.0528</td>\n",
       "      <td id=\"T_62f96_row9_col7\" class=\"data row9 col7\" >0.0750</td>\n",
       "      <td id=\"T_62f96_row9_col8\" class=\"data row9 col8\" >0.8160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_62f96_level0_row10\" class=\"row_heading level0 row10\" >qda</th>\n",
       "      <td id=\"T_62f96_row10_col0\" class=\"data row10 col0\" >Quadratic Discriminant Analysis</td>\n",
       "      <td id=\"T_62f96_row10_col1\" class=\"data row10 col1\" >0.7439</td>\n",
       "      <td id=\"T_62f96_row10_col2\" class=\"data row10 col2\" >0.6441</td>\n",
       "      <td id=\"T_62f96_row10_col3\" class=\"data row10 col3\" >0.9504</td>\n",
       "      <td id=\"T_62f96_row10_col4\" class=\"data row10 col4\" >0.7712</td>\n",
       "      <td id=\"T_62f96_row10_col5\" class=\"data row10 col5\" >0.8465</td>\n",
       "      <td id=\"T_62f96_row10_col6\" class=\"data row10 col6\" >0.0333</td>\n",
       "      <td id=\"T_62f96_row10_col7\" class=\"data row10 col7\" >0.0493</td>\n",
       "      <td id=\"T_62f96_row10_col8\" class=\"data row10 col8\" >0.0190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_62f96_level0_row11\" class=\"row_heading level0 row11\" >rf</th>\n",
       "      <td id=\"T_62f96_row11_col0\" class=\"data row11 col0\" >Random Forest Classifier</td>\n",
       "      <td id=\"T_62f96_row11_col1\" class=\"data row11 col1\" >0.7233</td>\n",
       "      <td id=\"T_62f96_row11_col2\" class=\"data row11 col2\" >0.5970</td>\n",
       "      <td id=\"T_62f96_row11_col3\" class=\"data row11 col3\" >0.8956</td>\n",
       "      <td id=\"T_62f96_row11_col4\" class=\"data row11 col4\" >0.7758</td>\n",
       "      <td id=\"T_62f96_row11_col5\" class=\"data row11 col5\" >0.8314</td>\n",
       "      <td id=\"T_62f96_row11_col6\" class=\"data row11 col6\" >0.0819</td>\n",
       "      <td id=\"T_62f96_row11_col7\" class=\"data row11 col7\" >0.0892</td>\n",
       "      <td id=\"T_62f96_row11_col8\" class=\"data row11 col8\" >1.3430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_62f96_level0_row12\" class=\"row_heading level0 row12\" >knn</th>\n",
       "      <td id=\"T_62f96_row12_col0\" class=\"data row12 col0\" >K Neighbors Classifier</td>\n",
       "      <td id=\"T_62f96_row12_col1\" class=\"data row12 col1\" >0.7171</td>\n",
       "      <td id=\"T_62f96_row12_col2\" class=\"data row12 col2\" >0.5745</td>\n",
       "      <td id=\"T_62f96_row12_col3\" class=\"data row12 col3\" >0.8887</td>\n",
       "      <td id=\"T_62f96_row12_col4\" class=\"data row12 col4\" >0.7737</td>\n",
       "      <td id=\"T_62f96_row12_col5\" class=\"data row12 col5\" >0.8272</td>\n",
       "      <td id=\"T_62f96_row12_col6\" class=\"data row12 col6\" >0.0683</td>\n",
       "      <td id=\"T_62f96_row12_col7\" class=\"data row12 col7\" >0.0737</td>\n",
       "      <td id=\"T_62f96_row12_col8\" class=\"data row12 col8\" >0.0930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_62f96_level0_row13\" class=\"row_heading level0 row13\" >et</th>\n",
       "      <td id=\"T_62f96_row13_col0\" class=\"data row13 col0\" >Extra Trees Classifier</td>\n",
       "      <td id=\"T_62f96_row13_col1\" class=\"data row13 col1\" >0.7058</td>\n",
       "      <td id=\"T_62f96_row13_col2\" class=\"data row13 col2\" >0.5801</td>\n",
       "      <td id=\"T_62f96_row13_col3\" class=\"data row13 col3\" >0.8628</td>\n",
       "      <td id=\"T_62f96_row13_col4\" class=\"data row13 col4\" >0.7760</td>\n",
       "      <td id=\"T_62f96_row13_col5\" class=\"data row13 col5\" >0.8171</td>\n",
       "      <td id=\"T_62f96_row13_col6\" class=\"data row13 col6\" >0.0756</td>\n",
       "      <td id=\"T_62f96_row13_col7\" class=\"data row13 col7\" >0.0786</td>\n",
       "      <td id=\"T_62f96_row13_col8\" class=\"data row13 col8\" >0.6430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_62f96_level0_row14\" class=\"row_heading level0 row14\" >dt</th>\n",
       "      <td id=\"T_62f96_row14_col0\" class=\"data row14 col0\" >Decision Tree Classifier</td>\n",
       "      <td id=\"T_62f96_row14_col1\" class=\"data row14 col1\" >0.6556</td>\n",
       "      <td id=\"T_62f96_row14_col2\" class=\"data row14 col2\" >0.5333</td>\n",
       "      <td id=\"T_62f96_row14_col3\" class=\"data row14 col3\" >0.7667</td>\n",
       "      <td id=\"T_62f96_row14_col4\" class=\"data row14 col4\" >0.7780</td>\n",
       "      <td id=\"T_62f96_row14_col5\" class=\"data row14 col5\" >0.7723</td>\n",
       "      <td id=\"T_62f96_row14_col6\" class=\"data row14 col6\" >0.0657</td>\n",
       "      <td id=\"T_62f96_row14_col7\" class=\"data row14 col7\" >0.0658</td>\n",
       "      <td id=\"T_62f96_row14_col8\" class=\"data row14 col8\" >0.0740</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f4919b194d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,\n",
       "              l1_ratio=0.15, learning_rate='optimal', loss='hinge',\n",
       "              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',\n",
       "              power_t=0.5, random_state=227, shuffle=True, tol=0.001,\n",
       "              validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_models(exclude='dummy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The F1 score is a good measure of how well a model is predicting both positive and negative sentiment, the best model for this is 'svm'.\n",
    "\n",
    "Lets use this model on our test data to see if it seems to be predicting correct sentiment for our reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-08T17:48:15.213028Z",
     "iopub.status.busy": "2023-01-08T17:48:15.212557Z",
     "iopub.status.idle": "2023-01-08T17:48:16.409977Z",
     "shell.execute_reply": "2023-01-08T17:48:16.408300Z",
     "shell.execute_reply.started": "2023-01-08T17:48:15.212990Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>Topic_0</th>\n",
       "      <th>Topic_0</th>\n",
       "      <th>Topic_0</th>\n",
       "      <th>Topic_0</th>\n",
       "      <th>Positive</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>who doesn't like angrybirds?but the paid version is better as it doesn't have all those annoying adds. blocking your shots!</td>\n",
       "      <td>0.085445</td>\n",
       "      <td>0.085445</td>\n",
       "      <td>0.085445</td>\n",
       "      <td>0.085445</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>Free and fun, what could be better?  The birds are angry, it's everything I expected, and anyway, those pigs had it coming!</td>\n",
       "      <td>0.079090</td>\n",
       "      <td>0.079090</td>\n",
       "      <td>0.079090</td>\n",
       "      <td>0.079090</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1294</th>\n",
       "      <td>I downloaded this to my tablet, as my phone is out of space. Very easy to read the latest tweets that way</td>\n",
       "      <td>0.118320</td>\n",
       "      <td>0.118320</td>\n",
       "      <td>0.118320</td>\n",
       "      <td>0.118320</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4352</th>\n",
       "      <td>I love this App and also use Out Of Milk via the website. It makes creating my lists and sharing it with others, quick and easy! It also keeps track of my cost as I add to is, making budgeting a breeze.</td>\n",
       "      <td>0.081643</td>\n",
       "      <td>0.081643</td>\n",
       "      <td>0.081643</td>\n",
       "      <td>0.081643</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7016</th>\n",
       "      <td>its actualy saying wat I'm going through. its very fun and creative. I will be sure to use it everyday. no complaints. good job guys. :)</td>\n",
       "      <td>0.104748</td>\n",
       "      <td>0.104748</td>\n",
       "      <td>0.104748</td>\n",
       "      <td>0.104748</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                      reviewText  \\\n",
       "60                                                                                   who doesn't like angrybirds?but the paid version is better as it doesn't have all those annoying adds. blocking your shots!   \n",
       "159                                                                                  Free and fun, what could be better?  The birds are angry, it's everything I expected, and anyway, those pigs had it coming!   \n",
       "1294                                                                                                   I downloaded this to my tablet, as my phone is out of space. Very easy to read the latest tweets that way   \n",
       "4352  I love this App and also use Out Of Milk via the website. It makes creating my lists and sharing it with others, quick and easy! It also keeps track of my cost as I add to is, making budgeting a breeze.   \n",
       "7016                                                                    its actualy saying wat I'm going through. its very fun and creative. I will be sure to use it everyday. no complaints. good job guys. :)   \n",
       "\n",
       "       Topic_0   Topic_0   Topic_0   Topic_0  Positive  Label  \n",
       "60    0.085445  0.085445  0.085445  0.085445         1      1  \n",
       "159   0.079090  0.079090  0.079090  0.079090         1      1  \n",
       "1294  0.118320  0.118320  0.118320  0.118320         1      1  \n",
       "4352  0.081643  0.081643  0.081643  0.081643         1      1  \n",
       "7016  0.104748  0.104748  0.104748  0.104748         1      1  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = create_model('svm', verbose=False)\n",
    "new_predictions = predict_model(best_model, data=test)\n",
    "new_predictions = new_predictions.join(amazon_reviews)\n",
    "new_predictions = new_predictions[['reviewText', 'Topic_0', 'Topic_0', 'Topic_0', 'Topic_0', 'Positive', 'Label']]\n",
    "new_predictions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'Positive' is our original sentiment for our reviews, and 'Label' is the sentiment predicted by the model. Looking at the first few reviews seems to confirm that our model is able to predict the sentiment of reviews quite well.\n",
    "\n",
    "This type of text classification or sentiment analysis model could be used for many different types of business application, for example on customer requests to identify complaints. A customer complaints prediction model could be used to classify thousands of customer requests, which could then be used to prioritise customer requests that are flagged as complaints by the model, or pass these on to a specialist team. This could ensure customer complaints were dealt with quickly regardless of how many total customer messages were incoming."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sJDX6XytJRnV"
   },
   "source": [
    "## Conclusion\n",
    "\n",
    "In this article we have looked at the huge benefits NLP applications can bring to businesses. Most state of the art NLP applications use deep learning which often require specialist resources not all businesses will be able or willing initially to support.\n",
    "\n",
    "We have shown here some examples of how NLP applications without deep learning - such as topic modelling or sentiment analysis and text classification, can bring huge benefits to businesses despite not being state of the art methods, especially for businesses new to Data Science, Machine Learning and AI."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "1b039c053bdc4f528de7123df5b9a19a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "Processing: ",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d4bd5eb1e58947588d31f5cfb195eb4c",
      "max": 20005,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5e6ce698b5464b4c834bd8aadf3937d2",
      "value": 18339
     }
    },
    "49e1bb466033406e930431fc51b62d12": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "54031f3d3e58425c8111f92251763f0f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "Processing: ",
      "description_tooltip": null,
      "layout": "IPY_MODEL_87dff002b24f47e095d409ccc1d67270",
      "max": 11,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8e53cef91b144386aed6eb17fbbf4429",
      "value": 11
     }
    },
    "5e6ce698b5464b4c834bd8aadf3937d2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "87dff002b24f47e095d409ccc1d67270": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8e53cef91b144386aed6eb17fbbf4429": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c031bb3be83c4cc4a053b215c2a9ec30": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d4bd5eb1e58947588d31f5cfb195eb4c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "eb5912f2b5744dc78e24e155e63a4a8b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "Processing: ",
      "description_tooltip": null,
      "layout": "IPY_MODEL_49e1bb466033406e930431fc51b62d12",
      "max": 4,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c031bb3be83c4cc4a053b215c2a9ec30",
      "value": 4
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
