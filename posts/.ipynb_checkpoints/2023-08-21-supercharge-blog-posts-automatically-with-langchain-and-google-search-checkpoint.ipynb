{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "date: '2023-08-21'\n",
    "categories:\n",
    " - natural-language-processing\n",
    " - deep-learning\n",
    " - langchain\n",
    " - activeloop\n",
    " - openai\n",
    "title: Supercharge Your Blog Posts Automatically with LangChain and Google Search\n",
    "description: In this post, we will take you step by step through the process of building an AI application that can effortlessly expand text sections of an article.\n",
    "image: https://github.com/pranath/blog/raw/master/images/langchain-deeplake4.png\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Artificial intelligence is currently revolutionising the copyrighting industry by acting as a writing assistant. These language models can detect spelling and grammatical problems, change tones, summarise, and even expand on the content. However, there are situations when the model may lack the specialised expertise in a certain topic to make expert-level suggestions for enhancing sections of an article.\n",
    "\n",
    "In this post, we'll walk you through the process of creating an application that can easily expand text sections of an article.\n",
    "\n",
    "## Import Libs & Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mdSIAIj-iXZp",
    "outputId": "d3e62703-ea95-47e3-acdd-3c41ccf1086a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m939.3/939.3 kB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.1/211.1 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.1/81.1 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.3/93.3 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.1/49.1 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Building wheel for tinysegmenter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Building wheel for feedfinder2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Building wheel for jieba3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
     ]
    }
   ],
   "source": [
    "#| include: false\n",
    "!pip install -q langchain==0.0.208 openai tiktoken newspaper3k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6N1YVZcngzRY"
   },
   "outputs": [],
   "source": [
    "# let's setup the keys\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ[\"GOOGLE_CSE_ID\"] = \"<GOOGLE_CSE_ID>\"\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"<GOOGLE_API_KEY>\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"<OPENAI_API_KEY>\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improve Blog Posts Automatically\n",
    "\n",
    "To begin, request that an LLM (ChatGPT) develop a few search queries based on the material at hand. These queries will then be used to search the Internet for relevant information on the subject using Google Search API. Finally, the most relevant findings will be supplied to the model as context in order for it to suggest better content.\n",
    "\n",
    "We have three variables here that represent the title and content of an article (text_all). (According to Artificial Intelligence News) The text_to_change variable also specifies which section of the text we want to expand on. These constants are presented for reference purposes only and will remain constant throughout the post."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I0Ed6yWdgzRa"
   },
   "outputs": [],
   "source": [
    "url = \"https://www.artificialintelligence-news.com/2023/05/16/openai-ceo-ai-regulation-is-essential/\"\n",
    "\n",
    "title = \"OpenAI CEO: AI regulation ‘is essential’\"\n",
    "\n",
    "text_all = \"\"\"Altman highlighted the potential benefits of AI technologies like ChatGPT and Dall-E 2 to help address significant challenges such as climate change and cancer, but he also stressed the need to mitigate the risks associated with increasingly powerful AI models.\n",
    "\n",
    "Altman proposed that governments consider implementing licensing and testing requirements for AI models that surpass a certain threshold of capabilities. He highlighted OpenAI’s commitment to safety and extensive testing before releasing any new systems, emphasising the company’s belief that ensuring the safety of AI is crucial.\n",
    "\n",
    "Senators Josh Hawley and Richard Blumenthal expressed their recognition of the transformative nature of AI and the need to understand its implications for elections, jobs, and security. Blumenthal played an audio introduction using an AI voice cloning software trained on his speeches, demonstrating the potential of the technology.\n",
    "\n",
    "Blumenthal raised concerns about various risks associated with AI, including deepfakes, weaponised disinformation, discrimination, harassment, and impersonation fraud. He also emphasised the potential displacement of workers in the face of a new industrial revolution driven by AI.\"\"\"\n",
    "\n",
    "text_to_change = \"\"\"Senators Josh Hawley and Richard Blumenthal expressed their recognition of the transformative nature of AI and the need to understand its implications for elections, jobs, and security. Blumenthal played an audio introduction using an AI voice cloning software trained on his speeches, demonstrating the potential of the technology.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following diagram explains the workflow of this project.\n",
    "\n",
    "<img src=\"https://github.com/pranath/blog/raw/master/images/activeloop-supercharge-blog-posts.png\" width=\"800\"/>\n",
    "\n",
    "First, we build candidate search phrases based on the paragraph we want to extend. The searches are then utilised to extract relevant content from a search engine (for example, Bing or Google Search), which are then divided into little parts. We then construct embeddings for these chunks and save them in a Deep Lake dataset. Finally, the most similar chunks to the paragraph we wish to expand are downloaded from Deep Lake and used in a prompt to expand the paragraph with more information.\n",
    "\n",
    "## Generate Search Queries\n",
    "\n",
    "The code below processes an article and suggests three suitable search keywords using OpenAI's ChatGPT model. We design a prompt that asks the model to recommend Google search phrases that might be used to learn more about the issue. The LLMChain connects the ChatOpenAI model with the ChatPromptTemplate to form the chain used to communicate with the model. Finally, to extract the data, it separates the response by newline and removes the first characters. The syntax indicated above works because we asked the API to generate each query in a new line beginning with -. (The OutputParser class can be used to achieve the same effect)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cWwSTxxbgzRb",
    "outputId": "0981d02a-1cab-498c-fb6d-2f35ce6af596"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\"AI implications for elections\"', '\"AI job displacement\"', '\"AI security risks\"']\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "\n",
    "template = \"\"\"You are an exceptional copywriter and content creator.\n",
    "\n",
    "You're reading an article with the following title:\n",
    "----------------\n",
    "{title}\n",
    "----------------\n",
    "\n",
    "You've just read the following piece of text from that article.\n",
    "----------------\n",
    "{text_all}\n",
    "----------------\n",
    "\n",
    "Inside that text, there's the following TEXT TO CONSIDER that you want to enrich with new details.\n",
    "----------------\n",
    "{text_to_change}\n",
    "----------------\n",
    "\n",
    "What are some simple and high-level Google queries that you'd do to search for more info to add to that paragraph?\n",
    "Write 3 queries as a bullet point list, prepending each line with -.\n",
    "\"\"\"\n",
    "\n",
    "human_message_prompt = HumanMessagePromptTemplate(\n",
    "    prompt=PromptTemplate(\n",
    "        template=template,\n",
    "        input_variables=[\"text_to_change\", \"text_all\", \"title\"],\n",
    "    )\n",
    ")\n",
    "\n",
    "chat_prompt_template = ChatPromptTemplate.from_messages([human_message_prompt])\n",
    "chat = ChatOpenAI(temperature=0.9)\n",
    "chain = LLMChain(llm=chat, prompt=chat_prompt_template)\n",
    "response = chain.run({\n",
    "    \"text_to_change\": text_to_change,\n",
    "    \"text_all\": text_all,\n",
    "    \"title\": title\n",
    "})\n",
    "queries = [line[2:] for line in response.split(\"\\n\")]\n",
    "print(queries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Search Results\n",
    "\n",
    "To use Google search API, we must first create an API Key and a custom search engine. To obtain the key, go to the [Google Cloud dashboard](https://console.cloud.google.com/apis/credentials) and produce it by clicking the CREATE CREDENTIALS button at the top and selecting API KEY. Then, go to the [Programmable Search Engine dashboard](https://programmablesearchengine.google.com/controlpanel/create) and make sure you check the \"Search the entire web\" box. In the details, the Search engine ID will be shown. You may also need to enable the \"Custom Search API\" service under the APIs and services section. (If necessary, API will send you the instructions.) We can now set the environment variables GOOGLE_CSE_ID and GOOGLE_API_KEY, which will allow the Google wrapper to communicate with the API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m2k2kaY_gzRd"
   },
   "outputs": [],
   "source": [
    "# first, we create a tool that allows us to use Google search.\n",
    "# we'll use it to retrieve the first 10 results\n",
    "\n",
    "from langchain.tools import Tool\n",
    "from langchain.utilities import GoogleSearchAPIWrapper\n",
    "\n",
    "search = GoogleSearchAPIWrapper()\n",
    "TOP_N_RESULTS = 5\n",
    "\n",
    "def top_n_results(query):\n",
    "    return search.results(query, TOP_N_RESULTS)\n",
    "\n",
    "tool = Tool(\n",
    "    name = \"Google Search\",\n",
    "    description=\"Search Google for recent results.\",\n",
    "    func=top_n_results\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A4yhq11bgzRd",
    "outputId": "61785be7-5171-4742-90f5-730db48e7b23"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job Displacement - AI SUPERPOWERS new book by Kai-Fu Lee of ...\n",
      "https://www.aisuperpowers.com/job-displacement\n",
      "AI Job Displacement Index. How will your job be affected by AI? Within the next fifteen years, AI and automation will be able to do virtually all basic work ...\n",
      "--------------------------------------------------\n",
      "OWASP AI Security and Privacy Guide | OWASP Foundation\n",
      "https://owasp.org/www-project-ai-security-and-privacy-guide/\n",
      "Feb 15, 2023 ... Particular AI security risks · Data Security Risks: · AI model attacks, or adversarial machine learning attacks represent important security risks ...\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# this is how we can use the tool. For each result, we have:\n",
    "# 1. the result title\n",
    "# 2. its URL\n",
    "# 3. and the snippet that we would see if we were on the Google UI\n",
    "\n",
    "all_results = []\n",
    "\n",
    "for query in queries:\n",
    "    results = tool.run(query)\n",
    "    all_results += results\n",
    "\n",
    "    if \"title\" in results[0]: # Sample\n",
    "        print(results[0][\"title\"])\n",
    "        print(results[0][\"link\"])\n",
    "        print(results[0][\"snippet\"])\n",
    "        print(\"-\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variable all_results contains 15 web addresses. (3 ChatGPT inquiries x 5 top Google search results) However, using all of the information as a context in our application is not an optimal flow. There are technical, financial, and contextual factors to consider.\n",
    "\n",
    "To begin, the LLMs' input length is limited to a range of 2K to 4K tokens, which varies depending on the model. Although we can bypass this limitation by using a different chain type, it is more efficient and produces better results when we stick to the model's window size. Second, it is critical to understand that increasing the quantity of words we submit to the API incurs a higher cost. While it is possible to divide a prompt into numerous chains, we should exercise caution because the cost of these models is controlled by the token count. Finally, the content provided by the saved search results will be contextually relevant. So, it is a good idea to use the most relevant results.\n",
    "\n",
    "## Find the Most Relevant Results\n",
    "\n",
    "As previously stated, Google Search returns the URL for each source. However, the content of these pages is required. Using the.parse() method, the newspaper package can retrieve the contents of a web link. The code below will cycle through the results and try to extract the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1C0q-i52gzRe",
    "outputId": "b76c9d60-5f96-4ecc-a16c-08ef1ec5f2ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pages:  10\n"
     ]
    }
   ],
   "source": [
    "# let's visit all the URLs from the results and use the newspaper library\n",
    "# to download their texts. The library won't work on some URLs, e.g.\n",
    "# if the content is a PDF file or if the website has some anti-bot mechanisms\n",
    "# adopted.\n",
    "\n",
    "import newspaper\n",
    "\n",
    "pages_content = []\n",
    "\n",
    "for result in all_results:\n",
    "    try:\n",
    "        article = newspaper.Article(result[\"link\"])\n",
    "        article.download()\n",
    "        article.parse()\n",
    "        if len(article.text) > 0:\n",
    "            pages_content.append({ \"url\": result[\"link\"], \"text\": article.text })\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "print(\"Number of pages: \", len(pages_content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The given output reveals that 14 pages were processed, but we expected 15. There are some situations in which the newspaper library may have difficulty extracting information. These include search results that direct to a PDF file or websites that prohibit web scraping.\n",
    "\n",
    "To ensure that the articles do not exceed the model's input length, the recorded contents must now be divided into smaller chunks. Depending on the situation, the code below divides the text by newlines or spaces. It ensures that each chunk contains 3000 characters and that there are no more than 100 overlaps between chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ktObmDfxgzRe",
    "outputId": "9eec2389-6d12-49fc-e094-7313c4a975a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks:  26\n"
     ]
    }
   ],
   "source": [
    "# we split the article texts into small chunks. While doing so, we keep track of each\n",
    "# chunk metadata (i.e. the URL where it comes from). Each metadata is a dictionary and\n",
    "# we need to use the \"source\" key for the document source so that the chain\n",
    "# that we'll create later knows where to retrieve the source.\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.docstore.document import Document\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=3000, chunk_overlap=100)\n",
    "\n",
    "docs = []\n",
    "for d in pages_content:\n",
    "    chunks = text_splitter.split_text(d[\"text\"])\n",
    "    for chunk in chunks:\n",
    "        new_doc = Document(page_content=chunk, metadata={ \"source\": d[\"url\"] })\n",
    "        docs.append(new_doc)\n",
    "\n",
    "print(\"Number of chunks: \", len(docs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the docs variable has 26 data chunks. It's time to locate the most relevant bits and feed them into the broader language model as context. OpenAI will be used by the OpenAIEmbeddings class to translate the texts into vector space that has semantics. We then embedded both document pieces as well as the appropriate sentence from the main article that was selected for enlargement. The text_to_change variable represents the sentence that was picked at the start of this lesson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rtXDiBx2gzRf"
   },
   "outputs": [],
   "source": [
    "# then, we embed both the chunks and the query\n",
    "\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
    "\n",
    "docs_embeddings = embeddings.embed_documents([doc.page_content for doc in docs])\n",
    "query_embedding = embeddings.embed_query(text_to_change)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cosine similarity measure can be used to calculate the distance between high-dimensionality embedding vectors. It calculates the distance between two points in the vector space. Because the embeddings carry contextual information, their proximity indicates that they have a common meaning. As a result, the source document with the highest similarity score can be used.\n",
    "\n",
    "We utilised the sklearn library's cosine_similarity function. It computes the distance between each chunk and the selected sentence in order to return the index of the top three results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TVULhkU9gzRf"
   },
   "outputs": [],
   "source": [
    "# next, we compute the cosine similarities between the document vectors and\n",
    "# the query vectors using numpy and sklearn. We are interested only in the top 3\n",
    "# chunks for now because we'll later put them in a prompt and the prompt size is\n",
    "# limited.\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def get_top_k_indices(list_of_doc_vectors, query_vector, top_k):\n",
    "    # convert the lists of vectors to numpy arrays\n",
    "    list_of_doc_vectors = np.array(list_of_doc_vectors)\n",
    "    query_vector = np.array(query_vector)\n",
    "\n",
    "    # compute cosine similarities\n",
    "    similarities = cosine_similarity(query_vector.reshape(1, -1), list_of_doc_vectors).flatten()\n",
    "\n",
    "    # sort the vectors based on cosine similarity\n",
    "    sorted_indices = np.argsort(similarities)[::-1]\n",
    "\n",
    "    # retrieve the top K indices from the sorted list\n",
    "    top_k_indices = sorted_indices[:top_k]\n",
    "\n",
    "    return top_k_indices\n",
    "\n",
    "top_k = 3\n",
    "best_indexes = get_top_k_indices(docs_embeddings, query_embedding, top_k)\n",
    "best_k_documents = [doc for i, doc in enumerate(docs) if i in best_indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ywfXTKUagzRg",
    "outputId": "0c830a5f-f9c7-45ff-9b51-599324ed07c2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='How to Prepare for AI Job Displacement Kai-Fu Lee · Follow · Oct 25, 2018 3 min read -- 1 Listen Share\\n\\nAs individuals, we should accept that routine jobs are going away. For young people in these routine jobs, start now by finding careers that fit your strengths and that are not easily replaced by AI. For older people, when early retirement is offered to you, consider accepting, with gig economy and volunteering to make some income and live a life you enjoy.\\n\\nWe should encourage more people to go into service careers, choosing jobs into which they can pour their hearts and souls, spreading their love and experiences.\\n\\nWe should embrace AI tools, especially for professionals, understanding that they will get better with more data and use. We should use these tools to do parts of our jobs, allowing them to do more of our routine tasks, freeing us to move into areas that are more suitable for humans.\\n\\nWe should encourage all kinds of creativity beyond the sciences: painting, architecture, music, poetry, acting, storytelling, PR, and marketing.\\n\\nLarge companies should establish and fund serious corporate social responsibility efforts and take steps to help society transition into the age of automation and the future of work.\\n\\nCorporations with a large workforce facing displacement should introduce employee training programs. These involve training employees for emotional quotient and soft skills, reimbursement for online training, and developing a culture of lifelong learning.\\n\\nService industries should develop clear career ladders for service professionals and share best practices and role models so that we attract more people to this large and more sustainable industry.\\n\\nInvestment companies should look at impact investment, not just investing in stocks or tech start-ups, but investing in companies with social impact. These companies, typically service companies, can have decent but not exponential growth and can provide lasting employment to large numbers of people. Such investments may not yield the highest returns but should be done as pro bono.\\n\\nEducational institutions should rethink their roles. Rote learning will only lead to graduates who are easily replaced by AI. Schools need to teach about emotional quotient including communication, teamwork, winning trust, and empathy. Students should be encouraged to pursue their passion, and teaching should become more personalized.\\n\\nSchools should embrace STEM education and find prodigies who will become the inventors of the next breakthroughs in AI, neurobiology, genomics, materials, energy, or basic sciences.\\n\\nWe as a society need to start shifting our culture and values. We have been conditioned to believe that our primary role in society (and even our identity) is found in wage-earning work.', metadata={'source': 'https://kaifulee.medium.com/how-to-prepare-for-ai-job-displacement-78d850e5c1ce'}),\n",
       " Document(page_content='“GPT-4 is a remarkable leap forward in natural language-based models, significantly expanding its potential use cases and building on the achievements of its previous iterations,” said Ferran, pointing to its expanded capability to write code in any language, he said.\\n\\nWilliams agreed, saying that AI is like any powerful tool: Organizations must do their own due diligence.\\n\\n“Are there risks that people can use it for nefarious purposes? Of course, but the benefits far outweigh the risks,” he said.', metadata={'source': 'https://venturebeat.com/security/security-risks-evolve-with-release-of-gpt-4/'}),\n",
       " Document(page_content='Across the globe, organizations are waking up to the power of artificial intelligence (AI). Even before ChatGPT, the technology was starting to move from being an early adopter buzzword to something capable of affecting business transformation for the corporate masses. The market for AI software, hardware and services is expected to hit yet another milestone – $500bn in value – by 2024, thanks to impressive double-digit growth. Yet however they’re deployed to drive business success, AI services are only as strong as the data that powers them.\\n\\nThat means organizations wanting to extract maximum value from AI must also build security into projects from the start to help mitigate AI security risks and threats. A best practice layered approach must begin with securing the data itself - data-centric AI security\\n\\nThe power of AI\\n\\nWe should all be aware by now of the value AI tools can provide to organizations – in both a customer-facing and back office context. One obvious advantage of chatbots like ChatGPT is in enhancing customer service with a realistic human-like interface to field queries and complaints. In doing so, it will free up staff to focus on higher-value tasks. AI-based automation could also reduce the manual, repetitive tasks some team members still have to undertake in industries like banking and retail – such as on- and offboarding customers and approving mortgages. This would also minimize human error and improve overall efficiency.\\n\\nA third output from AI tools – and perhaps the one business leaders are most excited about – revolves around decision-making. By applying the right algorithms to large datasets, companies can generate insight with which to make more successful decisions. For example, they can forecast multiple market scenarios to help predict stock levels, customer sentiment and pricing sensitivity – and adjust strategy accordingly. This will be an increasingly critical driver of agility – especially in times of tremendous business uncertainty and macro-economic volatility.\\n\\nRisk is everywhere: data security risks facing AI & machine learning applications\\n\\nYet where there is data, there are inevitably risks over how it is used and who has access to it. Top AI data security risks include:\\n\\nModel poisoning Model poisoning is a type of attack where threat actors deliberately inject malicious data into an AI or machine learning (ML) model, with the goal of compromising its performance. In most cases, the malicious data will either be significantly different from the distribution of the AI/ML’s training data or heavily biased leading the AI/ML system to misclassify the data and make unreliable decisions.\\n\\n\\n\\nData manipulation/tampering Data manipulation or tampering could occur before data is even fed into algorithms. It is a tactic used by threat actors to deceive an AI/machine learning model, sabotage results or influence other outcomes that the threat actor wants.', metadata={'source': 'https://insights.comforte.com/ai-means-business-so-start-with-data-centric-security'})]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_k_documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extend the Sentence\n",
    "\n",
    "We can now define the prompt using the additional information from Google search. There are six input variables in the template:\n",
    "\n",
    "- title that holds the main article’s title;\n",
    "- text_all to present the whole article we are working on;\n",
    "- text_to_change is the selected part of the article that requires expansion;\n",
    "- doc_1, doc_2, doc_3 to include the close Google search results as context.\n",
    "\n",
    "The remaining part of the code should be familiar, as it follows the same structure used for generating Google queries. It defines a HumanMessage template to be compatible with the ChatGPT API, which is defined with a high-temperature value to encourage creativity. The LLMChain class will create a chain that combines the model and prompt to finish up the process by using .run() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0hVQWtS_gzRg",
    "outputId": "878e954d-a1b7-4acf-a497-13efd09b5aad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text to Change:  Senators Josh Hawley and Richard Blumenthal expressed their recognition of the transformative nature of AI and the need to understand its implications for elections, jobs, and security. Blumenthal played an audio introduction using an AI voice cloning software trained on his speeches, demonstrating the potential of the technology.\n",
      "Expanded Variation: Senators Josh Hawley and Richard Blumenthal expressed their recognition of the transformative nature of AI and the need to understand its implications for elections, jobs, and security. Blumenthal even showcased the potential of AI technology by playing an audio introduction using an AI voice cloning software trained on his speeches. However, as pointed out by Kai-Fu Lee, individuals and organizations must be prepared for AI job displacement and actively seek out careers that cannot easily be replaced by AI. This can include service careers that require emotional intelligence and creativity beyond the sciences. Investment companies can also look into impact investment in service companies that provide lasting employment to large numbers of people, even if they may not yield the highest returns. Additionally, organizations using AI must ensure the security of the data that powers them, including guarding against risks such as model poisoning and data manipulation/tampering. Despite these potential risks, OpenAI CEO Greg Brockman emphasized the need for AI regulation and safety measures to mitigate any negative impacts.\n"
     ]
    }
   ],
   "source": [
    "template = \"\"\"You are an exceptional copywriter and content creator.\n",
    "\n",
    "You're reading an article with the following title:\n",
    "----------------\n",
    "{title}\n",
    "----------------\n",
    "\n",
    "You've just read the following piece of text from that article.\n",
    "----------------\n",
    "{text_all}\n",
    "----------------\n",
    "\n",
    "Inside that text, there's the following TEXT TO CONSIDER that you want to enrich with new details.\n",
    "----------------\n",
    "{text_to_change}\n",
    "----------------\n",
    "\n",
    "Searching around the web, you've found this ADDITIONAL INFORMATION from distinct articles.\n",
    "----------------\n",
    "{doc_1}\n",
    "----------------\n",
    "{doc_2}\n",
    "----------------\n",
    "{doc_3}\n",
    "----------------\n",
    "\n",
    "Modify the previous TEXT TO CONSIDER by enriching it with information from the previous ADDITIONAL INFORMATION.\n",
    "\"\"\"\n",
    "\n",
    "human_message_prompt = HumanMessagePromptTemplate(\n",
    "    prompt=PromptTemplate(\n",
    "        template=template,\n",
    "        input_variables=[\"text_to_change\", \"text_all\", \"title\", \"doc_1\", \"doc_2\", \"doc_3\"],\n",
    "    )\n",
    ")\n",
    "chat_prompt_template = ChatPromptTemplate.from_messages([human_message_prompt])\n",
    "\n",
    "chat = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.9)\n",
    "chain = LLMChain(llm=chat, prompt=chat_prompt_template)\n",
    "\n",
    "response = chain.run({\n",
    "    \"text_to_change\": text_to_change,\n",
    "    \"text_all\": text_all,\n",
    "    \"title\": title,\n",
    "    \"doc_1\": best_k_documents[0].page_content,\n",
    "    \"doc_2\": best_k_documents[1].page_content,\n",
    "    \"doc_3\": best_k_documents[2].page_content\n",
    "})\n",
    "\n",
    "print(\"Text to Change: \", text_to_change)\n",
    "print(\"Expanded Variation:\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LCIbgKPxgzRh",
    "outputId": "15a8f887-7165-463a-efae-8a456a331306"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Senators Josh Hawley and Richard Blumenthal expressed their recognition of the transformative nature of AI and the need to understand its implications for elections, jobs, and security. Blumenthal played an audio introduction using an AI voice cloning software trained on his speeches, demonstrating the potential of the technology.\n"
     ]
    }
   ],
   "source": [
    "print(text_to_change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IphEI-ChgzRh",
    "outputId": "7f9b9937-8a87-4e95-bcf7-29fb5011ac63"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Senators Josh Hawley and Richard Blumenthal expressed their recognition of the transformative nature of AI and the need to understand its implications\n",
      "for elections, jobs, and security. Blumenthal played an audio introduction using an AI voice cloning software trained on his speeches, demonstrating\n",
      "the potential of the technology.\n",
      "\n",
      "Senators Josh Hawley and Richard Blumenthal expressed their recognition of the transformative nature of AI and the need to understand its implications\n",
      "for elections, jobs, and security. Blumenthal even showcased the potential of AI technology by playing an audio introduction using an AI voice cloning\n",
      "software trained on his speeches. However, as pointed out by Kai-Fu Lee, individuals and organizations must be prepared for AI job displacement and\n",
      "actively seek out careers that cannot easily be replaced by AI. This can include service careers that require emotional intelligence and creativity\n",
      "beyond the sciences. Investment companies can also look into impact investment in service companies that provide lasting employment to large numbers\n",
      "of people, even if they may not yield the highest returns. Additionally, organizations using AI must ensure the security of the data that powers them,\n",
      "including guarding against risks such as model poisoning and data manipulation/tampering. Despite these potential risks, OpenAI CEO Greg Brockman\n",
      "emphasized the need for AI regulation and safety measures to mitigate any negative impacts.\n"
     ]
    }
   ],
   "source": [
    "import textwrap\n",
    "\n",
    "print(textwrap.fill(text_to_change, width=150))\n",
    "print()\n",
    "print(textwrap.fill(response, width=150))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T1O2bdf5gzRi"
   },
   "source": [
    "## Conclusion\n",
    "\n",
    "In this post, we learned how to use Google search results to expand the model's prompt by including extra information. The example demonstrated the use of embedding vectors to discover content that has a similar meaning or context, as well as the process of adding relevant information to a prompt to improve output. Incorporating external information, such as Google search, is a powerful tool for improving models by providing supplemental context in instances where data is scarce.\n",
    "\n",
    "## Acknowledgements\n",
    "\n",
    "I'd like to express my thanks to the wonderful [LangChain & Vector Databases in Production Course](https://learn.activeloop.ai/courses/langchain) by Activeloop - which i completed, and acknowledge the use of some images and other materials from the course in this article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
