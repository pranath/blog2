{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "date: '2023-08-22'\n",
    "categories:\n",
    " - natural-language-processing\n",
    " - deep-learning\n",
    " - langchain\n",
    " - activeloop\n",
    " - openai\n",
    "title: Recreating the Bing Chatbot\n",
    "description: This article will explore the idea of finding the best articles from the Internet as the context for a chatbot to find the correct answer\n",
    "image: https://github.com/pranath/blog/raw/master/images/langchain-deeplake1.png\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "While Large Language Models (LLMs) have outstanding capabilities, they have some limits that might cause problems when deployed in a production context. The hallucination problem causes people to confidently answer certain questions incorrectly. This problem can be linked to a number of variables, one of which is that their training procedure has a deadline. As a result, these models cannot access events prior to that date.\n",
    "\n",
    "Presenting the relevant information to the model and leveraging its reasoning abilities to find/extract the answer is a workaround strategy. Furthermore, the top-matched results returned by a search engine can be shown as the context for a user's query.\n",
    "\n",
    "This article will investigate the concept of using the finest articles on the Internet as the backdrop for a chatbot to get the proper answer. To extract stories from search results, we will use LangChain's interaction with Google Search API and the Newspaper library. This is followed by selecting and employing the most pertinent selections in the prompt.\n",
    "\n",
    "The same pipeline may be used with the Bing API, but we'll use the Google Search API in this project because it's utilised in previous lessons in this course, reducing the need to create several keys for the same functionality. Please see the tutorial below (or the Bing Web Search API for direct access) to retrieve the Bing Subscription Key and LangChain.\n",
    "\n",
    "<img src=\"https://github.com/pranath/blog/raw/master/images/activeloop-bing-chatbot.png\" width=\"800\"/>\n",
    "\n",
    "Using a search engine (e.g., Bing or Google Search), the user query is utilised to extract relevant articles, which are then divided into pieces. The embeddings of each chunk are then computed, ranked by cosine similarity to the query's embedding, and the most relevant chunks are entered into a prompt to construct the final answer while maintaining track of the sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zDK_lS0VgMy7",
    "outputId": "3fe2372e-509e-4f91-e494-a4345b568d36"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m61.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "#| include: false\n",
    "!pip install -q langchain==0.0.208 openai tiktoken newspaper3k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ask Trending Questions\n",
    "\n",
    "Let's begin by looking at an example. The following paragraph should be familiar by now. It creates an assistant to answer queries using the OpenAI GPT-3.5-turbo model. We'll ask the model to name the most recent Fast & Furious movie. As a result, the model could not have seen the solution during training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "WvxICip__N4a",
    "outputId": "d196b702-2275-4dc2-da2d-cb286b946e3b"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'\\nThe latest Fast and Furious movie is Fast & Furious 9, which is set to be released in May 2021.'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import LLMChain, PromptTemplate\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "llm = OpenAI(temperature=0)\n",
    "\n",
    "template = \"\"\"You are an assistant that answer the following question correctly and honestly: {question}\\n\\n\"\"\"\n",
    "prompt_template = PromptTemplate(input_variables=[\"question\"], template=template)\n",
    "\n",
    "question_chain = LLMChain(llm=llm, prompt=prompt_template)\n",
    "\n",
    "question_chain.run(\"what is the latest fast and furious movie?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The response demonstrates that the model uses the previous movie title as the solution. This is due to the fact that the new film (10th sequel) has yet to be produced in its fictional universe! Let us now address the issue.\n",
    "\n",
    "## Google API\n",
    "\n",
    "Before we start, let’s set up the API Key and a custom search engine. If you don’t have the keys from the previous lesson, head to the [Google Cloud console](https://console.cloud.google.com/apis/credentials?project=amazing-codex-395218) and generate the key by pressing the CREATE CREDENTIALS buttons from the top and choosing API KEY. Then, head to the [Programmable Search Engine](https://programmablesearchengine.google.com/controlpanel/create) dashboard and remember to select the “Search the entire web” option. The Search engine ID will be visible in the details. You might also need to enable the “Custom Search API” service under the Enable APIs and services. (You will receive the instruction from API if required) Now we can set the environment variables for both Google and OpenAI APIs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EKq7TEQvX68X"
   },
   "outputs": [],
   "source": [
    "# let's setup the keys\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ[\"GOOGLE_CSE_ID\"] = \"<Custom_Search_Engine_ID>\"\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"<Google_API_Key>\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"<OpenAI_Key>\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Search Results\n",
    "\n",
    "To obtain search results, this component employs LangChain's GoogleSearchAPIWrapper class. It interacts with the Tool class, which provides utilities for agents to let them interface with the outside world. It is possible to make a tool out of any function, such as top_n_results, in this example. The API will return the title, URL, and a brief description of the page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zOi1iUqFX68a"
   },
   "outputs": [],
   "source": [
    "# first, we create a tool that allows us to use Google search.\n",
    "# we'll use it to retrieve the first 10 results\n",
    "\n",
    "from langchain.tools import Tool\n",
    "from langchain.utilities import GoogleSearchAPIWrapper\n",
    "\n",
    "search = GoogleSearchAPIWrapper()\n",
    "TOP_N_RESULTS = 10\n",
    "\n",
    "def top_n_results(query):\n",
    "    return search.results(query, TOP_N_RESULTS)\n",
    "\n",
    "tool = Tool(\n",
    "    name = \"Google Search\",\n",
    "    description=\"Search Google for recent results.\",\n",
    "    func=top_n_results\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7TlsYaDiX68b",
    "outputId": "19b50ae5-d4f2-44b4-9375-a181508eb204"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fast & Furious movies in order | chronological and release order ...\n",
      "https://www.radiotimes.com/movies/fast-and-furious-order/\n",
      "Mar 22, 2023 ... Fast & Furious Presents: Hobbs & Shaw (2019); F9 (2021); Fast and Furious 10 (2023). Tokyo Drift also marks the first appearance of Han Lue, a ...\n",
      "--------------------------------------------------\n",
      "FAST X | Official Trailer 2 - YouTube\n",
      "https://www.youtube.com/watch?v=aOb15GVFZxU\n",
      "Apr 19, 2023 ... Fast X, the tenth film in the Fast & Furious Saga, launches the final ... witnessed it all and has spent the last 12 years masterminding a ...\n",
      "--------------------------------------------------\n",
      "Fast & Furious 10: Release date, cast, plot and latest news on Fast X\n",
      "https://www.radiotimes.com/movies/fast-and-furious-10-release-date/\n",
      "Apr 17, 2023 ... Fast X is out in cinemas on 19th May 2023 – find out how to rewatch all the Fast & Furious movies in order, and read our Fast & Furious 9 review ...\n",
      "--------------------------------------------------\n",
      "Fast & Furious - Wikipedia\n",
      "https://en.wikipedia.org/wiki/Fast_%26_Furious\n",
      "The main films are known as The Fast Saga. Universal expanded the series to include the spin-off film Fast & Furious Presents: Hobbs & Shaw (2019), ...\n",
      "--------------------------------------------------\n",
      "How many 'Fast & Furious' movies are there? Here's the list in order.\n",
      "https://www.usatoday.com/story/entertainment/movies/2022/07/29/fast-and-furious-movies-order-of-release/10062943002/\n",
      "Jul 29, 2022 ... There are currently nine films in the main \"Fast and Furious\" franchise, with the 10th, \"Fast X,\" set to release on May 19, 2023. There are ...\n",
      "--------------------------------------------------\n",
      "How to Watch Fast and Furious Movies in Chronological Order - IGN\n",
      "https://www.ign.com/articles/fast-and-furious-movies-in-order\n",
      "Apr 6, 2023 ... Looking to go on a Fast and Furious binge before the next movie comes out? ... This is the last Fast film with Paul Walker's Brian O'Conner, ...\n",
      "--------------------------------------------------\n",
      "'Fast and Furious 10': Everything We Know So Far\n",
      "https://www.usmagazine.com/entertainment/pictures/fast-and-furious-10-everything-we-know-so-far/\n",
      "7 days ago ... Fast X will be the second-to-last film in the blockbuster franchise, and Dominic Toretto's next adventure is set to be one of the biggest so far ...\n",
      "--------------------------------------------------\n",
      "Latest 'Fast & Furious' Movie Leads Weekend Box Office - WSJ\n",
      "https://www.wsj.com/articles/latest-fast-furious-movie-leads-weekend-box-office-11624815451\n",
      "Jun 27, 2021 ... “F9,” however, offers the clearest test yet on the post-pandemic habits of moviegoers. The movie is the most-anticipated title released since ...\n",
      "--------------------------------------------------\n",
      "Fast & Furious Movies In Order: How to Watch Fast Saga ...\n",
      "https://editorial.rottentomatoes.com/guide/fast-furious-movies-in-order/\n",
      "After that, hop to franchise best Furious 7. Follow it up with The Fate of the Furious and spin-off Hobbs & Shaw and then the latest: F9 and Fast X. See below ...\n",
      "--------------------------------------------------\n",
      "Looming release of latest \"Fast and Furious\" movie heightens ...\n",
      "https://www.cbsnews.com/losangeles/news/looming-release-of-latest-fast-and-furious-movie-heightens-concerns-over-street-racing-takeovers/\n",
      "17 hours ago ... With the latest installment of the \"Fast and Furious\" franchise set to hit theaters this weekend, local law enforcement is banding together ...\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# this is how we can use the tool. For each result, we have:\n",
    "# 1. the result title\n",
    "# 2. its URL\n",
    "# 3. and the snippet that we would see if we were on the Google UI\n",
    "\n",
    "query = \"what is the latest fast and furious movie?\"\n",
    "\n",
    "results = tool.run(query)\n",
    "\n",
    "for result in results:\n",
    "    print(result[\"title\"])\n",
    "    print(result[\"link\"])\n",
    "    print(result[\"snippet\"])\n",
    "    print(\"-\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now use the link key of the results variable to download and parse the contents. Everything is taken care of by the newspaper library. However, under certain circumstances, such as anti-bot measures or having a file as a result, it may be difficult to record some items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1pqogA2ZX68c",
    "outputId": "82b0eb51-eb07-438a-be7e-03f6c9a23803"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "# let's visit all the URLs from the results and use the newspaper library\n",
    "# to download their texts. The library won't work on some URLs, e.g.\n",
    "# if the content is a PDF file or if the website has some anti-bot mechanisms\n",
    "# adopted.\n",
    "\n",
    "import newspaper\n",
    "\n",
    "pages_content = []\n",
    "\n",
    "for result in results:\n",
    "    try:\n",
    "        article = newspaper.Article(result[\"link\"])\n",
    "        article.download()\n",
    "        article.parse()\n",
    "        if len(article.text) > 0:\n",
    "            pages_content.append({ \"url\": result[\"link\"], \"text\": article.text })\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "print(len(pages_content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process the Search Results\n",
    "\n",
    "We now have the top 10 results from the Google search. (Honestly, who looks at Google’s second page?) However, it is not efficient to pass all the contents to the model because of the following reasons:\n",
    "\n",
    "- The model’s context length is limited.\n",
    "- It will significantly increase the cost if we process all the search results.\n",
    "- In almost all cases, they share similar pieces of information.\n",
    "\n",
    "So, let’s find the most relevant results.\n",
    "\n",
    "By incorporating the embedded generating capacity of the LLM, we will be able to identify contextually related information. Converting the text to a high-dimensionality tensor that captures meaning is required. The cosine similarity function can locate the most relevant article in relation to the user's query.\n",
    "\n",
    "It begins by separating the texts with the RecursiveCharacterTextSplitter class to guarantee that the content lengths are within the input length of the model. The Document class will construct a data structure from each piece, allowing you to save metadata such as the URL as the source. The model can then utilise this information to determine the placement of the content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rE2z01EPX68d",
    "outputId": "d96dc6c6-65e0-402a-e89e-c093a650d749"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we split the article texts into small chunks. While doing so, we keep track of each\n",
    "# chunk metadata (i.e. the URL where it comes from). Each metadata is a dictionary and\n",
    "# we need to use the \"source\" key for the document source so that the chain\n",
    "# that we'll create later knows where to retrieve the source.\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.docstore.document import Document\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=4000, chunk_overlap=100)\n",
    "\n",
    "docs = []\n",
    "for d in pages_content:\n",
    "    chunks = text_splitter.split_text(d[\"text\"])\n",
    "    for chunk in chunks:\n",
    "        new_doc = Document(page_content=chunk, metadata={ \"source\": d[\"url\"] })\n",
    "        docs.append(new_doc)\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The subsequent step involves utilizing the OpenAI API's OpenAIEmbeddings class, specifically the .embed_documents() method for search results and the .embed_query() method for the user's question, to generate embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FS9S2zCgX68d"
   },
   "outputs": [],
   "source": [
    "# then, we embed both the chunks and the query\n",
    "\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "docs_embeddings = embeddings.embed_documents([doc.page_content for doc in docs])\n",
    "query_embedding = embeddings.embed_query(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, the get_top_k_indices function accepts the content and query embedding vectors and returns the index of top K candidates with the highest cosine similarities to the user's request. Later, we use the indexes to retrieve the best-fit documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FnUAL6CGX68e"
   },
   "outputs": [],
   "source": [
    "# next, we compute the cosine similarities between the document vectors and\n",
    "# the query vectors using numpy and sklearn. We are interested only in the top 3\n",
    "# chunks for now because we'll later put them in a prompt and the prompt size is\n",
    "# limited.\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def get_top_k_indices(list_of_doc_vectors, query_vector, top_k):\n",
    "    # convert the lists of vectors to numpy arrays\n",
    "    list_of_doc_vectors = np.array(list_of_doc_vectors)\n",
    "    query_vector = np.array(query_vector)\n",
    "\n",
    "    # compute cosine similarities\n",
    "    similarities = cosine_similarity(query_vector.reshape(1, -1), list_of_doc_vectors).flatten()\n",
    "\n",
    "    # sort the vectors based on cosine similarity\n",
    "    sorted_indices = np.argsort(similarities)[::-1]\n",
    "\n",
    "    # retrieve the top K indices from the sorted list\n",
    "    top_k_indices = sorted_indices[:top_k]\n",
    "\n",
    "    return top_k_indices\n",
    "\n",
    "top_k = 2\n",
    "best_indexes = get_top_k_indices(docs_embeddings, query_embedding, top_k)\n",
    "best_k_documents = [doc for i, doc in enumerate(docs) if i in best_indexes]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chain with Source\n",
    "\n",
    "Finally, we used the articles from our prompt (through the stuff technique) to help the model identify the correct response. The load_qa_with_sources_chain() chain is provided by LangChain and is meant to accept a list of input_documents as a source of information and a question argument that is the user's inquiry. The final step is to preprocess the model's response in order to extract its answer and the sources it used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vkuc1pTtX68e"
   },
   "outputs": [],
   "source": [
    "# we are now ready to create a question answering chain that leverages\n",
    "# sources, and we'll use the load_qa_with_sources_chain function for that\n",
    "\n",
    "from langchain.chains.qa_with_sources import load_qa_with_sources_chain\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "chain = load_qa_with_sources_chain(OpenAI(temperature=0), chain_type=\"stuff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FbPM3MtsX68f",
    "outputId": "f6278df4-d90f-4a9c-ebf7-7f7487c35508"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: The latest Fast and Furious movie is Fast X, scheduled for release on May 19, 2023.\n",
      "Sources: https://www.radiotimes.com/movies/fast-and-furious-10-release-date/, https://en.wikipedia.org/wiki/Fast_%26_Furious\n"
     ]
    }
   ],
   "source": [
    "# last, let's generate the response to our query\n",
    "response = chain({\"input_documents\": best_k_documents, \"question\": query}, return_only_outputs=True)\n",
    "\n",
    "response_text, response_sources = response[\"output_text\"].split(\"SOURCES:\")\n",
    "response_text = response_text.strip()\n",
    "response_sources = response_sources.strip()\n",
    "\n",
    "print(f\"Answer: {response_text}\")\n",
    "print(f\"Sources: {response_sources}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oq5bH8nMX68f",
    "outputId": "b0706194-c8b4-4666-d347-85ac0373a1d0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output_text': ' The latest Fast and Furious movie is Fast X, scheduled for release on May 19, 2023.\\nSOURCES: https://www.radiotimes.com/movies/fast-and-furious-10-release-date/, https://en.wikipedia.org/wiki/Fast_%26_Furious'}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model was able to locate the correct response because to the utilisation of search results, even though it had never seen it previously during the training stage. The source of the question and answer chain offers information about the sources used by the model to create the answer.\n",
    "\n",
    "## Conclusion\n",
    "We covered how to use external knowledge from a search engine to create a powerful application in this course. The context can come from a variety of sources, including PDFs, text documents, CSV files, and even the Internet! We used Google search results as the source of information, which allowed the model to accurately answer the question it had previously been unable to answer.\n",
    "\n",
    "## Acknowledgements\n",
    "\n",
    "I'd like to express my thanks to the wonderful [LangChain & Vector Databases in Production Course](https://learn.activeloop.ai/courses/langchain) by Activeloop - which i completed, and acknowledge the use of some images and other materials from the course in this article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
