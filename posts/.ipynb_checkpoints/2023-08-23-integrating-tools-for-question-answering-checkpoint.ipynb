{
 "cells": [
  {
   "cell_type": "raw",
   "id": "9adf9193-7267-4849-ad08-6e3a35d00213",
   "metadata": {},
   "source": [
    "---\n",
    "date: '2023-08-23'\n",
    "categories:\n",
    " - natural-language-processing\n",
    " - deep-learning\n",
    " - langchain\n",
    " - activeloop\n",
    " - openai\n",
    "title: Integrating Multiple Tools for Web-Based Question-Answering\n",
    "description: The post walks through the process of finding answers to queries by searching the web and saving the retrieved answers to a text file using multiple tools\n",
    "image: https://github.com/pranath/blog/raw/master/images/langchain-deeplake2.png\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf75b16-ed61-4ed7-b0f9-26456321d4ad",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "As developers and data enthusiasts, we frequently need to use numerous tools and libraries to acquire and analyse data. We can construct powerful, efficient, and complete solutions for the systems we design using LangChain by leveraging many technologies at the same time.  This post will show you how to use the power of Google Search with the versatile Python-REPL tool for an effective outcome. You will discover how to maximise the power of various technologies operating in tandem to expedite your own information retrieval projects.\n",
    "\n",
    "Let's be more precise about what we aim to achieve:\n",
    "\n",
    "1. Search the web for an answer to a query: The agent should utilise its tools and language model to locate the most appropriate sources for it.\n",
    "2. store the answer to a file: Once the response has been retrieved, the agent is supposed to store it to a text file.\n",
    "\n",
    "## Import Libs & Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a0f352-bcd6-49e8-ac74-ee4895e9485f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"<YOUR-OPENAI-API-KEY>\"\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"<YOUR-GOOGLE-SEARCH-API-KEY>\"\n",
    "os.environ[\"GOOGLE_CSE_ID\"] = \"<YOUR-CUSTOM-SEARCH-ENGINE-ID>\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25475d6d-72ab-4254-89d8-7e7dbe534976",
   "metadata": {},
   "source": [
    "You can sign up for these keys by following [these instructions](https://support.google.com/googleapi/answer/6158862?hl=en)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635b2834-3be1-4230-8f5d-d8634ab5558a",
   "metadata": {},
   "source": [
    "Next thing, we want to import the libraries we aim to use for our project. Remember to install the required packages with the following command: pip install langchain==0.0.208 deeplake openai tiktoken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829e558b-4f76-42c2-bc70-fa0c91c31717",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.agents import Tool, initialize_agent, AgentType\n",
    "\n",
    "from langchain.utilities import GoogleSearchAPIWrapper, PythonREPL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf98f76-6994-4205-87c9-a2af5f449821",
   "metadata": {},
   "source": [
    "We’re going to declare some wrappers. The GoogleSearchAPIWrapper wrapper allows us to easily create a tool for using the Google Search APIs, whereas the PythonREPL wrapper allows the model to execute generated Python code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de3758f-4e86-47b7-9ce7-1de24da3ac24",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = GoogleSearchAPIWrapper()\n",
    "python_repl = PythonREPL()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2891f1-0498-41a7-b343-a6bc9be325c3",
   "metadata": {},
   "source": [
    "\n",
    "The next code block creates an instance of the OpenAI language model with a temperature parameter set to 0. This parameter influences the randomness of the model's output, and by setting it to 0, the generated responses will be more deterministic and focused."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d918acda-7785-471e-8f2f-80e19ac0b54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(model=\"text-davinci-003\", temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6814db2-2f9f-436b-8266-97d8d60cea55",
   "metadata": {},
   "source": [
    "Here we have our toolkit set assembled of:\n",
    "\n",
    "1. The google-search tool is a convenient way to perform Google searches when an agent needs information about current events. The tool makes use of Google's API to provide relevant search results.\n",
    "2. The python_repl tool: This tool wraps a Python shell, allowing the execution of Python commands directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a90330-b18e-4271-ac92-76e69c1eecb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "toolkit = [\n",
    "    Tool(\n",
    "        name=\"google-search\",\n",
    "        func=search.run,\n",
    "        description=\"useful for when you need to search Google to answer questions about current events\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"python_repl\",\n",
    "        description=\"A Python shell. Use this to execute Python commands. Input should be a valid Python command. Useful for saving strings to files.\",\n",
    "        func=python_repl.run\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e1e00f-a4c9-42a6-b767-4f04b181969c",
   "metadata": {},
   "source": [
    "These tools are then added to the toolkit list, which is used to initialize an agent with the specified tools. The agent can then perform various tasks using the tools in its toolkit. The agent can be easily extended by adding more tools to the toolkit, allowing it to handle a wide range of tasks and situations. Let’s instantiate the agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729c68ab-ac7b-479f-a0e6-8bea351eb1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = initialize_agent(\n",
    "\ttoolkit,\n",
    "\tllm,\n",
    "\tagent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "\tverbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3206bbbd-3117-4b38-9b5e-dbb2280c144d",
   "metadata": {},
   "source": [
    "The parameter agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION specifies the agent's strategy, which means that the agent will attempt to perform tasks without any prior examples, relying solely on its understanding of the problem description and the available tools (and their descriptions).\n",
    "\n",
    "Now let’s run the experiment! We should be able to ask the Agent directly by giving him instructions on what we want:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc670ce-ffde-4466-82d7-05673c706b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.run(\"Find the birth date of Napoleon Bonaparte and save it to a file 'final.txt'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5279a562-6027-43e8-a9f4-f0f625f59391",
   "metadata": {},
   "source": [
    "The agent first uses the google-search tool with the query \"Napoleon Bonaparte birth date\". Upon seeing its result, the agent then wrote the following Python program to save the answer to the answer.txt local file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e6d1ab-de66-4755-a70d-5851f36f1aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('answer.txt', 'w') as f:\n",
    "    f.write('Napoleon Bonaparte was born on August 15, 1769')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32214034-7dc7-4bdd-be34-db3dd5dad49a",
   "metadata": {},
   "source": [
    "You should now have a local file answer.txt containing a text similar to Napoleon Bonaparte, born on August 15, 1769.\n",
    "\n",
    "Let’s also find the death date of Napoleon and append it to the answer.txt file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3ea4c2-023e-472e-952b-7e5fb645d32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Find when Napoleon Bonaparte died and append this information \" \\\n",
    "    \"to the content of the 'answer.txt' file in a new line.\"\n",
    "\n",
    "agent.run(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb677ca3-2c13-4d9c-be37-66f6db0cb0ff",
   "metadata": {},
   "source": [
    "Your final answer.txt should look like the following:\n",
    "\n",
    "**Napoleon Bonaparte was born on August 15, 1769\n",
    "Napoleon Bonaparte died on May 5, 1821.**\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "Finally, we demonstrated how a LangChain agent may successfully use many tools and methodologies to complete a task, such as answering questions on the web and saving the answers in a file. This example demonstrates the ability of LangChain agents to provide valuable assistance in a variety of settings.\n",
    "\n",
    "## Acknowledgements\n",
    "\n",
    "I'd like to express my thanks to the wonderful [LangChain & Vector Databases in Production Course](https://learn.activeloop.ai/courses/langchain) by Activeloop - which i completed, and acknowledge the use of some images and other materials from the course in this article."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
