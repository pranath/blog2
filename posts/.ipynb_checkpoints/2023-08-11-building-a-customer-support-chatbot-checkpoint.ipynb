{
 "cells": [
  {
   "cell_type": "raw",
   "id": "a90fa738-7eab-4d1b-b3d4-f8b9ba0246d6",
   "metadata": {},
   "source": [
    "---\n",
    "date: '2023-08-11'\n",
    "categories:\n",
    " - natural-language-processing\n",
    " - deep-learning\n",
    " - langchain\n",
    " - activeloop\n",
    " - openai\n",
    " - retrievers\n",
    " - vectordb\n",
    "title: Building a Customer Support Question Answering Chatbot\n",
    "description: Here, we show how to use website material as additional context to help a chatbot efficiently reply to user queries. The code implementation uses data loaders, and stores the associated embeddings in the Deep Lake dataset, and then retrieves the documents that are most relevant to the user's query.\n",
    "image: https://github.com/pranath/blog/raw/master/images/langchain-deeplake2.png\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41408a5d-4c53-4bd8-a590-9c7925990b19",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Large language models like GPT-4 and ChatGPT have emerged as key advancements in the IT world as we observe faster technological growth. These cutting-edge models exhibit outstanding skill in content creation. They do, however, face some difficulties, including as biases and hallucinations. Despite these drawbacks, LLMs have the power to completely change the way chatbot development is done.\n",
    "\n",
    "Traditional chatbots, which are mostly intent-based, are made to react to particular user intentions. These intentions include a number of model questions and related answers. A \"Restaurant Recommendations\" purpose, for instance, would have sample inquiries like \"Can you recommend a good Italian restaurant nearby?\" or \"Where can I get the best sushi in town?\" with answers like \"You should try the Italian restaurant \"La Trattoria\" nearby\" or \"Sushi Palace\" is the best sushi restaurant in town.\"\n",
    "\n",
    "When consumers engage with the chatbot, their inquiries are compared to those with the most like intent, producing the corresponding response. However, as LLMs continue to advance, chatbot development is trending towards more advanced and dynamic options that can handle a wider variety of customer enquiries with more accuracy and nuance.\n",
    "\n",
    "## Having a Knowledge Base\n",
    "\n",
    "LLMs can greatly improve chatbot functionality by linking larger intents with Knowledge Base (KB) documents rather than individual questions and replies. This method simplifies intent management and produces more personalised responses to user enquiries.\n",
    "\n",
    "The maximum prompt size in GPT3 is roughly 4,000 tokens, which is large but insufficient for combining a full knowledge base into a single prompt. \n",
    "\n",
    "Future LLMs may not have this restriction while still having text creation capabilities. However, for the time being, we must develop a solution around it.\n",
    "\n",
    "## Workflow\n",
    "\n",
    "The goal of this project is to create a chatbot that uses GPT3 to search for answers within documents. The experiment's workflow is depicted in the diagram below.\n",
    "\n",
    "<img src=\"https://github.com/pranath/blog/raw/master/images/customer-support-activeloop-workflow.png\" width=\"800\"/>\n",
    "\n",
    "To begin, we extract some content from internet publications, divide it into little parts, compute its embeddings, and store it in Deep Lake. Then, using a user inquiry, we retrieve the most relevant chunks from Deep Lake and place them in a prompt, which will be used by the LLM to construct the final answer.\n",
    "\n",
    "It is vital to highlight that when utilising LLMs, there is always the possibility of generating hallucinations or incorrect information. Although this may not be acceptable for many customer service use cases, the chatbot can nonetheless aid operators in crafting answers that they can double-check before delivering to the user.\n",
    "\n",
    "n the next steps, we'll explore how to manage conversations with GPT-3 and provide examples to demonstrate the effectiveness of this workflow:\n",
    "\n",
    "## Import Libs & Setup\n",
    "\n",
    "First, set up the OPENAI_API_KEY and ACTIVELOOP_TOKEN environment variables with your API keys and tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16cfc04c-6f65-4321-aad6-8ab7b1745e92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: unstructured in /Users/pranathfernando/opt/anaconda3/lib/python3.9/site-packages (0.7.1)\n",
      "Requirement already satisfied: selenium in /Users/pranathfernando/opt/anaconda3/lib/python3.9/site-packages (4.11.2)\n",
      "Requirement already satisfied: msg-parser in /Users/pranathfernando/opt/anaconda3/lib/python3.9/site-packages (from unstructured) (1.2.0)\n",
      "Requirement already satisfied: openpyxl in /Users/pranathfernando/opt/anaconda3/lib/python3.9/site-packages (from unstructured) (3.0.10)\n",
      "Requirement already satisfied: python-magic in /Users/pranathfernando/opt/anaconda3/lib/python3.9/site-packages (from unstructured) (0.4.27)\n",
      "Requirement already satisfied: python-pptx in /Users/pranathfernando/opt/anaconda3/lib/python3.9/site-packages (from unstructured) (0.6.21)\n",
      "Requirement already satisfied: markdown in /Users/pranathfernando/opt/anaconda3/lib/python3.9/site-packages (from unstructured) (3.3.4)\n",
      "Requirement already satisfied: requests in /Users/pranathfernando/opt/anaconda3/lib/python3.9/site-packages (from unstructured) (2.28.1)\n",
      "Requirement already satisfied: xlrd in /Users/pranathfernando/opt/anaconda3/lib/python3.9/site-packages (from unstructured) (2.0.1)\n",
      "Requirement already satisfied: pdfminer.six in /Users/pranathfernando/opt/anaconda3/lib/python3.9/site-packages (from unstructured) (20221105)\n",
      "Requirement already satisfied: pillow in /Users/pranathfernando/opt/anaconda3/lib/python3.9/site-packages (from unstructured) (9.2.0)\n",
      "Requirement already satisfied: pypandoc in /Users/pranathfernando/opt/anaconda3/lib/python3.9/site-packages (from unstructured) (1.11)\n",
      "Requirement already satisfied: argilla in /Users/pranathfernando/opt/anaconda3/lib/python3.9/site-packages (from unstructured) (1.8.0)\n",
      "Requirement already satisfied: python-docx in /Users/pranathfernando/opt/anaconda3/lib/python3.9/site-packages (from unstructured) (0.8.11)\n",
      "Requirement already satisfied: nltk in /Users/pranathfernando/opt/anaconda3/lib/python3.9/site-packages (from unstructured) (3.7)\n",
      "Requirement already satisfied: chardet in /Users/pranathfernando/opt/anaconda3/lib/python3.9/site-packages (from unstructured) (4.0.0)\n",
      "Requirement already satisfied: pandas in /Users/pranathfernando/opt/anaconda3/lib/python3.9/site-packages (from unstructured) (1.4.4)\n",
      "Requirement already satisfied: lxml in /Users/pranathfernando/opt/anaconda3/lib/python3.9/site-packages (from unstructured) (4.9.1)\n",
      "Requirement already satisfied: urllib3[socks]<3,>=1.26 in /Users/pranathfernando/opt/anaconda3/lib/python3.9/site-packages (from selenium) (1.26.11)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in /Users/pranathfernando/opt/anaconda3/lib/python3.9/site-packages (from selenium) (0.10.3)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in /Users/pranathfernando/opt/anaconda3/lib/python3.9/site-packages (from selenium) (2023.5.7)\n",
      "Requirement already satisfied: trio~=0.17 in /Users/pranathfernando/opt/anaconda3/lib/python3.9/site-packages (from selenium) (0.22.2)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc9 in /Users/pranathfernando/opt/anaconda3/lib/python3.9/site-packages (from trio~=0.17->selenium) (1.1.2)\n",
      "Requirement already satisfied: attrs>=20.1.0 in /Users/pranathfernando/opt/anaconda3/lib/python3.9/site-packages (from trio~=0.17->selenium) (21.4.0)\n",
      "Requirement already satisfied: sortedcontainers in /Users/pranathfernando/opt/anaconda3/lib/python3.9/site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: sniffio in /Users/pranathfernando/opt/anaconda3/lib/python3.9/site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: idna in /Users/pranathfernando/opt/anaconda3/lib/python3.9/site-packages (from trio~=0.17->selenium) (3.3)\n",
      "Requirement already satisfied: outcome in /Users/pranathfernando/opt/anaconda3/lib/python3.9/site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: wsproto>=0.14 in /Users/pranathfernando/opt/anaconda3/lib/python3.9/site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in /Users/pranathfernando/opt/anaconda3/lib/python3.9/site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/pranathfernando/opt/anaconda3/lib/python3.9/site-packages (from argilla->unstructured) (21.3)\n",
      "Requirement already satisfied: httpx<0.24,>=0.15 in /Users/pranathfernando/opt/anaconda3/lib/python3.9/site-packages (from argilla->unstructured) (0.23.3)\n",
      "Requirement already satisfied: rich<=13.0.1 in /Users/pranathfernando/opt/anaconda3/lib/python3.9/site-packages (from argilla->unstructured) (13.0.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.6.0 in /Users/pranathfernando/opt/anaconda3/lib/python3.9/site-packages (from argilla->unstructured) (0.9.0)\n",
      "Requirement already satisfied: deprecated~=1.2.0 in /Users/pranathfernando/opt/anaconda3/lib/python3.9/site-packages (from argilla->unstructured) (1.2.14)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.13 in /Users/pranathfernando/opt/anaconda3/lib/python3.9/site-packages (from argilla->unstructured) (1.14.1)\n",
      "Requirement already satisfied: backoff in /Users/pranathfernando/opt/anaconda3/lib/python3.9/site-packages (from argilla->unstructured) (2.2.1)\n",
      "Requirement already satisfied: monotonic in /Users/pranathfernando/opt/anaconda3/lib/python3.9/site-packages (from argilla->unstructured) (1.6)\n",
      "Requirement already satisfied: pydantic>=1.10.7 in /Users/pranathfernando/opt/anaconda3/lib/python3.9/site-packages (from argilla->unstructured) (1.10.8)\n",
      "Requirement already satisfied: numpy<1.24.0 in /Users/pranathfernando/opt/anaconda3/lib/python3.9/site-packages (from argilla->unstructured) (1.23.5)\n",
      "Requirement already satisfied: tqdm>=4.27.0 in /Users/pranathfernando/opt/anaconda3/lib/python3.9/site-packages (from argilla->unstructured) (4.65.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/pranathfernando/opt/anaconda3/lib/python3.9/site-packages (from pandas->unstructured) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/pranathfernando/opt/anaconda3/lib/python3.9/site-packages (from pandas->unstructured) (2022.1)\n",
      "Requirement already satisfied: olefile>=0.46 in /Users/pranathfernando/opt/anaconda3/lib/python3.9/site-packages (from msg-parser->unstructured) (0.46)\n",
      "Requirement already satisfied: click in /Users/pranathfernando/opt/anaconda3/lib/python3.9/site-packages (from nltk->unstructured) (8.0.4)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/pranathfernando/opt/anaconda3/lib/python3.9/site-packages (from nltk->unstructured) (2022.7.9)\n",
      "Requirement already satisfied: joblib in /Users/pranathfernando/opt/anaconda3/lib/python3.9/site-packages (from nltk->unstructured) (1.1.0)\n",
      "Requirement already satisfied: et_xmlfile in /Users/pranathfernando/opt/anaconda3/lib/python3.9/site-packages (from openpyxl->unstructured) (1.1.0)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in /Users/pranathfernando/opt/anaconda3/lib/python3.9/site-packages (from pdfminer.six->unstructured) (37.0.1)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in /Users/pranathfernando/opt/anaconda3/lib/python3.9/site-packages (from pdfminer.six->unstructured) (2.0.4)\n",
      "Requirement already satisfied: XlsxWriter>=0.5.7 in /Users/pranathfernando/opt/anaconda3/lib/python3.9/site-packages (from python-pptx->unstructured) (3.0.3)\n",
      "Requirement already satisfied: cffi>=1.12 in /Users/pranathfernando/opt/anaconda3/lib/python3.9/site-packages (from cryptography>=36.0.0->pdfminer.six->unstructured) (1.15.1)\n",
      "Requirement already satisfied: httpcore<0.17.0,>=0.15.0 in /Users/pranathfernando/opt/anaconda3/lib/python3.9/site-packages (from httpx<0.24,>=0.15->argilla->unstructured) (0.16.3)\n",
      "Requirement already satisfied: rfc3986[idna2008]<2,>=1.3 in /Users/pranathfernando/opt/anaconda3/lib/python3.9/site-packages (from httpx<0.24,>=0.15->argilla->unstructured) (1.5.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/pranathfernando/opt/anaconda3/lib/python3.9/site-packages (from packaging>=20.0->argilla->unstructured) (3.0.9)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /Users/pranathfernando/opt/anaconda3/lib/python3.9/site-packages (from pydantic>=1.10.7->argilla->unstructured) (4.6.3)\n",
      "Requirement already satisfied: six>=1.5 in /Users/pranathfernando/opt/anaconda3/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas->unstructured) (1.16.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.6.0 in /Users/pranathfernando/opt/anaconda3/lib/python3.9/site-packages (from rich<=13.0.1->argilla->unstructured) (2.15.1)\n",
      "Requirement already satisfied: commonmark<0.10.0,>=0.9.0 in /Users/pranathfernando/opt/anaconda3/lib/python3.9/site-packages (from rich<=13.0.1->argilla->unstructured) (0.9.1)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in /Users/pranathfernando/opt/anaconda3/lib/python3.9/site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
      "Requirement already satisfied: pycparser in /Users/pranathfernando/opt/anaconda3/lib/python3.9/site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six->unstructured) (2.21)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in /Users/pranathfernando/opt/anaconda3/lib/python3.9/site-packages (from httpcore<0.17.0,>=0.15.0->httpx<0.24,>=0.15->argilla->unstructured) (3.5.0)\n"
     ]
    }
   ],
   "source": [
    "#| include: false\n",
    "!pip install unstructured selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2e7b1e9-7382-4037-826d-58ac96c8fd5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import DeepLake\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain import OpenAI\n",
    "from langchain.document_loaders import SeleniumURLLoader\n",
    "from langchain import PromptTemplate\n",
    "import os\n",
    "import openai\n",
    "import sys\n",
    "sys.path.append('../..')\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "openai.api_key  = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798d3fbb-f6b4-4be7-aa1b-c6c26abc9d52",
   "metadata": {},
   "source": [
    "These libraries provide OpenAI embeddings, vector storage management, text splitting, and communicating with the OpenAI API. They also allow for the development of a context-aware question-answering system that incorporates retrieval and text generation.\n",
    "\n",
    "Our chatbot's database will be made up of articles about technical challenges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65fdbddc-4cad-4606-8b7a-1592d3d7dabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we'll use information from the following articles\n",
    "urls = ['https://beebom.com/what-is-nft-explained/',\n",
    "        'https://beebom.com/how-delete-spotify-account/',\n",
    "        'https://beebom.com/how-download-gif-twitter/',\n",
    "        'https://beebom.com/how-use-chatgpt-linux-terminal/',\n",
    "        'https://beebom.com/how-delete-spotify-account/',\n",
    "        'https://beebom.com/how-save-instagram-story-with-music/',\n",
    "        'https://beebom.com/how-install-pip-windows/',\n",
    "        'https://beebom.com/how-check-disk-usage-linux/']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448b25db-f6ed-47de-8fc9-5e396548a3b2",
   "metadata": {},
   "source": [
    "## Split the documents into chunks and compute their embeddings\n",
    "\n",
    "We load the pages from the specified URLs and split them into 1000 parts with no overlap using the CharacterTextSplitter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42dbda78-b11d-42ce-ac2a-578445b76f21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 1226, which is longer than the specified 1000\n"
     ]
    }
   ],
   "source": [
    "# use the selenium scraper to load the documents\n",
    "loader = SeleniumURLLoader(urls=urls)\n",
    "docs_not_splitted = loader.load()\n",
    "\n",
    "# we split the documents into smaller chunks\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "docs = text_splitter.split_documents(docs_not_splitted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096d3c34-bdb8-41af-998f-42f109cb1064",
   "metadata": {},
   "source": [
    "The embeddings are then computed using OpenAIEmbeddings and stored in a Deep Lake vector store in the cloud. In an ideal production scenario, we could upload an entire website or course lesson to a Deep Lake dataset, enabling search over thousands or millions of documents. Because we are using a cloud serverless Deep Lake dataset, applications running in multiple locations may easily access the same centralised dataset without the need for a vector store to be deployed on a specific machine.\n",
    "\n",
    "Now, change the following code to include your Activeloop organisation ID. It's worth remembering that the org id is your default username."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f1b8eb9f-4c1f-4062-a2a5-57078a4f9487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your Deep Lake dataset has been successfully created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\\"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset(path='hub://pranath/langchain_course_customer_support', tensors=['embedding', 'id', 'metadata', 'text'])\n",
      "\n",
      "  tensor      htype       shape      dtype  compression\n",
      "  -------    -------     -------    -------  ------- \n",
      " embedding  embedding  (146, 1536)  float32   None   \n",
      "    id        text      (146, 1)      str     None   \n",
      " metadata     json      (146, 1)      str     None   \n",
      "   text       text      (146, 1)      str     None   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['52ad71cc-3c5e-11ee-bdd8-acde48001122',\n",
       " '52ad732a-3c5e-11ee-bdd8-acde48001122',\n",
       " '52ad738e-3c5e-11ee-bdd8-acde48001122',\n",
       " '52ad73d4-3c5e-11ee-bdd8-acde48001122',\n",
       " '52ad7410-3c5e-11ee-bdd8-acde48001122',\n",
       " '52ad7456-3c5e-11ee-bdd8-acde48001122',\n",
       " '52ad7492-3c5e-11ee-bdd8-acde48001122',\n",
       " '52ad74ce-3c5e-11ee-bdd8-acde48001122',\n",
       " '52ad750a-3c5e-11ee-bdd8-acde48001122',\n",
       " '52ad7550-3c5e-11ee-bdd8-acde48001122',\n",
       " '52ad758c-3c5e-11ee-bdd8-acde48001122',\n",
       " '52ad75c8-3c5e-11ee-bdd8-acde48001122',\n",
       " '52ad7604-3c5e-11ee-bdd8-acde48001122',\n",
       " '52ad7640-3c5e-11ee-bdd8-acde48001122',\n",
       " '52ad7686-3c5e-11ee-bdd8-acde48001122',\n",
       " '52ad76c2-3c5e-11ee-bdd8-acde48001122',\n",
       " '52ad76fe-3c5e-11ee-bdd8-acde48001122',\n",
       " '52ad7744-3c5e-11ee-bdd8-acde48001122',\n",
       " '52ad7780-3c5e-11ee-bdd8-acde48001122',\n",
       " '52ad77bc-3c5e-11ee-bdd8-acde48001122',\n",
       " '52ad77f8-3c5e-11ee-bdd8-acde48001122',\n",
       " '52ad783e-3c5e-11ee-bdd8-acde48001122',\n",
       " '52ad787a-3c5e-11ee-bdd8-acde48001122',\n",
       " '52ad78b6-3c5e-11ee-bdd8-acde48001122',\n",
       " '52ad78f2-3c5e-11ee-bdd8-acde48001122',\n",
       " '52ad792e-3c5e-11ee-bdd8-acde48001122',\n",
       " '52ad7974-3c5e-11ee-bdd8-acde48001122',\n",
       " '52ad79b0-3c5e-11ee-bdd8-acde48001122',\n",
       " '52ad79ec-3c5e-11ee-bdd8-acde48001122',\n",
       " '52ad7a28-3c5e-11ee-bdd8-acde48001122',\n",
       " '52ad7a64-3c5e-11ee-bdd8-acde48001122',\n",
       " '52ad7aaa-3c5e-11ee-bdd8-acde48001122',\n",
       " '52ad7ae6-3c5e-11ee-bdd8-acde48001122',\n",
       " '52ad7b22-3c5e-11ee-bdd8-acde48001122',\n",
       " '52ad7b5e-3c5e-11ee-bdd8-acde48001122',\n",
       " '52ad7b9a-3c5e-11ee-bdd8-acde48001122',\n",
       " '52ad7be0-3c5e-11ee-bdd8-acde48001122',\n",
       " '52ad7c1c-3c5e-11ee-bdd8-acde48001122',\n",
       " '52ad7c94-3c5e-11ee-bdd8-acde48001122',\n",
       " '52ad7cd0-3c5e-11ee-bdd8-acde48001122',\n",
       " '52ad7d0c-3c5e-11ee-bdd8-acde48001122',\n",
       " '52ad7d52-3c5e-11ee-bdd8-acde48001122',\n",
       " '52ad7d8e-3c5e-11ee-bdd8-acde48001122',\n",
       " '52ad7dca-3c5e-11ee-bdd8-acde48001122',\n",
       " '52ad7e10-3c5e-11ee-bdd8-acde48001122',\n",
       " '52ad7e4c-3c5e-11ee-bdd8-acde48001122',\n",
       " '52ad7e88-3c5e-11ee-bdd8-acde48001122',\n",
       " '52ad7ec4-3c5e-11ee-bdd8-acde48001122',\n",
       " '52ad7f0a-3c5e-11ee-bdd8-acde48001122',\n",
       " '52ad7f46-3c5e-11ee-bdd8-acde48001122',\n",
       " '52ad7f82-3c5e-11ee-bdd8-acde48001122',\n",
       " '52ad7fbe-3c5e-11ee-bdd8-acde48001122',\n",
       " '52ad7ffa-3c5e-11ee-bdd8-acde48001122',\n",
       " '52ad805e-3c5e-11ee-bdd8-acde48001122',\n",
       " '52ad809a-3c5e-11ee-bdd8-acde48001122',\n",
       " '52ad80d6-3c5e-11ee-bdd8-acde48001122',\n",
       " '52ad8112-3c5e-11ee-bdd8-acde48001122',\n",
       " '52ad814e-3c5e-11ee-bdd8-acde48001122',\n",
       " '52ad8194-3c5e-11ee-bdd8-acde48001122',\n",
       " '52ad81d0-3c5e-11ee-bdd8-acde48001122',\n",
       " '52ad820c-3c5e-11ee-bdd8-acde48001122',\n",
       " '52ad8248-3c5e-11ee-bdd8-acde48001122',\n",
       " '52ad828e-3c5e-11ee-bdd8-acde48001122',\n",
       " '52ad82ca-3c5e-11ee-bdd8-acde48001122',\n",
       " '52ad8306-3c5e-11ee-bdd8-acde48001122',\n",
       " '52ad8342-3c5e-11ee-bdd8-acde48001122',\n",
       " '52ad8388-3c5e-11ee-bdd8-acde48001122',\n",
       " '52ad83c4-3c5e-11ee-bdd8-acde48001122',\n",
       " '52ad8400-3c5e-11ee-bdd8-acde48001122',\n",
       " '52ad843c-3c5e-11ee-bdd8-acde48001122',\n",
       " '52ad8478-3c5e-11ee-bdd8-acde48001122',\n",
       " '52ad84b4-3c5e-11ee-bdd8-acde48001122',\n",
       " '52ad84f0-3c5e-11ee-bdd8-acde48001122',\n",
       " '52ad852c-3c5e-11ee-bdd8-acde48001122',\n",
       " '52ad8572-3c5e-11ee-bdd8-acde48001122',\n",
       " '52ad85ae-3c5e-11ee-bdd8-acde48001122',\n",
       " '52ad85ea-3c5e-11ee-bdd8-acde48001122',\n",
       " '52ad863a-3c5e-11ee-bdd8-acde48001122',\n",
       " '52ad8676-3c5e-11ee-bdd8-acde48001122',\n",
       " '52ad86b2-3c5e-11ee-bdd8-acde48001122',\n",
       " '52ad86ee-3c5e-11ee-bdd8-acde48001122',\n",
       " '52ad873e-3c5e-11ee-bdd8-acde48001122',\n",
       " '52ad877a-3c5e-11ee-bdd8-acde48001122',\n",
       " '52ad87b6-3c5e-11ee-bdd8-acde48001122',\n",
       " '52ad87f2-3c5e-11ee-bdd8-acde48001122',\n",
       " '52ad882e-3c5e-11ee-bdd8-acde48001122',\n",
       " '52ad8874-3c5e-11ee-bdd8-acde48001122',\n",
       " '52ad88b0-3c5e-11ee-bdd8-acde48001122',\n",
       " '52ad88ec-3c5e-11ee-bdd8-acde48001122',\n",
       " '52ad8928-3c5e-11ee-bdd8-acde48001122',\n",
       " '52ad8964-3c5e-11ee-bdd8-acde48001122',\n",
       " '52ad89a0-3c5e-11ee-bdd8-acde48001122',\n",
       " '52ad89dc-3c5e-11ee-bdd8-acde48001122',\n",
       " '52ad8a18-3c5e-11ee-bdd8-acde48001122',\n",
       " '52ad8a54-3c5e-11ee-bdd8-acde48001122',\n",
       " '52ad8a9a-3c5e-11ee-bdd8-acde48001122',\n",
       " '52ad8ad6-3c5e-11ee-bdd8-acde48001122',\n",
       " '52ad8b12-3c5e-11ee-bdd8-acde48001122',\n",
       " '52ad8b4e-3c5e-11ee-bdd8-acde48001122',\n",
       " '52ad8b8a-3c5e-11ee-bdd8-acde48001122',\n",
       " '52ad8bc6-3c5e-11ee-bdd8-acde48001122',\n",
       " '52ad8c02-3c5e-11ee-bdd8-acde48001122',\n",
       " '52ad8c3e-3c5e-11ee-bdd8-acde48001122',\n",
       " '52ad8c7a-3c5e-11ee-bdd8-acde48001122',\n",
       " '52ad8cb6-3c5e-11ee-bdd8-acde48001122',\n",
       " '52ad8cf2-3c5e-11ee-bdd8-acde48001122',\n",
       " '52ad8d2e-3c5e-11ee-bdd8-acde48001122',\n",
       " '52ad8d6a-3c5e-11ee-bdd8-acde48001122',\n",
       " '52ad8db0-3c5e-11ee-bdd8-acde48001122',\n",
       " '52ad8dec-3c5e-11ee-bdd8-acde48001122',\n",
       " '52ad8e32-3c5e-11ee-bdd8-acde48001122',\n",
       " '52ad8e6e-3c5e-11ee-bdd8-acde48001122',\n",
       " '52ad8eaa-3c5e-11ee-bdd8-acde48001122',\n",
       " '52ad8ee6-3c5e-11ee-bdd8-acde48001122',\n",
       " '52ad8f22-3c5e-11ee-bdd8-acde48001122',\n",
       " '52ad8f5e-3c5e-11ee-bdd8-acde48001122',\n",
       " '52ad8f9a-3c5e-11ee-bdd8-acde48001122',\n",
       " '52ad8fd6-3c5e-11ee-bdd8-acde48001122',\n",
       " '52ad9012-3c5e-11ee-bdd8-acde48001122',\n",
       " '52ad904e-3c5e-11ee-bdd8-acde48001122',\n",
       " '52ad908a-3c5e-11ee-bdd8-acde48001122',\n",
       " '52ad90d0-3c5e-11ee-bdd8-acde48001122',\n",
       " '52ad915c-3c5e-11ee-bdd8-acde48001122',\n",
       " '52ad91a2-3c5e-11ee-bdd8-acde48001122',\n",
       " '52ad91de-3c5e-11ee-bdd8-acde48001122',\n",
       " '52ad921a-3c5e-11ee-bdd8-acde48001122',\n",
       " '52ad9256-3c5e-11ee-bdd8-acde48001122',\n",
       " '52ad9292-3c5e-11ee-bdd8-acde48001122',\n",
       " '52ad92d8-3c5e-11ee-bdd8-acde48001122',\n",
       " '52ad931e-3c5e-11ee-bdd8-acde48001122',\n",
       " '52ad935a-3c5e-11ee-bdd8-acde48001122',\n",
       " '52ad93a0-3c5e-11ee-bdd8-acde48001122',\n",
       " '52ad93dc-3c5e-11ee-bdd8-acde48001122',\n",
       " '52ad9418-3c5e-11ee-bdd8-acde48001122',\n",
       " '52ad9454-3c5e-11ee-bdd8-acde48001122',\n",
       " '52ad9490-3c5e-11ee-bdd8-acde48001122',\n",
       " '52ad94d6-3c5e-11ee-bdd8-acde48001122',\n",
       " '52ad9512-3c5e-11ee-bdd8-acde48001122',\n",
       " '52ad954e-3c5e-11ee-bdd8-acde48001122',\n",
       " '52ad958a-3c5e-11ee-bdd8-acde48001122',\n",
       " '52ad95c6-3c5e-11ee-bdd8-acde48001122',\n",
       " '52ad960c-3c5e-11ee-bdd8-acde48001122',\n",
       " '52ad9648-3c5e-11ee-bdd8-acde48001122',\n",
       " '52ad9684-3c5e-11ee-bdd8-acde48001122',\n",
       " '52ad96c0-3c5e-11ee-bdd8-acde48001122',\n",
       " '52ad96fc-3c5e-11ee-bdd8-acde48001122']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Before executing the following code, make sure to have\n",
    "# your OpenAI key saved in the “OPENAI_API_KEY” environment variable.\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
    "\n",
    "# create Deep Lake dataset\n",
    "# TODO: use your organization id here. (by default, org id is your username)\n",
    "my_activeloop_org_id = \"pranath\"\n",
    "my_activeloop_dataset_name = \"langchain_course_customer_support\"\n",
    "dataset_path = f\"hub://{my_activeloop_org_id}/{my_activeloop_dataset_name}\"\n",
    "db = DeepLake(dataset_path=dataset_path, embedding_function=embeddings)\n",
    "\n",
    "# add documents to our Deep Lake dataset\n",
    "db.add_documents(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0501d44f-4075-43fe-b031-f208a20cebb2",
   "metadata": {},
   "source": [
    "To retrieve the most similar chunks to a given query, we can use the similarity_search method of the Deep Lake vector store:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "886a1afc-2189-4c22-92f8-ca2ff237751d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Home  Tech  How to Check Disk Usage in Linux (4 Methods)\n",
      "\n",
      "How to Check Disk Usage in Linux (4 Methods)\n",
      "\n",
      "Beebom Staff\n",
      "\n",
      "Last Updated: June 19, 2023 5:14 pm\n",
      "\n",
      "There may be times when you need to download some important files or transfer some photos to your Linux system, but face a problem of insufficient disk space. You head over to your file manager to delete the large files which you no longer require, but you have no clue which of them are occupying most of your disk space. In this article, we will show some easy methods to check disk usage in Linux from both the terminal and the GUI application.\n",
      "\n",
      "Monitor Disk Usage in Linux (2023)\n",
      "\n",
      "Table of Contents\n",
      "\n",
      "Check Disk Space Using the df Command\n",
      "\t\t\n",
      "Display Disk Usage in Human Readable FormatDisplay Disk Occupancy of a Particular Type\n",
      "\n",
      "Check Disk Usage using the du Command\n",
      "\t\t\n",
      "Display Disk Usage in Human Readable FormatDisplay Disk Usage for a Particular DirectoryCompare Disk Usage of Two Directories\n"
     ]
    }
   ],
   "source": [
    "# let's see the top relevant documents to a specific query\n",
    "query = \"how to check disk usage in linux?\"\n",
    "docs = db.similarity_search(query)\n",
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471e94e5-31c1-494c-be97-8789216b0385",
   "metadata": {},
   "source": [
    "## Craft a prompt for GPT-3 using the suggested strategies\n",
    "\n",
    "We'll develop a prompt template that combines role-prompting, Knowledge Base information, and the user's question:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e5f00db-ef88-4b50-87b5-90361776e3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's write a prompt for a customer support chatbot that\n",
    "# answer questions using information extracted from our db\n",
    "template = \"\"\"You are an exceptional customer support chatbot that gently answer questions.\n",
    "\n",
    "You know the following context information.\n",
    "\n",
    "{chunks_formatted}\n",
    "\n",
    "Answer to the following question from a customer. Use only information from the previous context information. Do not invent stuff.\n",
    "\n",
    "Question: {query}\n",
    "\n",
    "Answer:\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"chunks_formatted\", \"query\"],\n",
    "    template=template,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccea8077-e1d6-4ee1-b1ed-5a05f3f6a754",
   "metadata": {},
   "source": [
    "The template establishes the chatbot's persona as an outstanding customer support chatbot. The template accepts two variables as input: chunks_formatted, which contains pre-formatted chunks from articles, and query, which represents the customer's question. The goal is to construct an accurate answer utilising only the available chunks while avoiding the creation of erroneous or fictional information.\n",
    "\n",
    "## Utilize the GPT3 model with a temperature of 0 for text generation\n",
    "\n",
    "To construct a response, we first obtain the top-k (e.g., top-3) chunks that are most comparable to the user question, format the prompt, and send it to the GPT3 model with a temperature of 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ef663406-f5ef-4b93-a81e-7b5ddbc4870d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " You can check disk usage in Linux using the df command or by using a GUI tool such as the GDU Disk Usage Analyzer or the Gnome Disks Tool. The df command is used to check the current disk usage and the available disk space in Linux. The syntax for the df command is: df <options> <file_system>. The options to use with the df command are: a, h, t, and x. To install the GDU Disk Usage Analyzer, use the command: sudo snap install gdu-disk-usage-analyzer. To install the Gnome Disks Tool, use the command: sudo apt-get -y install gnome-disk-utility.\n"
     ]
    }
   ],
   "source": [
    "# the full pipeline\n",
    "\n",
    "# user question\n",
    "query = \"How to check disk usage in linux?\"\n",
    "\n",
    "# retrieve relevant chunks\n",
    "docs = db.similarity_search(query)\n",
    "retrieved_chunks = [doc.page_content for doc in docs]\n",
    "\n",
    "# format the prompt\n",
    "chunks_formatted = \"\\n\\n\".join(retrieved_chunks)\n",
    "prompt_formatted = prompt.format(chunks_formatted=chunks_formatted, query=query)\n",
    "\n",
    "# generate answer\n",
    "llm = OpenAI(model=\"text-davinci-003\", temperature=0)\n",
    "answer = llm(prompt_formatted)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b434fd6-132c-4ec8-bfe8-e8c7aa245b4d",
   "metadata": {},
   "source": [
    "## Issues with Generating Answers using GPT-3\n",
    "\n",
    "In the above scenario, the chatbot performs admirably. However, there are some cases where it may fail.\n",
    "\n",
    "Assume we ask GPT-3, \"Is the Linux distribution free?\" and provide context in the form of a document regarding kernel features. It may provide a response such as \"Yes, the Linux distribution is free to download and use,\" even if such information is not contained in the context page. False information is extremely undesirable for customer service chatbots!\n",
    "\n",
    "When the answer to the user's question is contained inside the context, GPT-3 is less likely to generate misleading information. We cannot always rely on the semantic search stage to find the proper document because user questions are frequently brief and vague. There is always the possibility of generating erroneous information.\n",
    "\n",
    "## An Alternative - SalesCopilot Helping Support Human Customer Services\n",
    "\n",
    "There may be times for various reasons you choose to use humans in customer services, in these cases you may be able to use something like [SalesCopilot](https://github.com/e-johnstonn/SalesCopilot) as described by [this article](https://www.activeloop.ai/resources/conversation-intelligence-gong-io-open-source-alternative-ai-sales-assistant/) which looks into how LangChain, Deep Lake, and GPT-4 can be used to develop a sales assistant able to give advice to salesman, taking into considerations internal guidelines.\n",
    "\n",
    "This article goes into detail about a sales call assistant that connects you to a chatbot that understands the context of your conversation. One of SalesCopilot's biggest features is its ability to recognise probable customer complaints and provide ideas on how to effectively handle them.\n",
    "\n",
    "The post illustrates the obstacles encountered and solutions uncovered during the project's development. You'll discover the two unique text-splitting approaches that failed and how these failures paved the path for an effective solution.\n",
    "\n",
    "Initially, the authors attempted to rely entirely on the LLM, but they experienced challenges with GPT-4 such as response inconsistency and sluggish response times. Second, they erroneously divided the custom knowledge base into chunks, which resulted in context misalignment and inefficient results.\n",
    "\n",
    "<img src=\"https://github.com/pranath/blog/raw/master/images/sales-copilot.png\" width=\"800\"/>\n",
    "\n",
    "Following these failed attempts, a more intelligent method of partitioning the knowledge base based on its structure was developed. This improvement significantly enhanced response quality and ensured stronger context grounding for LLM responses. This process is detailed, allowing you to understand how to overcome comparable issues in your own AI projects.\n",
    "\n",
    "The paper then delves into how SalesCopilot was linked with Deep Lake. This integration expanded SalesCopilot's capabilities by collecting the most appropriate responses from a proprietary knowledge base, resulting in a dependable, efficient, and highly adjustable solution for dealing with client concerns.\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "GPT-3 is quite good at generating conversational chatbots that can answer particular queries based on the context provided in the prompt. However, because the model has a tendency to hallucinate (i.e., invent new, potentially erroneous information), it might be difficult to ensure that it generates answers simply based on the context. The intensity of erroneous information generation varies based on the use case.\n",
    "\n",
    "Finally, we used LangChain to build a context-aware question-answering system, following the code and ideas supplied. Splitting documents into chunks, computing their embeddings, constructing a retriever to discover related chunks, creating a prompt for GPT-3, and using the GPT3 model for text production were all part of the procedure. This method highlights the power of exploiting GPT-3 to build powerful and contextually correct chatbots while also emphasising the need to be cautious about the possibilities of providing fake information.\n",
    "\n",
    "Further Reading:\n",
    "\n",
    "[https://learnprompting.org/docs/applied_prompting/build_chatbot_from_kb](https://learnprompting.org/docs/applied_prompting/build_chatbot_from_kb)\n",
    "\n",
    "## Acknowledgements\n",
    "\n",
    "I'd like to express my thanks to the wonderful [LangChain & Vector Databases in Production Course](https://learn.activeloop.ai/courses/langchain) by Activeloop - which i completed, and acknowledge the use of some images and other materials from the course in this article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf85e3b-37f3-41d2-bc8a-b169dc6dac96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
