{
 "cells": [
  {
   "cell_type": "raw",
   "id": "6e92828b-ae8b-4188-9e56-a9fa468fbbd5",
   "metadata": {},
   "source": [
    "---\n",
    "date: '2023-05-07'\n",
    "categories:\n",
    " - opinion\n",
    " - deep-learning\n",
    "title: Do our hopes and fears about AI tell us more about Humans than they do about AI ?\n",
    "description: Recent developments in AI have inspired great debate and both dystopian fears & demands for action as well as utopian visions of AI saving us. But do these debates help us understand AI or do they perhaps say more about the dysfunctions and weaknesses of human civilisation?\n",
    "image: https://github.com/pranath/blog/raw/master/images/human-ai-utopia.png\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1723e1b-7ce0-4e9d-902b-f0b8653bf6ec",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "The recent rapid developments in AI (such as ChatGPT) have given rise to passionate and furious debate in the media and in the public more generally, which range from AI apoclyptic scenarios and demand for preventitive action to utopian visions of AI transforming humanity for the better. But do these visions give us a better idea of what is actually likely to happen with AI? or does this tell us more about who we are as humans than it does the future of AI.\n",
    "\n",
    "In this article I explore some ideas i've been thinking about in this space about what is really going on with our visions of the future of AI, as someone who is actually working in this industry and has worked with the technology directly as can be seen by the many articles I've written on deep learning and AI in this blog.\n",
    "\n",
    "## We can't actually predict the future - But are terrified of accepting that uncertainty \n",
    "\n",
    "One of the things I find most fascinating about not only debates about the future of AI, but indeed humans discussing almost anything - is the tendancy of humans to be far more certain that their beliefs are literally true, as opposed to being comfortable with the possibility that their belief's might not but true or the whole truth. Nowhere is this perhaps more hillarious than humans beliefs about the future. \n",
    "\n",
    "In a post-enlightment world with quantum computers, iphones, and space ships you might be forgiven for thinking that prophecies about the future might be somewhat passé ? Yet sadly not. When speaking about the future most of us seem to have maintained our historic religious zeal for 'being so absolutely certain the future will be the way I feel' regardless of when reality starts to diverge and intrude on our cherished prophecies. What I also find quite amusing about this is most often includes scientists, central bankers, and many others who apparently beleive in post-enlightenment rational based thinking, and the value not only of reason but evidence. Reality can be inconvienient for our beliefs, when our predictions about the future don't come true.\n",
    "\n",
    "Is this surprising though? Perhaps not. Many studies have highlighted how terrified humans are of the unknown. For example in [recent studies by Psychologist Ema Tanovic](https://www.bbc.com/worklife/article/20211022-why-were-so-terrified-of-the-unknown) evidence for how simply uncertainty can intensify how threatening a situation feels - regardless of there actually being threat or not. As she highlights:\n",
    "\n",
    "> 'People can try very hard to reduce uncertainty and the anxiety that comes with it, like repeatedly calling a loved one to make sure they are OK, texting a crush incessantly when they haven't texted back, compulsively refreshing one's inbox when expecting to hear back about an interview...sometimes it works, and the behaviour resolves the uncertainty, but these actions can often be quite costly in terms of the time, effort and effect on relationships.'\n",
    "\n",
    "This has also been confirmed from studies in Neuroscience which has uncovered evidence that the perception of uncertainty causes [cognitive strain and negative feelings in our brains](https://qz.com/work/1494807/why-its-so-hard-to-think-effectively-about-the-future). In fact, dealing with uncertainty is so uncomfortable that it interferes with learning as well as decision-making and mental risk evaluation.\n",
    "\n",
    "This is because the brain values certainty in a way that is very similar to how it values things like food, sex, and interpersonal relationships. The brain perceives uncertainty—and the inability to foresee the future—as a source of intense discomfort because a sense of certainty affords a perceived control over the environment that is fundamentally satisfying.\n",
    "\n",
    "So rather than these speculations actually helping us better understand the future, perhaps its more the case that we are projecting our worst fears and best hopes onto the blank canvas of the uncertainty of the future of AI, and believing our wild speculations are likely to be be true, making us feel more emotionally comfortable? Rather than be unfashionable and simply accept 'well actually we don't know whats going to happen' which would of course be rather more uncomfortable despite being the more honest and rational position.\n",
    "\n",
    "In the context of these studies then, perhaps we can understand the tendancy of people (including leading scientists and journalists) to prefer to feel certain in their Dystopian beliefs about the dangers of AI for example [Max Tegmark](https://time.com/6273743/thinking-that-could-doom-us-with-ai/) or [Elon Musk](https://edition.cnn.com/2023/04/17/tech/elon-musk-ai-warning-tucker-carlson/index.html#:~:text=%E2%80%9CAI%20is%20more%20dangerous%20than,in%20his%20interview%20with%20Tucker) or the more Utopian beliefs in the potential of AI such as [Denis Hassabis](https://www.newscientist.com/article/mg24833140-700-demis-hassabis-interview-our-ai-will-unlock-secrets-of-how-life-works/) or [Satya Nadella](https://www.newscientist.com/article/mg24833140-700-demis-hassabis-interview-our-ai-will-unlock-secrets-of-how-life-works/) despite often a severe lack of evidence and the objective fact that we don't actually know how AI will develop in the future and what the actual benefits or dangers will be.\n",
    "\n",
    "## Most AI fantasies seem to be about Subjigation - Why?\n",
    "\n",
    "So how might we better approach dealing with the future of AI beyond Dystopian or Utopian fantasies? for that i'm actually going to suggest it could be helpful first to look at the past and present of humanity, not AI.\n",
    "\n",
    "One thing that stikes me is something that both Dystopian and Utopian speculations/fantasies of the future of AI appear to both have in common - which is the idea of **Subjigation or Control**. In both fantasies, either AI subjigates and controls humanity for its benefit, or humanity subjigates and controls AI for its benefit - but the relationship of subjigation is common.\n",
    "\n",
    "This makes me curious - why is this? Why can we only imagine a future relationship with AI based on some kind of subjigation? for example, why can't we imagine a future where we collaberate with AI, where AI is either tool or a 'partner' we can work or play with? Why are such speculations rare?\n",
    "\n",
    "Could it be related to the fact that we often see human relationships as defined by subjigation, power and control? While it could be argued that the progress to more equality and co-operation between humans has made progress, one could also argue that for most of recent human history, heirrachy control and subjigation have had a bigger impact on defining not only how humans relate to each other but also in terms of how humans relate to the rest of the world more generally, and that this is very present with us still today as a defining characteristic of our species.\n",
    "\n",
    "And indeed while social scientists continue to debate about what extent humans are [more inherrrently](https://press.princeton.edu/ideas/the-case-for-hierarchy) hierarchical [than not in the past](https://press.princeton.edu/ideas/the-case-for-hierarchy), few would disagree that heirarchy has been in more modern times a defining aspect of our species, arguably to different degrees in different cultures and societies.\n",
    "\n",
    "So its my hypothesis that this would inevitably limit what we could imagine our relationship with AI would be, or could most likely be. Given we struggle to relate to other humans as equals, is it so surpising we can't really imagine any other kind of future relationship with AI that is'nt some kind of subjigation?\n",
    "\n",
    "## Misinformation and AI - Are the media and journalists even worse than AI?\n",
    "\n",
    "\n",
    "\n",
    "- Desparate media for attention influence and relevance distorts actual current science facts misleads public\n",
    "- Debates about AI making stuff up seem somewhat ironic and hillarous from a species that knows how to that itself in style\n",
    "- Effect on jobs, transformation of work etc\n",
    "- Job/Career for life vs continual learning and adaptation\n",
    "- AI fears like immigration fears? \n",
    "\n",
    "\n",
    "- AI as a new god? messiah complex\n",
    "- Loss of connection to ourselves, alienation, to each other\n",
    "\n",
    "## Passive vs Participatory Visions of the Future\n",
    "\n",
    "- One fuel of dystopian is not only fear of uncertainty of future but also lack of control or influence on it\n",
    "- My article hows some examples demonstrates power but also limitations http://localhost:5852/posts/2023-05-01-best-practice-for-prompting-large-language-models.html\n",
    "- This article: image, text google, quill bot, chat gpt\n",
    "- The copernican effect and the nature of reality vs our perceptions and the progress of human knowledge about reality\n",
    "- Daniel Third attractor\n",
    "- Context is everything?\n",
    "- What does it mean to be human? enhaced use of technology, social media... (art images)\n",
    "- Maybe our best hope for ourselves and the future of AI is to start to realise that our worst fears may not nesscairly be true, that it can be valuable to not only be have feelings but to integrate our feelings with more objective and rational thinking and evidence, and possibility that the path for humans to live more equally and freely with each other while slow is making progress, and our capacity to imagine and create a world where humans don't need to subjigate each other may have a big influence on if our relationship with AI will be charactetrised by subjicgation or co-operation and partnership\n",
    "- STAY FOCUSSED ON THE MAIN POINT DONT GO OFF ON TOO MANY TANGENTS !!!\n",
    "\n",
    "https://joshbersin.com/2023/04/why-is-the-world-afraid-of-ai-the-fears-are-unfounded-and-heres-why/\n",
    "\n",
    "https://blogs.scientificamerican.com/observations/dont-fear-the-terminator/\n",
    "\n",
    "https://www.mycustomer.com/marketing/strategy/how-research-proves-emotion-is-more-powerful-than-logic-in-marketing\n",
    "\n",
    "https://news.harvard.edu/gazette/story/2023/02/will-chatgpt-replace-human-writers-pinker-weighs-in/\n",
    "\n",
    "https://www.psychologytoday.com/gb/blog/evolution-the-self/201706/what-s-emotional-reasoning-and-why-is-it-such-problem\n",
    "\n",
    "https://rebelwisdom.co.uk/18-film-content/general/924-in-search-of-the-third-attractor-daniel-schmachtenberger-part-1\n",
    "\n",
    "https://rebelwisdom.co.uk/18-film-content/general/925-in-search-of-the-third-attractor-daniel-schmachtenberger-part-2\n",
    "\n",
    "https://www.businessinsider.com/ai-will-give-every-student-personalized-tutor-sal-khan-academy-2023-5?r=US&IR=T\n",
    "\n",
    "https://www.theguardian.com/technology/2018/jul/25/ai-artificial-intelligence-social-media-bots-wrong"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
