{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "date: '2023-05-04'\n",
    "categories:\n",
    " - natural-language-processing\n",
    " - deep-learning\n",
    " - openai\n",
    "title: Inferring with Text Prompts for Large Language Models\n",
    "description: Here we look at how to use Large Language Models such as ChatGPT to infer sentiment and topics from product reviews and news articles\n",
    "image: https://github.com/pranath/blog/raw/master/images/chatgpt1.jpg\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Large language models such as [ChatGPT](https://openai.com/blog/chatgpt) can generate text responses based on a given prompt or input. Writing prompts allow users to guide the language model's output by providing a specific context or topic for the response. This feature has many practical applications, such as generating creative writing prompts, assisting in content creation, and even aiding in customer service chatbots. \n",
    "\n",
    "For example, a writing prompt such as \"Write a short story about a time traveler who goes back to the medieval period\" could lead the language model to generate a variety of unique and creative responses. Additionally, prompts can be used to generate more specific and relevant responses for tasks such as language translation or summarization. In these cases, the prompt would provide information about the desired output, such as the language to be translated or the key points to be included in the summary. Overall, prompts provide a way to harness the power of large language models for a wide range of practical applications.\n",
    "\n",
    "However, creating effective prompts for large language models remains a significant challenge, as even prompts that seem similar can produce vastly different outputs. \n",
    "\n",
    "In my previous article, we looked at [how to use prompts to summarize text with a focus on specific topics](2023-05-03-creating-prompts-to-summarise-text-with-large-language-models.html).\n",
    "\n",
    "In this article, we will look at how to infer sentiment and topics from product reviews and news articles.\n",
    "\n",
    "\n",
    "## Setup\n",
    "\n",
    "### Load the API key and relevant Python libaries.\n",
    "\n",
    "First we need to load certain python libs and connect the OpenAi api.\n",
    "\n",
    "The OpenAi api library needs to be configured with an account's secret key, which is available on the [website](https://platform.openai.com/account/api-keys). \n",
    "\n",
    "You can either set it as the `OPENAI_API_KEY` environment variable before using the library:\n",
    " ```\n",
    " !export OPENAI_API_KEY='sk-...'\n",
    " ```\n",
    "\n",
    "Or, set `openai.api_key` to its value:\n",
    "\n",
    "```\n",
    "import openai\n",
    "openai.api_key = \"sk-...\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "openai.api_key  = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper function\n",
    "\n",
    "We will use OpenAI's `gpt-3.5-turbo` model and the [chat completions endpoint](https://platform.openai.com/docs/guides/chat). \n",
    "\n",
    "This helper function will make it easier to use prompts and look at the generated outputs:\n",
    "\n",
    "We'll simply define this helper function to make it easier to use prompts and examine outputs that are generated. *GetCompletion* is a function that just accepts a prompt and returns the completion for that prompt. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0, # this is the degree of randomness of the model's output\n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inferring using Large Language Models\n",
    "\n",
    "We will now examine inferring, which can be thought of as tasks where the model receives a text as input and conducts some sort of analysis. Therefore, this may be things like extracting names, extracting labels, or sort of interpreting the sentiment of a text. \n",
    "So if you want to extract a sentiment, positive or negative, with a piece of text, in the traditional machine learning approach, you'd have to collect the label data set, train the model, figure out how to deploy the model someplace in the cloud and make inferences. And while that has some potential for success, going through the process was simply time-consuming.\n",
    "\n",
    "And so for every task, such as sentiment versus extracting names versus something else, you have to train and deploy a separate model. A large language model has the benefit of allowing you to write a prompt for many of these tasks and have it begin producing results almost immediately. And that brings amazing speed in terms of application development. And you can also just use one model, one API, to handle many various tasks rather than trying to figure out how to train and deploy a bunch of different models. \n",
    "\n",
    "## Product review text\n",
    "\n",
    "So let's begin by using a lamp review as an example. We want to create a prompt to categorise this's sentiment. And if I want the system to inform me of the sentiment, I can simply write it down along with the customary delimiter, the review text, and other relevant information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lamp_review = \"\"\"\n",
    "Needed a nice lamp for my bedroom, and this one had \\\n",
    "additional storage and not too high of a price point. \\\n",
    "Got it fast.  The string to our lamp broke during the \\\n",
    "transit and the company happily sent over a new one. \\\n",
    "Came within a few days as well. It was easy to put \\\n",
    "together.  I had a missing part, so I contacted their \\\n",
    "support and they very quickly got me the missing piece! \\\n",
    "Lumina seems to me to be a great company that cares \\\n",
    "about their customers and products!!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment (positive/negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "What is the sentiment of the following product review, \n",
    "which is delimited with triple backticks?\n",
    "\n",
    "Review text: '''{lamp_review}'''\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {.callout-tip}\n",
    "## Output\n",
    "The sentiment of the product review is positive.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This indicates a good attitude towards the product, which actually seems about appropriate. Although this light isn't ideal, the buyer seems to be content with it.\n",
    "\n",
    "I can take this prompt and add another directive to have you respond with a single word, either positive or negative, if you wanted to be more succinct to make it easier for post-processing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "What is the sentiment of the following product review, \n",
    "which is delimited with triple backticks?\n",
    "\n",
    "Give your answer as a single word, either \"positive\" \\\n",
    "or \"negative\".\n",
    "\n",
    "Review text: '''{lamp_review}'''\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {.callout-tip}\n",
    "## Output\n",
    "positive\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify types of emotions\n",
    "\n",
    "Let's imagine we wish to list the emotions the author of the review is expressing, with a maximum of five items per list. \n",
    "Large language models can therefore be rather effective at identifying specific information inside a text. We're expressing our feelings in this instance, I believe. And knowing this might help you figure out what a certain product's customers believe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "Identify a list of emotions that the writer of the \\\n",
    "following review is expressing. Include no more than \\\n",
    "five items in the list. Format your answer as a list of \\\n",
    "lower-case words separated by commas.\n",
    "\n",
    "Review text: '''{lamp_review}'''\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {.callout-tip}\n",
    "## Output\n",
    "happy, satisfied, grateful, impressed, content\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify anger\n",
    "\n",
    "It's critical to know if a certain user is severely upset for many customer support organisations. As a result, you might be experiencing a different classification issue. Is the reviewer upset? \n",
    "\n",
    "Because if a person is truly upset, it can be worth paying extra attention to have a customer review, to have customer support or customer success reach out to determine what's wrong and make things right for the consumer. The client is not irate in this instance, I promise. Additionally, you can see that using supervised learning, there is no way I could have built all of these classifiers in a short period of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "Is the writer of the following review expressing anger?\\\n",
    "The review is delimited with triple backticks. \\\n",
    "Give your answer as either yes or no.\n",
    "\n",
    "Review text: '''{lamp_review}'''\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {.callout-tip}\n",
    "## Output\n",
    "No\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract product and company name from customer reviews\n",
    "\n",
    "Let's examine a different topic: getting more detailed information from customer reviews. \n",
    "\n",
    "Information extraction, then, is the area of NLP, or natural language processing, that has to do with taking a text and extracting specific information from it. The following things, the purchase date, and the name of the manufacturer are what I'm asking you to name in this prompt. Once more, if you're trying to summarise a lot of reviews from an online store, it might be helpful to identify the products, the manufacturer, the positive and negative feedback, and any trends in positive or negative sentiment for particular products or manufacturers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "Identify the following items from the review text: \n",
    "- Item purchased by reviewer\n",
    "- Company that made the item\n",
    "\n",
    "The review is delimited with triple backticks. \\\n",
    "Format your response as a JSON object with \\\n",
    "\"Item\" and \"Brand\" as the keys. \n",
    "If the information isn't present, use \"unknown\" \\\n",
    "as the value.\n",
    "Make your response as short as possible.\n",
    "  \n",
    "Review text: '''{lamp_review}'''\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {.callout-tip}\n",
    "## Output\n",
    "{\n",
    "  \"Item\": \"lamp\",\n",
    "  \"Brand\": \"Lumina\"\n",
    "}\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doing multiple tasks at once\n",
    "\n",
    "You saw how to create a prompt to identify the sentiment, determine whether someone is upset, and then extract the product and brand from the instances we looked at. \n",
    "A single prompt can actually be written to extract all of this information at once, as opposed to using three or four prompts and calling getCompletion repeatedly to extract the various fields one at a time.\n",
    "\n",
    "So, let's say we want to find the fine elements, extract sentiment, and then, here, tell it to structure the angry value as a, as a boolean value, which returns a JSON.\n",
    "The item was extracted as a lamp with additional storage instead of lamp, which seems good, but this method can be used to extract multiple fields from a piece of text with just one prompt where sentiment is positive, anger, and there are no quotes around false. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "Identify the following items from the review text: \n",
    "- Sentiment (positive or negative)\n",
    "- Is the reviewer expressing anger? (true or false)\n",
    "- Item purchased by reviewer\n",
    "- Company that made the item\n",
    "\n",
    "The review is delimited with triple backticks. \\\n",
    "Format your response as a JSON object with \\\n",
    "\"Sentiment\", \"Anger\", \"Item\" and \"Brand\" as the keys.\n",
    "If the information isn't present, use \"unknown\" \\\n",
    "as the value.\n",
    "Make your response as short as possible.\n",
    "Format the Anger value as a boolean.\n",
    "\n",
    "Review text: '''{lamp_review}'''\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {.callout-tip}\n",
    "## Output\n",
    "{\n",
    "  \"Sentiment\": \"positive\",\n",
    "  \"Anger\": false,\n",
    "  \"Item\": \"lamp with additional storage\",\n",
    "  \"Brand\": \"Lumina\"\n",
    "}\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inferring topics\n",
    "\n",
    "Inferring themes is a fantastic use for large language models. What is the subject matter of a lengthy passage of text? What subjects are covered? Here is a made-up newspaper story that describes how government employees feel about the organisation they work for. Therefore, the findings of the most recent government poll, were evaluated at NASA, which was a well-liked department with a high satisfaction rating.  With this prompt, we can ask an article like this one to identify five subjects that will be covered in the content that follows. We can format the response as a list with each item being one or two words long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "story = \"\"\"\n",
    "In a recent survey conducted by the government, \n",
    "public sector employees were asked to rate their level \n",
    "of satisfaction with the department they work at. \n",
    "The results revealed that NASA was the most popular \n",
    "department with a satisfaction rating of 95%.\n",
    "\n",
    "One NASA employee, John Smith, commented on the findings, \n",
    "stating, \"I'm not surprised that NASA came out on top. \n",
    "It's a great place to work with amazing people and \n",
    "incredible opportunities. I'm proud to be a part of \n",
    "such an innovative organization.\"\n",
    "\n",
    "The results were also welcomed by NASA's management team, \n",
    "with Director Tom Johnson stating, \"We are thrilled to \n",
    "hear that our employees are satisfied with their work at NASA. \n",
    "We have a talented and dedicated team who work tirelessly \n",
    "to achieve our goals, and it's fantastic to see that their \n",
    "hard work is paying off.\"\n",
    "\n",
    "The survey also revealed that the \n",
    "Social Security Administration had the lowest satisfaction \n",
    "rating, with only 45% of employees indicating they were \n",
    "satisfied with their job. The government has pledged to \n",
    "address the concerns raised by employees in the survey and \n",
    "work towards improving job satisfaction across all departments.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "Determine five topics that are being discussed in the \\\n",
    "following text, which is delimited by triple backticks.\n",
    "\n",
    "Make each item one or two words long. \n",
    "\n",
    "Format your response as a list of items separated by commas.\n",
    "\n",
    "Text sample: '''{story}'''\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {.callout-tip}\n",
    "## Output\n",
    "government survey, job satisfaction, NASA, Social Security Administration, employee concerns\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a news alert for certain topics\n",
    "\n",
    "If you have a collection of articles from which you have extracted the themes, you can utilise a large language model to assist you index the articles into several categories. So I will utilise a little different topic list. Let's imagine we own a news website or something, and these are the things we follow: NASA, local government, engineering, customer happiness, and the federal government. \n",
    "\n",
    "And let's say you want to determine which of these subjects are covered in a specific news item. So, I can use this prompt. \n",
    "\n",
    "Determine whether each item in the list of topics below is a topic in the text below, is what I'm going to say. \n",
    "Give each topic's response as a list of 0s and 1s. \n",
    "\n",
    "Therefore, the story text is the same as previously.  It concerns NASA. Local governments and engineering are unrelated, I would say. It concerns both the federal government and employee pleasure. Due to the lack of labelled training data, this approach is sometimes referred to as a \"zero shot\" learning algorithm in machine learning.  And it was able to detect which of these subjects are covered in that news item with simply a prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_list = [\n",
    "    \"nasa\", \"local government\", \"engineering\", \n",
    "    \"employee satisfaction\", \"federal government\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "Determine whether each item in the following list of \\\n",
    "topics is a topic in the text below, which\n",
    "is delimited with triple backticks.\n",
    "\n",
    "Give your answer as list with 0 or 1 for each topic.\\\n",
    "\n",
    "List of topics: {\", \".join(topic_list)}\n",
    "\n",
    "Text sample: '''{story}'''\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {.callout-tip}\n",
    "## Output\n",
    "nasa: 1\n",
    "local government: 0\n",
    "engineering: 0\n",
    "employee satisfaction: 1\n",
    "federal government: 1\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_dict = {i.split(': ')[0]: int(i.split(': ')[1]) for i in response.split(sep='\\n')}\n",
    "if topic_dict['nasa'] == 1:\n",
    "    print(\"ALERT: New NASA story!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {.callout-tip}\n",
    "## Output\n",
    "ALERT: New NASA story!\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So that's it for inference; in contrast to the days or even weeks it would have previously took an experienced machine learning engineer, you can now design a number of systems for inferring information from text in just a few minutes. \n",
    "\n",
    "I find it quite exciting, because prompting can now be used to quickly build and begin drawing conclusions on quite challenging natural language processing problems like these, both for experienced machine learning developers and for others who are more new to machine learning.\n",
    "\n",
    "## Acknowledgements\n",
    "\n",
    "I'd like to express my thanks to the wonderful [ChatGPT Prompt Engineering for Developers Course](https://www.deeplearning.ai/short-courses/chatgpt-prompt-engineering-for-developers/) by DeepLearning.ai and OpenAI - which i completed, and acknowledge the use of some images and other materials from the course in this article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
